researcher,title,year,venue,citations,authors,first_author,last_author,author_count,abstract,url
Yash Mehta,Recent Trends in Deep Learning Based Personality Detection,2020,Artificial Intelligence Review,389,"Yash Mehta, Navonil Majumder, Alexander Gelbukh, Erik Cambria",Yash Mehta,Erik Cambria,4,"Recently, the automatic prediction of personality traits has received a lot of attention. Specifically, personality trait prediction from multimodal data has emerged as a hot topic within the field of affective computing. In this paper, we review significant machine learning models which have been employed for personality detection, with an emphasis on deep learning-based methods. This review paper provides an overview of the most popular approaches to automated personality detection, various computational datasets, its industrial applications, and state-of-the-art machine learning models for personality detection with specific focus on multimodal approaches. Personality detection is a very broad and diverse topic: this survey only focuses on computational approaches and leaves out psychological studies on personality detection.",https://link.springer.com/article/10.1007/s10462-019-09770-z
Yash Mehta,Bottom-Up and Top-Down: Predicting Personality with Psycholinguistic and Language Model Features,2020,2020 IEEE International Conference on Data Mining (ICDM),144,"Yash Mehta, Samin Fatehi, Amirmohammad Kazameini, Clemens Stachl, Erik Cambria",Yash Mehta,Erik Cambria,5,"State-of-the-art personality prediction with text data mostly relies on bottom up, automated feature generation as part of the deep learning process. More traditional models rely on hand-crafted, theory-based text-feature categories. We propose a novel deep learning-based model which integrates traditional psycholinguistic features with language model embeddings to predict personality from the Essays dataset for Big-Five and Kaggle dataset for MBTI. With this approach we achieve state-of-the-art model performance. Additionally, we use interpretable machine learning to visualize and quantify the impact of various language features in the respective personality prediction models. We conclude with a discussion on the potential this work has for computational modeling and psychological science alike.",https://ieeexplore.ieee.org/abstract/document/9338428/
Yash Mehta,Personality Trait Detection Using Bagged SVM over BERT Word Embedding Ensembles,2020,ACL WiNLP Workshop,89,"Amirmohammad Kazameini, Samin Fatehi, Yash Mehta, Sauleh Eetemadi, Erik Cambria",Amirmohammad Kazameini,Erik Cambria,5,"Recently, the automatic prediction of personality traits has received increasing attention and has emerged as a hot topic within the field of affective computing. In this work, we present a novel deep learning-based approach for automated personality detection from text. We leverage state of the art advances in natural language understanding, namely the BERT language model to extract contextualized word embeddings from textual data for automated author personality detection. Our primary goal is to develop a computationally efficient, high-performance personality prediction model which can be easily used by a large number of people without access to huge computation resources. Our extensive experiments with this ideology in mind, led us to develop a novel model which feeds contextualized embeddings along with psycholinguistic features toa Bagged-SVM classifier for personality trait prediction. Our model outperforms the previous state of the art by 1.04% and, at the same time is significantly more computationally efficient to train. We report our results on the famous gold standard Essays dataset for personality detection.",https://arxiv.org/abs/2010.01309
Yash Mehta,Multitask learning for emotion and personality detection,2022,Neurocomputing,72,"Yang Li, Amirmohammad Kazameini, Yash Mehta, Erik Cambria",Yang Li,Erik Cambria,4,"In recent years, deep learning-based automated personality traits detection has received a lot of attention, especially now, due to the massive digital footprints of an individual. Moreover, many researchers have demonstrated that there is a strong link between personality traits and emotions. In this paper, we build on the known correlation between personality traits and emotional behaviors and propose a novel transferring based multitask learning framework that simultaneously predicts both of them. We also empirically evaluate and discuss different information-sharing mechanisms between the two tasks. To ensure the high quality of the learning process, we adopt a model-agnostic meta-learning-like framework for model optimization. Our computationally efficient multitask learning model achieves the state-of-the-art performance across multiple famous personality and emotion datasets, even outperforming …",https://www.sciencedirect.com/science/article/pii/S0925231222004180
Yash Mehta,NAS-Bench-Suite: NAS Evaluation is (Now) Surprisingly Easy,2022,International Conference on Learning Representations (ICLR),56,"Yash Mehta, Colin White, Arber Zela, Arjun Krishnakumar, Guri Zabergja, Shakiba Moradian, Mahmoud Safari, Kaicheng Yu, Frank Hutter",Yash Mehta,Frank Hutter,9,"The release of tabular benchmarks, such as NAS-Bench-101 and NAS-Bench-201, has significantly lowered the computational overhead for conducting scientific research in neural architecture search (NAS). Although they have been widely adopted and used to tune real-world NAS algorithms, these benchmarks are limited to small search spaces and focus solely on image classification. Recently, several new NAS benchmarks have been introduced that cover significantly larger search spaces over a wide range of tasks, including object detection, speech recognition, and natural language processing. However, substantial differences among these NAS benchmarks have so far prevented their widespread adoption, limiting researchers to using just a few benchmarks. In this work, we present an in-depth analysis of popular NAS algorithms and performance prediction methods across 25 different combinations of search spaces and datasets, finding that many conclusions drawn from a few NAS benchmarks do not generalize to other benchmarks. To help remedy this problem, we introduce NAS-Bench-Suite, a comprehensive and extensible collection of NAS benchmarks, accessible through a unified interface, created with the aim to facilitate reproducible, generalizable, and rapid NAS research. Our code is available at https://github.com/automl/naslib.",https://arxiv.org/abs/2201.13396
Yash Mehta,Towards Biologically Plausible Convolutional Networks,2021,Advances in Neural Information Processing Systems (NeurIPS),31,"Roman Pogodin, Yash Mehta, Timothy P Lillicrap, Peter E Latham",Roman Pogodin,Peter E Latham,4,"Convolutional networks are ubiquitous in deep learning. They are particularly useful for images, as they reduce the number of parameters, reduce training time, and increase accuracy. However, as a model of the brain they are seriously problematic, since they require weight sharing-something real neurons simply cannot do. Consequently, while neurons in the brain can be locally connected (one of the features of convolutional networks), they cannot be convolutional. Locally connected but non-convolutional networks, however, significantly underperform convolutional ones. This is troublesome for studies that use convolutional networks to explain activity in the visual system. Here we study plausible alternatives to weight sharing that aim at the same regularization principle, which is to make each neuron within a pool react similarly to identical inputs. The most natural way to do that is by showing the network multiple translations of the same image, akin to saccades in animal vision. However, this approach requires many translations, and doesn't remove the performance gap. We propose instead to add lateral connectivity to a locally connected network, and allow learning via Hebbian plasticity. This requires the network to pause occasionally for a sleep-like phase of"" weight sharing"". This method enables locally connected networks to achieve nearly convolutional performance on ImageNet and improves their fit to the ventral stream data, thus supporting convolutional networks as a model of the visual stream.",https://proceedings.neurips.cc/paper/2021/hash/746b02b6680562f44ad7526675bac026-Abstract.html
Yash Mehta,On the Stability and Scalability of Node Perturbation Learning,2022,,17,"Naoki Hiratani, Yash Mehta, Timothy Lillicrap, Peter Latham",Naoki Hiratani,Peter Latham,4,"To survive, animals must adapt synaptic weights based on external stimuli and rewards. And they must do so using local, biologically plausible, learning rules--a highly nontrivial constraint. One possible approach is to perturb neural activity (or use intrinsic, ongoing noise to perturb it), determine whether performance increases or decreases, and use that information to adjust the weights. This algorithm--known as node perturbation--has been shown to work on simple problems, but little is known about either its stability or its scalability with respect to network size. We investigate these issues both analytically, in deep linear networks, and numerically, in deep nonlinear ones. We show analytically that in deep linear networks with one hidden layer, both learning time and performance depend very weakly on hidden layer size. However, unlike stochastic gradient descent, when there is model mismatch between the student and teacher networks, node perturbation is always unstable. The instability is triggered by weight diffusion, which eventually leads to very large weights. This instability can be suppressed by weight normalization, at the cost of bias in the learning rule. We confirm numerically that a similar instability, and to a lesser extent scalability, exist in deep nonlinear networks trained on both a motor control task and image classification tasks. Our study highlights the limitations and potential of node perturbation as a biologically plausible learning rule in the brain.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/cf38eb1549024cce4b3d2c1bb87a6c27-Abstract-Conference.html
Yash Mehta,Model Based Inference of Synaptic Plasticity Rules,2024,Advances in Neural Information Processing Systems (NeurIPS),4,"Yash Mehta, Danil Tyulmankov, Adithya E Rajagopalan, Glenn C Turner, James E Fitzgerald, Jan Funke",Yash Mehta,Jan Funke,6,"Understanding learning through synaptic plasticity rules in the brain is a grand challenge for neuroscience. Here we introduce a novel computational framework for inferring plasticity rules from experimental data on neural activity trajectories and behavioral learning dynamics. Our methodology parameterizes the plasticity function to provide theoretical interpretability and facilitate gradient-based optimization. For instance, we use Taylor series expansions or multilayer perceptrons to approximate plasticity rules, and we adjust their parameters via gradient descent over entire trajectories to closely match observed neural activity and behavioral data. Notably, our approach can learn intricate rules that induce long nonlinear time-dependencies, such as those incorporating postsynaptic activity and current synaptic weights. We validate our method through simulations, accurately recovering established rules, like Oja's, as well as more complex hypothetical rules incorporating reward-modulated terms. We assess the resilience of our technique to noise and, as a tangible application, apply it to behavioral data from Drosophila during a probabilistic reward-learning experiment. Remarkably, we identify an active forgetting component of reward learning in flies that enhances the predictive accuracy of previous models. Overall, our modeling framework provides an exciting new avenue to elucidate the computational principles governing synaptic plasticity and learning in the brain.",https://www.biorxiv.org/content/10.1101/2023.12.11.571103.abstract
Yash Mehta,Future-generation personality prediction from digital footprints,2022,Future Generation Computer Systems,2,"Yash Mehta, Clemens Stachl, Konstantin Markov, Joseph T Yun, Björn W Schuller",Yash Mehta,Björn W Schuller,5,"Perceiving the personality of others is an intuitive task that humans perform on a daily basis. However, it is more difficult to formalize how this process happens exactly and it is particularly challenging to teach machines to do so. Personality traits are conceptualized as characteristic patterns of thoughts, feelings, and behaviors [1]. Personality traits have repeatedly been related to a wide range of important life outcomes at personal (e. g., well-being, psychopathology), interpersonal (e. g., relationship satisfaction), and social-institutional levels (e. g., occupational choices, job success)[2],[3]. Hence, knowing someones personality can be extremely informative to anticipate behaviors, thoughts, and feelings across different situations and to decide who to hire, what to recommend [4], to befriend, to marry, or to open a company with. Related, there has been a massive surge in the development of computational models …",https://www.sciencedirect.com/science/article/pii/S0167739X22002229
Yash Mehta,Exploring untrained neural network architectures for modeling higher visual cortex representations,2024,,0,"Yash Mehta, Atlas Kazemian, Colin Conwell, Michael F Bonner",Yash Mehta,Michael F Bonner,4,"Convolutional neural networks (CNNs) have been widely employed to model the visual cortex, with the prevailing view being that supervised training of these CNNs is crucial for achieving high representational similarity with the visual cortex. We investigate the extent to which untrained neural networks can align with visual features extracted by the brain solely based on the optimization of architectural parameters. Notably, we find that untrained neural networks employing pre-specified wavelets can achieve 95% of the performance of trained AlexNet in the occipital temporal cortex region on human fMRI data. Our results suggest that while supervised training is beneficial, it is not strictly necessary for achieving high brain scores in CNNs. This research opens up new avenues for exploring the relationship between artificial neural networks and the visual cortex, aiming to uncover the shared architectural principles of …",https://scholar.google.com/scholar?cluster=16414100221096213130&hl=en&oi=scholarr
David Ha,World models,2018,Advances in Neural Information Processing Systems 31 (NeurIPS 2018),2327,"David Ha, Jürgen Schmidhuber",David Ha,Jürgen Schmidhuber,2,"We explore building generative neural network models of popular reinforcement learning environments. Our world model can be trained quickly in an unsupervised manner to learn a compressed spatial and temporal representation of the environment. By using features extracted from the world model as inputs to an agent, we can train a very compact and simple policy that can solve the required task. We can even train our agent entirely inside of its own hallucinated dream generated by its world model, and transfer this policy back into the actual environment. An interactive version of this paper is available at https://worldmodels.github.io/",https://arxiv.org/abs/1803.10122
David Ha,Hypernetworks,2017,ICLR 2017,1835,"David Ha, Andrew M Dai, Quoc V Le",David Ha,Quoc V Le,3,"This work explores hypernetworks: an approach of using a one network, also known as a hypernetwork, to generate the weights for another network. Hypernetworks provide an abstraction that is similar to what is found in nature: the relationship between a genotype - the hypernetwork - and a phenotype - the main network. Though they are also reminiscent of HyperNEAT in evolution, our hypernetworks are trained end-to-end with backpropagation and thus are usually faster. The focus of this work is to make hypernetworks useful for deep convolutional networks and long recurrent networks, where hypernetworks can be viewed as relaxed form of weight-sharing across layers. Our main result is that hypernetworks can generate non-shared weights for LSTM and achieve near state-of-the-art results on a variety of sequence modelling tasks including character-level language modelling, handwriting generation and neural machine translation, challenging the weight-sharing paradigm for recurrent networks. Our results also show that hypernetworks applied to convolutional networks still achieve respectable results for image recognition tasks compared to state-of-the-art baseline models while requiring fewer learnable parameters.",https://arxiv.org/abs/1609.09106
David Ha,Learning Latent Dynamics for Planning from Pixels,2019,Thirty-sixth International Conference on Machine Learning,1682,"Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, James Davidson",Danijar Hafner,James Davidson,7,"Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. We propose the Deep Planning Network (PlaNet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. We approach this using a latent dynamics model with both deterministic and stochastic transition components. Moreover, we propose a multi-step variational inference objective that we name latent overshooting. Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. PlaNet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.",https://proceedings.mlr.press/v97/hafner19a.html
David Ha,A Neural Representation of Sketch Drawings,2017,Sixth International Conference on Learning Representations,1076,"David Ha, Douglas Eck",David Ha,Douglas Eck,2,"We present sketch-rnn, a recurrent neural network (RNN) able to construct stroke-based drawings of common objects. The model is trained on thousands of crude human-drawn images representing hundreds of classes. We outline a framework for conditional and unconditional sketch generation, and describe new robust training methods for generating coherent sketch drawings in a vector format.",https://arxiv.org/abs/1704.03477
David Ha,Pathnet: Evolution channels gradient descent in super neural networks,2017,arXiv preprint arXiv:1701.08734,1022,"Chrisantha Fernando, Dylan Banarse, Charles Blundell, Yori Zwols, David Ha, Andrei A Rusu, Alexander Pritzel, Daan Wierstra",Chrisantha Fernando,Daan Wierstra,8,"For artificial general intelligence (AGI) it would be efficient if multiple users trained the same giant neural network, permitting parameter reuse, without catastrophic forgetting. PathNet is a first step in this direction. It is a neural network algorithm that uses agents embedded in the neural network whose task is to discover which parts of the network to re-use for new tasks. Agents are pathways (views) through the network which determine the subset of parameters that are used and updated by the forwards and backwards passes of the backpropogation algorithm. During learning, a tournament selection genetic algorithm is used to select pathways through the neural network for replication and mutation. Pathway fitness is the performance of that pathway measured according to a cost function. We demonstrate successful transfer learning; fixing the parameters along a path learned on task A and re-evolving a new population of paths for task B, allows task B to be learned faster than it could be learned from scratch or after fine-tuning. Paths evolved on task B re-use parts of the optimal path evolved on task A. Positive transfer was demonstrated for binary MNIST, CIFAR, and SVHN supervised learning classification tasks, and a set of Atari and Labyrinth reinforcement learning tasks, suggesting PathNets have general applicability for neural network training. Finally, PathNet also significantly improves the robustness to hyperparameter choices of a parallel asynchronous reinforcement learning algorithm (A3C).",https://arxiv.org/abs/1701.08734
David Ha,Deep Learning for Classical Japanese Literature,2018,"Neural Information Processing Systems 2018, ML for Creativity Workshop",749,"Tarin Clanuwat, Mikel Bober-Irizar, Asanobu Kitamoto, Alex Lamb, Kazuaki Yamamoto, David Ha",Tarin Clanuwat,David Ha,6,"Much of machine learning research focuses on producing models which perform well on benchmark tasks, in turn improving our understanding of the challenges associated with those tasks. From the perspective of ML researchers, the content of the task itself is largely irrelevant, and thus there have increasingly been calls for benchmark tasks to more heavily focus on problems which are of social or cultural relevance. In this work, we introduce Kuzushiji-MNIST, a dataset which focuses on Kuzushiji (cursive Japanese), as well as two larger, more challenging datasets, Kuzushiji-49 and Kuzushiji-Kanji. Through these datasets, we wish to engage the machine learning community into the world of classical Japanese literature. Dataset available at https://github.com/rois-codh/kmnist",https://arxiv.org/abs/1812.01718
David Ha,Weight Agnostic Neural Networks,2019,Advances in Neural Information Processing Systems,335,"Adam Gaier, David Ha",Adam Gaier,David Ha,2,"Not all neural network architectures are created equal, some perform much better than others for certain tasks. But how important are the weight parameters of a neural network compared to its architecture? In this work, we question to what extent neural network architectures alone, without learning any weight parameters, can encode solutions for a given task. We propose a search method for neural network architectures that can already perform a task without any explicit weight training. To evaluate these networks, we populate the connections with a single shared weight parameter sampled from a uniform random distribution, and measure the expected performance. We demonstrate that our method can find minimal neural network architectures that can perform several reinforcement learning tasks without weight training. On a supervised learning domain, we find network architectures that achieve much higher than chance accuracy on MNIST using random weights.",https://proceedings.neurips.cc/paper/2019/hash/e98741479a7b998f88b8f8c9f0b6b6f1-Abstract.html
David Ha,Reinforcement Learning for Improving Agent Design,2019,Artificial life,168,David Ha,David Ha,David Ha,1,"In many reinforcement learning tasks, the goal is to learn a policy to manipulate an agent, whose design is fixed, to maximize some notion of cumulative reward. The design of the agent's physical structure is rarely optimized for the task at hand. In this work, we explore the possibility of learning a version of the agent's design that is better suited for its task, jointly with the policy. We propose an alteration to the popular OpenAI Gym framework, where we parameterize parts of an environment, and allow an agent to jointly learn to modify these environment parameters along with its policy. We demonstrate that an agent can learn a better structure of its body that is not only better suited for the task, but also facilitates policy learning. Joint learning of policy and structure may even uncover design principles that are useful for assisted-design applications.",https://direct.mit.edu/artl/article-abstract/25/4/352/93262
David Ha,Neuroevolution of Self-Interpretable Agents,2020,,139,"Yujin Tang, Duong Nguyen, David Ha",Yujin Tang,David Ha,3,"Inattentional blindness is the psychological phenomenon that causes one to miss things in plain sight. It is a consequence of the selective attention in perception that lets us remain focused on important parts of our world without distraction from irrelevant details. Motivated by selective attention, we study the properties of artificial agents that perceive the world through the lens of a self-attention bottleneck. By constraining access to only a small fraction of the visual input, we show that their policies are directly interpretable in pixel space. We find neuroevolution ideal for training self-attention architectures for vision-based reinforcement learning (RL) tasks, allowing us to incorporate modules that can include discrete, non-differentiable operations which are useful for our agent. We argue that self-attention has similar properties as indirect encoding, in the sense that large implicit weight matrices are generated from a …",https://dl.acm.org/doi/abs/10.1145/3377930.3389847
David Ha,A Learned Representation for Scalable Vector Graphics,2019,Proceedings of the IEEE/CVF International Conference on Computer Vision,126,"Raphael Gontijo Lopes, David Ha, Douglas Eck, Jonathon Shlens",Raphael Gontijo Lopes,Jonathon Shlens,4,"Dramatic advances in generative models have resulted in near photographic quality for artificially rendered faces, animals and other objects in the natural world. In spite of such advances, a higher level understanding of vision and imagery does not arise from exhaustively modeling an object, but instead identifying higher-level attributes that best summarize the aspects of an object. In this work we attempt to model the drawing process of fonts by building sequential generative models of vector graphics. This model has the benefit of providing a scale-invariant representation for imagery whose latent representation may be systematically manipulated and exploited to perform style propagation. We demonstrate these results on a large dataset of fonts crawled from the web and highlight how such a model captures the statistical dependencies and richness of this dataset. We envision that our model can find use as a tool for graphic designers to facilitate font design.",http://openaccess.thecvf.com/content_ICCV_2019/html/Lopes_A_Learned_Representation_for_Scalable_Vector_Graphics_ICCV_2019_paper.html
David Ha,Pommerman: A Multi-Agent Playground,2018,AAAI 2019 Workshop on Reinforcement Learning in Games,110,"Cinjon Resnick, Wes Eldridge, David Ha, Denny Britz, Jakob Foerster, Julian Togelius, Kyunghyun Cho, Joan Bruna",Cinjon Resnick,Joan Bruna,8,"We present Pommerman, a multi-agent environment based on the classic console game Bomberman. Pommerman consists of a set of scenarios, each having at least four players and containing both cooperative and competitive aspects. We believe that success in Pommerman will require a diverse set of tools and methods, including planning, opponent/teammate modeling, game theory, and communication, and consequently can serve well as a multi-agent benchmark. To date, we have already hosted one competition, and our next one will be featured in the NIPS 2018 competition track.",https://arxiv.org/abs/1809.07124
David Ha,Collective intelligence for deep learning: A survey of recent developments,2022,Collective Intelligence,92,"David Ha, Yujin Tang",David Ha,Yujin Tang,2,"In the past decade, we have witnessed the rise of deep learning to dominate the field of artificial intelligence. Advances in artificial neural networks alongside corresponding advances in hardware accelerators with large memory capacity, together with the availability of large datasets enabled practitioners to train and deploy sophisticated neural network models that achieve state-of-the-art performance on tasks across several fields spanning computer vision, natural language processing, and reinforcement learning. However, as these neural networks become bigger, more complex, and more widely used, fundamental problems with current deep learning models become more apparent. State-of-the-art deep learning models are known to suffer from issues that range from poor robustness, inability to adapt to novel task settings, to requiring rigid and inflexible configuration assumptions. Collective behavior, commonly …",https://journals.sagepub.com/doi/abs/10.1177/26339137221114874
David Ha,The Sensory Neuron as a Transformer: Permutation-Invariant Neural Networks for Reinforcement Learning,2021,Advances in Neural Information Processing Systems,84,"Yujin Tang, David Ha",Yujin Tang,David Ha,2,"In complex systems, we often observe complex global behavior emerge from a collection of agents interacting with each other in their environment, with each individual agent acting only on locally available information, without knowing the full picture. Such systems have inspired development of artificial intelligence algorithms in areas such as swarm optimization and cellular automata. Motivated by the emergence of collective behavior from complex cellular systems, we build systems that feed each sensory input from the environment into distinct, but identical neural networks, each with no fixed relationship with one another. We show that these sensory networks can be trained to integrate information received locally, and through communication via an attention mechanism, can collectively produce a globally coherent policy. Moreover, the system can still perform its task even if the ordering of its inputs is randomly permuted several times during an episode. These permutation invariant systems also display useful robustness and generalization properties that are broadly applicable. Interactive demo and videos of our results: https://attentionneuron. github. io",https://proceedings.neurips.cc/paper_files/paper/2021/hash/be3e9d3f7d70537357c67bb3f4086846-Abstract.html
David Ha,The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery,2024,arXiv preprint arXiv:2408.06292,81,"Chris Lu, Cong Lu, Robert Tjarko Lange, Jakob Foerster, Jeff Clune, David Ha",Chris Lu,David Ha,6,"One of the grand challenges of artificial general intelligence is developing agents capable of conducting scientific research and discovering new knowledge. While frontier models have already been used as aides to human scientists, e.g. for brainstorming ideas, writing code, or prediction tasks, they still conduct only a small part of the scientific process. This paper presents the first comprehensive framework for fully automatic scientific discovery, enabling frontier large language models to perform research independently and communicate their findings. We introduce The AI Scientist, which generates novel research ideas, writes code, executes experiments, visualizes results, describes its findings by writing a full scientific paper, and then runs a simulated review process for evaluation. In principle, this process can be repeated to iteratively develop ideas in an open-ended fashion, acting like the human scientific community. We demonstrate its versatility by applying it to three distinct subfields of machine learning: diffusion modeling, transformer-based language modeling, and learning dynamics. Each idea is implemented and developed into a full paper at a cost of less than $15 per paper. To evaluate the generated papers, we design and validate an automated reviewer, which we show achieves near-human performance in evaluating paper scores. The AI Scientist can produce papers that exceed the acceptance threshold at a top machine learning conference as judged by our automated reviewer. This approach signifies the beginning of a new era in scientific discovery in machine learning: bringing the transformative benefits of AI agents to the …",https://arxiv.org/abs/2408.06292
David Ha,Evolutionary optimization of model merging recipes,2024,arXiv preprint arXiv:2403.13187,69,"Takuya Akiba, Makoto Shing, Yujin Tang, Qi Sun, David Ha",Takuya Akiba,David Ha,5,"We present a novel application of evolutionary algorithms to automate the creation of powerful foundation models. While model merging has emerged as a promising approach for LLM development due to its cost-effectiveness, it currently relies on human intuition and domain knowledge, limiting its potential. Here, we propose an evolutionary approach that overcomes this limitation by automatically discovering effective combinations of diverse open-source models, harnessing their collective intelligence without requiring extensive additional training data or compute. Our approach operates in both parameter space and data flow space, allowing for optimization beyond just the weights of the individual models. This approach even facilitates cross-domain merging, generating models like a Japanese LLM with Math reasoning capabilities. Surprisingly, our Japanese Math LLM achieved state-of-the-art performance on a variety of established Japanese LLM benchmarks, even surpassing models with significantly more parameters, despite not being explicitly trained for such tasks. Furthermore, a culturally-aware Japanese VLM generated through our approach demonstrates its effectiveness in describing Japanese culture-specific content, outperforming previous Japanese VLMs. This work not only contributes new state-of-the-art models back to the open-source community, but also introduces a new paradigm for automated model composition, paving the way for exploring alternative, efficient approaches to foundation model development.",https://arxiv.org/abs/2403.13187
David Ha,Collabdraw: An environment for collaborative sketching with an artificial agent,2019,,58,"Judith E Fan, Monica Dinculescu, David Ha",Judith E Fan,David Ha,3,"Sketching is one of the most accessible techniques for communicating our ideas quickly and for collaborating in real time. Here we present a web-based environment for collaborative sketching of everyday visual concepts. We explore the integration of an artificial agent, instantiated as a recurrent neural network, who is both cooperative and responsive to actions performed by its human collaborator. To evaluate the quality of the sketches produced in this environment, we conducted an experimental user study and found that sketches produced collaboratively carried as much semantically relevant information as those produced by humans on their own. Further control analyses suggest that the semantic information in these sketches were indeed the product of collaboration, rather than attributable to the contributions of the human or the artificial agent alone. Taken together, our findings attest to the potential of …",https://dl.acm.org/doi/abs/10.1145/3325480.3326578
David Ha,Evojax: Hardware-accelerated neuroevolution,2022,,49,"Yujin Tang, Yingtao Tian, David Ha",Yujin Tang,David Ha,3,"Evolutionary computation has been shown to be a highly effective method for training neural networks, particularly when employed at scale on CPU clusters. Recent work have also showcased their effectiveness on hardware accelerators, such as GPUs, but so far such demonstrations are tailored for very specific tasks, limiting applicability to other domains. We present EvoJAX, a scalable, general purpose, hardware-accelerated neuroevolution toolkit. Building on top of the JAX library, our toolkit enables neuroevolution algorithms to work with neural networks running in parallel across multiple TPU/GPUs. EvoJAX achieves very high performance by implementing the evolution algorithm, neural network and task all in NumPy, which is compiled just-in-time to run on accelerators. We provide extensible examples of EvoJAX for a wide range of tasks, including supervised learning, reinforcement learning and generative …",https://dl.acm.org/doi/abs/10.1145/3520304.3528770
David Ha,Learning to Predict Without Looking Ahead: World Models Without Forward Prediction,2019,Advances in Neural Information Processing Systems,48,"Daniel Freeman, Luke Metz, David Ha",Daniel Freeman,David Ha,3,"Much of model-based reinforcement learning involves learning a model of an agent's world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware---eg, a brain---arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent. That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call observational dropout, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into learning a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment. Videos of our results available at https://learningtopredict. github. io/",https://proceedings.neurips.cc/paper_files/paper/2019/hash/15cf76466b97264765356fcc56d801d1-Abstract.html
David Ha,Modern evolution strategies for creativity: Fitting concrete images and abstract concepts,2022,,46,"Yingtao Tian, David Ha",Yingtao Tian,David Ha,2,"Evolutionary algorithms (ES) have been used in the digital art scene since the 1970s. A popular application of genetic algorithms is to optimize the procedural placement of vector graphic primitives to resemble a given painting. In recent years, deep learning-based approaches have also been proposed to generate procedural drawings, which can be optimized using gradient descent. In this work, we revisit the use of evolutionary algorithms for computational creativity. We find that modern ES algorithms, when tasked with the placement of shapes, offer large improvements in both quality and efficiency compared to traditional genetic algorithms, and even comparable to gradient-based methods. We demonstrate that ES is also well suited at optimizing the placement of shapes to fit the CLIP model, and can produce diverse, distinct geometric abstractions that are aligned with human interpretation of language.",https://link.springer.com/chapter/10.1007/978-3-031-03789-4_18
David Ha,Finding Game Levels with the Right Difficulty in a Few Trials through Intelligent Trial-and-Error,2020,2020 IEEE Conference on Games (CoG),40,"Miguel González-Duque, Rasmus Berg Palm, David Ha, Sebastian Risi",Miguel González-Duque,Sebastian Risi,4,"Methods for dynamic difficulty adjustment allow games to be tailored to particular players to maximize their engagement. However, current methods often only modify a limited set of game features such as the difficulty of the opponents, or the availability of resources. Other approaches, such as experience-driven Procedural Content Generation (PCG), can generate complete levels with desired properties such as levels that are neither too hard nor too easy, but require many iterations. This paper presents a method that can generate and search for complete levels with a specific target difficulty in only a few trials. This advance is enabled by through an Intelligent Trial-and-Error algorithm, originally developed to allow robots to adapt quickly. Our algorithm first creates a large variety of different levels that vary across predefined dimensions such as leniency or map coverage. The performance of an AI playing agent on …",https://ieeexplore.ieee.org/abstract/document/9231548/
David Ha,Evolving Stable Strategies,2017,blog.otoro.net,37,David Ha,David Ha,David Ha,1,"In the previous article, I have described a few evolution strategies (ES) algorithms that can optimise the parameters of a function without the need to explicitly calculate gradients. These algorithms can be applied to reinforcement learning (RL) problems to help find a suitable set of model parameters for a neural network agent. In this article, I will explore applying ES to some of these RL problems, and also highlight methods we can use to find policies that are more stable and robust.",https://blog.otoro.net/2017/11/12/evolving-stable-strategies/
David Ha,Evolving Modular Soft Robots without Explicit Inter-Module Communication Using Local Self-Attention,2022,Proceedings of the 2022 Genetic and Evolutionary Computation Conference,31,"Federico Pigozzi, Yujin Tang, Eric Medvet, David Ha",Federico Pigozzi,David Ha,4,"Modularity in robotics holds great potential. In principle, modular robots can be disassembled and reassembled in different robots, and possibly perform new tasks. Nevertheless, actually exploiting modularity is yet an unsolved problem: controllers usually rely on inter-module communication, a practical requirement that makes modules not perfectly interchangeable and thus limits their flexibility. Here, we focus on Voxel-based Soft Robots (VSRs), aggregations of mechanically identical elastic blocks. We use the same neural controller inside each voxel, but without any inter-voxel communication, hence enabling ideal conditions for modularity: modules are all equal and interchangeable. We optimize the parameters of the neural controller---shared among the voxels---by evolutionary computation. Crucially, we use a local self-attention mechanism inside the controller to overcome the absence of inter-module …",https://dl.acm.org/doi/abs/10.1145/3512290.3528762
David Ha,Scones: Towards Conversational Authoring of Sketches,2020,,30,"Forrest Huang, Eldon Schoop, David Ha, John Canny",Forrest Huang,John Canny,4,"Iteratively refining and critiquing sketches are crucial steps to developing effective designs. We introduce Scones, a mixed-initiative, machine-learning-driven system that enables users to iteratively author sketches from text instructions. Scones is a novel deep-learning-based system that iteratively generates scenes of sketched objects composed with semantic specifications from natural language. Scones exceeds state-of-the-art performance on a text-based scene modification task, and introduces a mask-conditioned sketching model that can generate sketches with poses specified by high-level scene information. In an exploratory user evaluation of Scones, participants reported enjoying an iterative drawing task with Scones, and suggested additional features for further applications. We believe Scones is an early step towards automated, intelligent systems that support human-in-the-loop applications for …",https://dl.acm.org/doi/abs/10.1145/3377325.3377485
David Ha,Experiments in handwriting with a neural network,2016,Distill,30,"Shan Carter, David Ha, Ian Johnson, Chris Olah",Shan Carter,Chris Olah,4,"Neural networks are an extremely successful approach to machine learning, but it’s tricky to understand why they behave the way they do. This has sparked a lot of interest and effort around trying to understand and visualize them, which we think is so far just scratching the surface of what is possible.In this article we will try to push forward in this direction by taking a generative model of handwriting 2 and visualizing it in a number of ways. The model is quite simple (so as to run well in the browser) so the generated output mostly produces gibberish letters and words (albeit, gibberish that look like real handwriting), but it is still useful for our purposes of exploring visualization techniques.",https://distill.pub/2016/handwriting/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue
David Ha,Learning via social awareness: improving sketch representations with facial feedback,2018,,27,"Natasha Jaques, Jesse Engel, David Ha, Fred Bertsch, Rosalind Picard, Douglas Eck",Natasha Jaques,Douglas Eck,6,"In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model.",https://openreview.net/forum?id=Bkyn3dJPG
David Ha,Learning to generalize with object-centric agents in the open world survival game crafter,2023,IEEE Transactions on Games,17,"Aleksandar Stanić, Yujin Tang, David Ha, Jürgen Schmidhuber",Aleksandar Stanić,Jürgen Schmidhuber,4,"Reinforcement learning agents must generalize beyond their training experience. Prior work has focused mostly on identical training and evaluation environments. Starting from the recently introduced  Crafter  benchmark, a 2-D open world survival game, we introduce a new set of environments suitable for evaluating some agent's ability to generalize on previously unseen (numbers of) objects and to adapt quickly (meta-learning). In  Crafter , the agents are evaluated by the number of unlocked achievements (such as collecting resources) when trained for 1 M steps. We show that current agents struggle to generalize, and introduce novel object-centric agents that improve over strong baselines. We also provide critical insights of general interest for future work on  Crafter  through several experiments. We show that careful hyperparameter tuning improves the PPO baseline agent by a large margin and that even …",https://ieeexplore.ieee.org/abstract/document/10125026/
David Ha,Slime Volleyball Gym Environment,2020,,17,David Ha,David Ha,David Ha,1,,https://scholar.google.com/scholar?cluster=6619471762065535994&hl=en&oi=scholarr
David Ha,Generating Large Images from Latent Vectors,2016,blog.otoro.net,17,David Ha,David Ha,David Ha,1,"BackgroundIn the previous post, we have explored the use of CPPNs to produce high resolution images containing some interesting random patterns. Since the input to the CPPN consist of the coordinates of a certain pixel, and the output is the colour for that coordinate, CPPNs can generate images of arbitrary resolution, limited by the machine’s memory. This feature gives CPPNs some fractal-like characteristics, because you can just zoom-in, or zoom-out of an image as much as you want, by just adjusting a set of scaled input coordinates of the desired view of the image. We also find that by randomising the weights of the CPPN, we see that we can generate many abstract patterns that may look aesthetically pleasing to some people. Also, if we fix the neural network architecture, and fix set of random weights, we can explore the space of images that the CPPN can produce by varying around the addition latent vector input into the network.",https://blog.otoro.net/2016/04/01/generating-large-images-from-latent-vectors/
David Ha,Multi-task neural networks with task-specific paths,2020,,11,"Daniel Pieter Wierstra, Chrisantha Thomas Fernando, Alexander Pritzel, Dylan Sunil Banarse, Charles Blundell, Andrei-Alexandru Rusu, Yori Zwols, David Ha",Daniel Pieter Wierstra,David Ha,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using multi-task neural networks. One of the methods includes receiving a first network input and data identifying a first machine learning task to be performed on the first network input; selecting a path through the plurality of layers in a super neural network that is specific to the first machine learning task, the path specifying, for each of the layers, a proper subset of the modular neural networks in the layer that are designated as active when performing the first machine learning task; and causing the super neural network to process the first network input using (i) for each layer, the modular neural networks in the layer that are designated as active by the selected path and (ii) the set of one or more output layers corresponding to the identified first machine learning task.",https://patents.google.com/patent/US10748065B2/en
David Ha,Sketchtransfer: A new dataset for exploring detail-invariance and the abstractions learned by deep networks,2020,Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision,10,"Alex Lamb, Sherjil Ozair, Vikas Verma, David Ha",Alex Lamb,David Ha,4,"Deep networks have achieved excellent results in perceptual tasks, yet their ability to generalize to variations not seen during training has come under increasing scrutiny. In this work we focus on their ability to have invariance towards the presence or absence of details. For example, humans are able to watch cartoons, which are missing many visual details, without being explicitly trained to do so. As another example, 3D rendering software is a relatively recent development, yet people are able to understand such rendered scenes even though they are missing details (consider a film like Toy Story). This capability goes beyond visual data: humans are easily able to recognize isolated melodies from musical pieces when heard for the first time, even if the only piece they've listened to previously is from an orchestra. Thus the failure of machine learning algorithms to do this indicates a significant gap in generalization between human abilities and the abilities of deep networks. We propose a dataset that will make it easier to study the detail-invariance problem concretely. We produce a concrete task for this: SketchTransfer, and we show that state-of-the-art domain transfer algorithms still struggle with this task. The state-of-the-art technique which achieves over 95% on MNIST\xrightarrow SVHN transfer only achieves 59% accuracy on the SketchTransfer task, which is much better than random (11% accuracy) but falls short of the 87% accuracy of a classifier trained directly on labeled sketches. This indicates that this task is approachable with today's best methods but has substantial room for improvement.",http://openaccess.thecvf.com/content_WACV_2020/html/Lamb_SketchTransfer_A_New_Dataset_for_Exploring_Detail-Invariance_and_the_Abstractions_WACV_2020_paper.html
David Ha,Paper cubes: evolving 3D characters in augmented reality using recurrent neural networks,2017,"Neural Information Processing Systems 2017, ML for Creativity Workshop",10,"Anna Fusté, Judith Amores, David Ha, Jonas Jongejan, Amit Pitaru",Anna Fusté,Amit Pitaru,5,"Paper Cubes is a DIY Augmented Reality (AR) Platform that uses paper cube 1 patterns and an AR application to teach computational concepts such as Neural 2 Networks in a simple and engaging manner. We present an AR representation 3 of a Recurrent Neural Network in the form of stick figures that move in the 4 user’s physical space and evolve over time. We argue that using Recurrent Neural 5 Networks to drive agents in AR and in real-time can potentially help to generate 6 more interactive and engaging storytelling, gaming and learning experiences. 7",https://nips2017creativity.github.io/doc/Paper_Cubes.pdf
David Ha,Recurrent net dreams up fake chinese characters in vector format with tensorflow,2015,,8,David Ha,David Ha,David Ha,1,"Update June 2018: An interactive browser demo is now available online: otoro. net/kanji-rnn. This demo uses the more recent Sketch-RNN model (Javascript, TensorFlow), trained on a more fine-tuned dataset.",https://blog.otoro.net/2015/12/28/recurrent-net-dreams-up-fake-chinese-characters-in-vector-format-with-tensorflow/
David Ha,Neuroevolution for deep reinforcement learning problems,2020,,7,David Ha,David Ha,David Ha,1,"1. Calculate the fitness score of each candidate solution in generation. 2. Isolates the best 25% of the population in generation, in purple. 3. Using only the best solutions, and using the mean of the current generation (the green dot), calculate the covariance matrix of the next generation. 4. Sample a new set of candidate solutions using the updated mean and covariance matrix.",https://dl.acm.org/doi/pdf/10.1145/3377929.3389859
David Ha,Generating parameter values for recurrent neural networks,2021,,6,"Andrew M Dai, Quoc V Le, David Ha",Andrew M Dai,David Ha,3,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing inputs using recurrent neural networks. One of the systems includes a main recurrent neural network comprising one or more recurrent neural network layers and a respective hyper recurrent neural network corresponding to each of the one or more recurrent neural network layers, wherein each hyper recurrent neural network is configured to, at each of a plurality of time steps: process the layer input at the time step to the corresponding recurrent neural network layer, the current layer hidden state of the corresponding recurrent neural network layer, and a current hypernetwork hidden state of the hyper recurrent neural network to generate an updated hypernetwork hidden state.",https://patents.google.com/patent/US11164066B1/en
David Ha,Sketch-Based Creativity Support Tools Using Deep Learning,2021,Artificial Intelligence for Human Computer Interaction: A Modern Approach,5,"Forrest Huang, Eldon Schoop, David Ha, Jeffrey Nichols, John Canny",Forrest Huang,John Canny,5,"Sketching is a natural and effective visual communication medium commonly used in creative processes. Recent developments in deep-learning models drastically improved machines’ ability in understanding and generating visual content. An exciting area of development explores deep-learning approaches used to model human sketches, opening opportunities for creative applications. This chapter describes three fundamental steps in developing deep-learning-driven creativity support tools that consume and generate sketches: (1) a data collection effort that generated a new paired dataset between sketches and mobile user interfaces; (2) a sketch-based user interface retrieval system adapted from state-of-the-art computer vision techniques; and, (3) a conversational sketching system that supports the novel interaction of a natural-language-based sketch/critique authoring process. In this chapter, we …",https://link.springer.com/chapter/10.1007/978-3-030-82681-9_12
David Ha,Teaching machines to draw,2017,Article. Retrieved December,2,David Ha,David Ha,David Ha,1,"Teaching Machines to Draw Jump to Content Research Research Who we are Back to Who we 
are menu Defining the technology of today and tomorrow. Philosophy We strive to create an 
environment conducive to many different types of research across many different time scales 
and levels of risk. Learn more about our Philosophy Philosophy People Our researchers drive 
advancements in computer science through both fundamental and applied research. Learn 
more about our People People Teams Our research teams have the opportunity to impact 
technology used by billions of people every day. Learn more about our Teams Teams 
Research areas Back to Research areas menu AI/ML Foundations & Capabilities Machine 
Intelligence Machine Perception Machine Translation Natural Language Processing Speech 
Processing AI/ML Foundations & Capabilities Back to AI/ML Foundations & Capabilities menu …",http://research.google/pubs/teaching-machines-to-draw/
David Ha,Automating the Search for Artificial Life with Foundation Models,2024,arXiv preprint arXiv:2412.17799,1,"Akarsh Kumar, Chris Lu, Louis Kirsch, Yujin Tang, Kenneth O Stanley, Phillip Isola, David Ha",Akarsh Kumar,David Ha,7,"With the recent Nobel Prize awarded for radical advances in protein discovery, foundation models (FMs) for exploring large combinatorial spaces promise to revolutionize many scientific fields. Artificial Life (ALife) has not yet integrated FMs, thus presenting a major opportunity for the field to alleviate the historical burden of relying chiefly on manual design and trial-and-error to discover the configurations of lifelike simulations. This paper presents, for the first time, a successful realization of this opportunity using vision-language FMs. The proposed approach, called Automated Search for Artificial Life (ASAL), (1) finds simulations that produce target phenomena, (2) discovers simulations that generate temporally open-ended novelty, and (3) illuminates an entire space of interestingly diverse simulations. Because of the generality of FMs, ASAL works effectively across a diverse range of ALife substrates including Boids, Particle Life, Game of Life, Lenia, and Neural Cellular Automata. A major result highlighting the potential of this technique is the discovery of previously unseen Lenia and Boids lifeforms, as well as cellular automata that are open-ended like Conway's Game of Life. Additionally, the use of FMs allows for the quantification of previously qualitative phenomena in a human-aligned way. This new paradigm promises to accelerate ALife research beyond what is possible through human ingenuity alone.",https://arxiv.org/abs/2412.17799
David Ha,Simultaneous Multiple-Prompt Guided Generation Using Differentiable Optimal Transport,2022,arXiv preprint arXiv:2204.08472,1,"Yingtao Tian, Marco Cuturi, David Ha",Yingtao Tian,David Ha,3,"Recent advances in deep learning, such as powerful generative models and joint text-image embeddings, have provided the computational creativity community with new tools, opening new perspectives for artistic pursuits. Text-to-image synthesis approaches that operate by generating images from text cues provide a case in point. These images are generated with a latent vector that is progressively refined to agree with text cues. To do so, patches are sampled within the generated image, and compared with the text prompts in the common text-image embedding space; The latent vector is then updated, using gradient descent, to reduce the mean (average) distance between these patches and text cues. While this approach provides artists with ample freedom to customize the overall appearance of images, through their choice in generative models, the reliance on a simple criterion (mean of distances) often causes mode collapse: The entire image is drawn to the average of all text cues, thereby losing their diversity. To address this issue, we propose using matching techniques found in the optimal transport (OT) literature, resulting in images that are able to reflect faithfully a wide diversity of prompts. We provide numerous illustrations showing that OT avoids some of the pitfalls arising from estimating vectors with mean distances, and demonstrate the capacity of our proposed method to perform better in experiments, qualitatively and quantitatively.",https://arxiv.org/abs/2204.08472
David Ha,Neural network evolution playground with backprop NEAT,2016,,1,David Ha,David Ha,David Ha,1,"A few weeks ago, Google released a Web Demo called TensorFlow Playground. If you haven’t played with it yet, I do encourage you to do so, as it is a really well designed web demo displaying the training progress of how a neural network handles a simple classification problem with a few dummy datasets. You get to customise many aspects of the network, such as the number of layers, neurons per layer and its activation function, initial input features, and so on.One of the things that interested me was the feedback from users of that demo. People started experimenting with different neural network configurations, such as how many neural network layers are actually needed to fit a certain data set, or what initial features should be used for another data set. Which activation functions work better for which dataset?",https://blog.otoro.net/2016/05/07/backprop-neat/
David Ha,Generating parameter values for recurrent neural networks,2024,,0,"Andrew M Dai, Quoc V Le, David Ha",Andrew M Dai,David Ha,3,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing inputs using recurrent neural networks. One of the systems includes a main recurrent neural network comprising one or more recurrent neural network layers and a respective hyper recurrent neural network corresponding to each of the one or more recurrent neural network layers, wherein each hyper recurrent neural network is configured to, at each of a plurality of time steps: process the layer input at the time step to the corresponding recurrent neural network layer, the current layer hidden state of the corresponding recurrent neural network layer, and a current hypernetwork hidden state of the hyper recurrent neural network to generate an updated hypernetwork hidden state.",https://patents.google.com/patent/US11900235B1/en
David Ha,Multi-task neural networks with task-specific paths,2024,,0,"Daniel Pieter Wierstra, Chrisantha Thomas Fernando, Alexander Pritzel, Dylan Sunil Banarse, Charles Blundell, Andrei-Alexandru Rusu, Yori Zwols, David Ha",Daniel Pieter Wierstra,David Ha,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using multi-task neural networks. One of the methods includes receiving a first network input and data identifying a first machine learning task to be performed on the first network input; selecting a path through the plurality of layers in a super neural network that is specific to the first machine learning task, the path specifying, for each of the layers, a proper subset of the modular neural networks in the layer that are designated as active when performing the first machine learning task; and causing the super neural network to process the first network input using (i) for each layer, the modular neural networks in the layer that are designated as active by the selected path and (ii) the set of one or more output layers corresponding to the identified first machine learning task.",https://patents.google.com/patent/US20240046106A1/en
David Ha,Multi-task neural networks with task-specific paths,2023,,0,"Daniel Pieter Wierstra, Chrisantha Thomas Fernando, Alexander Pritzel, Dylan Sunil Banarse, Charles Blundell, Andrei-Alexandru Rusu, Yori Zwols, David Ha",Daniel Pieter Wierstra,David Ha,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using multi-task neural networks. One of the methods includes receiving a first network input and data identifying a first machine learning task to be performed on the first network input; selecting a path through the plurality of layers in a super neural network that is specific to the first machine learning task, the path specifying, for each of the layers, a proper subset of the modular neural networks in the layer that are designated as active when performing the first machine learning task; and causing the super neural network to process the first network input using (i) for each layer, the modular neural networks in the layer that are designated as active by the selected path and (ii) the set of one or more output layers corresponding to the identified first machine learning task.",https://patents.google.com/patent/US11790238B2/en
David Ha,Permutation-Invariant Neural Networks for Reinforcement Learning,2021,,0,David Ha,David Ha,David Ha,1,"MethodOur approach takes observations from the environment at each time-step and feeds each element of the observation into distinct, but identical neural networks (called “sensory neurons”), each with no fixed relationship with one another. Each sensory neuron integrates over time information from only their particular sensory input channel. Because each sensory neuron receives only a small part of the full picture, they need to self-organize through communication in order for a global coherent behavior to emerge.",https://blog.otoro.net/2021/11/18/attentionneuron/
David Ha,World Models and Attention for Reinforcement Learning,2021,ALIFE 2021: The 2021 Conference on Artificial Life,0,David Ha,David Ha,David Ha,1,"Consciousness and the concept of internal mental models are foundational topics in neuroscience and psychology. Yet, we do not understand them well enough to engineer artificial lifeforms that are conscious. In this talk, I will be discussing a line of work on developing “world models” for artificial agents. Such world models construct an abstract representation of the agent’s world that helps it navigate in its environment. We will be discussing the use of world models and attention as a form of bottleneck for an artificial agent, connecting this line of work with ideas and techniques from computational evolution and artificial life. The goal of the talk is to encourage the development of artificial life that incorporates a form of internal mental model, which will be a stepping stone for creating conscious machines.",https://direct.mit.edu/isal/proceedings-abstract/isal2021/33/102973
David Ha,Scones,2020,Proceedings of the 25th International Conference on Intelligent User Interfaces,0,"Forrest Huang, Eldon Schoop, David Ha, John Canny",Forrest Huang,John Canny,4,"Scones | CiNii Research CiNii 国立情報学研究所 学術情報ナビゲータ[サイニィ] 詳細へ移動 検索
フォームへ移動 論文・データをさがす 大学図書館の本をさがす 日本の博士論文をさがす English 
検索 タイトル 人物/団体名 所属機関 ISSN DOI 期間 ~ 本文リンク 本文リンクあり データソース JaLC 
IRDB Crossref DataCite NDL NDL-Digital RUDA JDCat NINJAL CiNii Articles CiNii Books 
CiNii Dissertations DBpedia Nikkei BP KAKEN Integbio MDR PubMed LSDB Archive 公共データ
カタログ ムーンショット型研究開発事業 すべて 研究データ 論文 本 博士論文 プロジェクト [2023年
10月31日掲載]CiNii Dissertations及びCiNii BooksのCiNii Researchへの統合について 新「国立
国会図書館サーチ」公開によるCiNiiサービスへの影響について CiNiiのサービスに関するアンケート
を実施中です(期間:2024年1月19日(金)から2024年2月18日(日)まで) Scones DOI Web Site 被
引用文献1件 Forrest Huang University of California Eldon Schoop University of California …",https://cir.nii.ac.jp/crid/1360298765166708736
David Ha,The Frog of CIFAR 10,2016,,0,David Ha,David Ha,David Ha,1,"In the previous post, we constructed a generative model that can draw MNIST digits at a very high image resolution, using a latent space vector representation of images. The generator network uses the CPPN model to produce images of any specified resolution. Now using the same model from last time, we will try to apply it naively to train on the CIFAR-10 dataset.There is still a lot of work to be done, because the current model is nowhere able to fit a large space of possible colour images, but I thought it would be interesting to see what we can generate out of the model as is. Currently, the model tends to draw a few states of images only, so the encoding function of the VAE will not work well, because there is too much variety in the set of training images for this model to handle.",https://blog.otoro.net/2016/04/06/the-frog-of-cifar-10/
David Ha,HyperNetworks (Blog Post),2016,,0,David Ha,David Ha,David Ha,1,"HyperNetworks (Blog Post) Jump to Content Research Research Who we are Back to Who we 
are menu Defining the technology of today and tomorrow. Philosophy We strive to create an 
environment conducive to many different types of research across many different time scales 
and levels of risk. Learn more about our Philosophy Philosophy People Our researchers drive 
advancements in computer science through both fundamental and applied research. Learn 
more about our People People Teams Our research teams have the opportunity to impact 
technology used by billions of people every day. Learn more about our Teams Teams 
Research areas Back to Research areas menu AI/ML Foundations & Capabilities Machine 
Intelligence Machine Perception Machine Translation Natural Language Processing Speech 
Processing AI/ML Foundations & Capabilities Back to AI/ML Foundations & Capabilities menu …",http://research.google/pubs/hypernetworks-blog-post/
David Ha,creatures avoiding planks,2015,,0,David Ha,David Ha,David Ha,1,"Recently I came across a video of a simulation that demonstrates the use of evolutionary techniques to train agents to avoid moving obstacles. The methodology used seems to employ a variation of the NEAT algorithm used to evolve the topology of neural networks so that it can perform certain tasks correctly. It was written to be used in the Unity 5 game engine to be incorporated to general game AIs which interested me.The results are really cool and the dynamics seemed quite elegant, so I wanted to try to implement a similar demo in javascript that can run inside a browser session. After playing around with a basic implementation, I found out that for obstacle avoiding problems, it turns out that a very simple neural network can be used effectively, and that even a fully connected neural network can be overkill. I also realised in the end that that even a simple perceptron-like network works quite well, and that hidden units may not add much advantage in the previously mentioned obstacle avoiding demo.",https://blog.otoro.net/2015/05/07/creatures-avoiding-planks/
David Ha,Tutorial Agenda,,,0,David Ha,David Ha,David Ha,1,"1. Calculate the fitness score of each candidate solution in generation. 2. Isolates the best 25% of the population in generation, in purple. 3. Using only the best solutions, and using the mean of the current generation (the green dot), calculate the covariance matrix of the next generation. 4. Sample a new set of candidate solutions using the updated mean and covariance matrix.",https://pdfs.semanticscholar.org/5da4/50ba1088af8948e8ba7e3bac57e04f94d7ee.pdf
David Ha,LEARNING VIA SOCIAL AWARENESS: IMPROVING SKETCH REPRESENTATIONS WITH FACIAL FEEDBACK,,,0,"Natasha Jaques12, Jesse Engel, David Ha, Fred Bertsch, Rosalind Picard, Douglas Eck",Natasha Jaques12,Douglas Eck,6,"In the quest towards general artificial intelligence (AI), researchers have explored developing loss functions that act as intrinsic motivators in the absence of external rewards. This paper argues that such research has overlooked an important and useful intrinsic motivator: social interaction. We posit that making an AI agent aware of implicit social feedback from humans can allow for faster learning of more generalizable and useful representations, and could potentially impact AI safety. We collect social feedback in the form of facial expression reactions to samples from Sketch RNN, an LSTM-based variational autoencoder (VAE) designed to produce sketch drawings. We use a Latent Constraints GAN (LC-GAN) to learn from the facial feedback of a small group of viewers, and then show in an independent evaluation with 76 users that this model produced sketches that lead to significantly more positive facial expressions. Thus, we establish that implicit social feedback can improve the output of a deep learning model.",https://scholar.google.com/scholar?cluster=2862415316798621036&hl=en&oi=scholarr
Jan Funke,Large Scale Image Segmentation with Structured Loss based Deep Learning for Connectome Reconstruction,2017,arXiv preprint arXiv:1709.02974,251,"Jan Funke, Fabian David Tschopp, William Grisaitis, Arlo Sheridan, Chandan Singh, Stephan Saalfeld, Srinivas C Turaga",Jan Funke,Srinivas C Turaga,7,"We present a method combining affinity prediction with region agglomeration, which improves significantly upon the state of the art of neuron segmentation from electron microscopy (EM) in accuracy and scalability. Our method consists of a 3D U-Net, trained to predict affinities between voxels, followed by iterative region agglomeration. We train using a structured loss based on Malis, encouraging topologically correct segmentations obtained from affinity thresholding. Our extension consists of two parts: First, we present a quasi-linear method to compute the loss gradient, improving over the original quadratic algorithm. Second, we compute the gradient in two separate passes to avoid spurious gradient contributions in early training stages. Our predictions are accurate enough that simple learning-free percentile-based agglomeration outperforms more involved methods used earlier on inferior predictions. We …",https://ieeexplore.ieee.org/abstract/document/8364622/
Jan Funke,Reconstruction of motor control circuits in adult Drosophila using automated transmission electron microscopy,2021,Cell,216,"Jasper S Phelps, David Grant Colburn Hildebrand, Brett J Graham, Aaron T Kuan, Logan A Thomas, Tri M Nguyen, Julia Buhmann, Anthony W Azevedo, Anne Sustar, Sweta Agrawal, Mingguan Liu, Brendan L Shanny, Jan Funke, John C Tuthill, Wei-Chung Allen Lee",Jasper S Phelps,Wei-Chung Allen Lee,15,"To investigate circuit mechanisms underlying locomotor behavior, we used serial-section electron microscopy (EM) to acquire a synapse-resolution dataset containing the ventral nerve cord (VNC) of an adult female Drosophila melanogaster. To generate this dataset, we developed GridTape, a technology that combines automated serial-section collection with automated high-throughput transmission EM. Using this dataset, we studied neuronal networks that control leg and wing movements by reconstructing all 507 motor neurons that control the limbs. We show that a specific class of leg sensory neurons synapses directly onto motor neurons with the largest-caliber axons on both sides of the body, representing a unique pathway for fast limb control. We provide open access to the dataset and reconstructions registered to a standard atlas to permit matching of cells between EM and light microscopy data. We also …",https://www.cell.com/cell/fulltext/S0092-8674(20)31683-4?uuid=uuid%3A914d0252-0615-4494-9026-ada0f50d78dd
Jan Funke,Whole-cell organelle segmentation in volume electron microscopy,2021,Nature,207,"Larissa Heinrich, Davis Bennett, David Ackerman, Woohyun Park, John Bogovic, Nils Eckstein, Alyson Petruncio, Jody Clements, Song Pang, C Shan Xu, Jan Funke, Wyatt Korff, Harald F Hess, Jennifer Lippincott-Schwartz, Stephan Saalfeld, Aubrey V Weigel, COSEM Project Team Ali Riasat 1 Arruda Rebecca 1 Bahtra Rohit 1 Nguyen Destiny 1",Larissa Heinrich,COSEM Project Team Ali Riasat 1 Arruda Rebecca 1 Bahtra Rohit 1 Nguyen Destiny 1,17,"Cells contain hundreds of organelles and macromolecular assemblies. Obtaining a complete understanding of their intricate organization requires the nanometre-level, three-dimensional reconstruction of whole cells, which is only feasible with robust and scalable automatic methods. Here, to support the development of such methods, we annotated up to 35 different cellular organelle classes—ranging from endoplasmic reticulum to microtubules to ribosomes—in diverse sample volumes from multiple cell types imaged at a near-isotropic resolution of 4 nm per voxel with focused ion beam scanning electron microscopy (FIB-SEM). We trained deep learning architectures to segment these structures in 4 nm and 8 nm per voxel FIB-SEM volumes, validated their performance and showed that automatic reconstructions can be used to directly quantify previously inaccessible metrics including spatial interactions …",https://www.nature.com/articles/s41586-021-03977-3
Jan Funke,Neuronal wiring diagram of an adult brain,2024,Nature,173,"Sven Dorkenwald, Arie Matsliah, Amy R Sterling, Philipp Schlegel, Szi-Chieh Yu, Claire E McKellar, Albert Lin, Marta Costa, Katharina Eichler, Yijie Yin, Will Silversmith, Casey Schneider-Mizell, Chris S Jordan, Derrick Brittain, Akhilesh Halageri, Kai Kuehner, Oluwaseun Ogedengbe, Ryan Morey, Jay Gager, Krzysztof Kruk, Eric Perlman, Runzhe Yang, David Deutsch, Doug Bland, Marissa Sorek, Ran Lu, Thomas Macrina, Kisuk Lee, J Alexander Bae, Shang Mu, Barak Nehoran, Eric Mitchell, Sergiy Popovych, Jingpeng Wu, Zhen Jia, Manuel A Castro, Nico Kemnitz, Dodam Ih, Alexander Shakeel Bates, Nils Eckstein, Jan Funke, Forrest Collman, Davi D Bock, Gregory SXE Jefferis, H Sebastian Seung, Mala Murthy",Sven Dorkenwald,Mala Murthy,46,"Connections between neurons can be mapped by acquiring and analysing electron microscopic brain images. In recent years, this approach has been applied to chunks of brains to reconstruct local connectivity maps that are highly informative, , , , –, but nevertheless inadequate for understanding brain function more globally. Here we present a neuronal wiring diagram of a whole brain containing 5 × 107 chemical synapses between 139,255 neurons reconstructed from an adult female Drosophila melanogaster,. The resource also incorporates annotations of cell classes and types, nerves, hemilineages and predictions of neurotransmitter identities, –. Data products are available for download, programmatic access and interactive browsing and have been made interoperable with other fly data resources. We derive a projectome—a map of projections between regions—from the connectome and report on tracing …",https://www.nature.com/articles/s41586-024-07558-y
Jan Funke,Automatic detection of synaptic partners in a whole-brain Drosophila electron microscopy data set,2021,Nature methods,135,"Julia Buhmann, Arlo Sheridan, Caroline Malin-Mayor, Philipp Schlegel, Stephan Gerhard, Tom Kazimiers, Renate Krause, Tri M Nguyen, Larissa Heinrich, Wei-Chung Allen Lee, Rachel Wilson, Stephan Saalfeld, Gregory SXE Jefferis, Davi D Bock, Srinivas C Turaga, Matthew Cook, Jan Funke",Julia Buhmann,Jan Funke,17,"We develop an automatic method for synaptic partner identification in insect brains and use it to predict synaptic partners in a whole-brain electron microscopy dataset of the fruit fly. The predictions can be used to infer a connectivity graph with high accuracy, thus allowing fast identification of neural pathways. To facilitate circuit reconstruction using our results, we develop CIRCUITMAP, a user interface add-on for the circuit annotation tool CATMAID.",https://www.nature.com/articles/s41592-021-01183-7
Jan Funke,Dense neuronal reconstruction through X-ray holographic nano-tomography,2020,Biophysical Journal,134,Aaron T Kuan,Aaron T Kuan,Aaron T Kuan,1,"1416-Pos Modulation of Human Stem Cell Derived Neuron Activity through Addition of an External Conductance using Dynamic Clamp Brian K. Panama1, Leigh Korbel1, Brandon Franks1, Christine Hickey2, Glenna Bett2, Randall L. Rasmusson2, Mark W. Nowak1. 1Cytocybernetics, Buffalo, NY, USA, 2Dept Physiology and Biophysics, State Univ New York Buffalo, Buffalo, NY, USA. Human stem-cell derived (hiPSC) neurons are a model system for studying the electrophysiological properties of neurons. HiPSC neurons, however, display depolarized resting membrane potentials (RMPs) due to insufficient expression of background K þ currents. Using a real-time dynamic clamp system, we have previously demonstrated with iCell hiPSC GABA neurons that electronic expression of K þ currents allows RMP tuning to physiological levels (À55 to À65 mV) and recording of stable action potentials (APs). In the present …",https://www.cell.com/biophysj/fulltext/S0006-3495(19)32580-9
Jan Funke,Neurotransmitter classification from electron microscopy images at synaptic sites in Drosophila melanogaster,2024,Cell,126,"Nils Eckstein, Alexander Shakeel Bates, Andrew Champion, Michelle Du, Yijie Yin, Philipp Schlegel, Alicia Kun-Yang Lu, Thomson Rymer, Samantha Finley-May, Tyler Paterson, Ruchi Parekh, Sven Dorkenwald, Arie Matsliah, Szi-Chieh Yu, Claire McKellar, Amy Sterling, Katharina Eichler, Marta Costa, Sebastian Seung, Mala Murthy, Volker Hartenstein, Gregory SXE Jefferis, Jan Funke",Nils Eckstein,Jan Funke,23,"High-resolution electron microscopy of nervous systems has enabled the reconstruction of synaptic connectomes. However, we do not know the synaptic sign for each connection (i.e., whether a connection is excitatory or inhibitory), which is implied by the released transmitter. We demonstrate that artificial neural networks can predict transmitter types for presynapses from electron micrographs: a network trained to predict six transmitters (acetylcholine, glutamate, GABA, serotonin, dopamine, octopamine) achieves an accuracy of 87% for individual synapses, 94% for neurons, and 91% for known cell types across a D. melanogaster whole brain. We visualize the ultrastructural features used for prediction, discovering subtle but significant differences between transmitter phenotypes. We also analyze transmitter distributions across the brain and find that neurons that develop together largely express only one fast …",https://www.cell.com/cell/fulltext/S0092-8674(24)00307-6
Jan Funke,Synaptic Cleft Segmentation in Non-isotropic Volume Electron Microscopy of the Complete Drosophila Brain,2018,"Medical Image Computing and Computer Assisted Intervention–MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part II 11",93,"Larissa Heinrich, Jan Funke, Constantin Pape, Juan Nunez-Iglesias, Stephan Saalfeld",Larissa Heinrich,Stephan Saalfeld,5,"Neural circuit reconstruction at single synapse resolution is increasingly recognized as crucially important to decipher the function of biological nervous systems. Volume electron microscopy in serial transmission or scanning mode has been demonstrated to provide the necessary resolution to segment or trace all neurites and to annotate all synaptic connections.Automatic annotation of synaptic connections has been done successfully in near isotropic electron microscopy of vertebrate model organisms. Results on non-isotropic data in insect models, however, are not yet on par with human annotation.We designed a new 3D-U-Net architecture to optimally represent isotropic fields of view in non-isotropic data. We used regression on a signed distance transform of manually annotated synaptic clefts of the CREMI challenge dataset to train this model and observed significant improvement …",https://link.springer.com/chapter/10.1007/978-3-030-00934-2_36
Jan Funke,Accurate and linear time pose estimation from points and lines,2016,,81,"Alexander Vakhitov, Jan Funke, Francesc Moreno-Noguer",Alexander Vakhitov,Francesc Moreno-Noguer,3,"The Perspective-n-Point (PnP) problem seeks to estimate the pose of a calibrated camera from n 3D-to-2D point correspondences. There are situations, though, where PnP solutions are prone to fail because feature point correspondences cannot be reliably estimated (e.g. scenes with repetitive patterns or with low texture). In such scenarios, one can still exploit alternative geometric entities, such as lines, yielding the so-called Perspective-n-Line (PnL) algorithms. Unfortunately, existing PnL solutions are not as accurate and efficient as their point-based counterparts. In this paper we propose a novel approach to introduce 3D-to-2D line correspondences into a PnP formulation, allowing to simultaneously process points and lines. For this purpose we introduce an algebraic line error that can be formulated as linear constraints on the line endpoints, even when these are not directly observable. These …",https://link.springer.com/chapter/10.1007/978-3-319-46478-7_36
Jan Funke,Efficient automatic 3D-reconstruction of branching neurons from EM data,2012,2012 IEEE Conference on Computer Vision and Pattern Recognition,79,"Jan Funke, Bjoern Andres, Fred A Hamprecht, Albert Cardona, Matthew Cook",Jan Funke,Matthew Cook,5,"We present an approach for the automatic reconstruction of neurons from 3D stacks of electron microscopy sections. The core of our system is a set of possible assignments, each of which proposes with some cost a link between neuron regions in consecutive sections. These can model the continuation, branching, and end of neurons. The costs are trainable on positive assignment samples. An optimal and consistent set of assignments is found for the whole volume at once by solving an integer linear program. This set of assignments determines both the segmentation into neuron regions and the correspondence between such regions in neighboring slices. For each picked assignment, a confidence value helps to prioritize decisions to be reviewed by a human expert. We evaluate the performance of our method on an annotated volume of neural tissue and compare to the current state of the art [26]. Our method is …",https://ieeexplore.ieee.org/abstract/document/6247777/
Jan Funke,Efficient convolutional neural networks for pixelwise classification on heterogeneous hardware systems,2016,ISBI,66,"Fabian Tschopp, Julien N. P. Martel, Srinivas C. Turaga, Matthew Cook, Jan Funke",Fabian Tschopp,Jan Funke,5,"With recent advances in high-throughput Electron Microscopy (EM) imaging it is now possible to image an entire nervous system of organisms like Drosophila melanogaster. One of the bottlenecks to reconstruct a connectome from these large volumes (œ 100 TiB) is the pixel-wise prediction of membranes. The time it would typically take to process such a volume using a convolutional neural network (CNN) with a sliding window approach is in the order of years on a current GPU. With sliding windows, however, a lot of redundant computations are carried out. In this paper, we present an extension to the Caffe library to increase throughput by predicting many pixels at once. On a sliding window network successfully used for membrane classification, we show that our method achieves a speedup of up to 57×, maintaining identical prediction results.",https://ieeexplore.ieee.org/abstract/document/7493487/
Jan Funke,Local shape descriptors for neuron segmentation,2023,Nature methods,57,"Arlo Sheridan, Tri M Nguyen, Diptodip Deb, Wei-Chung Allen Lee, Stephan Saalfeld, Srinivas C Turaga, Uri Manor, Jan Funke",Arlo Sheridan,Jan Funke,8,"We present an auxiliary learning task for the problem of neuron segmentation in electron microscopy volumes. The auxiliary task consists of the prediction of local shape descriptors (LSDs), which we combine with conventional voxel-wise direct neighbor affinities for neuron boundary detection. The shape descriptors capture local statistics about the neuron to be segmented, such as diameter, elongation, and direction. On a study comparing several existing methods across various specimen, imaging techniques, and resolutions, auxiliary learning of LSDs consistently increases segmentation accuracy of affinity-based methods over a range of metrics. Furthermore, the addition of LSDs promotes affinity-based segmentation methods to be on par with the current state of the art for neuron segmentation (flood-filling networks), while being two orders of magnitudes more efficient—a critical requirement for the processing …",https://www.nature.com/articles/s41592-022-01711-z
Jan Funke,Segmented anisotropic sstem dataset of neural tissue,2013,figshare,49,"Stephan Gerhard, Jan Funke, Julien Martel, Albert Cardona, Richard Fetter",Stephan Gerhard,Richard Fetter,5,"We provide two image stacks where each contains 20 sections from serial section Transmission Electron Microscopy (ssTEM) of the Drosophila melanogaster third instar larva ventral nerve cord. Both stacks measure approx. 4.7 x 4.7 x 1 microns with a resolution of 4.6 x 4.6 nm/pixel and section thickness of 45-50 nm. In addition to the raw image data, we provide for the first stack a dense labeling of neuron membranes (including orientation and junction), mitochondria, synapses and glia/extracellular space. The first stack serves as a training dataset, and a second stack of the same dimension can be used as a test dataset.",https://www.zora.uzh.ch/id/eprint/91121/
Jan Funke,A Connectome of the Male Drosophila Ventral Nerve Cord,2023,BioRxiv,46,"Shin-ya Takemura, Kenneth J Hayworth, Gary B Huang, Michal Januszewski, Zhiyuan Lu, Elizabeth C Marin, Stephan Preibisch, C Shan Xu, John Bogovic, Andrew S Champion, Han SJ Cheong, Marta Costa, Katharina Eichler, William Katz, Christopher Knecht, Feng Li, Billy J Morris, Christopher Ordish, Patricia K Rivlin, Philipp Schlegel, Kazunori Shinomiya, Tomke Stürner, Ting Zhao, Griffin Badalamente, Dennis Bailey, Paul Brooks, Brandon S Canino, Jody Clements, Michael Cook, Octave Duclos, Christopher R Dunne, Kelli Fairbanks, Siqi Fang, Samantha Finley-May, Audrey Francis, Reed George, Marina Gkantia, Kyle Harrington, Gary Patrick Hopkins, Joseph Hsu, Philip M Hubbard, Alexandre Javier, Dagmar Kainmueller, Wyatt Korff, Julie Kovalyak, Dominik Krzemiński, Shirley A Lauchie, Alanna Lohff, Charli Maldonado, Emily A Manley, Caroline Mooney, Erika Neace, Matthew Nichols, Omotara Ogundeyi, Nneoma Okeoma, Tyler Paterson, Elliott Phillips, Emily M Phillips, Caitlin Ribeiro, Sean M Ryan, Jon Thomson Rymer, Anne K Scott, Ashley L Scott, David Shepherd, Aya Shinomiya, Claire Smith, Natalie Smith, Alia Suleiman, Satoko Takemura, Iris Talebi, Imaan FM Tamimi, Eric T Trautman, Lowell Umayam, John J Walsh, Tansy Yang, Gerald M Rubin, Louis K Scheffer, Jan Funke, Stephan Saalfeld, Harald F Hess, Stephen M Plaza, Gwyneth M Card, Gregory SXE Jefferis, Stuart Berg",Shin-ya Takemura,Stuart Berg,84,"Animal behavior is principally expressed through neural control of muscles. Therefore understanding how the brain controls behavior requires mapping neuronal circuits all the way to motor neurons. We have previously established technology to collect large-volume electron microscopy data sets of neural tissue and fully reconstruct the morphology of the neurons and their chemical synaptic connections throughout the volume. Using these tools we generated a dense wiring diagram, or connectome, for a large portion of the Drosophila central brain. However, in most animals, including the fly, the majority of motor neurons are located outside the brain in a neural center closer to the body, i.e. the mammalian spinal cord or insect ventral nerve cord (VNC). In this paper, we extend our effort to map full neural circuits for behavior by generating a connectome of the VNC of a male fly.",https://www.biorxiv.org/content/10.1101/2023.06.05.543757.abstract
Jan Funke,Optimal Joint Segmentation and Tracking of Escherichia Coli in the Mother Machine,2014,"Bayesian and graphical Models for Biomedical Imaging: First International Workshop, BAMBI 2014, Cambridge, MA, USA, September 18, 2014, Revised Selected Papers",46,"Florian Jug, Tobias Pietzsch, Dagmar Kainmüller, Jan Funke, Matthias Kaiser, Erik van Nimwegen, Carsten Rother, Gene Myers",Florian Jug,Gene Myers,8,"We introduce a graphical model for the joint segmentation and tracking of E. coli cells from time lapse videos. In our setup cells are grown in narrow columns (growth channels) in a so-called “Mother Machine” [1]. In these growth channels, cells are vertically aligned, grow and divide over time, and eventually leave the channel at the top. The model is built on a large set of cell segmentation hypotheses for each video frame that we extract from data using a novel parametric max-flow variation. Possible tracking assignments between segments across time, including cell identity mapping, cell division, and cell exit events are enumerated. Each such assignment is represented as a binary decision variable with unary costs based on image and object features of the involved segments. We find a cost-minimal and consistent solution by solving an integer linear program. We introduce a new and important type of …",https://link.springer.com/chapter/10.1007/978-3-319-12289-2_3
Jan Funke,Structured cerebellar connectivity supports resilient pattern separation,2023,Nature,45,"Tri M Nguyen, Logan A Thomas, Jeff L Rhoades, Ilaria Ricchi, Xintong Cindy Yuan, Arlo Sheridan, David GC Hildebrand, Jan Funke, Wade G Regehr, Wei-Chung Allen Lee",Tri M Nguyen,Wei-Chung Allen Lee,10,"The cerebellum is thought to help detect and correct errors between intended and executed commands, and is critical for social behaviours, cognition and emotion, , –. Computations for motor control must be performed quickly to correct errors in real time and should be sensitive to small differences between patterns for fine error correction while being resilient to noise. Influential theories of cerebellar information processing have largely assumed random network connectivity, which increases the encoding capacity of the network’s first layer, , , , –. However, maximizing encoding capacity reduces the resilience to noise. To understand how neuronal circuits address this fundamental trade-off, we mapped the feedforward connectivity in the mouse cerebellar cortex using automated large-scale transmission electron microscopy and convolutional neural network-based image segmentation. We found that both the input …",https://www.nature.com/articles/s41586-022-05471-w
Jan Funke,Network statistics of the whole-brain connectome of Drosophila,2024,Nature,40,"Albert Lin, Runzhe Yang, Sven Dorkenwald, Arie Matsliah, Amy R Sterling, Philipp Schlegel, Szi-chieh Yu, Claire E McKellar, Marta Costa, Katharina Eichler, Alexander Shakeel Bates, Nils Eckstein, Jan Funke, Gregory SXE Jefferis, Mala Murthy",Albert Lin,Mala Murthy,15,"Brains comprise complex networks of neurons and connections, similar to the nodes and edges of artificial networks. Network analysis applied to the wiring diagrams of brains can offer insights into how they support computations and regulate the flow of information underlying perception and behaviour. The completion of the first whole-brain connectome of an adult fly, containing over 130,000 neurons and millions of synaptic connections, –, offers an opportunity to analyse the statistical properties and topological features of a complete brain. Here we computed the prevalence of two- and three-node motifs, examined their strengths, related this information to both neurotransmitter composition and cell type annotations,, and compared these metrics with wiring diagrams of other animals. We found that the network of the fly brain displays rich-club organization, with a large population (30% of the connectome) of highly …",https://www.nature.com/articles/s41586-024-07968-y
Jan Funke,Neural network organization for courtship-song feature detection in Drosophila,2022,Current Biology,29,"Christa A Baker, Claire McKellar, Rich Pang, Aljoscha Nern, Sven Dorkenwald, Diego A Pacheco, Nils Eckstein, Jan Funke, Barry J Dickson, Mala Murthy",Christa A Baker,Mala Murthy,10,"Animals communicate using sounds in a wide range of contexts, and auditory systems must encode behaviorally relevant acoustic features to drive appropriate reactions. How feature detection emerges along auditory pathways has been difficult to solve due to challenges in mapping the underlying circuits and characterizing responses to behaviorally relevant features. Here, we study auditory activity in the Drosophila melanogaster brain and investigate feature selectivity for the two main modes of fly courtship song, sinusoids and pulse trains. We identify 24 new cell types of the intermediate layers of the auditory pathway, and using a new connectomic resource, FlyWire, we map all synaptic connections between these cell types, in addition to connections to known early and higher-order auditory neurons—this represents the first circuit-level map of the auditory pathway. We additionally determine the sign (excitatory …",https://www.cell.com/current-biology/fulltext/S0960-9822(22)00978-2
Jan Funke,Hierarchical architecture of dopaminergic circuits enables second-order conditioning in Drosophila,2023,Elife,27,"Daichi Yamada, Daniel Bushey, Feng Li, Karen L Hibbard, Megan Sammons, Jan Funke, Ashok Litwin-Kumar, Toshihide Hige, Yoshinori Aso",Daichi Yamada,Yoshinori Aso,9,"Dopaminergic neurons with distinct projection patterns and physiological properties compose memory subsystems in a brain. However, it is poorly understood whether or how they interact during complex learning. Here, we identify a feedforward circuit formed between dopamine subsystems and show that it is essential for second-order conditioning, an ethologically important form of higher-order associative learning. The Drosophila mushroom body comprises a series of dopaminergic compartments, each of which exhibits distinct memory dynamics. We find that a slow and stable memory compartment can serve as an effective ‘teacher’by instructing other faster and transient memory compartments via a single key interneuron, which we identify by connectome analysis and neurotransmitter prediction. This excitatory interneuron acquires enhanced response to reward-predicting odor after first-order conditioning and, upon activation, evokes dopamine release in the ‘student’compartments. These hierarchical connections between dopamine subsystems explain distinct properties of first-and second-order memory long known by behavioral psychologists.",https://elifesciences.org/articles/79042
Jan Funke,Automated reconstruction of whole-embryo cell lineages by learning from sparse annotations,2023,Nature biotechnology,27,"Caroline Malin-Mayor, Peter Hirsch, Leo Guignard, Katie McDole, Yinan Wan, William C Lemon, Dagmar Kainmueller, Philipp J Keller, Stephan Preibisch, Jan Funke",Caroline Malin-Mayor,Jan Funke,10,"We present a method to automatically identify and track nuclei in time-lapse microscopy recordings of entire developing embryos. The method combines deep learning and global optimization. On a mouse dataset, it reconstructs 75.8% of cell lineages spanning 1 h, as compared to 31.8% for the competing method. Our approach improves understanding of where and when cell fate decisions are made in developing embryos, tissues, and organs.",https://www.nature.com/articles/s41587-022-01427-7
Jan Funke,Learning to segment: Training hierarchical segmentation under a topological loss,2015,"Medical Image Computing and Computer-Assisted Intervention–MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18",27,"Jan Funke, Fred A Hamprecht, Chong Zhang",Jan Funke,Chong Zhang,3,"We propose a generic and efficient learning framework that is applicable to segment images in which individual objects are mainly discernible by boundary cues. Our approach starts by first hierarchically clustering the image and then explaining the image in terms of a cost-minimal subset of non-overlapping segments. The cost of a segmentation is defined as a weighted sum of features of the selected candidates. This formulation allows us to take into account an extensible set of arbitrary features. The maximally discriminative linear combination of features is learned from training data using a margin-rescaled structured SVM. At the core of our formulation is a novel and simple topology-based structured loss which is a combination of counts and geodesic distance of topological errors (splits, merges, false positives and false negatives) relative to the training set. We demonstrate the generality and accuracy …",https://link.springer.com/chapter/10.1007/978-3-319-24574-4_32
Jan Funke,A framework for evaluating visual slam,2009,Proceedings of the British Machine Vision Conference (BMVC),24,"Jan Funke, Tobias Pietzsch",Jan Funke,Tobias Pietzsch,2,"Performance analysis in the field of camera-based simultaneous localisation and mapping (Visual SLAM, VSLAM) is still an unsolved problem. For VSLAM systems, there is a lack of generally accepted performance measures, test frameworks, and benchmark problems. Most researchers test by visually inspecting their systems on recorded image sequences, or measuring accuracy on simulated data of simplified point-cloud-like environments. Both approaches have their disadvantages. Recorded sequences lack ground truth. Simulations tend to oversimplify low-level aspects of the problem. In this paper, we propose to evaluate VSLAM systems on rendered image sequences. The intention is to move simulations towards more realistic conditions while still having ground truth. For this purpose, we provide a complete and extensible framework which addresses all aspects, from rendering to ground truth generation and automated evaluation. To illustrate the usefulness of this framework, we provide experimental results assessing the benefit of feature normal estimation and subpixel accurate matching on sequences with and without motion blur.",https://www.academia.edu/download/38621715/FunkePietzschBMVC.pdf
Jan Funke,Who is talking to whom: synaptic partner detection in anisotropic volumes of insect brain,2015,"Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part I 18",23,"Anna Kreshuk, Jan Funke, Albert Cardona, Fred A Hamprecht",Anna Kreshuk,Fred A Hamprecht,4,"Automated reconstruction of neural connectivity graphs from electron microscopy image stacks is an essential step towards large-scale neural circuit mapping. While significant progress has recently been made in automated segmentation of neurons and detection of synapses, the problem of synaptic partner assignment for polyadic (one-to-many) synapses, prevalent in the Drosophila brain, remains unsolved. In this contribution, we propose a method which automatically assigns pre- and postsynaptic roles to neurites adjacent to a synaptic site. The method constructs a probabilistic graphical model over potential synaptic partner pairs which includes factors to account for a high rate of one-to-many connections, as well as the possibility of the same neuron to be pre-synaptic in one synapse and post-synaptic in another. The algorithm has been validated on a publicly available stack of ssTEM images of …",https://link.springer.com/chapter/10.1007/978-3-319-24553-9_81
Jan Funke,Transverse endoplasmic reticulum expansion in hereditary spastic paraplegia corticospinal axons,2022,Human Molecular Genetics,22,"Peng-Peng Zhu, Hui-Fang Hung, Natalia Batchenkova, Jonathon Nixon-Abell, James Henderson, Pengli Zheng, Benoit Renvoisé, Song Pang, C Shan Xu, Stephan Saalfeld, Jan Funke, Yuxiang Xie, Fabian Svara, Harald F Hess, Craig Blackstone",Peng-Peng Zhu,Craig Blackstone,15,"Hereditary spastic paraplegias (HSPs) comprise a large group of inherited neurologic disorders affecting the longest corticospinal axons (SPG1–86 plus others), with shared manifestations of lower extremity spasticity and gait impairment. Common autosomal dominant HSPs are caused by mutations in genes encoding the microtubule-severing ATPase spastin (SPAST; SPG4), the membrane-bound GTPase atlastin-1 (ATL1; SPG3A) and the reticulon-like, microtubule-binding protein REEP1 (REEP1; SPG31). These proteins bind one another and function in shaping the tubular endoplasmic reticulum (ER) network. Typically, mouse models of HSPs have mild, later onset phenotypes, possibly reflecting far shorter lengths of their corticospinal axons relative to humans. Here, we have generated a robust, double mutant mouse model of HSP in which atlastin-1 is genetically modified with a K80A knock-in (KI …",https://academic.oup.com/hmg/article-abstract/31/16/2779/6553888
Jan Funke,Automatic whole cell organelle segmentation in volumetric electron microscopy,2020,bioRxiv,20,"Larissa Heinrich, Davis Bennett, David Ackerman, Woohyun Park, John Bogovic, Nils Eckstein, Alyson Petruncio, Jody Clements, C Shan Xu, Jan Funke, Wyatt Korff, Harald F Hess, Jennifer Lippincott-Schwartz, Stephan Saalfeld, Aubrey V Weigel, COSEM Project Team",Larissa Heinrich,COSEM Project Team,16,"Cells contain hundreds of different organelle and macromolecular assemblies intricately organized relative to each other to meet any cellular demands. Obtaining a complete understanding of their organization is challenging and requires nanometer-level, threedimensional reconstruction of whole cells. Even then, the immense size of datasets and large number of structures to be characterized requires generalizable, automatic methods. To meet this challenge, we developed an analysis pipeline for comprehensively reconstructing and analyzing the cellular organelles in entire cells imaged by focused ion beam scanning electron microscopy (FIB-SEM) at a near-isotropic size of 4 or 8 nm per voxel. The pipeline involved deep learning architectures trained on diverse samples for automatic reconstruction of 35 different cellular organelle classes - ranging from endoplasmic reticulum to microtubules to ribosomes - from multiple cell types.Automatic reconstructions were used to directly quantify various previously inaccessible metrics about these structures, including their spatial interactions. We show that automatic organelle reconstructions can also be used to automatically register light and electron microscopy images for correlative studies. We created an open data and open source web repository, OpenOrganelle, to share the data, computer code, and trained models, enabling scientists everywhere to query and further reconstruct the datasets.",https://www.biorxiv.org/content/10.1101/2020.11.14.382143.abstract
Jan Funke,Synaptic partner prediction from point annotations in insect brains,2018,"Medical Image Computing and Computer Assisted Intervention–MICCAI 2018: 21st International Conference, Granada, Spain, September 16-20, 2018, Proceedings, Part II 11",19,"Julia Buhmann, Renate Krause, Rodrigo Ceballos Lentini, Nils Eckstein, Matthew Cook, Srinivas Turaga, Jan Funke",Julia Buhmann,Jan Funke,7,"High-throughput electron microscopy allows recording of large stacks of neural tissue with sufficient resolution to extract the wiring diagram of the underlying neural network. Current efforts to automate this process focus mainly on the segmentation of neurons. However, in order to recover a wiring diagram, synaptic partners need to be identified as well. This is especially challenging in insect brains like Drosophila melanogaster, where one presynaptic site is associated with multiple postsynaptic elements. Here we propose a 3D U-Net architecture to directly identify pairs of voxels that are pre- and postsynaptic to each other. To that end, we formulate the problem of synaptic partner identification as a classification problem on long-range edges between voxels to encode both the presence of a synaptic pair and its direction. This formulation allows us to directly learn from synaptic point annotations instead of …",https://link.springer.com/chapter/10.1007/978-3-030-00934-2_35
Jan Funke,Analyzing image segmentation for connectomics,2018,Frontiers in neural circuits,18,"Stephen M Plaza, Jan Funke",Stephen M Plaza,Jan Funke,2,"Automatic image segmentation is critical to scale up electron microscope (EM) connectome reconstruction. To this end, segmentation competitions, such as CREMI and SNEMI, exist to help researchers evaluate segmentation algorithms with the goal of improving them. Because generating ground truth is time-consuming, these competitions often fail to capture the challenges in segmenting larger datasets required in connectomics. More generally, the common metrics for EM image segmentation do not emphasize impact on downstream analysis and are often not very useful for isolating problem areas in the segmentation. For example, they do not capture connectivity information and often over-rate the quality of a segmentation as we demonstrate later. To address these issues, we introduce a novel strategy to enable evaluation of segmentation at large scales both in a supervised setting, where ground truth is available, or an unsupervised setting. To achieve this, we first introduce new metrics more closely aligned with the use of segmentation in downstream analysis and reconstruction. In particular, these include synapse connectivity and completeness metrics that provide both meaningful and intuitive interpretations of segmentation quality as it relates to the preservation of neuron connectivity. Also, we propose measures of segmentation correctness and completeness with respect to the percentage of “orphan” fragments and the concentrations of self-loops formed by segmentation failures, which are helpful in analysis and can be computed without ground truth. The introduction of new metrics intended to be used for practical applications …",https://www.frontiersin.org/articles/10.3389/fncir.2018.00102/full
Jan Funke,A leaky integrate-and-fire computational model based on the connectome of the entire adult Drosophila brain reveals insights into sensorimotor processing,2023,bioRxiv,17,"Philip K Shiu, Gabriella R Sterne, Nico Spiller, Romain Franconville, Andrea Sandoval, Joie Zhou, Neha Simha, Chan Hyuk Kang, Seongbong Yu, Jinseop S Kim, Sven Dorkenwald, Arie Matsliah, Philipp Schlegel, Yu Szi-Chieh, Claire E McKellar, Amy Sterling, Marta Costa, Katharina Eichler, Gregory SXE Jefferis, Mala Murthy, Alexander Shakeel Bates, Nils Eckstein, Jan Funke, Salil S Bidaye, Stefanie Hampel, Andrew M Seeds, Kristin Scott",Philip K Shiu,Kristin Scott,27,"The forthcoming assembly of the adult Drosophila melanogaster central brain connectome, containing over 125,000 neurons and 50 million synaptic connections, provides a template for examining sensory processing throughout the brain. Here, we create a leaky integrate-and-fire computational model of the entire Drosophila brain, based on neural connectivity and neurotransmitter identity, to study circuit properties of feeding and grooming behaviors. We show that activation of sugar-sensing or water-sensing gustatory neurons in the computational model accurately predicts neurons that respond to tastes and are required for feeding initiation. Computational activation of neurons in the feeding region of the Drosophila brain predicts those that elicit motor neuron firing, a testable hypothesis that we validate by optogenetic activation and behavioral studies. Moreover, computational activation of different classes of …",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10187186/
Jan Funke,Candidate sampling for neuron reconstruction from anisotropic electron microscopy volumes,2014,"Medical Image Computing and Computer-Assisted Intervention–MICCAI 2014: 17th International Conference, Boston, MA, USA, September 14-18, 2014, Proceedings, Part I 17",17,"Jan Funke, Julien NP Martel, Stephan Gerhard, Bjoern Andres, Dan C Cireşan, Alessandro Giusti, Luca M Gambardella, Jürgen Schmidhuber, Hanspeter Pfister, Albert Cardona, Matthew Cook",Jan Funke,Matthew Cook,11,"The automatic reconstruction of neurons from stacks of electron microscopy sections is an important computer vision problem in neuroscience. Recent advances are based on a two step approach: First, a set of possible 2D neuron candidates is generated for each section independently based on membrane predictions of a local classifier. Second, the candidates of all sections of the stack are fed to a neuron tracker that selects and connects them in 3D to yield a reconstruction. The accuracy of the result is currently limited by the quality of the generated candidates. In this paper, we propose to replace the heuristic set of candidates used in previous methods with samples drawn from a conditional random field (CRF) that is trained to label sections of neural tissue. We show on a stack of Drosophila melanogaster neural tissue that neuron candidates generated with our method produce 30% less reconstruction …",https://link.springer.com/chapter/10.1007/978-3-319-10404-1_3
Jan Funke,TED: A tolerant edit distance for segmentation evaluation,2017,Methods,16,"Jan Funke, Jonas Klein, Francesc Moreno-Noguer, Albert Cardona, Matthew Cook",Jan Funke,Matthew Cook,5,"In this paper, we present a novel error measure to compare a computer-generated segmentation of images or volumes against ground truth. This measure, which we call Tolerant Edit Distance (TED), is motivated by two observations that we usually encounter in biomedical image processing: (1) Some errors, like small boundary shifts, are tolerable in practice. Which errors are tolerable is application dependent and should be explicitly expressible in the measure. (2) Non-tolerable errors have to be corrected manually. The effort needed to do so should be reflected by the error measure. Our measure is the minimal weighted sum of split and merge operations to apply to one segmentation such that it resembles another segmentation within specified tolerance bounds. This is in contrast to other commonly used measures like Rand index or variation of information, which integrate small, but tolerable, differences …",https://www.sciencedirect.com/science/article/pii/S1046202316305072
Jan Funke,A Drosophila computational brain model reveals sensorimotor processing,2024,Nature,15,"Philip K Shiu, Gabriella R Sterne, Nico Spiller, Romain Franconville, Andrea Sandoval, Joie Zhou, Neha Simha, Chan Hyuk Kang, Seongbong Yu, Jinseop S Kim, Sven Dorkenwald, Arie Matsliah, Philipp Schlegel, Szi-chieh Yu, Claire E McKellar, Amy Sterling, Marta Costa, Katharina Eichler, Alexander Shakeel Bates, Nils Eckstein, Jan Funke, Gregory SXE Jefferis, Mala Murthy, Salil S Bidaye, Stefanie Hampel, Andrew M Seeds, Kristin Scott",Philip K Shiu,Kristin Scott,27,"The recent assembly of the adult Drosophila melanogaster central brain connectome, containing more than 125,000 neurons and 50 million synaptic connections, provides a template for examining sensory processing throughout the brain,. Here we create a leaky integrate-and-fire computational model of the entire Drosophila brain, on the basis of neural connectivity and neurotransmitter identity, to study circuit properties of feeding and grooming behaviours. We show that activation of sugar-sensing or water-sensing gustatory neurons in the computational model accurately predicts neurons that respond to tastes and are required for feeding initiation. In addition, using the model to activate neurons in the feeding region of the Drosophila brain predicts those that elicit motor neuron firing—a testable hypothesis that we validate by optogenetic activation and behavioural studies. Activating different classes of gustatory …",https://www.nature.com/articles/s41586-024-07763-9
Jan Funke,Connectome-driven neural inventory of a complete visual system,2024,bioRxiv,14,"Aljoscha Nern, Frank Loesche, Shin-ya Takemura, Laura E Burnett, Marisa Dreher, Eyal Gruntman, Judith Hoeller, Gary B Huang, Michał Januszewski, Nathan C Klapoetke, Sanna Koskela, Kit D Longden, Zhiyuan Lu, Stephan Preibisch, Wei Qiu, Edward M Rogers, Pavithraa Seenivasan, Arthur Zhao, John Bogovic, Brandon S Canino, Jody Clements, Michael Cook, Samantha Finley-May, Miriam A Flynn, Imran Hameed, Alexandra MC Fragniere, Kenneth J Hayworth, Gary Patrick Hopkins, Philip M Hubbard, William T Katz, Julie Kovalyak, Shirley A Lauchie, Meghan Leonard, Alanna Lohff, Charli A Maldonado, Caroline Mooney, Nneoma Okeoma, Donald J Olbris, Christopher Ordish, Tyler Paterson, Emily M Phillips, Tobias Pietzsch, Jennifer Rivas Salinas, Patricia K Rivlin, Philipp Schlegel, Ashley L Scott, Louis A Scuderi, Satoko Takemura, Iris Talebi, Alexander Thomson, Eric T Trautman, Lowell Umayam, Claire Walsh, John J Walsh, C Shan Xu, Emily A Yakal, Tansy Yang, Ting Zhao, Jan Funke, Reed George, Harald F Hess, Gregory SXE Jefferis, Christopher Knecht, Wyatt Korff, Stephen M Plaza, Sandro Romani, Stephan Saalfeld, Louis K Scheffer, Stuart Berg, Gerald M Rubin, Michael B Reiser",Aljoscha Nern,Michael B Reiser,71,"Vision provides animals with detailed information about their surroundings, conveying diverse features such as color, form, and movement across the visual scene. Computing these parallel spatial features requires a large and diverse network of neurons, such that in animals as distant as flies and humans, visual regions comprise half the brain’s volume. These visual brain regions often reveal remarkable structure-function relationships, with neurons organized along spatial maps with shapes that directly relate to their roles in visual processing. To unravel the stunning diversity of a complex visual system, a careful mapping of the neural architecture matched to tools for targeted exploration of that circuitry is essential. Here, we report a new connectome of the right optic lobe from a male Drosophila central nervous system FIB-SEM volume and a comprehensive inventory of the fly’s visual neurons. We developed a …",https://pmc.ncbi.nlm.nih.gov/articles/PMC11042306/
Jan Funke,A benchmark for epithelial cell tracking,2018,Proceedings of The European Conference on Computer Vision (ECCV) Workshops,14,"Jan Funke, Lisa Mais, Andrew Champion, Natalie Dye, Dagmar Kainmueller",Jan Funke,Dagmar Kainmueller,5,"Segmentation and tracking of epithelial cells in light microscopy (LM) movies of developing tissue is an abundant task in celland developmental biology. Epithelial cells are densely packed cells that form a honeycomb-like grid. This dense packing distinguishes membranestained epithelial cells from the types of objects recent cell tracking benchmarks have focused on, like cell nuclei and freely moving individual cells. While semi-automated tools for segmentation and tracking of epithelial cells are available to biologists, common tools rely on classical watershed based segmentation and engineered tracking heuristics, and entail a tedious phase of manual curation. However, a different kind of densely packed cell imagery has become a focus of recent computer vision research, namely electron microscopy (EM) images of neurons. In this work we explore the benefits of two recent neuron EM segmentation methods for epithelial cell tracking in light microscopy. In particular we adapt two different deep learning approaches for neuron segmentation, namely Flood Filling Networks and MALA, to epithelial cell tracking. We benchmark these on a dataset of eight movies with up to 200 frames. We compare to Moral Lineage Tracing, a combinatorial optimization approach that recently claimed state of the art results for epithelial cell tracking. Furthermore, we compare to Tissue Analyzer, an off-the-shelf tool used by Biologists that serves as our baseline.",https://openaccess.thecvf.com/content_eccv_2018_workshops/w33/html/Funke_A_Benchmark_for_Epithelial_Cell_Tracking_ECCVW_2018_paper.html
Jan Funke,Segmented anisotropic sstem dataset of neural tissue. figshare,2013,Dataset. doi,14,"Stephan Gerhard, Jan Funke, Julien Martel, Albert Cardona, Richard Fetter",Stephan Gerhard,Richard Fetter,5,,https://scholar.google.com/scholar?cluster=5870657680779053719&hl=en&oi=scholarr
Jan Funke,Discriminative attribution from paired images,2022,,7,"Nils Eckstein, Habib Bukhari, Alexander S Bates, Gregory SXE Jefferis, Jan Funke",Nils Eckstein,Jan Funke,5,"We present a method for deep neural network interpretability by combining feature attribution with counterfactual explanations to generate attribution maps that highlight the most discriminative features between classes. Crucially, this method can be used to quantitatively evaluate the performance of feature attribution methods in an objective manner, thus preventing potential observer bias. We evaluate the proposed method on six diverse datasets, and use it to discover so far unknown morphological features of synapses in Drosophila melanogaster. We show quantitatively and qualitatively that the highlighted features are substantially more discriminative than those extracted using conventional attribution methods and improve upon similar approaches for counterfactual explainability. We argue that the extracted explanations are better suited for understanding fine grained class differences as learned by a deep …",https://link.springer.com/chapter/10.1007/978-3-031-25069-9_27
Jan Funke,Segmented anisotropic ssTEM dataset of neural tissue (2013),,URL http://dx. doi. org/10.6084/m9. figshare,7,"Stephan Gerhard, Jan Funke, Julien Martel, Albert Cardona, Richard Fetter",Stephan Gerhard,Richard Fetter,5,,https://scholar.google.com/scholar?cluster=8226759234018109623&hl=en&oi=scholarr
Jan Funke,Microtubule tracking in electron microscopy volumes,2020,"Medical Image Computing and Computer Assisted Intervention–MICCAI 2020: 23rd International Conference, Lima, Peru, October 4–8, 2020, Proceedings, Part V 23",6,"Nils Eckstein, Julia Buhmann, Matthew Cook, Jan Funke",Nils Eckstein,Jan Funke,4,"We present a method for microtubule tracking in electron microscopy volumes. Our method first identifies a sparse set of voxels that likely belong to microtubules. Similar to prior work, we then enumerate potential edges between these voxels, which we represent in a candidate graph. Tracks of microtubules are found by selecting nodes and edges in the candidate graph by solving a constrained optimization problem incorporating biological priors on microtubule structure. For this, we present a novel integer linear programming formulation, which results in speed-ups of three orders of magnitude and an increase of 53% in accuracy compared to prior art (evaluated on three m volumes of Drosophila neural tissue). We also propose a scheme to solve the optimization problem in a block-wise fashion, which allows distributed tracking and is necessary to process very large electron microscopy volumes …",https://link.springer.com/chapter/10.1007/978-3-030-59722-1_10
Jan Funke,Automatic neuron reconstruction from anisotropic electron microscopy volumes,2014,,6,Jan Funke,Jan Funke,Jan Funke,1,"The work presented in this thesis addresses the problem of the automatic extraction of the wiring diagram of a nervous system from anisotropic electron microscopy volumes with high x-and y-resolution but low z-resolution, as obtained by serial section electron microscopy imaging procedures. A necessary step towards this goal is the segmentation of neural tissue to separate neuron cell interior from membrane and extracellular space, and thus reveal the 3D shape of each neuron, a process called neuron reconstruction. The core of this thesis is a novel method for the reconstruction of neurons from serial section electron microscopy images. Due to the anisotropy of serial section imaging methods, we treat the data as a stack of 2D images, rather then a continuous 3D volume. However, the detection of neuron slices (ie, cross-sections of neural processes) in 2D images is difficult due to ambiguities in the data. Therefore, we propose to enumerate several diverse and possibly contradictory candidate neuron slices by identifying separating membranes with varying thresholds for each image individually. Between candidates of adjacent images in the stack, we enumerate assignments that reflect possible ways to follow a neural process from one image to another. We assign costs to each candidate and assignment and formulate constraints that ensure consistency between the assignments. We show how a globally cost-minimal segmentation of neuron slices and assignments between images can be found jointly and efficiently. Furthermore, we derive a structured learning formulation to learn the assignment costs from annotated ground truth and …",https://www.research-collection.ethz.ch/bitstream/handle/20.500.11850/155078/eth-47683-01.pdf
Jan Funke,The candidate multi-cut for cell segmentation,2018,2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018),5,"Jan Funke, Chong Zhang, Tobias Pietzsch, Miguel A Gonzalez Ballester, Stephan Saalfeld",Jan Funke,Stephan Saalfeld,5,"Two successful approaches for the segmentation of biomedical images are (1) the selection of segment candidates from a merge-tree, and (2) the clustering of small superpixels by solving a Multi-Cut problem. In this paper, we introduce a model that unifies both approaches. Our model, the Candidate Multi-Cut (CMC), allows joint selection and clustering of segment candidates from a merge-tree. This way, we overcome the respective limitations of the individual methods: (1) the space of possible segmentations is not constrained to candidates of a merge-tree, and (2) the decision for clustering can be made on candidates larger than superpixels, using features over larger contexts. We solve the optimization problem of selecting and clustering of candidates using an integer linear program. On datasets of 2D light microscopy of cell populations and 3D electron microscopy of neurons, we show that our method …",https://ieeexplore.ieee.org/abstract/document/8363658/
Jan Funke,Multi-hypothesis crf-segmentation of neural tissue in anisotropic em volumes,2011,arXiv preprint arXiv:1109.2449,5,"Jan Funke, Björn Andres, Fred Hamprecht, Albert Cardona, Matthew Cook",Jan Funke,Matthew Cook,5,"We present an approach for the joint segmentation and grouping of similar components in anisotropic 3D image data and use it to segment neural tissue in serial sections electron microscopy (EM) images. We first construct a nested set of neuron segmentation hypotheses for each slice. A conditional random field (CRF) then allows us to evaluate both the compatibility of a specific segmentation and a specific inter-slice assignment of neuron candidates with the underlying observations. The model is solved optimally for an entire image stack simultaneously using integer linear programming (ILP), which yields the maximum a posteriori solution in amortized linear time in the number of slices. We evaluate the performance of our approach on an annotated sample of the Drosophila larva neuropil and show that the consideration of different segmentation hypotheses in each slice leads to a significant improvement in the segmentation and assignment accuracy.",https://arxiv.org/abs/1109.2449
Jan Funke,Model Based Inference of Synaptic Plasticity Rules,2023,bioRxiv,4,"Yash Mehta, Danil Tyulmankov, Adithya E Rajagopalan, Glenn C Turner, James E Fitzgerald, Jan Funke",Yash Mehta,Jan Funke,6,"Understanding learning through synaptic plasticity rules in the brain is a grand challenge for neuroscience. Here we introduce a novel computational framework for inferring plasticity rules from experimental data on neural activity trajectories and behavioral learning dynamics. Our methodology parameterizes the plasticity function to provide theoretical interpretability and facilitate gradient-based optimization. For instance, we use Taylor series expansions or multilayer perceptrons to approximate plasticity rules, and we adjust their parameters via gradient descent over entire trajectories to closely match observed neural activity and behavioral data. Notably, our approach can learn intricate rules that induce long nonlinear time-dependencies, such as those incorporating postsynaptic activity and current synaptic weights. We validate our method through simulations, accurately recovering established rules, like Oja's, as well as more complex hypothetical rules incorporating reward-modulated terms. We assess the resilience of our technique to noise and, as a tangible application, apply it to behavioral data from Drosophila during a probabilistic reward-learning experiment. Remarkably, we identify an active forgetting component of reward learning in flies that enhances the predictive accuracy of previous models. Overall, our modeling framework provides an exciting new avenue to elucidate the computational principles governing synaptic plasticity and learning in the brain.",https://www.biorxiv.org/content/10.1101/2023.12.11.571103.abstract
Jan Funke,Tracking by Weakly-Supervised Learning and Graph Optimization for Whole-Embryo C. elegans lineages,2022,,4,"Peter Hirsch, Caroline Malin-Mayor, Anthony Santella, Stephan Preibisch, Dagmar Kainmueller, Jan Funke",Peter Hirsch,Jan Funke,6,"Tracking all nuclei of an embryo in noisy and dense fluorescence microscopy data is a challenging task. We build upon a recent method for nuclei tracking that combines weakly-supervised learning from a small set of nuclei center point annotations with an integer linear program (ILP) for optimal cell lineage extraction. Our work specifically addresses the following challenging properties of C. elegans embryo recordings: (1) Many cell divisions as compared to benchmark recordings of other organisms, and (2) the presence of polar bodies that are easily mistaken as cell nuclei. To cope with (1), we devise and incorporate a learnt cell division detector. To cope with (2), we employ a learnt polar body detector. We further propose automated ILP weights tuning via a structured SVM, alleviating the need for tedious manual set-up of a respective grid search.Our method outperforms the previous leader of the cell tracking …",https://link.springer.com/chapter/10.1007/978-3-031-16440-8_3
Jan Funke,How shift equivariance impacts metric learning for instance segmentation,2021,Proceedings of the IEEE/CVF International Conference on Computer Vision,4,"Josef Lorenz Rumberger, Xiaoyan Yu, Peter Hirsch, Melanie Dohmen, Vanessa Emanuela Guarino, Ashkan Mokarian, Lisa Mais, Jan Funke, Dagmar Kainmueller",Josef Lorenz Rumberger,Dagmar Kainmueller,9,"Metric learning has received conflicting assessments concerning its suitability for solving instance segmentation tasks. It has been dismissed as theoretically flawed due to the shift equivariance of the employed CNNs and their respective inability to distinguish same-looking objects. Yet it has been shown to yield state of the art results for a variety of tasks, and practical issues have mainly been reported in the context of tile-and-stitch approaches, where discontinuities at tile boundaries have been observed. To date, neither of the reported issues have undergone thorough formal analysis. In our work, we contribute a comprehensive formal analysis of the shift equivariance properties of encoder-decoder-style CNNs, which yields a clear picture of what can and cannot be achieved with metric learning in the face of same-looking objects. In particular, we prove that a standard encoder-decoder network that takes d-dimensional images as input, with l pooling layers and pooling factor f, has the capacity to distinguish at most f^(dl) same-looking objects, and we show that this upper limit can be reached. Furthermore, we show that to avoid discontinuities in a tile-and-stitch approach, assuming standard batch size 1, it is necessary to employ valid convolutions in combination with a training output window size strictly greater than f^ l, while at test-time it is necessary to crop tiles to size n* f^ l before stitching, with n>= 1. We complement these theoretical findings by discussing a number of insightful special cases for which we show empirical results on synthetic and real data.",http://openaccess.thecvf.com/content/ICCV2021/html/Rumberger_How_Shift_Equivariance_Impacts_Metric_Learning_for_Instance_Segmentation_ICCV_2021_paper.html
Jan Funke,Inpainting Networks Learn to Separate Cells in Microscopy Images,2020,British Machine Vision Conference,4,"Steffen Wolf, Fred A Hamprecht, Jan Funke",Steffen Wolf,Jan Funke,3,"Deep neural networks trained to inpaint partially occluded images show a deep understanding of image composition and have even been shown to remove objects from images convincingly. In this work, we investigate how this implicit knowledge of image composition can be be used to separate cells in densely populated microscopy images. We propose a measure for the independence of two image regions given a fully selfsupervised inpainting network and separate objects by maximizing this independence. We evaluate our method on two cell segmentation datasets and show that cells can be separated without any supervision. Furthermore, combined with simple foreground detection, our method yields instance segmentation of similar quality to fully supervised methods.",http://129.206.117.249/sites/default/files/publications/files/852479027/wolf_20_inpainting-min.pdf
Jan Funke,Unsupervised Learning of Object-Centric Embeddings for Cell Instance Segmentation in Microscopy Images,2023,Proceedings of the IEEE/CVF International Conference on Computer Vision,3,"Steffen Wolf, Manan Lalit, Henry Westmacott, Katie McDole, Jan Funke",Steffen Wolf,Jan Funke,5,"Segmentation of objects in microscopy images is required for many biomedical applications. We introduce object-centric embeddings (OCEs), which embed image patches such that the spatial offsets between patches cropped from the same object are preserved. Those learnt embeddings can be used to delineate individual objects and thus obtain instance segmentations. Here, we show theoretically that, under assumptions commonly found in microscopy images, OCEs can be learnt through a self-supervised task that predicts the spatial offset between image patches. Together, this forms an unsupervised cell instance segmentation method which we evaluate on nine diverse large-scale microscopy datasets. Segmentations obtained with our method lead to substantially improved results, compared to a state-of-the-art baseline on six out of nine datasets, and perform on par on the remaining three datasets. If ground-truth annotations are available, our method serves as an excellent starting point for supervised training, reducing the required amount of ground-truth needed by one order of magnitude, thus substantially increasing the practical applicability of our method. Source code is available at github. com/funkelab/cellulus.",http://openaccess.thecvf.com/content/ICCV2023/html/Wolf_Unsupervised_Learning_of_Object-Centric_Embeddings_for_Cell_Instance_Segmentation_in_ICCV_2023_paper.html
Jan Funke,Instance separation emerges from inpainting,2020,arXiv preprint arXiv:2003.00891,3,"Steffen Wolf, Fred A Hamprecht, Jan Funke",Steffen Wolf,Jan Funke,3,"Deep neural networks trained to inpaint partially occluded images show a deep understanding of image composition and have even been shown to remove objects from images convincingly. In this work, we investigate how this implicit knowledge of image composition can be leveraged for fully self-supervised instance separation. We propose a measure for the independence of two image regions given a fully self-supervised inpainting network and separate objects by maximizing this independence. We evaluate our method on two microscopy image datasets and show that it reaches similar segmentation performance to fully supervised methods.",https://arxiv.org/abs/2003.00891
Jan Funke,Neural-circuit basis of song preference learning in fruit flies,2024,iScience,1,"Keisuke Imoto, Yuki Ishikawa, Yoshinori Aso, Jan Funke, Ryoya Tanaka, Azusa Kamikouchi",Keisuke Imoto,Azusa Kamikouchi,6,"As observed in human language learning and song learning in birds, the fruit fly Drosophila melanogaster changes its auditory behaviors according to prior sound experiences. This phenomenon, known as song preference learning in flies, requires GABAergic input to pC1 neurons in the brain, with these neurons playing a key role in mating behavior. The neural circuit basis of this GABAergic input, however, is not known. Here, we find that GABAergic neurons expressing the sex-determination gene doublesex are necessary for song preference learning. In the brain, only four doublesex-expressing GABAergic neurons exist per hemibrain, identified as pCd-2 neurons. pCd-2 neurons directly, and in many cases mutually, connect with pC1 neurons, suggesting the existence of reciprocal circuits between them. Moreover, GABAergic and dopaminergic inputs to doublesex-expressing GABAergic neurons are necessary …",https://www.cell.com/iscience/fulltext/S2589-0042(24)01491-3
Jan Funke,Publisher Correction: Structured cerebellar connectivity supports resilient pattern separation,2023,Nature,1,"Tri M Nguyen, Logan A Thomas, Jeff L Rhoades, Ilaria Ricchi, Xintong Cindy Yuan, Arlo Sheridan, David GC Hildebrand, Jan Funke, Wade G Regehr, Wei-Chung Allen Lee",Tri M Nguyen,Wei-Chung Allen Lee,10,"Publisher Correction: Structured cerebellar connectivity supports resilient pattern separation 
Publisher Correction: Structured cerebellar connectivity supports resilient pattern separation 
Nature. 2023 Feb;614(7946):E18. doi: 10.1038/s41586-023-05703-7. Authors Tri M Nguyen # 
1 , Logan A Thomas # 1 2 , Jeff L Rhoades 1 3 , Ilaria Ricchi 1 4 , Xintong Cindy Yuan 1 3 , Arlo 
Sheridan 5 6 , David GC Hildebrand 1 7 , Jan Funke 5 , Wade G Regehr 1 , Wei-Chung Allen 
Lee 8 Affiliations 1 Department of Neurobiology, Harvard Medical School, Boston, MA, USA. 2 
Biophysics Graduate Group, University of California Berkeley, Berkeley, CA, USA. 3 Program 
in Neuroscience, Division of Medical Sciences, Graduate School of Arts and Sciences, 
Harvard University, Cambridge, MA, USA. 4 Neuro-X Institute, École Polytechnique Fédérale 
de Lausanne (EPFL), Geneva, Switzerland. 5 HHMI Janelia Research Campus, Ashburn, …",https://pubmed.ncbi.nlm.nih.gov/36631615/
Jan Funke,Physics-Informed Variational Autoencoder for Undersampled Fourier Ptychography,2022,Computational Optical Sensing and Imaging,1,"Yolanda Hu, Andrew Olsen, Jan Funke, Srinivas Turaga, Vidya Ganapati",Yolanda Hu,Vidya Ganapati,5,"This paper presents an unsupervised deep learning method for complex object reconstruction in severely undersampled Fourier ptychographic microscopy. The method requires no ground truth objects, only a dataset of undersampled measurements.",https://opg.optica.org/abstract.cfm?uri=COSI-2022-CF1D.8
Jan Funke,Which image-based phenotypes are most promising for using AI to understand cellular functions and why?,2021,Cell Systems,1,"Emma Lundberg, Jan Funke, Virginie Uhlmann, Daniel Gerlich, Thomas Walter, Anne Carpenter, Luis Pedro Coelho",Emma Lundberg,Luis Pedro Coelho,7,"Finding rare phenotypes Developments in microscopy and visualization techniques have long pushed the boundaries of our understanding of cells. With powerful machine-learning techniques, we’re now facing a paradigm shift in image analysis for cell biology. Conventionally, image-based phenotypes have been described using a selected set of features we can easily intuit, such as shape or marker intensity. In the deep-learning era, neural network models can automatically learn representations of cellular phenotypes. These deep-learning features are data-driven, scalable, and sensitive to the representation of sophisticated or hidden patterns in the images. This comes with possibilities like continuous modeling of cell phenotypes and the discovery of rare or new phenotypes by deep anomaly detection.The challenge will be to translate the unexpected phenotypes unraveled with machine learning into deeper …",https://www.cell.com/cell-systems/fulltext/S2405-4712(21)00155-1
Jan Funke,Tracking of microtubules in anisotropic volumes of neural tissue,2016,2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI),1,"Julia M Buhmann, Stephan Gerhard, Matthew Cook, Jan Funke",Julia M Buhmann,Jan Funke,4,"For both the automatic and manual reconstruction of neural circuits from electron microscopy (EM) images, the detection and identification of intracellular structures provide useful cues. This is particularly true for microtubules which are indicative of the scaffold of neuronal morphology. However, to our knowledge, the automated reconstruction of microtubules from EM images of neural tissue has received no attention so far. In this paper, we present an automatic method for the tracking of microtubules in 3D EM volumes of neural tissue. We formulate an energy-based model on short candidate segments of microtubules found by a local classifier. We enumerate and score possible links between candidates, in order to find a cost-minimal subset of candidates and links by solving an integer linear program. The model provides a way to incorporate biological priors including both hard constraints (e.g. microtubules are …",https://ieeexplore.ieee.org/abstract/document/7493275/
Jan Funke,Structured learning of assignment models for neuron reconstruction to minimize topological errors,2016,2016 IEEE 13th International Symposium on Biomedical Imaging (ISBI),1,"Jan Funke, Jonas Klein, Francesc Moreno-Noguer, Albert Cardona, Matthew Cook",Jan Funke,Matthew Cook,5,"Structured learning provides a powerful framework for empirical risk minimization on the predictions of structured models. It allows end-to-end learning of model parameters to minimize an application specific loss function. This framework is particularly well suited for discrete optimization models that are used for neuron reconstruction from anisotropic electron microscopy (EM) volumes. However, current methods are still learning unary potentials by training a classifier that is agnostic about the model it is used in. We believe the reason for that lies in the difficulties of (1) finding a representative training sample, and (2) designing an application specific loss function that captures the quality of a proposed solution. In this paper, we show how to find a representative training sample from human generated ground truth, and propose a loss function that is suitable to minimize topological errors in the reconstruction. We …",https://ieeexplore.ieee.org/abstract/document/7493341/
Jan Funke,DaCapo: a modular deep learning framework for scalable 3D image segmentation,2024,arXiv preprint arXiv:2408.02834,0,"William Patton, Jeff L Rhoades, Marwan Zouinkhi, David G Ackerman, Caroline Malin-Mayor, Diane Adjavon, Larissa Heinrich, Davis Bennett, Yurii Zubov, CellMap Project Team, Aubrey V Weigel, Jan Funke",William Patton,Jan Funke,12,"DaCapo is a specialized deep learning library tailored to expedite the training and application of existing machine learning approaches on large, near-isotropic image data. In this correspondence, we introduce DaCapo's unique features optimized for this specific domain, highlighting its modular structure, efficient experiment management tools, and scalable deployment capabilities. We discuss its potential to improve access to large-scale, isotropic image segmentation and invite the community to explore and contribute to this open-source initiative.",https://arxiv.org/abs/2408.02834
Jan Funke,A Bayesian Solution to Count the Number of Molecules within a Diffraction Limited Spot,2024,bioRxiv,0,"Alexander Hillsley, Johannes Stein, Paul W Tillberg, David L Stern, Jan Funke",Alexander Hillsley,Jan Funke,5,"We address the problem of inferring the number of in-dependently blinking fluorescent light emitters, when only their combined intensity contributions can be observed at each timepoint. This problem occurs regularly in light microscopy of objects that are smaller than the diffraction limit, where one wishes to count the number of fluorescently labelled subunits. Our proposed solution directly models the photo-physics of the system, as well as the blinking kinetics of the fluorescent emitters as a fully differentiable hidden Markov model. Given a trace of intensity over time, our model jointly estimates the parameters of the intensity distribution per emitter, their blinking rates, as well as a posterior distribution of the total number of fluorescent emitters. We show that our model is consistently more accurate and increases the range of countable subunits by a factor of two compared to current state-of-the-art methods, which count based on autocorrelation and blinking frequency, Further-more, we demonstrate that our model can be used to investigate the effect of blinking kinetics on counting ability, and therefore can inform experimental conditions that will maximize counting accuracy.",https://www.biorxiv.org/content/10.1101/2024.04.18.590066.abstract
Jan Funke,Spatial single-cell Organellomics reveals nutrient dependent hepatocyte heterogeneity and predicts pathophysiological status in vivo,2024,bioRxiv,0,"Alexander Hillsley, Raghabendra Adhikari, Alana Dowdell Johnson, Isabel Espinosa-Medina, Jan Funke, Daniel Feliciano",Alexander Hillsley,Daniel Feliciano,6,"Cellular heterogeneity within complex tissues and organs is essential to coordinate biological processes across biological scales. The effect of local cues and tissue microenvironments on cell heterogeneity has been mainly studied at the transcriptional level. However, it is within the subcellular scale - the organelles - that lays the machinery to conduct most metabolic reactions and maintain cells alive, ensuring proper tissue function. How changes in subcellular organization under different microenvironments define the functional diversity of cells within organs remains largely unexplored. Here we determine how organelles adapt to different microenvironments using the mouse liver as model system, in combination with computational approaches and machine-learning. To understand organelle adaptation in response to changing nutritional conditions, we analyzed 3D fluorescent microscopy volumes of liver samples labeled to simultaneously visualize mitochondria, peroxisomes, and lipid droplets from mice subjected to different diets: a control diet, a high-fat diet, and a control diet plus fasting. A Cellpose based pipeline was implemented for cell and organelle segmentation, which allowed us to measure ~100 different organelle metrics and helped us define subcellular architectures in liver samples at the single cell level. Our results showed that hepatocytes display distinct subcellular architectures within different regions of the liver -close to the central vein, in the middle region, and near the portal vein- and across the various diet groups, thus reflecting their adaptation to specific nutritional inputs. Principal component analysis and clustering of …",https://www.biorxiv.org/content/10.1101/2024.12.06.627285.abstract
Jan Funke,Quantitative Attributions with Counterfactuals,2024,bioRxiv,0,"Diane-Yayra Adjavon, Nils Eckstein, Alexander S Bates, Gregory SXE Jefferis, Jan Funke",Diane-Yayra Adjavon,Jan Funke,5,"We address the problem of explaining the decision process of deep neural network classifiers on images, which is of particular importance in biomedical datasets where class-relevant differences are not always obvious to a human observer. Our proposed solution, termed quantitative attribution with counterfactuals (QuAC), generates visual explanations that highlight class-relevant differences by attributing the classifier decision to changes of visual features in small parts of an image. To that end, we train a separate network to generate counterfactual images (i.e., to translate images between different classes). We then find the most important differences using novel discriminative attribution methods. Crucially, QuAC allows scoring of the attribution and thus provides a measure to quantify and compare the fidelity of a visual explanation. We demonstrate the suitability and limitations of QuAC on two datasets: (1) a synthetic dataset with known class differences, representing different levels of protein aggregation in cells and (2) an electron microscopy dataset of D. melanogaster synapses with different neurotransmitters, where QuAC reveals so far unknown visual differences. We further discuss how QuAC can be used to interrogate mispredictions to shed light on unexpected inter-class similarities and intra-class differences.",https://www.biorxiv.org/content/10.1101/2024.11.26.625505.abstract
Jan Funke,Towards Generalizable Organelle Segmentation in Volume Electron Microscopy,2023,,0,"Larissa Heinrich, Will Patton, Davis Bennett, David Ackerman, Grace Park, John A Bogovic, Nils Eckstein, Alyson Petruncio, Jody Clements, Song Pang, C Shan Xu, Jan Funke, Wyatt Korff, Harald Hess, Jennifer Lippincott-Schwartz, Stephan Saalfeld, Aubrey Weigel, CellMap Project Team",Larissa Heinrich,CellMap Project Team,18,"Volume electron microscopy enables the joint visualization of multiple subcellular structures within the same sample, making it an ideal tool for studying interactions between different organelles at high resolution. However, the identification of these structures relies solely on their texture and morphology, and as a result, advanced image analysis methods are required to reconstruct them at scale. Recent advancements in machine learning techniques for analyzing this data are leading to new discoveries about the inner workings of cells and tissues.We manually annotated 36 subcellular structures in small blocks from high-resolution focused ion beam scanning electron microscopy data of various cell types and tissues. With this diverse set of ground truth, we trained deep neural networks to predict signed boundary distances for each organelle that we can use to generate large scale reconstructions for a variety of …",https://academic.oup.com/mam/article-abstract/29/Supplement_1/975/7228807
Jan Funke,Unpaired Image Enhancement for Neurite Segmentation in x-ray Tomography,2023,2023 IEEE 20th International Symposium on Biomedical Imaging (ISBI),0,"Jeff L Rhoades, Arlo Sheridan, Mukul Narwani, Brian Reicher, Mark Larson, Shuhan Xie, Tri Nguyen, Aaron Kuan, Alexandra Pacureanu, Wei-Chung Allen Lee, Jan Funke",Jeff L Rhoades,Jan Funke,11,"As the field of connectomics strives to tackle questions regarding increasingly large neuronal circuits, technologies improving imaging throughput will be vital. X-Ray Holographic Nanotomography (XNH) may play a key role, by allowing for fast, non-destructive, multi-resolution imaging. XNH is well suited for rapidly imaging large tissue volumes, with throughput easily increased at the cost of resolution and image quality. We therefore set out to systematically examine the potential for cycle-consistent generative adversarial networks (CycleGANs) to facilitate high-quality segmentation from low-quality data. Additionally, we introduce the Split Cycle-GAN, a modification of the original formulation designed to prevent collaboration between generators that could result in hidden features in generated images. We find that our new formulation, as well as the original CycleGAN, both improve segmentation results over the …",https://ieeexplore.ieee.org/abstract/document/10230381/
Jan Funke,Research briefing,2023,Nature Methods,0,"Arlo Sheridan, Jan Funke",Arlo Sheridan,Jan Funke,2,We developed an advanced deep learning approach called local shape descriptors (LSDs) to enable analysis of large electron microscopy datasets with increased efficiency. This technique will speed processing of future petabyte-sized datasets and democratize connectomics research by enabling these analyses using modest computational infrastructure available to most laboratories.,https://www.nature.com/articles/s41592-022-01712-y
Jan Funke,Artificial intelligence gives neuron reconstruction a performance boost,2023,,0,"Arlo Sheridan, Jan Funke",Arlo Sheridan,Jan Funke,2,We developed an advanced deep learning approach called local shape descriptors (LSDs) to enable analysis of large electron microscopy datasets with increased efficiency. This technique will speed processing of future petabyte-sized datasets and democratize connectomics research by enabling these analyses using modest computational infrastructure available to most laboratories.,https://scholar.google.com/scholar?cluster=13769100735889273629&hl=en&oi=scholarr
Jan Funke,Ultrastructural readout of in vivo synaptic activity for functional connectomics,2021,BioRxiv,0,"Anna Simon, Arnd Roth, Arlo Sheridan, Mehmet Fişek, Vincenzo Marra, Claudia Racca, Jan Funke, Kevin Staras, Michael Häusser",Anna Simon,Michael Häusser,9,"Large-volume ultrastructural mapping approaches yield detailed circuit wiring diagrams but lack an integrated synaptic activity readout which is essential for functional interpretation of the connectome. Here we resolve this limitation by combining functional synaptic labelling in vivo with focused ion-beam scanning electron microscopy (FIBSEM) and machine learning-based segmentation. Our approach generates high-resolution near-isotropic three-dimensional readouts of activated vesicle pools across large populations of individual synapses in a volume of tissue, opening the way for detailed functional connectomics studies. We apply this method to measure presynaptic activity in an ultrastructural context in synapses activated by sensory input in primary visual cortex in awake head-fixed mice, showing that the numbers of recycling and non-recycling vesicles approximate to a lognormal distribution across a large number of synapses. We also demonstrate that neighbouring boutons of the same axon, which share the same spiking activity, can differ greatly in their presynaptic release probability.",https://www.biorxiv.org/content/10.1101/2021.07.07.451278.abstract
Jan Funke,JAN-US,,,0,"Caroline Malin-Mayor, Peter Hirsch, Leo Guignard, Katie McDole, Yinan Wan, William C Lemon, Philipp J Keller, Stephan Preibisch, Jan Funke",Caroline Malin-Mayor,Jan Funke,9,"We use sparse point annotations to train a convolutional neural network to predict at each pixel a cell indicator value that peaks at the center of each nucleus [1, 2], and a movement vector that points to the center of the same cell nucleus in the previous time frame [3, 4]. From these predictions, we generate a candidate graph in two steps: first, we place nodes at the local maxima of the cell indicator values to represent possible cell center locations, with a score to encode the network's confidence. Second, we locally connect nodes in adjacent frames with edges to represent the possibility that the nodes represent the same cell, and assign a score to each edge based on agreement with the predicted movement vector. Next, we solve a global constrained optimization problem on the candidate graph to select a subset of nodes and edges that form coherent lineage trees. We know that between time frames, cells can move, divide into two, enter or leave the field of view, or die, but not merge or split into more than two. Thus, we introduce hard constraints to prevent merging and divisions producing more than two progeny. The objective function incorporates prior knowledge that cell movement is much more common than division, death, and entering or leaving the field of view, encouraging long, continuous lineages by penalizing the start and end of tracks. These tree constraints and continuity costs are similar to those in previous work [5, 6, 7]; however, we also incorporate the node and edge scores generated by the neural networks into the objective function as learned costs. Thus, we optimize for valid lineages that are both continuous and supported …",https://public.celltrackingchallenge.net/participants/JAN-US.pdf
Jan Funke,Supplementary Material How Shift Equivariance Impacts Metric Learning for Instance Segmentation,,,0,"Josef Lorenz Rumberger, Xiaoyan Yu, Peter Hirsch, Melanie Dohmen, Vanessa Emanuela Guarino, Ashkan Mokarian, Lisa Mais, Jan Funke, Dagmar Kainmueller",Josef Lorenz Rumberger,Dagmar Kainmueller,9,"Example 1: For a U-Net with identity convolutions, weights 0 for skip connections, and fixed upsampling, functions u that merely pass the value of a bottleneck pixel through to the output (cf. Fig. 1 in the main paper) are absolute-equal, yet relative-distinct.Example 2a: For a U-Net with output tile size w= 1 (ie a single output pixel per tile), employed in a sliding-window fashion (cf. Sec. 2.1 in the main paper), all functions u are relative-equal, yet absolute-distinct. Example 2b: For a U-Net with pooling factor f= 1 (ie no pooling and thus full shift equivariance), all functions u are relative-equal, yet absolute-distinct.",https://openaccess.thecvf.com/content/ICCV2021/supplemental/Rumberger_How_Shift_Equivariance_ICCV_2021_supplemental.pdf
Frank Hutter,Decoupled weight decay regularization,2017,ICLR 2019,25635,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=5602734827563786057&hl=en&oi=scholarr
Frank Hutter,Sgdr: Stochastic gradient descent with warm restarts,2016,ICLR 2017,9638,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,"Restart techniques are common in gradient-free optimization to deal with multimodal functions. Partial warm restarts are also gaining popularity in gradient-based optimization to improve the rate of convergence in accelerated gradient schemes to deal with ill-conditioned functions. In this paper, we propose a simple warm restart technique for stochastic gradient descent to improve its anytime performance when training deep neural networks. We empirically study its performance on the CIFAR-10 and CIFAR-100 datasets, where we demonstrate new state-of-the-art results at 3.14% and 16.21%, respectively. We also demonstrate its advantages on a dataset of EEG recordings and on a downsampled version of the ImageNet dataset. Our source code is available at https://github.com/loshchil/SGDR",https://arxiv.org/abs/1608.03983
Frank Hutter,Neural architecture search: A survey,2019,Journal of Machine Learning Research,3557,"Thomas Elsken, Jan Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,3,"Deep Learning has enabled remarkable progress over the last years on a variety of tasks, such as image recognition, speech recognition, and machine translation. One crucial aspect for this progress are novel neural architectures. Currently employed architectures have mostly been developed manually by human experts, which is a time-consuming and error-prone process. Because of this, there is growing interest in automated neural architecture search methods. We provide an overview of existing work in this field of research and categorize them according to three dimensions: search space, search strategy, and performance estimation strategy.",https://www.jmlr.org/papers/v20/18-598.html
Frank Hutter,Sequential model-based optimization for general algorithm configuration,2011,"Learning and Intelligent Optimization: 5th International Conference, LION 5, Rome, Italy, January 17-21, 2011. Selected Papers 5",3412,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We …",https://link.springer.com/chapter/10.1007/978-3-642-25566-3_40
Frank Hutter,Deep learning with convolutional neural networks for EEG decoding and visualization,2017,Human brain mapping,3075,"Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, Tonio Ball",Robin Tibor Schirrmeister,Tonio Ball,9,"Deep learning with convolutional neural networks (deep ConvNets) has revolutionized computer vision through end‐to‐end learning, that is, learning from the raw data. There is increasing interest in using deep ConvNets for end‐to‐end EEG analysis, but a better understanding of how to design and train ConvNets for end‐to‐end EEG decoding and how to visualize the informative EEG features the ConvNets learn is still needed. Here, we studied deep ConvNets with a range of different architectures, designed for decoding imagined or executed tasks from raw EEG. Our results show that recent advances from the machine learning field, including batch normalization and exponential linear units, together with a cropped training strategy, boosted the deep ConvNets decoding performance, reaching at least as good performance as the widely used filter bank common spatial patterns (FBCSP) algorithm (mean …",https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23730
Frank Hutter,Efficient and robust automated machine learning,2015,Advances in neural information processing systems,3022,"Matthias Feurer, Aaron Klein, Katharina Eggensperger, Jost Springenberg, Manuel Blum, Frank Hutter",Matthias Feurer,Frank Hutter,6,"The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. In this work we introduce a robust new AutoML system based on scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub auto-sklearn, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the first phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of auto-sklearn.",https://proceedings.neurips.cc/paper/2015/hash/11d0e6287202fced83f79975ec59a3a6-Abstract.html
Frank Hutter,"Automated machine learning: methods, systems, challenges",2019,,2263,"Frank Hutter, Lars Kotthoff, Joaquin Vanschoren",Frank Hutter,Joaquin Vanschoren,3,"This open access book presents the first comprehensive overview of general methods in Automated Machine Learning (AutoML), collects descriptions of existing systems based on these methods, and discusses the first series of international challenges of AutoML systems. The recent success of commercial ML applications and the rapid growth of the field has created a high demand for off-the-shelf ML methods that can be used easily and without expert knowledge. However, many of the recent machine learning successes crucially rely on human experts, who manually select appropriate ML architectures (deep learning architectures or more traditional ML workflows) and their hyperparameters. To overcome this problem, the field of AutoML targets a progressive automation of machine learning, based on principles from optimization and machine learning itself. This book serves as a point of entry into this quickly-developing field for researchers and advanced students alike, as well as providing a reference for practitioners aiming to use AutoML in their work.",https://library.oapen.org/handle/20.500.12657/23012
Frank Hutter,Auto-WEKA: Combined selection and hyperparameter optimization of classification algorithms,2013,,2135,"Chris Thornton, Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Chris Thornton,Kevin Leyton-Brown,4,"Many different machine learning algorithms exist; taking into account each algorithm's hyperparameters, there is a staggeringly large number of possible alternatives overall. We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters, going beyond previous work that attacks these issues separately. We show that this problem can be addressed by a fully automated approach, leveraging recent innovations in Bayesian optimization. Specifically, we consider a wide range of feature selection techniques (combining 3 search and 8 evaluator methods) and all classification approaches implemented in WEKA's standard distribution, spanning 2 ensemble methods, 10 meta-methods, 27 base classifiers, and hyperparameter settings for each classifier. On each of 21 popular datasets from the UCI repository, the KDD Cup 09, variants of the MNIST dataset and CIFAR-10, we …",https://dl.acm.org/doi/abs/10.1145/2487575.2487629
Frank Hutter,Hyperparameter optimization,2019,"Automated machine learning: Methods, systems, challenges",1800,"Matthias Feurer, Frank Hutter",Matthias Feurer,Frank Hutter,2,"Recent interest in complex and computationally expensive machine learning models with many hyperparameters, such as automated machine learning (AutoML) frameworks and deep neural networks, has resulted in a resurgence of research on hyperparameter optimization (HPO). In this chapter, we give an overview of the most prominent approaches for HPO. We first discuss blackbox function optimization methods based on model-free methods and Bayesian optimization. Since the high computational demand of many modern machine learning applications renders pure blackbox optimization extremely costly, we next focus on modern multi-fidelity methods that use (much) cheaper variants of the blackbox function to approximately assess the quality of hyperparameter settings. Lastly, we point to open problems and future research directions.",https://library.oapen.org/bitstream/handle/20.500.12657/23012/1/1007149.pdf#page=15
Frank Hutter,BOHB: Robust and efficient hyperparameter optimization at scale,2018,International conference on machine learning,1380,"Stefan Falkner, Aaron Klein, Frank Hutter",Stefan Falkner,Frank Hutter,3,"Modern deep learning methods are very sensitive to many hyperparameters, and, due to the long training times of state-of-the-art models, vanilla Bayesian hyperparameter optimization is typically computationally infeasible. On the other hand, bandit-based configuration evaluation approaches based on random search lack guidance and do not converge to the best configurations as quickly. Here, we propose to combine the benefits of both Bayesian optimization and bandit-based methods, in order to achieve the best of both worlds: strong anytime performance and fast convergence to optimal configurations. We propose a new practical state-of-the-art hyperparameter optimization method, which consistently outperforms both Bayesian optimization and Hyperband on a wide range of problem types, including high-dimensional toy functions, support vector machines, feed-forward neural networks, Bayesian neural networks, deep reinforcement learning, and convolutional neural networks. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.",https://proceedings.mlr.press/v80/falkner18a.html
Frank Hutter,ParamILS: an automatic algorithm configuration framework,2009,Journal of artificial intelligence research,1303,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown, Thomas Stützle",Frank Hutter,Thomas Stützle,4,"The identification of performance-optimizing parameter settings is an important part of the development and application of algorithms. We describe an automatic framework for this algorithm configuration problem. More formally, we provide methods for optimizing a target algorithms performance on a given class of problem instances by varying a set of ordinal and/or categorical parameters. We review a family of local-search-based algorithm configuration procedures and present novel techniques for accelerating them by adaptively limiting the time spent for evaluating individual configurations. We describe the results of a comprehensive experimental evaluation of our methods, based on the configuration of prominent complete and incomplete algorithms for SAT. We also present what is, to our knowledge, the first published work on automatically configuring the CPLEX mixed integer programming solver. All the algorithms we considered had default parameter settings that were manually identified with considerable effort. Nevertheless, using our automated algorithm configuration procedures, we achieved substantial and consistent performance improvements.",http://www.jair.org/index.php/jair/article/view/10628
Frank Hutter,SATzilla: portfolio-based algorithm selection for SAT,2008,Journal of artificial intelligence research,1184,"Lin Xu, Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"It has been widely observed that there is no single"" dominant"" SAT solver; instead, different solvers perform best on different instances. Rather than following the traditional approach of choosing the best solver for a given class of instances, we advocate making this decision online on a per-instance basis. Building on previous work, we describe SATzilla, an automated approach for constructing per-instance algorithm portfolios for SAT that use so-called empirical hardness models to choose among their constituent solvers. This approach takes as input a distribution of problem instances and a set of component solvers, and constructs a portfolio optimizing a given objective function (such as mean runtime, percent of instances solved, or score in a competition). The excellent performance of SATzilla was independently verified in the 2007 SAT Competition, where our SATzilla07 solvers won three gold, one silver and one bronze medal. In this article, we go well beyond SATzilla07 by making the portfolio construction scalable and completely automated, and improving it by integrating local search solvers as candidate solvers, by predicting performance score instead of runtime, and by using hierarchical hardness models that take into account different types of SAT instances. We demonstrate the effectiveness of these new techniques in extensive experimental results on data sets including instances from the most recent SAT competition.",https://www.jair.org/index.php/jair/article/view/10556
Frank Hutter,Auto-WEKA 2.0: Automatic model selection and hyperparameter optimization in WEKA,2017,Journal of Machine Learning Research,1000,"Lars Kotthoff, Chris Thornton, Holger H Hoos, Frank Hutter, Kevin Leyton-Brown",Lars Kotthoff,Kevin Leyton-Brown,5,"WEKA is a widely used, open-source machine learning platform. Due to its intuitive interface, it is particularly popular with novice users. However, such users often find it hard to identify the best approach for their particular dataset among the many available. We describe the new version of Auto-WEKA, a system designed to help such users by automatically searching through the joint space of WEKA's learning algorithms and their respective hyperparameter settings to maximize performance, using a state-of-the-art Bayesian optimization method. Our new package is tightly integrated with WEKA, making it just as accessible to end users as any other learning algorithm.",https://www.jmlr.org/papers/v18/16-261.html
Frank Hutter,Bayesian optimization in a billion dimensions via random embeddings,2016,Journal of Artificial Intelligence Research,889,"Ziyu Wang, Frank Hutter, Masrour Zoghi, David Matheson, Nando De Feitas",Ziyu Wang,Nando De Feitas,5,"Bayesian optimization techniques have been successfully applied to robotics, planning, sensor placement, recommendation, advertising, intelligent user interfaces and automatic algorithm configuration. Despite these successes, the approach is restricted to problems of moderate dimension, and several workshops on Bayesian optimization have identified its scaling to high-dimensions as one of the holy grails of the field. In this paper, we introduce a novel random embedding idea to attack this problem. The resulting Random EMbedding Bayesian Optimization (REMBO) algorithm is very simple, has important invariance properties, and applies to domains with both categorical and continuous variables. We present a thorough theoretical analysis of REMBO. Empirical results confirm that REMBO can effectively solve problems with billions of dimensions, provided the intrinsic dimensionality is low. They also show that REMBO achieves state-of-the-art performance in optimizing the 47 discrete parameters of a popular mixed integer linear programming solver.",https://www.jair.org/index.php/jair/article/view/10983
Frank Hutter,Nas-bench-101: Towards reproducible neural architecture search,2019,International conference on machine learning,851,"Chris Ying, Aaron Klein, Eric Christiansen, Esteban Real, Kevin Murphy, Frank Hutter",Chris Ying,Frank Hutter,6,"Recent advances in neural architecture search (NAS) demand tremendous computational resources, which makes it difficult to reproduce experiments and imposes a barrier-to-entry to researchers without access to large-scale computation. We aim to ameliorate these problems by introducing NAS-Bench-101, the first public architecture dataset for NAS research. To build NAS-Bench-101, we carefully constructed a compact, yet expressive, search space, exploiting graph isomorphisms to identify 423k unique convolutional architectures. We trained and evaluated all of these architectures multiple times on CIFAR-10 and compiled the results into a large dataset of over 5 million trained models. This allows researchers to evaluate the quality of a diverse range of models in milliseconds by querying the pre-computed dataset. We demonstrate its utility by analyzing the dataset as a whole and by benchmarking a range of architecture optimization algorithms.",http://proceedings.mlr.press/v97/ying19a
Frank Hutter,Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves,2015,Twenty-fourth international joint conference on artificial intelligence,819,"Tobias Domhan, Jost Tobias Springenberg, Frank Hutter",Tobias Domhan,Frank Hutter,3,"Deep neural networks (DNNs) show very strong performance on many machine learning problems, but they are very sensitive to the setting of their hyperparameters. Automated hyperparameter optimization methods have recently been shown to yield settings competitive with those found by human experts, but their widespread adoption is hampered by the fact that they require more computational resources than human experts. Humans have one advantage: when they evaluate a poor hyperparameter setting they can quickly detect (after a few steps of stochastic gradient descent) that the resulting network performs poorly and terminate the corresponding evaluation to save time. In this paper, we mimic the early termination of bad runs using a probabilistic model that extrapolates the performance from the first part of a learning curve. Experiments with a broad range of neural network architectures on various prominent object recognition benchmarks show that our resulting approach speeds up state-of-the-art hyperparameter optimization methods for DNNs roughly twofold, enabling them to find DNN settings that yield better performance than those chosen by human experts.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/15-IJCAI-Extrapolation_of_Learning_Curves.pdf
Frank Hutter,Fast bayesian optimization of machine learning hyperparameters on large datasets,2017,Artificial intelligence and statistics,753,"Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, Frank Hutter",Aaron Klein,Frank Hutter,5,"Bayesian optimization has become a successful tool for hyperparameter optimization of machine learning algorithms, such as support vector machines or deep neural networks. Despite its success, for large datasets, training and validating a single configuration often takes hours, days, or even weeks, which limits the achievable performance. To accelerate hyperparameter optimization, we propose a generative model for the validation error as a function of training set size, which is learned during the optimization process and allows exploration of preliminary configurations on small subsets, by extrapolating to the full dataset. We construct a Bayesian optimization procedure, dubbed FABOLAS, which models loss and training time as a function of dataset size and automatically trades off high information gain about the global optimum against computational cost. Experiments optimizing support vector machines and deep neural networks show that FABOLAS often finds high-quality solutions 10 to 100 times faster than other state-of-the-art Bayesian optimization methods or the recently proposed bandit strategy Hyperband.",http://proceedings.mlr.press/v54/klein17a.html
Frank Hutter,A downsampled variant of imagenet as an alternative to the cifar datasets,2017,arXiv preprint arXiv:1707.08819,706,"Patryk Chrabaszcz, Ilya Loshchilov, Frank Hutter",Patryk Chrabaszcz,Frank Hutter,3,"The original ImageNet dataset is a popular large-scale benchmark for training Deep Neural Networks. Since the cost of performing experiments (e.g, algorithm design, architecture search, and hyperparameter tuning) on the original dataset might be prohibitive, we propose to consider a downsampled version of ImageNet. In contrast to the CIFAR datasets and earlier downsampled versions of ImageNet, our proposed ImageNet3232 (and its variants ImageNet6464 and ImageNet1616) contains exactly the same number of classes and images as ImageNet, with the only difference that the images are downsampled to 3232 pixels per image (6464 and 1616 pixels for the variants, respectively). Experiments on these downsampled variants are dramatically faster than on the original ImageNet and the characteristics of the downsampled datasets with respect to optimal hyperparameters appear to remain similar. The proposed datasets and scripts to reproduce our results are available at http://image-net.org/download-images and https://github.com/PatrykChrabaszcz/Imagenet32_Scripts",https://arxiv.org/abs/1707.08819
Frank Hutter,Efficient multi-objective neural architecture search via lamarckian evolution,2018,arXiv preprint arXiv:1804.09081,661,"Thomas Elsken, Jan Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,3,"Neural Architecture Search aims at automatically finding neural architectures that are competitive with architectures designed by human experts. While recent approaches have achieved state-of-the-art predictive performance for image recognition, they are problematic under resource constraints for two reasons: (1)the neural architectures found are solely optimized for high predictive performance, without penalizing excessive resource consumption, (2) most architecture search methods require vast computational resources. We address the first shortcoming by proposing LEMONADE, an evolutionary algorithm for multi-objective architecture search that allows approximating the entire Pareto-front of architectures under multiple objectives, such as predictive performance and number of parameters, in a single run of the method. We address the second shortcoming by proposing a Lamarckian inheritance mechanism for LEMONADE which generates children networks that are warmstarted with the predictive performance of their trained parents. This is accomplished by using (approximate) network morphism operators for generating children. The combination of these two contributions allows finding models that are on par or even outperform both hand-crafted as well as automatically-designed networks.",https://arxiv.org/abs/1804.09081
Frank Hutter,An efficient approach for assessing hyperparameter importance,2014,International conference on machine learning,651,"Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"The performance of many machine learning methods depends critically on hyperparameter settings. Sophisticated Bayesian optimization methods have recently achieved considerable successes in optimizing these hyperparameters, in several cases surpassing the performance of human experts. However, blind reliance on such methods can leave end users without insight into the relative importance of different hyperparameters and their interactions. This paper describes efficient methods that can be used to gain such insight, leveraging random forest models fit on the data already gathered by Bayesian optimization. We first introduce a novel, linear-time algorithm for computing marginals of random forest predictions and then show how to leverage these predictions within a functional ANOVA framework, to quantify the importance of both single hyperparameters and of interactions between hyperparameters. We conducted experiments with prominent machine learning frameworks and state-of-the-art solvers for combinatorial problems. We show that our methods provide insight into the relationship between hyperparameter settings and performance, and demonstrate that—even in very high-dimensional cases—most performance variation is attributable to just a few hyperparameters.",http://proceedings.mlr.press/v32/hutter14.html
Frank Hutter,Algorithm runtime prediction: Methods & evaluation,2014,Artificial Intelligence,594,"Frank Hutter, Lin Xu, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,4,"Perhaps surprisingly, it is possible to predict how long an algorithm will take to run on a previously unseen input, using machine learning techniques to build a model of the algorithmʼs runtime as a function of problem-specific instance features. Such models have important applications to algorithm analysis, portfolio-based algorithm selection, and the automatic configuration of parameterized algorithms. Over the past decade, a wide variety of techniques have been studied for building such models. Here, we describe extensions and improvements of existing models, new families of models, and—perhaps most importantly—a much more thorough treatment of algorithm parameters as model inputs. We also comprehensively describe new and existing features for predicting algorithm runtime for propositional satisfiability (SAT), travelling salesperson (TSP) and mixed integer programming (MIP) problems. We …",https://www.sciencedirect.com/science/article/pii/S0004370213001082
Frank Hutter,Initializing Bayesian Hyperparameter Optimization via Meta-Learning.,2015,AAAI,593,"Matthias Feurer, Jost Tobias Springenberg, Frank Hutter",Matthias Feurer,Frank Hutter,3,"Model selection and hyperparameter optimization is crucial in applying machine learning to a novel dataset. Recently, a subcommunity of machine learning has focused on solving this problem with Sequential Model-based Bayesian Optimization (SMBO), demonstrating substantial successes in many applications. However, for computationally expensive algorithms the overhead of hyperparameter optimization can still be prohibitive. In this paper we mimic a strategy human domain experts use: speed up optimization by starting from promising configurations that performed well on similar datasets. The resulting initialization technique integrates naturally into the generic SMBO framework and can be trivially applied to any SMBO method. To validate our approach, we perform extensive experiments with two established SMBO frameworks (Spearmint and SMAC) with complementary strengths; optimizing two machine learning frameworks on 57 datasets. Our initialization procedure yields mild improvements for low-dimensional hyperparameter optimization and substantially improves the state of the art for the more complex combined algorithm selection and hyperparameter optimization problem.",https://ojs.aaai.org/index.php/AAAI/article/view/9354
Frank Hutter,Bayesian optimization with robust Bayesian neural networks,2016,Advances in neural information processing systems,557,"Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, Frank Hutter",Jost Tobias Springenberg,Frank Hutter,4,"Bayesian optimization is a prominent method for optimizing expensive to evaluate black-box functions that is prominently applied to tuning the hyperparameters of machine learning algorithms. Despite its successes, the prototypical Bayesian optimization approach-using Gaussian process models-does not scale well to either many hyperparameters or many function evaluations. Attacking this lack of scalability and flexibility is thus one of the key challenges of the field. We present a general approach for using flexible parametric models (neural networks) for Bayesian optimization, staying as close to a truly Bayesian treatment as possible. We obtain scalability through stochastic gradient Hamiltonian Monte Carlo, whose robustness we improve via a scale adaptation. Experiments including multi-task Bayesian optimization with 21 tasks, parallel optimization of deep neural networks and deep reinforcement learning show the power and flexibility of this approach.",https://proceedings.neurips.cc/paper/2016/hash/a96d3afec184766bfeca7a9f989fc7e7-Abstract.html
Frank Hutter,Towards an empirical foundation for assessing bayesian optimization of hyperparameters,2013,NIPS workshop on Bayesian Optimization in Theory and Practice,476,"Katharina Eggensperger, Matthias Feurer, Frank Hutter, James Bergstra, Jasper Snoek, Holger Hoos, Kevin Leyton-Brown",Katharina Eggensperger,Kevin Leyton-Brown,7,"Progress in practical Bayesian optimization is hampered by the fact that the only available standard benchmarks are artificial test functions that are not representative of practical applications. To alleviate this problem, we introduce a library of benchmarks from the prominent application of hyperparameter optimization and use it to compare Spearmint, TPE, and SMAC, three recent Bayesian optimization methods for hyperparameter optimization.",https://www.cs.ubc.ca/~hoos/Publ/EggEtAl13.pdf
Frank Hutter,Decoupled weight decay regularization. arXiv 2017,2023,arXiv preprint arXiv:1711.05101,470,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=2722639118997490474&hl=en&oi=scholarr
Frank Hutter,Understanding and robustifying differentiable architecture search,2019,arXiv preprint arXiv:1909.09656,435,"Arber Zela, Thomas Elsken, Tonmoy Saikia, Yassine Marrakchi, Thomas Brox, Frank Hutter",Arber Zela,Frank Hutter,6,"Differentiable Architecture Search (DARTS) has attracted a lot of attention due to its simplicity and small search costs achieved by a continuous relaxation and an approximation of the resulting bi-level optimization problem. However, DARTS does not work robustly for new problems: we identify a wide range of search spaces for which DARTS yields degenerate architectures with very poor test performance. We study this failure mode and show that, while DARTS successfully minimizes validation loss, the found solutions generalize poorly when they coincide with high validation loss curvature in the architecture space. We show that by adding one of various types of regularization we can robustify DARTS to find solutions with less curvature and better generalization properties. Based on these observations, we propose several simple variations of DARTS that perform substantially more robustly in practice. Our observations are robust across five search spaces on three image classification tasks and also hold for the very different domains of disparity estimation (a dense regression task) and language modelling.",https://arxiv.org/abs/1909.09656
Frank Hutter,Automatic algorithm configuration based on local search,2007,Aaai,413,"Frank Hutter, Holger H Hoos, Thomas Stützle",Frank Hutter,Thomas Stützle,3,"The determination of appropriate values for free algorithm parameters is a challenging and tedious task in the design of effective algorithms for hard problems. Such parameters include categorical choices (eg, neighborhood structure in local search or variable/value ordering heuristics in tree search), as well as numerical parameters (eg, noise or restart timing). In practice, tuning of these parameters is largely carried out manually by applying rules of thumb and crude heuristics, while more principled approaches are only rarely used. In this paper, we present a local search approach for algorithm configuration and prove its convergence to the globally optimal parameter configuration. Our approach is very versatile: it can, eg, be used for minimising run-time in decision problems or for maximising solution quality in optimisation problems. It further applies to arbitrary algorithms, including heuristic tree search and local search algorithms, with no limitation on the number of parameters. Experiments in four algorithm configuration scenarios demonstrate that our automatically determined parameter settings always outperform the algorithm defaults, sometimes by several orders of magnitude. Our approach also shows better performance and greater flexibility than the recent CALIBRA system. Our ParamILS code, along with instructions on how to use it for tuning your own algorithms, is available on-line at http://www. cs. ubc. ca/labs/beta/Projects/ParamILS.",https://cdn.aaai.org/AAAI/2007/AAAI07-183.pdf
Frank Hutter,CMA-ES for hyperparameter optimization of deep neural networks,2016,arXiv preprint arXiv:1604.07269,391,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,"Hyperparameters of deep neural networks are often optimized by grid search, random search or Bayesian optimization. As an alternative, we propose to use the Covariance Matrix Adaptation Evolution Strategy (CMA-ES), which is known for its state-of-the-art performance in derivative-free optimization. CMA-ES has some useful invariance properties and is friendly to parallel evaluations of solutions. We provide a toy example comparing CMA-ES and state-of-the-art Bayesian optimization algorithms for tuning the hyperparameters of a convolutional neural network for the MNIST dataset on 30 GPUs in parallel.",https://arxiv.org/abs/1604.07269
Frank Hutter,SMAC3: A versatile Bayesian optimization package for hyperparameter optimization,2022,Journal of Machine Learning Research,373,"Marius Lindauer, Katharina Eggensperger, Matthias Feurer, André Biedenkapp, Difan Deng, Carolin Benjamins, Tim Ruhkopf, René Sass, Frank Hutter",Marius Lindauer,Frank Hutter,9,"Algorithm parameters, in particular hyperparameters of machine learning algorithms, can substantially impact their performance. To support users in determining well-performing hyperparameter configurations for their algorithms, datasets and applications at hand, SMAC3 offers a robust and flexible framework for Bayesian Optimization, which can improve performance within a few evaluations. It offers several facades and pre-sets for typical use cases, such as optimizing hyperparameters, solving low dimensional continuous (artificial) global optimization problems and configuring algorithms to perform well across multiple problem instances. The SMAC3 package is available under a permissive BSD-license.",https://www.jmlr.org/papers/v23/21-0888.html
Frank Hutter,Towards automatically-tuned neural networks,2016,Workshop on automatic machine learning,370,"Hector Mendoza, Aaron Klein, Matthias Feurer, Jost Tobias Springenberg, Frank Hutter",Hector Mendoza,Frank Hutter,5,"Recent advances in AutoML have led to automated tools that can compete with machine learning experts on supervised learning tasks. However, current AutoML tools do not yet support modern neural networks effectively. In this work, we present a first version of Auto-Net, which provides automatically-tuned feed-forward neural networks without any human intervention. We report results on datasets from the recent AutoML challenge showing that ensembling Auto-Net with Auto-sklearn often performs better than either alone, and report the first results on winning a competition dataset against human experts with automatically-tuned neural networks.",http://proceedings.mlr.press/v64/mendoza_towards_2016.html?ref=https://githubhelp.com
Frank Hutter,The surprising creativity of digital evolution: A collection of anecdotes from the evolutionary computation and artificial life research communities,2020,Artificial life,365,"Joel Lehman, Jeff Clune, Dusan Misevic, Christoph Adami, Lee Altenberg, Julie Beaulieu, Peter J Bentley, Samuel Bernard, Guillaume Beslon, David M Bryson, Nick Cheney, Patryk Chrabaszcz, Antoine Cully, Stephane Doncieux, Fred C Dyer, Kai Olav Ellefsen, Robert Feldt, Stephan Fischer, Stephanie Forrest, Antoine Fŕenoy, Christian Gagńe, Leni Le Goff, Laura M Grabowski, Babak Hodjat, Frank Hutter, Laurent Keller, Carole Knibbe, Peter Krcah, Richard E Lenski, Hod Lipson, Robert MacCurdy, Carlos Maestre, Risto Miikkulainen, Sara Mitri, David E Moriarty, Jean-Baptiste Mouret, Anh Nguyen, Charles Ofria, Marc Parizeau, David Parsons, Robert T Pennock, William F Punch, Thomas S Ray, Marc Schoenauer, Eric Schulte, Karl Sims, Kenneth O Stanley, François Taddei, Danesh Tarapore, Simon Thibault, Richard Watson, Westley Weimer, Jason Yosinski",Joel Lehman,Jason Yosinski,53,"Evolution provides a creative fount of complex and subtle adaptations that often surprise the scientists who discover them. However, the creativity of evolution is not limited to the natural world: Artificial organisms evolving in computational environments have also elicited surprise and wonder from the researchers studying them. The process of evolution is an algorithmic process that transcends the substrate in which it occurs. Indeed, many researchers in the field of digital evolution can provide examples of how their evolving algorithms and organisms have creatively subverted their expectations or intentions, exposed unrecognized bugs in their code, produced unexpectedly adaptations, or engaged in behaviors and outcomes, uncannily convergent with ones found in nature. Such stories routinely reveal surprise and creativity by evolution in these digital worlds, but they rarely fit into the standard scientific …",https://direct.mit.edu/artl/article-abstract/26/2/274/93255
Frank Hutter,Online batch selection for faster training of neural networks,2015,arXiv preprint arXiv:1511.06343,345,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,"Deep neural networks are commonly trained using stochastic non-convex optimization procedures, which are driven by gradient information estimated on fractions (batches) of the dataset. While it is commonly accepted that batch size is an important parameter for offline tuning, the benefits of online selection of batches remain poorly understood. We investigate online batch selection strategies for two state-of-the-art methods of stochastic gradient-based optimization, AdaDelta and Adam. As the loss function to be minimized for the whole dataset is an aggregation of loss functions of individual datapoints, intuitively, datapoints with the greatest loss should be considered (selected in a batch) more frequently. However, the limitations of this intuition and the proper control of the selection pressure over time are open questions. We propose a simple strategy where all datapoints are ranked w.r.t. their latest known loss value and the probability to be selected decays exponentially as a function of rank. Our experimental results on the MNIST dataset suggest that selecting batches speeds up both AdaDelta and Adam by a factor of about 5.",https://arxiv.org/abs/1511.06343
Frank Hutter,Auto-sklearn 2.0: Hands-free automl via meta-learning,2022,Journal of Machine Learning Research,338,"Matthias Feurer, Katharina Eggensperger, Stefan Falkner, Marius Lindauer, Frank Hutter",Matthias Feurer,Frank Hutter,5,"Automated Machine Learning (AutoML) supports practitioners and researchers with the tedious task of designing machine learning pipelines and has recently achieved substantial success. In this paper, we introduce new AutoML approaches motivated by our winning submission to the second ChaLearn AutoML challenge. We develop PoSH Auto-sklearn, which enables AutoML systems to work well on large datasets under rigid time limits by using a new, simple and meta-feature-free meta-learning technique and by employing a successful bandit strategy for budget allocation. However, PoSH Auto-sklearn introduces even more ways of running AutoML and might make it harder for users to set it up correctly. Therefore, we also go one step further and study the design space of AutoML itself, proposing a solution towards truly hands-free AutoML. Together, these changes give rise to the next generation of our AutoML system, Auto-sklearn 2.0 . We verify the improvements by these additions in an extensive experimental study on 39 AutoML benchmark datasets. We conclude the paper by comparing to other popular AutoML frameworks and Auto-sklearn 1.0 , reducing the relative error by up to a factor of 4:5, and yielding a performance in 10 minutes that is substantially better than what Auto-sklearn 1.0 achieves within an hour.",https://www.jmlr.org/papers/v23/21-0992.html
Frank Hutter,Trivialaugment: Tuning-free yet state-of-the-art data augmentation,2021,Proceedings of the IEEE/CVF international conference on computer vision,320,"Samuel G Müller, Frank Hutter",Samuel G Müller,Frank Hutter,2,"Automatic augmentation methods have recently become a crucial pillar for strong model performance in vision tasks. While existing automatic augmentation methods need to trade off simplicity, cost and performance, we present a most simple baseline, TrivialAugment, that outperforms previous methods for almost free. TrivialAugment is parameter-free and only applies a single augmentation to each image. Thus, TrivialAugment's effectiveness is very unexpected to us and we performed very thorough experiments to study its performance. First, we compare TrivialAugment to previous state-of-the-art methods in a variety of image classification scenarios. Then, we perform multiple ablation studies with different augmentation spaces, augmentation methods and setups to understand the crucial requirements for its performance. Additionally, we provide a simple interface to facilitate the widespread adoption of automatic augmentation methods, as well as our full code base for reproducibility. Since our work reveals a stagnation in many parts of automatic augmentation research, we end with a short proposal of best practices for sustained future progress in automatic augmentation methods.",http://openaccess.thecvf.com/content/ICCV2021/html/Muller_TrivialAugment_Tuning-Free_Yet_State-of-the-Art_Data_Augmentation_ICCV_2021_paper.html
Frank Hutter,Simple and efficient architecture search for convolutional neural networks,2017,arXiv preprint arXiv:1711.04528,316,"Thomas Elsken, Jan-Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,3,"Neural networks have recently had a lot of success for many tasks. However, neural network architectures that perform well are still typically designed manually by experts in a cumbersome trial-and-error process. We propose a new method to automatically search for well-performing CNN architectures based on a simple hill climbing procedure whose operators apply network morphisms, followed by short optimization runs by cosine annealing. Surprisingly, this simple method yields competitive results, despite only requiring resources in the same order of magnitude as training a single network. E.g., on CIFAR-10, our method designs and trains networks with an error rate below 6% in only 12 hours on a single GPU; training for one day reduces this error further, to almost 5%.",https://arxiv.org/abs/1711.04528
Frank Hutter,Maximizing acquisition functions for Bayesian optimization,2018,Advances in neural information processing systems,310,"James Wilson, Frank Hutter, Marc Deisenroth",James Wilson,Marc Deisenroth,3,"Bayesian optimization is a sample-efficient approach to global optimization that relies on theoretically motivated value heuristics (acquisition functions) to guide its search process. Fully maximizing acquisition functions produces the Bayes' decision rule, but this ideal is difficult to achieve since these functions are frequently non-trivial to optimize. This statement is especially true when evaluating queries in parallel, where acquisition functions are routinely non-convex, high-dimensional, and intractable. We first show that acquisition functions estimated via Monte Carlo integration are consistently amenable to gradient-based optimization. Subsequently, we identify a common family of acquisition functions, including EI and UCB, whose characteristics not only facilitate but justify use of greedy approaches for their maximization.",https://proceedings.neurips.cc/paper/2018/hash/498f2c21688f6451d9f5fd09d53edda7-Abstract.html
Frank Hutter,Scaling and probabilistic smoothing: Efficient dynamic local search for SAT,2002,Principles and Practice of Constraint Programming-CP 2002,302,"Frank Hutter, Dave Tompkins, Holger Hoos",Frank Hutter,Holger Hoos,3,"In this paper, we study the approach of dynamic local search for the SAT problem. We focus on the recent and promising Exponentiated Sub-Gradient (ESG) algorithm, and examine the factors determining the time complexity of its search steps. Based on the insights gained from our analysis, we developed Scaling and Probabilistic Smoothing (SAPS), an efficient SAT algorithm that is conceptually closely related to ESG. We also introduce a reactive version of SAPS (RSAPS) that adaptively tunes one of the algorithm’s important parameters. We show that for a broad range of standard benchmark problems for SAT, SAPS and RSAPS achieve significantly better performance than both ESG and the state-of-the-art WalkSAT variant, Novelty+.",https://link.springer.com/chapter/10.1007/3-540-46135-3_16
Frank Hutter,AI for social good: unlocking the opportunity for positive impact,2020,,298,"Nenad Tomašev, Julien Cornebise, Frank Hutter, Shakir Mohamed, Angela Picciariello, Bec Connelly, Danielle CM Belgrave, Daphne Ezer, Fanny Cachat van der Haert, Frank Mugisha, Gerald Abila, Hiromi Arai, Hisham Almiraat, Julia Proskurnia, Kyle Snyder, Mihoko Otake-Matsuura, Mustafa Othman, Tobias Glasmachers, Wilfried de Wever, Yee Whye Teh, Mohammad Emtiyaz Khan, Ruben De Winne, Tom Schaul, Claudia Clopath",Nenad Tomašev,Claudia Clopath,24,"Advances in machine learning (ML) and artificial intelligence (AI) present an opportunity to build better tools and solutions to help address some of the world’s most pressing challenges, and deliver positive social impact in accordance with the priorities outlined in the United Nations’ 17 Sustainable Development Goals (SDGs). The AI for Social Good (AI4SG) movement aims to establish interdisciplinary partnerships centred around AI applications towards SDGs. We provide a set of guidelines for establishing successful long-term collaborations between AI researchers and application-domain experts, relate them to existing AI4SG projects and identify key opportunities for future AI applications targeted towards social good.",https://www.nature.com/articles/s41467-020-15871-z
Frank Hutter,Hyperparameter importance across datasets,2018,,298,"Jan N Van Rijn, Frank Hutter",Jan N Van Rijn,Frank Hutter,2,"With the advent of automated machine learning, automated hyperparameter optimization methods are by now routinely used in data mining. However, this progress is not yet matched by equal progress on automatic analyses that yield information beyond performance-optimizing hyperparameter settings. In this work, we aim to answer the following two questions: Given an algorithm, what are generally its most important hyperparameters, and what are typically good values for these? We present methodology and a framework to answer these questions based on meta-learning across many datasets. We apply this methodology using the experimental meta-data available on OpenML to determine the most important hyperparameters of support vector machines, random forests and Adaboost, and to infer priors for all their hyperparameters. The results, obtained fully automatically, provide a quantitative basis to focus …",https://dl.acm.org/doi/abs/10.1145/3219819.3220058
Frank Hutter,Aslib: A benchmark library for algorithm selection,2016,Artificial Intelligence,295,"Bernd Bischl, Pascal Kerschke, Lars Kotthoff, Marius Lindauer, Yuri Malitsky, Alexandre Fréchette, Holger Hoos, Frank Hutter, Kevin Leyton-Brown, Kevin Tierney, Joaquin Vanschoren",Bernd Bischl,Joaquin Vanschoren,11,"The task of algorithm selection involves choosing an algorithm from a set of algorithms on a per-instance basis in order to exploit the varying performance of algorithms over a set of instances. The algorithm selection problem is attracting increasing attention from researchers and practitioners in AI. Years of fruitful applications in a number of domains have resulted in a large amount of data, but the community lacks a standard format or repository for this data. This situation makes it difficult to share and compare different approaches effectively, as is done in other, more established fields. It also unnecessarily hinders new researchers who want to work in this area. To address this problem, we introduce a standardized format for representing algorithm selection scenarios and a repository that contains a growing number of data sets from the literature. Our format has been designed to be able to express a wide variety of …",https://www.sciencedirect.com/science/article/pii/S0004370216300388
Frank Hutter,Sgdr: Stochastic gradient descent with warm restarts. arXiv 2016,2019,arXiv preprint arXiv:1608.03983,287,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=17510968973242529892&hl=en&oi=scholarr
Frank Hutter,Learning curve prediction with Bayesian neural networks,2017,International conference on learning representations,282,"Aaron Klein, Stefan Falkner, Jost Tobias Springenberg, Frank Hutter",Aaron Klein,Frank Hutter,4,"Different neural network architectures, hyperparameters and training protocols lead to different performances as a function of time. Human experts routinely inspect the resulting learning curves to quickly terminate runs with poor hyperparameter settings and thereby considerably speed up manual hyperparameter optimization. Exploiting the same information in automatic Bayesian hyperparameter optimization requires a probabilistic model of learning curves across hyperparameter settings. Here, we study the use of Bayesian neural networks for this purpose and improve their performance by a specialized learning curve layer.",https://openreview.net/forum?id=S11KBYclx
Frank Hutter,Auto-pytorch: Multi-fidelity metalearning for efficient and robust autodl,2021,IEEE transactions on pattern analysis and machine intelligence,276,"Lucas Zimmer, Marius Lindauer, Frank Hutter",Lucas Zimmer,Frank Hutter,3,"While early AutoML frameworks focused on optimizing traditional ML pipelines and their hyperparameters, a recent trend in AutoML is to focus on neural architecture search. In this paper, we introduce Auto-PyTorch, which brings together the best of these two worlds by jointly and robustly optimizing the network architecture and the training hyperparameters to enable fully automated deep learning (AutoDL). Auto-PyTorch achieves state-of-the-art performance on several tabular benchmarks by combining multi-fidelity optimization with portfolio construction for warmstarting and ensembling of deep neural networks (DNNs) and common baselines for tabular data. To thoroughly study our assumptions on how to design such an AutoDL system, we additionally introduce a new benchmark on learning curves for DNNs, dubbed LCBench, and run extensive ablation studies of the full Auto-PyTorch on typical AutoML …",https://ieeexplore.ieee.org/abstract/document/9382913/
Frank Hutter,Well-tuned simple nets excel on tabular datasets,2021,Advances in neural information processing systems,265,"Arlind Kadra, Marius Lindauer, Frank Hutter, Josif Grabocka",Arlind Kadra,Josif Grabocka,4,"Tabular datasets are the last"" unconquered castle"" for deep learning, with traditional ML methods like Gradient-Boosted Decision Trees still performing strongly even against recent specialized neural architectures. In this paper, we hypothesize that the key to boosting the performance of neural networks lies in rethinking the joint and simultaneous application of a large set of modern regularization techniques. As a result, we propose regularizing plain Multilayer Perceptron (MLP) networks by searching for the optimal combination/cocktail of 13 regularization techniques for each dataset using a joint optimization over the decision on which regularizers to apply and their subsidiary hyperparameters. We empirically assess the impact of these regularization cocktails for MLPs in a large-scale empirical study comprising 40 tabular datasets and demonstrate that (i) well-regularized plain MLPs significantly outperform recent state-of-the-art specialized neural network architectures, and (ii) they even outperform strong traditional ML methods, such as XGBoost.",https://proceedings.neurips.cc/paper/2021/hash/c902b497eb972281fb5b4e206db38ee6-Abstract.html
Frank Hutter,Beyond manual tuning of hyperparameters,2015,KI-Künstliche Intelligenz,265,"Frank Hutter, Jörg Lücke, Lars Schmidt-Thieme",Frank Hutter,Lars Schmidt-Thieme,3,"The success of hand-crafted machine learning systems in many applications raises the question of making machine learning algorithms more autonomous, i.e., to reduce the requirement of expert input to a minimum. We discuss two strategies towards this goal: (1) automated optimization of hyperparameters (including mechanisms for feature selection, preprocessing, model selection, etc) and (2) the development of algorithms with reduced sets of hyperparameters. Since many research directions (e.g., deep learning), show a tendency towards increasingly complex algorithms with more and more hyperparamters, the demand for both of these strategies continuously increases. We review recent hyperparameter optimization methods and discuss data-driven approaches to avoid the introduction of hyperparameters using unsupervised learning. We end in discussing how these complementary strategies can …",https://link.springer.com/article/10.1007/s13218-015-0381-0
Frank Hutter,Tabpfn: A transformer that solves small tabular classification problems in a second,2022,arXiv preprint arXiv:2207.01848,264,"Noah Hollmann, Samuel Müller, Katharina Eggensperger, Frank Hutter",Noah Hollmann,Frank Hutter,4,"We present TabPFN, a trained Transformer that can do supervised classification for small tabular datasets in less than a second, needs no hyperparameter tuning and is competitive with state-of-the-art classification methods. TabPFN performs in-context learning (ICL), it learns to make predictions using sequences of labeled examples (x, f(x)) given in the input, without requiring further parameter updates. TabPFN is fully entailed in the weights of our network, which accepts training and test samples as a set-valued input and yields predictions for the entire test set in a single forward pass. TabPFN is a Prior-Data Fitted Network (PFN) and is trained offline once, to approximate Bayesian inference on synthetic datasets drawn from our prior. This prior incorporates ideas from causal reasoning: It entails a large space of structural causal models with a preference for simple structures. On the 18 datasets in the OpenML-CC18 suite that contain up to 1 000 training data points, up to 100 purely numerical features without missing values, and up to 10 classes, we show that our method clearly outperforms boosted trees and performs on par with complex state-of-the-art AutoML systems with up to 230 speedup. This increases to a 5 700 speedup when using a GPU. We also validate these results on an additional 67 small numerical datasets from OpenML. We provide all our code, the trained TabPFN, an interactive browser demo and a Colab notebook at https://github.com/automl/TabPFN.",https://arxiv.org/abs/2207.01848
Frank Hutter,Automated configuration of mixed integer programming solvers,2010,"Integration of AI and OR Techniques in Constraint Programming for Combinatorial Optimization Problems: 7th International Conference, CPAIOR 2010, Bologna, Italy, June 14-18, 2010. Proceedings 7",260,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"State-of-the-art solvers for mixed integer programming (MIP) problems are highly parameterized, and finding parameter settings that achieve high performance for specific types of MIP instances is challenging. We study the application of an automated algorithm configuration procedure to different MIP solvers, instance types and optimization objectives. We show that this fully-automated process yields substantial improvements to the performance of three MIP solvers: Cplex, Gurobi, and lpsolve. Although our method can be used “out of the box” without any domain knowledge specific to MIP, we show that it outperforms the Cplex special-purpose automated tuning tool.",https://link.springer.com/chapter/10.1007/978-3-642-13520-0_23
Frank Hutter,Performance prediction and automated tuning of randomized and parametric algorithms,2006,"Principles and Practice of Constraint Programming-CP 2006: 12th International Conference, CP 2006, Nantes, France, September 25-29, 2006. Proceedings 12",249,"Frank Hutter, Youssef Hamadi, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,4,"Machine learning can be used to build models that predict the run-time of search algorithms for hard combinatorial problems. Such empirical hardness models have previously been studied for complete, deterministic search algorithms. In this work, we demonstrate that such models can also make surprisingly accurate predictions of the run-time distributions of incomplete and randomized search methods, such as stochastic local search algorithms. We also show for the first time how information about an algorithm’s parameter settings can be incorporated into a model, and how such models can be used to automatically adjust the algorithm’s parameters on a per-instance basis in order to optimize its performance. Empirical results for Novelty +  and SAPS on structured and unstructured SAT instances show very good predictive performance and significant speedups of our automatically determined …",https://link.springer.com/chapter/10.1007/11889205_17
Frank Hutter,Uncertainty estimates and multi-hypotheses networks for optical flow,2018,Proceedings of the European Conference on Computer Vision (ECCV),248,"Eddy Ilg, Ozgun Cicek, Silvio Galesso, Aaron Klein, Osama Makansi, Frank Hutter, Thomas Brox",Eddy Ilg,Thomas Brox,7,"Optical flow estimation can be formulated as an end-to-end supervised learning problem, which yields estimates with a superior accuracy-runtime tradeoff compared to alternative methodology. In this paper, we make such networks estimate their local uncertainty about the correctness of their prediction, which is vital information when building decisions on top of the estimations. For the first time we compare several strategies and techniques to estimate uncertainty in a large-scale computer vision task like optical flow estimation. Moreover, we introduce a new network architecture and loss function that enforce complementary hypotheses and provide uncertainty estimates efficiently with a single forward pass and without the need for sampling or ensembles. We demonstrate the quality of the uncertainty estimates, which is clearly above previous confidence measures on optical flow and allows for interactive frame rates.",http://openaccess.thecvf.com/content_ECCV_2018/html/Eddy_Ilg_Uncertainty_Estimates_and_ECCV_2018_paper.html
Frank Hutter,Towards automated deep learning: Efficient joint neural architecture and hyperparameter search,2018,arXiv preprint arXiv:1807.06906,242,"Arber Zela, Aaron Klein, Stefan Falkner, Frank Hutter",Arber Zela,Frank Hutter,4,"While existing work on neural architecture search (NAS) tunes hyperparameters in a separate post-processing step, we demonstrate that architectural choices and other hyperparameter settings interact in a way that can render this separation suboptimal. Likewise, we demonstrate that the common practice of using very few epochs during the main NAS and much larger numbers of epochs during a post-processing step is inefficient due to little correlation in the relative rankings for these two training regimes. To combat both of these problems, we propose to use a recent combination of Bayesian optimization and Hyperband for efficient joint neural architecture and hyperparameter search.",https://arxiv.org/abs/1807.06906
Frank Hutter,A new algorithm for RNA secondary structure design,2004,Journal of molecular biology,224,"Mirela Andronescu, Anthony P Fejes, Frank Hutter, Holger H Hoos, Anne Condon",Mirela Andronescu,Anne Condon,5,"The function of many RNAs depends crucially on their structure. Therefore, the design of RNA molecules with specific structural properties has many potential applications, e.g. in the context of investigating the function of biological RNAs, of creating new ribozymes, or of designing artificial RNA nanostructures. Here, we present a new algorithm for solving the following RNA secondary structure design problem: given a secondary structure, find an RNA sequence (if any) that is predicted to fold to that structure. Unlike the (pseudoknot-free) secondary structure prediction problem, this problem appears to be hard computationally. Our new algorithm, “RNA Secondary Structure Designer (RNA-SSD)”, is based on stochastic local search, a prominent general approach for solving hard combinatorial problems. A thorough empirical evaluation on computationally predicted structures of biological sequences and artificially …",https://www.sciencedirect.com/science/article/pii/S0022283603015596
Frank Hutter,Machine-learning-based diagnostics of EEG pathology,2020,NeuroImage,212,"Lukas AW Gemein, Robin T Schirrmeister, Patryk Chrabąszcz, Daniel Wilson, Joschka Boedecker, Andreas Schulze-Bonhage, Frank Hutter, Tonio Ball",Lukas AW Gemein,Tonio Ball,8,"Machine learning (ML) methods have the potential to automate clinical EEG analysis. They can be categorized into feature-based (with handcrafted features), and end-to-end approaches (with learned features). Previous studies on EEG pathology decoding have typically analyzed a limited number of features, decoders, or both. For a I) more elaborate feature-based EEG analysis, and II) in-depth comparisons of both approaches, here we first develop a comprehensive feature-based framework, and then compare this framework to state-of-the-art end-to-end methods. To this aim, we apply the proposed feature-based framework and deep neural networks including an EEG-optimized temporal convolutional network (TCN) to the task of pathological versus non-pathological EEG classification. For a robust comparison, we chose the Temple University Hospital (TUH) Abnormal EEG Corpus (v2.0.0), which contains …",https://www.sciencedirect.com/science/article/pii/S1053811920305073
Frank Hutter,Boosting verification by automatic tuning of decision procedures,2007,Formal Methods in Computer Aided Design (FMCAD'07),197,"Frank Hutter, Domagoj Babic, Holger H Hoos, Alan J Hu",Frank Hutter,Alan J Hu,4,"Parameterized heuristics abound in computer aided design and verification, and manual tuning of the respective parameters is difficult and time-consuming. Very recent results from the artificial intelligence (AI) community suggest that this tuning process can be automated, and that doing so can lead to significant performance improvements; furthermore, automated parameter optimization can provide valuable guidance during the development of heuristic algorithms. In this paper, we study how such an AI approach can improve a state-of-the-art SAT solver for large, real-world bounded model-checking and software verification instances. The resulting, automatically-derived parameter settings yielded runtimes on average 4.5 times faster on bounded model checking instances and 500 times faster on software verification problems than extensive hand-tuning of the decision procedure. Furthermore, the availability of …",https://ieeexplore.ieee.org/abstract/document/4401979/
Frank Hutter,Nas-bench-301 and the case for surrogate benchmarks for neural architecture search,2020,arXiv preprint arXiv:2008.09777,195,"Julien Siems, Lucas Zimmer, Arber Zela, Jovita Lukasik, Margret Keuper, Frank Hutter",Julien Siems,Frank Hutter,6,"Neural Architecture Search (NAS) is a logical next step in the automatic learning of representations, but the development of NAS methods is slowed by high computational demands. As a remedy, several tabular NAS benchmarks were proposed to simulate runs of NAS methods in seconds. However, all existing NAS benchmarks are limited to extremely small architectural spaces since they rely on exhaustive evaluations of the space. This leads to unrealistic results, such as a strong performance of local search and random search, that do not transfer to larger search spaces. To overcome this fundamental limitation, we propose NAS-Bench-301, the first model-based surrogate NAS benchmark, using a search space containing 1018 architectures, orders of magnitude larger than any previous NAS benchmark. We first motivate the benefits of using such a surrogate benchmark compared to a tabular one by smoothing out the noise stemming from the stochasticity of single SGD runs in a tabular benchmark. Then, we analyze our new dataset consisting of architecture evaluations and comprehensively evaluate various regression models as surrogates to demonstrate their capability to model the architecture space, also using deep ensembles to model uncertainty. Finally, we benchmark a wide range of NAS algorithms using NAS-Bench-301 allowing us to obtain comparable results to the true benchmark at a fraction of the cost.",https://www.researchgate.net/profile/Julien-Siems/publication/343849405_NAS-Bench-301_and_the_Case_for_Surrogate_Benchmarks_for_Neural_Architecture_Search/links/5f574413458515e96d390b7c/NAS-Bench-301-and-the-Case-for-Surrogate-Benchmarks-for-Neural-Architecture-Search.pdf
Frank Hutter,Nas-bench-1shot1: Benchmarking and dissecting one-shot neural architecture search,2020,arXiv preprint arXiv:2001.10422,193,"Arber Zela, Julien Siems, Frank Hutter",Arber Zela,Frank Hutter,3,"One-shot neural architecture search (NAS) has played a crucial role in making NAS methods computationally feasible in practice. Nevertheless, there is still a lack of understanding on how these weight-sharing algorithms exactly work due to the many factors controlling the dynamics of the process. In order to allow a scientific study of these components, we introduce a general framework for one-shot NAS that can be instantiated to many recently-introduced variants and introduce a general benchmarking framework that draws on the recent large-scale tabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot NAS methods. To showcase the framework, we compare several state-of-the-art one-shot NAS methods, examine how sensitive they are to their hyperparameters and how they can be improved by tuning their hyperparameters, and compare their performance to that of blackbox optimizers for NAS-Bench-101.",https://arxiv.org/abs/2001.10422
Frank Hutter,Fixing weight decay regularization in Adam. CoRR abs/1711.05101 (2017),2017,arXiv preprint arXiv:1711.05101,191,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=4958008868527834963&hl=en&oi=scholarr
Frank Hutter,Meta-learning of neural architectures for few-shot learning,2020,Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,190,"Thomas Elsken, Benedikt Staffler, Jan Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,4,"The recent progress in neural architecture search (NAS) has allowed scaling the automated design of neural architectures to real-world domains, such as object detection and semantic segmentation. However, one prerequisite for the application of NAS are large amounts of labeled data and compute resources. This renders its application challenging in few-shot learning scenarios, where many related tasks need to be learned, each with limited amounts of data and compute time. Thus, few-shot learning is typically done with a fixed neural architecture. To improve upon this, we propose MetaNAS, the first method which fully integrates NAS with gradient-based meta-learning. MetaNAS optimizes a meta-architecture along with the meta-weights during meta-training. During meta-testing, architectures can be adapted to a novel task with a few steps of the task optimizer, that is: task adaptation becomes computationally cheap and requires only little data per task. Moreover, MetaNAS is agnostic in that it can be used with arbitrary model-agnostic meta-learning algorithms and arbitrary gradient-based NAS methods. Empirical results on standard few-shot classification benchmarks show that MetaNAS with a combination of DARTS and REPTILE yields state-of-the-art results.",http://openaccess.thecvf.com/content_CVPR_2020/html/Elsken_Meta-Learning_of_Neural_Architectures_for_Few-Shot_Learning_CVPR_2020_paper.html
Frank Hutter,Autofolio: An automatically configured algorithm selector,2015,Journal of Artificial Intelligence Research,177,"Marius Lindauer, Holger H Hoos, Frank Hutter, Torsten Schaub",Marius Lindauer,Torsten Schaub,4,"Algorithm selection (AS) techniques - which involve choosing from a set of algorithms the one expected to solve a given problem instance most efficiently - have substantially improved the state of the art in solving many prominent AI problems, such as SAT, CSP, ASP, MAXSAT and QBF. Although several AS procedures have been introduced, not too surprisingly, none of them dominates all others across all AS scenarios. Furthermore, these procedures have parameters whose optimal values vary across AS scenarios. This holds specifically for the machine learning techniques that form the core of current AS procedures, and for their hyperparameters. Therefore, to successfully apply AS to new problems, algorithms and benchmark sets, two questions need to be answered: (i) how to select an AS approach and (ii) how to set its parameters effectively. We address both of these problems simultaneously by using automated algorithm configuration. Specifically, we demonstrate that we can automatically configure CLASPFOLIO 2, which implements a large variety of different AS approaches and their respective parameters in a single, highly-parameterized algorithm framework. Our approach, dubbed AUTOFOLIO, allows researchers and practitioners across a broad range of applications to exploit the combined power of many different AS methods. We demonstrate AUTOFOLIO can significantly improve the performance of CLASPFOLIO 2 on 8 out of the 13 scenarios from the Algorithm Selection Library, leads to new state-of-the-art algorithm selectors for 7 of these scenarios, and matches state-of-the-art performance (statistically) on all other scenarios …",https://www.jair.org/index.php/jair/article/view/10955
Frank Hutter,SATzilla-07: The Design and Analysis of an Algorithm Portfolio for SAT,2007,Principles and Practice of Constraint Programming–CP 2007,173,"Lin Xu, Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"It has been widely observed that there is no “dominant” SAT solver; instead, different solvers perform best on different instances. Rather than following the traditional approach of choosing the best solver for a given class of instances, we advocate making this decision online on a per-instance basis. Building on previous work, we describe a per-instance solver portfolio for SAT, SATzilla-07, which uses so-called empirical hardness models to choose among its constituent solvers. We leverage new model-building techniques such as censored sampling and hierarchical hardness models, and demonstrate the effectiveness of our techniques by building a portfolio of state-of-the-art SAT solvers and evaluating it on several widely-studied SAT data sets. Overall, we show that our portfolio significantly outperforms its constituent algorithms on every data set. Our approach has also proven itself to be effective in …",https://link.springer.com/chapter/10.1007/978-3-540-74970-7_50
Frank Hutter,Auto-sklearn 2.0: The next generation,2020,arXiv preprint arXiv:2007.04074,170,"Matthias Feurer, Katharina Eggensperger, Stefan Falkner, Marius Lindauer, Frank Hutter",Matthias Feurer,Frank Hutter,5,"Automated Machine Learning, which supports practitioners and researchers with the tedious task of manually designing machine learning pipelines, has recently achieved substantial success. In this paper we introduce new Automated Machine Learning (AutoML) techniques motivated by our winning submission to the second ChaLearn AutoML challenge, PoSH Auto-sklearn. For this, we extend Auto-sklearn with a new, simpler meta-learning technique, improve its way of handling iterative algorithms and enhance it with a successful bandit strategy for budget allocation. Furthermore, we go one step further and study the design space of AutoML itself and propose a solution towards truly hand-free AutoML. Together, these changes give rise to the next generation of our AutoML system, Auto-sklearn (2.0). We verify the improvement by these additions in a large experimental study on 39 AutoML benchmark datasets and conclude the paper by comparing to Auto-sklearn (1.0), reducing the regret by up to a factor of five.",https://www.researchgate.net/profile/Matthias-Feurer/publication/342801746_Auto-Sklearn_20_The_Next_Generation/links/5f7c334aa6fdccfd7b4a87de/Auto-Sklearn-20-The-Next-Generation.pdf
Frank Hutter,Automated Configuration of Algorithms for Solving Hard Computational Problems,2009,,168,Frank Hutter,Frank Hutter,Frank Hutter,1,"The best-performing algorithms for many hard problems are highly parameterized. Selecting the best heuristics and tuning their parameters for optimal overall performance is often a difficult, tedious, and unsatisfying task. This thesis studies the automation of this important part of algorithm design: the configuration of discrete algorithm components and their continuous parameters to construct an algorithm with desirable empirical performance characteristics. Automated configuration procedures can facilitate algorithm development and be applied on the end user side to optimize performance for new instance types and optimization objectives. The use of such procedures separates high-level cognitive tasks carried out by humans from tedious low-level tasks that can be left to machines. We introduce two alternative algorithm configuration frameworks: iterated local search in parameter configuration space and sequential optimization based on response surface models. To the best of our knowledge, our local search approach is the first that goes beyond local optima. Our model-based search techniques significantly outperform existing techniques and extend them in ways crucial for general algorithm configuration: they can handle categorical parameters, optimization objectives defined across multiple instances, and tens of thousands of data points. We study how many runs to perform for evaluating a parameter configuration and how to set the cutoff time, after which algorithm runs are terminated unsuccessfully. We introduce data-driven approaches for making these choices adaptively, most notably the first general method for adaptively setting the …",https://open.library.ubc.ca/soa/cIRcle/collections/ubctheses/24/items/1.0051652
Frank Hutter,Best practices for scientific research on neural architecture search,2020,Journal of Machine Learning Research,161,"Marius Lindauer, Frank Hutter",Marius Lindauer,Frank Hutter,2,"Finding a well-performing architecture is often tedious for both deep learning practitioners and researchers, leading to tremendous interest in the automation of this task by means of neural architecture search (NAS). Although the community has made major strides in developing better NAS methods, the quality of scientific empirical evaluations in the young field of NAS is still lacking behind that of other areas of machine learning. To address this issue, we describe a set of possible issues and ways to avoid them, leading to the NAS best practices checklist available at http://automl.org/nas_checklist.pdf.",https://www.jmlr.org/papers/v21/20-056.html
Frank Hutter,Efficient benchmarking of hyperparameter optimizers via surrogates,2015,Proceedings of the aaai conference on artificial intelligence,154,"Katharina Eggensperger, Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Katharina Eggensperger,Kevin Leyton-Brown,4,"Hyperparameter optimization is crucial for achieving peak performance with many machine learning algorithms; however, the evaluation of new optimization techniques on real-world hyperparameter optimization problems can be very expensive. Therefore, experiments are often performed using cheap synthetic test functions with characteristics rather different from those of real benchmarks of interest. In this work, we introduce another option: cheap-to-evaluate surrogates of real hyperparameter optimization benchmarks that share the same hyperparameter spaces and feature similar response surfaces. Specifically, we train regression models on data describing a machine learning algorithm’s performance depending on its hyperparameter setting, and then cheaply evaluate hyperparameter optimization methods using the model’s performance predictions in lieu of running the real algorithm. We evaluated a wide range of regression techniques, both in terms of how well they predict the performance of new hyperparameter settings and in terms of the quality of surrogate benchmarks obtained. We found that tree-based models capture the performance of several machine learning algorithms well and yield surrogate benchmarks that closely resemble real-world benchmarks, while being much easier to use and orders of magnitude cheaper to evaluate.",https://ojs.aaai.org/index.php/AAAI/article/view/9375
Frank Hutter,Hydra-MIP: Automated algorithm configuration and selection for mixed integer programming,2011,RCRA workshop on experimental evaluation of algorithms for solving problems with combinatorial explosion at the international joint conference on artificial intelligence (IJCAI),154,"Lin Xu, Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"State-of-the-art mixed integer programming (MIP) solvers are highly parameterized. For heterogeneous and a priori unknown instance distributions, no single parameter configuration generally achieves consistently strong performance, and hence it is useful to select from a portfolio of different configurations. HYDRA is a recent method for using automated algorithm configuration to derive multiple configurations of a single parameterized algorithm for use with portfolio-based selection. This paper shows that, leveraging two key innovations, HYDRA can achieve strong performance for MIP. First, we describe a new algorithm selection approach based on classification with a non-uniform loss function, which significantly improves the performance of algorithm selection for MIP (and SAT). Second, by modifying HYDRA’s method for selecting candidate configurations, we obtain better performance as a function of training time.",https://ada.liacs.nl/papers/XuEtAl11.pdf
Frank Hutter,Openml benchmarking suites,2017,arXiv preprint arXiv:1708.03731,148,"Bernd Bischl, Giuseppe Casalicchio, Matthias Feurer, Pieter Gijsbers, Frank Hutter, Michel Lang, Rafael G Mantovani, Jan N van Rijn, Joaquin Vanschoren",Bernd Bischl,Joaquin Vanschoren,9,"Machine learning research depends on objectively interpretable, comparable, and reproducible algorithm benchmarks. We advocate the use of curated, comprehensive suites of machine learning tasks to standardize the setup, execution, and reporting of benchmarks. We enable this through software tools that help to create and leverage these benchmarking suites. These are seamlessly integrated into the OpenML platform, and accessible through interfaces in Python, Java, and R. OpenML benchmarking suites (a) are easy to use through standardized data formats, APIs, and client libraries; (b) come with extensive meta-information on the included datasets; and (c) allow benchmarks to be shared and reused in future studies. We then present a first, carefully curated and practical benchmarking suite for classification: the OpenML Curated Classification benchmarking suite 2018 (OpenML-CC18). Finally, we discuss use cases and applications which demonstrate the usefulness of OpenML benchmarking suites and the OpenML-CC18 in particular.",https://arxiv.org/abs/1708.03731
Frank Hutter,How powerful are performance predictors in neural architecture search?,2021,Advances in Neural Information Processing Systems,144,"Colin White, Arber Zela, Robin Ru, Yang Liu, Frank Hutter",Colin White,Frank Hutter,5,"Early methods in the rapidly developing field of neural architecture search (NAS) required fully training thousands of neural networks. To reduce this extreme computational cost, dozens of techniques have since been proposed to predict the final performance of neural architectures. Despite the success of such performance prediction methods, it is not well-understood how different families of techniques compare to one another, due to the lack of an agreed-upon evaluation metric and optimization for different constraints on the initialization time and query time. In this work, we give the first large-scale study of performance predictors by analyzing 31 techniques ranging from learning curve extrapolation, to weight-sharing, to supervised learning, to zero-cost proxies. We test a number of correlation-and rank-based performance measures in a variety of settings, as well as the ability of each technique to speed up predictor-based NAS frameworks. Our results act as recommendations for the best predictors to use in different settings, and we show that certain families of predictors can be combined to achieve even better predictive power, opening up promising research directions. We release our code, featuring a library of 31 performance predictors.",https://proceedings.neurips.cc/paper/2021/hash/ef575e8837d065a1683c022d2077d342-Abstract.html
Frank Hutter,Transformers can do bayesian inference,2021,arXiv preprint arXiv:2112.10510,143,"Samuel Müller, Noah Hollmann, Sebastian Pineda Arango, Josif Grabocka, Frank Hutter",Samuel Müller,Frank Hutter,5,"Currently, it is hard to reap the benefits of deep learning for Bayesian methods, which allow the explicit specification of prior knowledge and accurately capture model uncertainty. We present Prior-Data Fitted Networks (PFNs). PFNs leverage large-scale machine learning techniques to approximate a large set of posteriors. The only requirement for PFNs to work is the ability to sample from a prior distribution over supervised learning tasks (or functions). Our method restates the objective of posterior approximation as a supervised classification problem with a set-valued input: it repeatedly draws a task (or function) from the prior, draws a set of data points and their labels from it, masks one of the labels and learns to make probabilistic predictions for it based on the set-valued input of the rest of the data points. Presented with a set of samples from a new supervised learning task as input, PFNs make probabilistic predictions for arbitrary other data points in a single forward propagation, having learned to approximate Bayesian inference. We demonstrate that PFNs can near-perfectly mimic Gaussian processes and also enable efficient Bayesian inference for intractable problems, with over 200-fold speedups in multiple setups compared to current methods. We obtain strong results in very diverse areas such as Gaussian process regression, Bayesian neural networks, classification for small tabular data sets, and few-shot image classification, demonstrating the generality of PFNs. Code and trained PFNs are released at https://github.com/automl/TransformersCanDoBayesianInference.",https://arxiv.org/abs/2112.10510
Frank Hutter,Managing extreme AI risks amid rapid progress,2024,Science,139,"Yoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Trevor Darrell, Yuval Noah Harari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, Gillian Hadfield, Jeff Clune, Tegan Maharaj, Frank Hutter, Atılım Güneş Baydin, Sheila McIlraith, Qiqi Gao, Ashwin Acharya, David Krueger, Anca Dragan, Philip Torr, Stuart Russell, Daniel Kahneman, Jan Brauner, Sören Mindermann",Yoshua Bengio,Sören Mindermann,25,"Artificial intelligence (AI) is progressing rapidly, and companies are shifting their focus to developing generalist AI systems that can autonomously act and pursue goals. Increases in capabilities and autonomy may soon massively amplify AI’s impact, with risks that include large-scale social harms, malicious uses, and an irreversible loss of human control over autonomous AI systems. Although researchers have warned of extreme risks from AI , there is a lack of consensus about how to manage them. Society’s response, despite promising first steps, is incommensurate with the possibility of rapid, transformative progress that is expected by many experts. AI safety research is lagging. Present governance initiatives lack the mechanisms and institutions to prevent misuse and recklessness and barely address autonomous systems. Drawing on lessons learned from other safety-critical technologies, we outline a …",https://www.science.org/doi/abs/10.1126/science.adn0117
Frank Hutter,An experimental investigation of model-based parameter optimisation: SPO and beyond,2009,,136,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown, Kevin P Murphy",Frank Hutter,Kevin P Murphy,4,"This work experimentally investigates model-based approaches for optimising the performance of parameterised randomised algorithms. We restrict our attention to procedures based on Gaussian process models, the most widely-studied family of models for this problem. We evaluated two approaches from the literature, and found that sequential parameter optimisation (SPO) [4] offered the most robust performance. We then investigated key design decisions within the SPO paradigm, characterising the performance consequences of each. Based on these findings, we propose a new version of SPO, dubbed SPO+, which extends SPO with a novel intensification procedure and log-transformed response values. Finally, in a domain for which performance results for other (model-free) parameter optimisation approaches are available, we demonstrate that SPO+ achieves state-of-the-art performance.",https://dl.acm.org/doi/abs/10.1145/1569901.1569940
Frank Hutter,Back to basics: Benchmarking canonical evolution strategies for playing atari,2018,arXiv preprint arXiv:1802.08842,134,"Patryk Chrabaszcz, Ilya Loshchilov, Frank Hutter",Patryk Chrabaszcz,Frank Hutter,3,"Evolution Strategies (ES) have recently been demonstrated to be a viable alternative to reinforcement learning (RL) algorithms on a set of challenging deep RL problems, including Atari games and MuJoCo humanoid locomotion benchmarks. While the ES algorithms in that work belonged to the specialized class of natural evolution strategies (which resemble approximate gradient RL algorithms, such as REINFORCE), we demonstrate that even a very basic canonical ES algorithm can achieve the same or even better performance. This success of a basic ES algorithm suggests that the state-of-the-art can be advanced further by integrating the many advances made in the field of ES in the last decades. We also demonstrate qualitatively that ES algorithms have very different performance characteristics than traditional RL algorithms: on some games, they learn to exploit the environment and perform much better while on others they can get stuck in suboptimal local minima. Combining their strengths with those of traditional RL algorithms is therefore likely to lead to new advances in the state of the art.",https://arxiv.org/abs/1802.08842
Frank Hutter,Parallel algorithm configuration,2012,,134,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"State-of-the-art algorithms for solving hard computational problems often expose many parameters whose settings critically affect empirical performance. Manually exploring the resulting combinatorial space of parameter settings is often tedious and unsatisfactory. Automated approaches for finding good parameter settings are becoming increasingly prominent and have recently lead to substantial improvements in the state of the art for solving a variety of computationally challenging problems. However, running such automated algorithm configuration procedures is typically very costly, involving many thousands of invocations of the algorithm to be configured. Here, we study the extent to which parallel computing can come to the rescue. We compare straightforward parallelization by multiple independent runs with a more sophisticated method of parallelizing the model-based configuration procedure SMAC …",https://link.springer.com/chapter/10.1007/978-3-642-34413-8_5
Frank Hutter,On the importance of hyperparameter optimization for model-based reinforcement learning,2021,International Conference on Artificial Intelligence and Statistics,132,"Baohe Zhang, Raghu Rajan, Luis Pineda, Nathan Lambert, André Biedenkapp, Kurtland Chua, Frank Hutter, Roberto Calandra",Baohe Zhang,Roberto Calandra,8,"Model-based Reinforcement Learning (MBRL) is a promising framework for learning control in a data-efficient manner. MBRL algorithms can be fairly complex due to the separate dynamics modeling and the subsequent planning algorithm, and as a result, they often possess tens of hyperparameters and architectural choices. For this reason, MBRL typically requires significant human expertise before it can be applied to new problems and domains. To alleviate this problem, we propose to use automatic hyperparameter optimization (HPO). We demonstrate that this problem can be tackled effectively with automated HPO, which we demonstrate to yield significantly improved performance compared to human experts. In addition, we show that tuning of several MBRL hyperparameters dynamically, ie during the training itself, further improves the performance compared to using static hyperparameters which are kept fix for the whole training. Finally, our experiments provide valuable insights into the effects of several hyperparameters, such as plan horizon or learning rate and their influence on the stability of training and resulting rewards.",http://proceedings.mlr.press/v130/zhang21n.html
Frank Hutter,Evaluating component solver contributions to portfolio-based algorithm selectors,2012,,132,"Lin Xu, Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"Portfolio-based methods exploit the complementary strengths of a set of algorithms and—as evidenced in recent competitions—represent the state of the art for solving many NP-hard problems, including SAT. In this work, we argue that a state-of-the-art method for constructing portfolio-based algorithm selectors, , also gives rise to an automated method for quantifying the importance of each of a set of available solvers. We entered a substantially improved version of  to the inaugural “analysis track” of the 2011 SAT competition, and draw two main conclusions from the results that we obtained. First, automatically-constructed portfolios of sequential, non-portfolio competition entries perform substantially better than the winners of all three sequential categories. Second, and more importantly, a detailed analysis of these portfolios yields valuable insights into the nature of successful solver designs in …",https://link.springer.com/chapter/10.1007/978-3-642-31612-8_18
Frank Hutter,Diagnosis by a waiter and a mars explorer,2004,Proceedings of the IEEE,131,"Nando De Freitas, Richard Dearden, Frank Hutter, Ruben Morales-Menendez, Jim Mutch, David Poole",Nando De Freitas,David Poole,6,"This paper shows how state-of-the-art state estimation techniques can be used to provide efficient solutions to the difficult problem of real-time diagnosis in mobile robots. The power of the adopted estimation techniques resides in our ability to combine particle filters with classical algorithms, such as Kalman filters. We demonstrate these techniques in two scenarios: a mobile waiter robot and planetary rovers designed by NASA for Mars exploration.",https://ieeexplore.ieee.org/abstract/document/1271400/
Frank Hutter,International conference on learning representations,2019,,127,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=303135073791800607&hl=en&oi=scholarr
Frank Hutter,SATzilla2012: Improved algorithm selection based on cost-sensitive classification models,2012,Proceedings of SAT Challenge,127,"Lin Xu, Frank Hutter, Jonathan Shen, Holger H Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,5,"Empirical studies often observe that the performance of different algorithms across problem instance distributions can be quite uncorrelated. When this occurs, there is an incentive to investigate the use of portfolio-based approaches that draw on the strengths of multiple algorithms. SATzilla is such a portfolio-based approach for SAT; it was first deployed in the 2003 and 2004 SAT competitions [5], and later versions won a number of prizes in the 2007 and 2009 SAT competitions [10, 8, 11], including gold medals in the random, crafted and application categories in 2009.Different from previous versions of SATzilla, which utilized empirical hardness models [4, 6] for estimating each candidate algorithm’s performance on a given SAT instance, SATzilla2012 is based on cost-sensitive classification models [7]. We also introduced a new procedure that generates a stand-alone SATzilla executable based on models learned within Matlab. Finally, we used new component algorithms and training instances. Overall, SATzilla2012 makes use of the same methodology as described in [9].",https://www.academia.edu/download/30605172/sc2012_proceedings.pdf#page=58
Frank Hutter,Neural architecture search: Insights from 1000 papers,2023,arXiv preprint arXiv:2301.08727,125,"Colin White, Mahmoud Safari, Rhea Sukthanker, Binxin Ru, Thomas Elsken, Arber Zela, Debadeepta Dey, Frank Hutter",Colin White,Frank Hutter,8,"In the past decade, advances in deep learning have resulted in breakthroughs in a variety of areas, including computer vision, natural language understanding, speech recognition, and reinforcement learning. Specialized, high-performing neural architectures are crucial to the success of deep learning in these areas. Neural architecture search (NAS), the process of automating the design of neural architectures for a given task, is an inevitable next step in automating machine learning and has already outpaced the best human-designed architectures on many tasks. In the past few years, research in NAS has been progressing rapidly, with over 1000 papers released since 2020 (Deng and Lindauer, 2021). In this survey, we provide an organized and comprehensive guide to neural architecture search. We give a taxonomy of search spaces, algorithms, and speedup techniques, and we discuss resources such as benchmarks, best practices, other surveys, and open-source libraries.",https://arxiv.org/abs/2301.08727
Frank Hutter,Neural ensemble search for performant and calibrated predictions,2020,arXiv preprint arXiv:2006.08573,121,"Sheheryar Zaidi, Arber Zela, Thomas Elsken, Chris Holmes, Frank Hutter, Yee Whye Teh",Sheheryar Zaidi,Yee Whye Teh,6,"• Calibration tells us how well the predicted confidence (probability of correctness) of the model aligns with the observed accuracy (frequency of correctness).• Eg in image classification: if the correct predicted class was always with 80% probability, then a perfectly calibrated system would imply that on 80% of the examples it predicted the true class.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/20-ARXIV-NES-slides.pdf
Frank Hutter,Practical automated machine learning for the automl challenge 2018,2018,International workshop on automatic machine learning at ICML,117,"Matthias Feurer, Katharina Eggensperger, Stefan Falkner, Marius Lindauer, Frank Hutter",Matthias Feurer,Frank Hutter,5,"Despite great successes in many fields, machine learning typically requires substantial human resources to determine a good machine learning pipeline (including various types of preprocessing, and the choice of classifiers and hyperparameters). AutoML aims to free human practitioners and researchers from these menial tasks. The current state-of-the-art in AutoML has been evaluated in the AutoML challenge 2018. Here, we describe our winning entry to this challenge, dubbed PoSH Auto-sklearn, which combines an automatically preselected portfolio, ensemble building and Bayesian optimization with successive halving. Finally, we share insights in the importance of different parts of our approach.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/18-AUTOML-AutoChallenge.pdf
Frank Hutter,Raiders of the lost architecture: Kernels for Bayesian optimization in conditional parameter spaces,2014,arXiv preprint arXiv:1409.4011,115,"Kevin Swersky, David Duvenaud, Jasper Snoek, Frank Hutter, Michael A Osborne",Kevin Swersky,Michael A Osborne,5,"In practical Bayesian optimization, we must often search over structures with differing numbers of parameters. For instance, we may wish to search over neural network architectures with an unknown number of layers. To relate performance data gathered for different architectures, we define a new kernel for conditional parameter spaces that explicitly includes information about which parameters are relevant in a given structure. We show that this kernel improves model quality and Bayesian optimization results over several simpler baseline kernels.",https://arxiv.org/abs/1409.4011
Frank Hutter,Tabular benchmarks for joint architecture and hyperparameter optimization,2019,arXiv preprint arXiv:1905.04970,114,"Aaron Klein, Frank Hutter",Aaron Klein,Frank Hutter,2,"Due to the high computational demands executing a rigorous comparison between hyperparameter optimization (HPO) methods is often cumbersome. The goal of this paper is to facilitate a better empirical evaluation of HPO methods by providing benchmarks that are cheap to evaluate, but still represent realistic use cases. We believe these benchmarks provide an easy and efficient way to conduct reproducible experiments for neural hyperparameter search. Our benchmarks consist of a large grid of configurations of a feed forward neural network on four different regression datasets including architectural hyperparameters and hyperparameters concerning the training pipeline. Based on this data, we performed an in-depth analysis to gain a better understanding of the properties of the optimization problem, as well as of the importance of different types of hyperparameters. Second, we exhaustively compared various different state-of-the-art methods from the hyperparameter optimization literature on these benchmarks in terms of performance and robustness.",https://arxiv.org/abs/1905.04970
Frank Hutter,"Dehb: Evolutionary hyperband for scalable, robust and efficient hyperparameter optimization",2021,arXiv preprint arXiv:2105.09821,112,"Noor Awad, Neeratyoy Mallik, Frank Hutter",Noor Awad,Frank Hutter,3,"Modern machine learning algorithms crucially rely on several design decisions to achieve strong performance, making the problem of Hyperparameter Optimization (HPO) more important than ever. Here, we combine the advantages of the popular bandit-based HPO method Hyperband (HB) and the evolutionary search approach of Differential Evolution (DE) to yield a new HPO method which we call DEHB. Comprehensive results on a very broad range of HPO problems, as well as a wide range of tabular benchmarks from neural architecture search, demonstrate that DEHB achieves strong performance far more robustly than all previous HPO methods we are aware of, especially for high-dimensional problems with discrete input dimensions. For example, DEHB is up to 1000x faster than random search. It is also efficient in computational time, conceptually simple and easy to implement, positioning it well to become a new default HPO method.",https://arxiv.org/abs/2105.09821
Frank Hutter,Robo: A flexible and robust bayesian optimization framework in python,2017,NIPS 2017 Bayesian optimization workshop,110,"Aaron Klein, Stefan Falkner, Numair Mansur, Frank Hutter",Aaron Klein,Frank Hutter,4,"Bayesian optimization is a powerful approach for the global derivative-free optimization of non-convex expensive functions. Even though there is a rich literature on Bayesian optimization, the source code of advanced methods is rarely available, making it difficult for practitioners to use them and for researchers to compare to and extend them. The BSD-licensed python package ROBO, released with this paper, tackles these problems by facilitating both ease of use and extensibility. Beyond the standard methods in Bayesian optimization, RoBO offers (to the best of our knowledge) the only available implementations of Bayesian optimization with Bayesian neural networks, multi-task optimization, and fast Bayesian hyperparameter optimization on large datasets (Fabolas).",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/17-BayesOpt-RoBO.pdf
Frank Hutter,HPOBench: A collection of reproducible multi-fidelity benchmark problems for HPO,2021,arXiv preprint arXiv:2109.06716,107,"Katharina Eggensperger, Philipp Müller, Neeratyoy Mallik, Matthias Feurer, René Sass, Aaron Klein, Noor Awad, Marius Lindauer, Frank Hutter",Katharina Eggensperger,Frank Hutter,9,"To achieve peak predictive performance, hyperparameter optimization (HPO) is a crucial component of machine learning and its applications. Over the last years, the number of efficient algorithms and tools for HPO grew substantially. At the same time, the community is still lacking realistic, diverse, computationally cheap, and standardized benchmarks. This is especially the case for multi-fidelity HPO methods. To close this gap, we propose HPOBench, which includes 7 existing and 5 new benchmark families, with a total of more than 100 multi-fidelity benchmark problems. HPOBench allows to run this extendable set of multi-fidelity HPO benchmarks in a reproducible way by isolating and packaging the individual benchmarks in containers. It also provides surrogate and tabular benchmarks for computationally affordable yet statistically sound evaluations. To demonstrate HPOBench's broad compatibility with various optimization tools, as well as its usefulness, we conduct an exemplary large-scale study evaluating 13 optimizers from 6 optimization tools. We provide HPOBench here: https://github.com/automl/HPOBench.",https://arxiv.org/abs/2109.06716
Frank Hutter,Openml-python: an extensible python api for openml,2021,Journal of Machine Learning Research,107,"Matthias Feurer, Jan N Van Rijn, Arlind Kadra, Pieter Gijsbers, Neeratyoy Mallik, Sahithya Ravi, Andreas Müller, Joaquin Vanschoren, Frank Hutter",Matthias Feurer,Frank Hutter,9,"OpenML is an online platform for open science collaboration in machine learning, used to share datasets and results of machine learning experiments. In this paper, we introduce OpenML-Python, a client API for Python, which opens up the OpenML platform for a wide range of Python-based machine learning tools. It provides easy access to all datasets, tasks and experiments on OpenML from within Python. It also provides functionality to conduct machine learning experiments, upload the results to OpenML, and reproduce results which are stored on OpenML. Furthermore, it comes with a scikit-learn extension and an extension mechanism to easily integrate other machine learning libraries written in Python into the OpenML ecosystem.",https://www.jmlr.org/papers/v22/19-920.html
Frank Hutter,Time-bounded sequential parameter optimization,2010,"Learning and Intelligent Optimization: 4th International Conference, LION 4, Venice, Italy, January 18-22, 2010. Selected Papers 4",104,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown, Kevin Murphy",Frank Hutter,Kevin Murphy,4,"The optimization of algorithm performance by automatically identifying good parameter settings is an important problem that has recently attracted much attention in the discrete optimization community. One promising approach constructs predictive performance models and uses them to focus attention on promising regions of a design space. Such methods have become quite sophisticated and have achieved significant successes on other problems, particularly in experimental design applications. However, they have typically been designed to achieve good performance only under a budget expressed as a number of function evaluations (e.g., target algorithm runs). In this work, we show how to extend the Sequential Parameter Optimization framework SPO; see 5] to operate effectively under time bounds. Our methods take into account both the varying amount of time required for different algorithm runs …",https://link.springer.com/chapter/10.1007/978-3-642-13800-3_30
Frank Hutter,Real-time fault detection and situational awareness for rovers: Report on the mars technology program task,2004,2004 ieee aerospace conference proceedings (ieee cat. no. 04th8720),104,"Richard Dearden, Thomas Willeke, Reid Simmons, Vandi Verma, Frank Hutter, Sebastian Thrun",Richard Dearden,Sebastian Thrun,6,"In this paper we describe the results of a project funded by the Mars technology program at NASA, aimed at developing algorithms to meet this requirement. We describe a number of particle filtering-based algorithms for state estimation which we have demonstrated successfully on diagnosis problems including the K-9 rover at NASA Ames Research Center and the Hyperion rover at CMU. Due to the close interaction between a rover and its environment, traditional discrete approaches to diagnosis are impractical for this domain. Therefore we model rover subsystems as hybrid discrete/continuous systems. There are three major challenges to make particle filters work in this domain. The first is that fault states typically have a very low probability of occurring, so there is a risk that no samples enter fault states. The second issue is coping with the high-dimensional continuous state spaces of the hybrid system models …",https://ieeexplore.ieee.org/abstract/document/1367683/
Frank Hutter,Using meta-learning to initialize bayesian optimization of hyperparameters.,2014,MetaSel@ ECAI,103,"Matthias Feurer, Jost Tobias Springenberg, Frank Hutter",Matthias Feurer,Frank Hutter,3,"Model selection and hyperparameter optimization is crucial in applying machine learning to a novel dataset. Recently, a subcommunity of machine learning has focussed on solving this problem with Sequential Model-based Bayesian Optimization (SMBO), demonstrating substantial successes in many applications. However, for expensive algorithms the computational overhead of hyperparameter optimization can still be prohibitive. In this paper we explore the possibility of speeding up SMBO by transferring knowledge from previous optimization runs on similar datasets; specifically, we propose to initialize SMBO with a small number of configurations suggested by a metalearning procedure. The resulting simple MI-SMBO technique can be trivially applied to any SMBO method, allowing us to perform experiments on two quite different SMBO methods with complementary strengths applied to optimize two machine learning frameworks on 57 classification datasets. We find that our initialization procedure mildly improves the state of the art in low-dimensional hyperparameter optimization and substantially improves the state of the art in the more complex problem of combined model selection and hyperparameter optimization.",http://repositorio.inesctec.pt/bitstream/123456789/4540/1/P-00G-699.pdf#page=8
Frank Hutter,An evaluation of sequential model-based optimization for expensive blackbox functions,2013,,101,"Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"We benchmark a sequential model-based optimization procedure, SMAC-BBOB, on the BBOB set of blackbox functions. We demonstrate that with a small budget of 10xD evaluations of D-dimensional functions, SMAC-BBOB in most cases outperforms the state-of-the-art blackbox optimizer CMA-ES. However, CMA-ES benefits more from growing the budget to 100xD, and for larger number of function evaluations SMAC-BBOB also requires increasingly large computational resources for building and using its models.",https://dl.acm.org/doi/abs/10.1145/2464576.2501592
Frank Hutter,The Sacred Infrastructure for Computational Research.,2017,SciPy,100,"Klaus Greff, Aaron Klein, Martin Chovanec, Frank Hutter, Jürgen Schmidhuber",Klaus Greff,Jürgen Schmidhuber,5,"A major part of machine learning research typically involves a significant number of computational experiments run with many different hyperparameter settings. This process holds many practical challenges, such as bookkeeping and maintaining reproducibility. To make matters worse, experiments often run on diverse and heterogeneous environments, ranging from laptops to cloud computing nodes. Due to deadline pressure and the inherently unpredictable nature of research, there is usually little incentive for researchers to build robust infrastructures. As a result, research code often evolves quickly and compromises essential aspects like bookkeeping and reproducibility.Many tools exist for tackling different aspects of this process, including databases, version control systems, command-line interface generators, tools for automated hyperparameter optimization, spreadsheets, and so on. Few, however, integrate these aspects into a unified system, so each tool has to be learned and used separately, each incurring its overhead. Since there is no common basis to build a workflow, the tools people create will be tied to their particular setup. This impedes sharing and collaboration on tools for major problems like optimizing hyperparameters, summarizing and analyzing results, rerunning experiments, distributing runs, etc..",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/17-SciPy-Sacred.pdf
Frank Hutter,AClib: A benchmark library for algorithm configuration,2014,"Learning and Intelligent Optimization: 8th International Conference, Lion 8, Gainesville, FL, USA, February 16-21, 2014. Revised Selected Papers 8",98,"Frank Hutter, Manuel López-Ibánez, Chris Fawcett, Marius Lindauer, Holger H Hoos, Kevin Leyton-Brown, Thomas Stützle",Frank Hutter,Thomas Stützle,7,"Modern solvers for hard computational problems often expose parameters that permit customization for high performance on specific instance types. Since it is tedious and time-consuming to manually optimize such highly parameterized algorithms, recent work in the AI literature has developed automated approaches for this algorithm configuration problem [1, 3, 10, 11, 13, 16].",https://link.springer.com/chapter/10.1007/978-3-319-09584-4_4
Frank Hutter,Automated reinforcement learning (autorl): A survey and open problems,2022,Journal of Artificial Intelligence Research,96,"Jack Parker-Holder, Raghu Rajan, Xingyou Song, André Biedenkapp, Yingjie Miao, Theresa Eimer, Baohe Zhang, Vu Nguyen, Roberto Calandra, Aleksandra Faust, Frank Hutter, Marius Lindauer",Jack Parker-Holder,Marius Lindauer,12,"The combination of Reinforcement Learning (RL) with deep learning has led to a series of impressive feats, with many believing (deep) RL provides a path towards generally capable agents. However, the success of RL agents is often highly sensitive to design choices in the training process, which may require tedious and error-prone manual tuning. This makes it challenging to use RL for new problems and also limits its full potential. In many other areas of machine learning, AutoML has shown that it is possible to automate such design choices, and AutoML has also yielded promising initial results when applied to RL. However, Automated Reinforcement Learning (AutoRL) involves not only standard applications of AutoML but also includes additional challenges unique to RL, that naturally produce a different set of methods. As such, AutoRL has been emerging as an important area of research in RL, providing promise in a variety of applications from RNA design to playing games, such as Go. Given the diversity of methods and environments considered in RL, much of the research has been conducted in distinct subfields, ranging from meta-learning to evolution. In this survey, we seek to unify the field of AutoRL, provide a common taxonomy, discuss each area in detail and pose open problems of interest to researchers going forward.",https://www.jair.org/index.php/jair/article/view/13596
Frank Hutter,Learning to design RNA,2018,arXiv preprint arXiv:1812.11951,96,"Frederic Runge, Danny Stoll, Stefan Falkner, Frank Hutter",Frederic Runge,Frank Hutter,4,"Designing RNA molecules has garnered recent interest in medicine, synthetic biology, biotechnology and bioinformatics since many functional RNA molecules were shown to be involved in regulatory processes for transcription, epigenetics and translation. Since an RNA's function depends on its structural properties, the RNA Design problem is to find an RNA sequence which satisfies given structural constraints. Here, we propose a new algorithm for the RNA Design problem, dubbed LEARNA. LEARNA uses deep reinforcement learning to train a policy network to sequentially design an entire RNA sequence given a specified target structure. By meta-learning across 65000 different RNA Design tasks for one hour on 20 CPU cores, our extension Meta-LEARNA constructs an RNA Design policy that can be applied out of the box to solve novel RNA Design tasks. Methodologically, for what we believe to be the first time, we jointly optimize over a rich space of architectures for the policy network, the hyperparameters of the training procedure and the formulation of the decision process. Comprehensive empirical results on two widely-used RNA Design benchmarks, as well as a third one that we introduce, show that our approach achieves new state-of-the-art performance on the former while also being orders of magnitudes faster in reaching the previous state-of-the-art performance. In an ablation study, we analyze the importance of our method's different components.",https://arxiv.org/abs/1812.11951
Frank Hutter,The reparameterization trick for acquisition functions,2017,arXiv preprint arXiv:1712.00424,94,"James T Wilson, Riccardo Moriconi, Frank Hutter, Marc Peter Deisenroth",James T Wilson,Marc Peter Deisenroth,4,"Bayesian optimization is a sample-efficient approach to solving global optimization problems. Along with a surrogate model, this approach relies on theoretically motivated value heuristics (acquisition functions) to guide the search process. Maximizing acquisition functions yields the best performance; unfortunately, this ideal is difficult to achieve since optimizing acquisition functions per se is frequently non-trivial. This statement is especially true in the parallel setting, where acquisition functions are routinely non-convex, high-dimensional, and intractable. Here, we demonstrate how many popular acquisition functions can be formulated as Gaussian integrals amenable to the reparameterization trick and, ensuingly, gradient-based optimization. Further, we use this reparameterized representation to derive an efficient Monte Carlo estimator for the upper confidence bound acquisition function in the context of parallel selection.",https://arxiv.org/abs/1712.00424
Frank Hutter,Autodispnet: Improving disparity estimation with automl,2019,Proceedings of the ieee/cvf international conference on computer vision,93,"Tonmoy Saikia, Yassine Marrakchi, Arber Zela, Frank Hutter, Thomas Brox",Tonmoy Saikia,Thomas Brox,5,"Much research work in computer vision is being spent on optimizing existing network architectures to obtain a few more percentage points on benchmarks. Recent AutoML approaches promise to relieve us from this effort. However, they are mainly designed for comparatively small-scale classification tasks. In this work, we show how to use and extend existing AutoML techniques to efficiently optimize large-scale U-Net-like encoder-decoder architectures. In particular, we leverage gradient-based neural architecture search and Bayesian optimization for hyperparameter search. The resulting optimization does not require a large-scale compute cluster. We show results on disparity estimation that clearly outperform the manually optimized baseline and reach state-of-the-art performance.",http://openaccess.thecvf.com/content_ICCV_2019/html/Saikia_AutoDispNet_Improving_Disparity_Estimation_With_AutoML_ICCV_2019_paper.html
Frank Hutter,Sequential model-based optimization for general algorithm configuration (extended version),2010,"Technical Report TR-2010–10, University of British Columbia, Computer Science, Tech. Rep.",90,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"State-of-the-art algorithms for hard computational problems often expose many parameters that can be modified to improve empirical performance. However, manually exploring the resulting combinatorial space of parameter settings is tedious and tends to lead to unsatisfactory outcomes. Recently, automated approaches for solving this algorithm configuration problem have led to substantial improvements in the state of the art for solving various problems. One promising approach constructs explicit regression models to describe the dependence of target algorithm performance on parameter settings; however, this approach has so far been limited to the optimization of few numerical algorithm parameters on single instances. In this paper, we extend this paradigm for the first time to general algorithm configuration problems, allowing many categorical parameters and optimization for sets of instances. We experimentally validate our new algorithm configuration procedure by optimizing a local search and a tree search solver for the propositional satisfiability problem (SAT), as well as the commercial mixed integer programming (MIP) solver CPLEX. In these experiments, our procedure yielded state-of-the-art performance, and in many cases outperformed the previous best configuration approach.",https://ai.dmi.unibas.ch/research/reading_group/hutter-et-al-tr2010.pdf
Frank Hutter,Meta-learning acquisition functions for transfer learning in bayesian optimization,2019,arXiv preprint arXiv:1904.02642,88,"Michael Volpp, Lukas P Fröhlich, Kirsten Fischer, Andreas Doerr, Stefan Falkner, Frank Hutter, Christian Daniel",Michael Volpp,Christian Daniel,7,"Transferring knowledge across tasks to improve data-efficiency is one of the open key challenges in the field of global black-box optimization. Readily available algorithms are typically designed to be universal optimizers and, therefore, often suboptimal for specific tasks. We propose a novel transfer learning method to obtain customized optimizers within the well-established framework of Bayesian optimization, allowing our algorithm to utilize the proven generalization capabilities of Gaussian processes. Using reinforcement learning to meta-train an acquisition function (AF) on a set of related tasks, the proposed method learns to extract implicit structural information and to exploit it for improved data-efficiency. We present experiments on a simulation-to-real transfer task as well as on several synthetic functions and on two hyperparameter search problems. The results show that our algorithm (1) automatically identifies structural properties of objective functions from available source tasks or simulations, (2) performs favourably in settings with both scarse and abundant source data, and (3) falls back to the performance level of general AFs if no particular structure is present.",https://arxiv.org/abs/1904.02642
Frank Hutter,Decoupled weight decay regularization. arXiv doi: 10.48550,2019,arXiv preprint arXiv.1711.05101,88,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=5094156892790128623&hl=en&oi=scholarr
Frank Hutter,A case study of algorithm selection for the traveling thief problem,2018,Journal of Heuristics,88,"Markus Wagner, Marius Lindauer, Mustafa Mısır, Samadhi Nallaperuma, Frank Hutter",Markus Wagner,Frank Hutter,5,"Many real-world problems are composed of several interacting components. In order to facilitate research on such interactions, the Traveling Thief Problem (TTP) was created in 2013 as the combination of two well-understood combinatorial optimization problems. With this article, we contribute in four ways. First, we create a comprehensive dataset that comprises the performance data of 21 TTP algorithms on the full original set of 9720 TTP instances. Second, we define 55 characteristics for all TPP instances that can be used to select the best algorithm on a per-instance basis. Third, we use these algorithms and features to construct the first algorithm portfolios for TTP, clearly outperforming the single best algorithm. Finally, we study which algorithms contribute most to this portfolio.",https://link.springer.com/article/10.1007/s10732-017-9328-y
Frank Hutter,Dynamic algorithm configuration: Foundation of a new meta-algorithmic framework,2020,,87,"André Biedenkapp, H Furkan Bozkurt, Theresa Eimer, Frank Hutter, Marius Lindauer",André Biedenkapp,Marius Lindauer,5,"The performance of many algorithms in the fields of hard combinatorial problem solving, machine learning or AI in general depends on parameter tuning. Automated methods have been proposed to alleviate users from the tedious and error-prone task of manually searching for performance-optimized configurations across a set of problem instances. However, there is still a lot of untapped potential through adjusting an algorithm’s parameters online since different parameter values can be optimal at different stages of the algorithm. Prior work showed that reinforcement learning is an effective approach to learn policies for online adjustments of algorithm parameters in a data-driven way. We extend that approach by formulating the resulting dynamic algorithm configuration as a contextual MDP, such that RL not only learns a policy for a single instance, but across a set of instances. To lay the foundation for studying …",https://ebooks.iospress.nl/volumearticle/54917
Frank Hutter,Evolutionary computation for wind farm layout optimization,2018,Renewable energy,87,"Dennis Wilson, Silvio Rodrigues, Carlos Segura, Ilya Loshchilov, Frank Hutter, Guillermo López Buenfil, Ahmed Kheiri, Ed Keedwell, Mario Ocampo-Pineda, Ender Özcan, Sergio Ivvan Valdez Peña, Brian Goldman, Salvador Botello Rionda, Arturo Hernández-Aguirre, Kalyan Veeramachaneni, Sylvain Cussat-Blanc",Dennis Wilson,Sylvain Cussat-Blanc,16,"This paper presents the results of the second edition of the Wind Farm Layout Optimization Competition, which was held at the 22nd Genetic and Evolutionary Computation COnference (GECCO) in 2015. During this competition, competitors were tasked with optimizing the layouts of five generated wind farms based on a simplified cost of energy evaluation function of the wind farm layouts. Online and offline APIs were implemented in C++, Java, Matlab and Python for this competition to offer a common framework for the competitors. The top four approaches out of eight participating teams are presented in this paper and their results are compared. All of the competitors' algorithms use evolutionary computation, the research field of the conference at which the competition was held. Competitors were able to downscale the optimization problem size (number of parameters) by casting the wind farm layout problem as a …",https://www.sciencedirect.com/science/article/pii/S096014811830363X
Frank Hutter,Identifying key algorithm parameters and instance features using forward selection,2013,"Learning and Intelligent Optimization: 7th International Conference, LION 7, Catania, Italy, January 7-11, 2013, Revised Selected Papers 7",87,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"Most state-of-the-art algorithms for large-scale optimization problems expose free parameters, giving rise to combinatorial spaces of possible configurations. Typically, these spaces are hard for humans to understand. In this work, we study a model-based approach for identifying a small set of both algorithm parameters and instance features that suffices for predicting empirical algorithm performance well. Our empirical analyses on a wide variety of hard combinatorial problem benchmarks (spanning SAT, MIP, and TSP) show that—for parameter configurations sampled uniformly at random—very good performance predictions can typically be obtained based on just two key parameters, and that similarly, few instance features and algorithm parameters suffice to predict the most salient algorithm performance characteristics in the combined configuration/feature space. We also use these models to identify …",https://link.springer.com/chapter/10.1007/978-3-642-44973-4_40
Frank Hutter,OpenML benchmarking suites and the OpenML100,2017,stat,85,"Bernd Bischl, Giuseppe Casalicchio, Matthias Feurer, Frank Hutter, Michel Lang, Rafael G Mantovani, Jan N Van Rijn, Joaquin Vanschoren",Bernd Bischl,Joaquin Vanschoren,8,"We advocate the use of curated, comprehensive benchmark suites of machine learning datasets, backed by standardized OpenML-based interfaces and complementary software toolkits written in Python, Java and R. Major distinguishing features of OpenML benchmark suites are (a) ease of use through standardized data formats, APIs, and existing client libraries;(b) machine-readable meta-information regarding the contents of the suite; and (c) online sharing of results, enabling large scale comparisons. As a first such suite, we propose the OpenML100, a machine learning benchmark suite of 100 classification datasets carefully curated from the thousands of datasets available on OpenML. org.",https://www.researchgate.net/profile/Giuseppe-Casalicchio/publication/319121901_OpenML_Benchmarking_Suites_and_the_OpenML100/links/599ee1bfaca272dff134f8c6/OpenML-Benchmarking-Suites-and-the-OpenML100.pdf
Frank Hutter,Managing ai risks in an era of rapid progress,2023,arXiv preprint arXiv:2310.17688,84,"Yoshua Bengio, Geoffrey Hinton, Andrew Yao, Dawn Song, Pieter Abbeel, Yuval Noah Harari, Ya-Qin Zhang, Lan Xue, Shai Shalev-Shwartz, Gillian Hadfield, Jeff Clune, Tegan Maharaj, Frank Hutter, Atılım Günes Baydin, Sheila McIlraith, Qiqi Gao, Ashwin Acharya, David Krueger, Anca Dragan, Philip Torr, Stuart Russell, Daniel Kahneman, Jan Brauner, Sören Mindermann",Yoshua Bengio,Sören Mindermann,24,"In this short consensus paper, we outline risks from upcoming, advanced AI systems. We examine large-scale social harms and malicious uses, as well as an irreversible loss of human control over autonomous AI systems. In light of rapid and continuing AI progress, we propose urgent priorities for AI R&D and governance.",https://blog.biocomm.ai/wp-content/uploads/2023/11/Managing-AI-Risks-in-an-Era-of-Rapid-Progress.pdf
Frank Hutter,Fast bayesian hyperparameter optimization on large datasets,2017,,83,"Aaron Klein, Stefan Falkner, Simon Bartels, Philipp Hennig, Frank Hutter",Aaron Klein,Frank Hutter,5,"Bayesian optimization has become a successful tool for optimizing the hyperparameters of machine learning algorithms, such as support vector machines or deep neural networks. Despite its success, for large datasets, training and validating a single configuration often takes hours, days, or even weeks, which limits the achievable performance. To accelerate hyperparameter optimization, we propose a generative model for the validation error as a function of training set size, which is learned during the optimization process and allows exploration of preliminary configurations on small subsets, by extrapolating to the full dataset. We construct a Bayesian optimization procedure, dubbed FABOLAS, which models loss and training time as a function of dataset size and automatically trades off high information gain about the global optimum against computational cost. Experiments optimizing support vector …",https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-11/issue-2/Fast-Bayesian-hyperparameter-optimization-on-large-datasets/10.1214/17-EJS1335SI.short
Frank Hutter,The configurable SAT solver challenge (CSSC),2017,Artificial Intelligence,82,"Frank Hutter, Marius Lindauer, Adrian Balint, Sam Bayless, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,6,"It is well known that different solution strategies work well for different types of instances of hard combinatorial problems. As a consequence, most solvers for the propositional satisfiability problem (SAT) expose parameters that allow them to be customized to a particular family of instances. In the international SAT competition series, these parameters are ignored: solvers are run using a single default parameter setting (supplied by the authors) for all benchmark instances in a given track. While this competition format rewards solvers with robust default settings, it does not reflect the situation faced by a practitioner who only cares about performance on one particular application and can invest some time into tuning solver parameters for this application. The new Configurable SAT Solver Competition (CSSC) compares solvers in this latter setting, scoring each solver by the performance it achieved after a fully …",https://www.sciencedirect.com/science/article/pii/S0004370216301138
Frank Hutter,Warmstarting of model-based algorithm configuration,2018,Proceedings of the AAAI Conference on Artificial Intelligence,81,"Marius Lindauer, Frank Hutter",Marius Lindauer,Frank Hutter,2,"The performance of many hard combinatorial problem solvers depends strongly on their parameter settings, and since manual parameter tuning is both tedious and suboptimal the AI community has recently developed several algorithm configuration (AC) methods to automatically address this problem. While all existing AC methods start the configuration process of an algorithm A from scratch for each new type of benchmark instances, here we propose to exploit information about A's performance on previous benchmarks in order to warmstart its configuration on new types of benchmarks. We introduce two complementary ways in which we can exploit this information to warmstart AC methods based on a predictive model. Experiments for optimizing a flexible modern SAT solver on twelve different instance sets show that our methods often yield substantial speedups over existing AC methods (up to 165-fold) and can also find substantially better configurations given the same compute budget.",https://ojs.aaai.org/index.php/AAAI/article/view/11532
Frank Hutter,Surrogate NAS benchmarks: Going beyond the limited search spaces of tabular NAS benchmarks,2020,arXiv preprint arXiv:2008.09777,80,"Arber Zela, Julien Siems, Lucas Zimmer, Jovita Lukasik, Margret Keuper, Frank Hutter",Arber Zela,Frank Hutter,6,"The most significant barrier to the advancement of Neural Architecture Search (NAS) is its demand for large computational resources, which hinders scientifically sound empirical evaluations of NAS methods. Tabular NAS benchmarks have alleviated this problem substantially, making it possible to properly evaluate NAS methods in seconds on commodity machines. However, an unintended consequence of tabular NAS benchmarks has been a focus on extremely small architectural search spaces since their construction relies on exhaustive evaluations of the space. This leads to unrealistic results that do not transfer to larger spaces. To overcome this fundamental limitation, we propose a methodology to create cheap NAS surrogate benchmarks for arbitrary search spaces. We exemplify this approach by creating surrogate NAS benchmarks on the existing tabular NAS-Bench-101 and on two widely used NAS search spaces with up to  architectures ( times larger than any previous tabular NAS benchmark). We show that surrogate NAS benchmarks can model the true performance of architectures better than tabular benchmarks (at a small fraction of the cost), that they lead to faithful estimates of how well different NAS methods work on the original non-surrogate benchmark, and that they can generate new scientific insight. We open-source all our code and believe that surrogate NAS benchmarks are an indispensable tool to extend scientifically sound work on NAS to large and exciting search spaces.",https://arxiv.org/abs/2008.09777
Frank Hutter,The gaussian particle filter for diagnosis of non-linear systems,2003,IFAC Proceedings Volumes,79,"Frank Hutter, Richard Dearden",Frank Hutter,Richard Dearden,2,"Fault diagnosis is a critical task for autonomous operation of systems such as spacecraft and planetary rovers, and must often be performed on-board. Unfortunately, these systems frequently also have relatively little computational power to devote to diagnosis. For this reason, algorithms for these applications must be extremely efficient, and preferably anytime. In this paper we introduce the Gaussian particle filter (GPF), a new variant on the particle filtering algorithm specifically for non-linear hybrid systems. Each particle samples a discrete mode and approximates the continuous variables by a multivariate Gaussian that is updated at each time-step using an unscented Kalman filter. The algorithm is closely related to Rao-Blackwellized Particle Filtering and equally efficient, but is more broadly applicable. We demonstrate the algorithm on a Mars rover problem and show that it is faster and more accurate than …",https://www.sciencedirect.com/science/article/pii/S1474667017366089
Frank Hutter,SATzilla2009: an automatic algorithm portfolio for SAT,2009,SAT,77,"Lin Xu, Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"Empirical studies often observe that the performance of algorithms across problem domains can be quite uncorrelated. When this occurs, it seems practical to investigate the use of algorithm portfolios that draw on the strengths of multiple algorithms. SATzilla is such an algorithm portfolio for SAT problems; it was first deployed in the 2004 SAT competition [12], and recently an updated version, SATzilla2007, won a number of prizes in the 2007 SAT competition [21], including the gold medals for the SAT+ UNSAT categories of both the random and handmade categories. SATzilla2008, submitted to the 2008 SAT Race, did not perform as well. We attribute this mainly to the lack of publicly available high-performance component solvers as well as to overheads in computing instance features for huge industrial instances; we addressed this latter point in SATzilla2009. SATzilla is based on empirical hardness models [10, 13], learned predictors that estimate each algorithm’s performance on a given SAT instance. Over the years, we have added several features to SATzilla. We integrated regression methods based on partly censored data, probabilistic prediction of instance satisfiability, and hierarchical hardness models [21, 22]. We also almost entirely automated the portfolio construction process based on automatic procedures for selecting pre-solvers and candidate component solvers [23].",https://www.academia.edu/download/48207470/booklet.pdf#page=57
Frank Hutter,Pitfalls and best practices in algorithm configuration,2019,Journal of Artificial Intelligence Research,76,"Katharina Eggensperger, Marius Lindauer, Frank Hutter",Katharina Eggensperger,Frank Hutter,3,"Good parameter settings are crucial to achieve high performance in many areas of artificial intelligence (AI), such as propositional satisfiability solving, AI planning, scheduling, and machine learning (in particular deep learning). Automated algorithm configuration methods have recently received much attention in the AI community since they replace tedious, irreproducible and error-prone manual parameter tuning and can lead to new state-of-the-art performance. However, practical applications of algorithm configuration are prone to several (often subtle) pitfalls in the experimental design that can render the procedure ineffective. We identify several common issues and propose best practices for avoiding them. As one possibility for automatically handling as many of these as possible, we also propose a tool called GenericWrapper4AC.",https://www.jair.org/index.php/jair/article/view/11420
Frank Hutter,Parameter adjustment based on performance prediction: Towards an instance-aware problem solver,2005,"Microsoft Research, Tech. Rep. MSR-TR-2005-125",73,"Frank Hutter, Youssef Hamadi",Frank Hutter,Youssef Hamadi,2,"Tuning an algorithm’s parameters for robust and high performance is a tedious and time-consuming task that often requires knowledge about both the domain and the algorithm of interest. Furthermore, the optimal parameter configuration to use may differ considerably across problem instances. In this report, we define and tackle the algorithm configuration problem, which is to automatically choose the optimal parameter configuration for a given algorithm on a per-instance base. We employ an indirect approach that predicts algorithm runtime for the problem instance at hand and each (continuous) parameter configuration, and then simply chooses the configuration that minimizes the prediction. This approach is based on similar work by Leyton-Brown et al.[LBNS02, NLBD+04] who tackle the algorithm selection problem [Ric76](given a problem instance, choose the best algorithm to solve it). While all previous studies for runtime prediction focussed on tree search algorithm, we demonstrate that it is possible to fairly accurately predict the runtime of SAPS [HTH02], one of the best-performing stochastic local search algorithms for SAT. We also show that our approach automatically picks parameter configurations that speed up SAPS by an average factor of more than two when compared to its default parameter configuration. Finally, we introduce sequential Bayesian learning to the problem of runtime prediction, enabling an incremental learning approach and yielding very informative estimates of predictive uncertainty.",https://www.cs.ubc.ca/~hutter/papers/msr_tr05-autoparam.pdf
Frank Hutter,BO: Augmenting Acquisition Functions with User Beliefs for Bayesian Optimization,2022,arXiv preprint arXiv:2204.11051,72,"Carl Hvarfner, Danny Stoll, Artur Souza, Marius Lindauer, Frank Hutter, Luigi Nardi",Carl Hvarfner,Luigi Nardi,6,"Bayesian optimization (BO) has become an established framework and popular tool for hyperparameter optimization (HPO) of machine learning (ML) algorithms. While known for its sample-efficiency, vanilla BO can not utilize readily available prior beliefs the practitioner has on the potential location of the optimum. Thus, BO disregards a valuable source of information, reducing its appeal to ML practitioners. To address this issue, we propose BO, an acquisition function generalization which incorporates prior beliefs about the location of the optimum in the form of a probability distribution, provided by the user. In contrast to previous approaches, BO is conceptually simple and can easily be integrated with existing libraries and many acquisition functions. We provide regret bounds when BO is applied to the common Expected Improvement acquisition function and prove convergence at regular rates independently of the prior. Further, our experiments show that BO outperforms competing approaches across a wide suite of benchmarks and prior characteristics. We also demonstrate that BO improves on the state-of-the-art performance for a popular deep learning task, with a 12.5  time-to-accuracy speedup over prominent BO approaches.",https://arxiv.org/abs/2204.11051
Frank Hutter,Efficient benchmarking of algorithm configurators via model-based surrogates,2018,Machine Learning,66,"Katharina Eggensperger, Marius Lindauer, Holger H Hoos, Frank Hutter, Kevin Leyton-Brown",Katharina Eggensperger,Kevin Leyton-Brown,5,"The optimization of algorithm (hyper-)parameters is crucial for achieving peak performance across a wide range of domains, ranging from deep neural networks to solvers for hard combinatorial problems. However, the proper evaluation of new algorithm configuration (AC) procedures (or configurators) is hindered by two key hurdles. First, AC scenarios are hard to set up, including the target algorithm to be optimized and the problem instances to be solved. Second, and even more significantly, they are computationally expensive: a single configurator run involves many costly runs of the target algorithm. Here, we propose a benchmarking approach that uses surrogate scenarios, which are computationally cheap while remaining close to the original AC scenarios. These surrogate scenarios approximate the response surface corresponding to true target algorithm performance using a regression model. In our …",https://link.springer.com/article/10.1007/s10994-017-5683-z
Frank Hutter,Smac v3: Algorithm configuration in python,2017,URL https://github. com/automl/SMAC3,64,"Marius Lindauer, Katharina Eggensperger, Matthias Feurer, Stefan Falkner, André Biedenkapp, Frank Hutter",Marius Lindauer,Frank Hutter,6,,https://scholar.google.com/scholar?cluster=5249839483341959557&hl=en&oi=scholarr
Frank Hutter,Automatic configuration of sequential planning portfolios,2015,Proceedings of the AAAI Conference on Artificial Intelligence,62,"Jendrik Seipp, Silvan Sievers, Malte Helmert, Frank Hutter",Jendrik Seipp,Frank Hutter,4,"Sequential planning portfolios exploit the complementary strengths of different planners. Similarly, automated algorithm configuration tools can customize parameterized planning algorithms for a given type of tasks. Although some work has been done towards combining portfolios and algorithm configuration, the problem of automatically generating a sequential planning portfolio from a parameterized planner for a given type of tasks is still largely unsolved. Here, we present Cedalion, a conceptually simple approach for this problem that greedily searches for the pair of parameter configuration and runtime which, when appended to the current portfolio, maximizes portfolio improvement per additional runtime spent. We show theoretically that Cedalion yields portfolios provably within a constant factor of optimal for the training set distribution. We evaluate Cedalion empirically by applying it to construct sequential planning portfolios based on component planners from the highly parameterized Fast Downward (FD) framework. Results for a broad range of planning settings demonstrate that--without any knowledge of planning or FD--Cedalion constructs sequential FD portfolios that rival, and in some cases substantially outperform, manually-built FD portfolios.",https://ojs.aaai.org/index.php/AAAI/article/view/9640
Frank Hutter,Improved features for runtime prediction of domain-independent planners,2014,Proceedings of the International Conference on Automated Planning and Scheduling,62,"Chris Fawcett, Mauro Vallati, Frank Hutter, Jörg Hoffmann, Holger Hoos, Kevin Leyton-Brown",Chris Fawcett,Kevin Leyton-Brown,6,"State-of-the-art planners often exhibit substantial runtime variation, making it useful to be able to efficiently predict how long a given planner will take to run on a given instance. In other areas of AI, such needs are met by building so-called empirical performance models (EPMs), statistical models derived from sets of problem instances and performance observations. Historically, such models have been less accurate for predicting the running times of planners. A key hurdle has been a relative weakness in instance features for characterizing instances: mappings from problem instances to real numbers that serve as the starting point for learning an EPM. We propose a new, extensive set of instance features for planning, and investigate its effectiveness across a range of model families. We built EPMs for various prominent planning systems on several thousand benchmark problems from the planning literature and from IPC benchmark sets, and conclude that our models predict runtime much more accurately than the previous state of the art. We also study the relative importance of these features.",https://ojs.aaai.org/index.php/ICAPS/article/view/13680
Frank Hutter,Understanding the empirical hardness of NP-complete problems,2014,Communications of the ACM,62,"Kevin Leyton-Brown, Holger H Hoos, Frank Hutter, Lin Xu",Kevin Leyton-Brown,Lin Xu,4,Using machine learning to predict algorithm runtime.,https://dl.acm.org/doi/abs/10.1145/2594413.2594424
Frank Hutter,Efficient parameter importance analysis via ablation with surrogates,2017,Proceedings of the AAAI Conference on Artificial Intelligence,60,"André Biedenkapp, Marius Lindauer, Katharina Eggensperger, Frank Hutter, Chris Fawcett, Holger Hoos",André Biedenkapp,Holger Hoos,6,"To achieve peak performance, it is often necessary to adjust the parameters of a given algorithm to the class of problem instances to be solved; this is known to be the case for popular solvers for a broad range of AI problems, including AI planning, propositional satisfiability (SAT) and answer set programming (ASP). To avoid tedious and often highly sub-optimal manual tuning of such parameters by means of ad-hoc methods, general-purpose algorithm configuration procedures can be used to automatically find performance-optimizing parameter settings. While impressive performance gains are often achieved in this manner, additional, potentially costly parameter importance analysis is required to gain insights into what parameter changes are most responsible for those improvements. Here, we show how the running time cost of ablation analysis, a well-known general-purpose approach for assessing parameter importance, can be reduced substantially by using regression models of algorithm performance constructed from data collected during the configuration process. In our experiments, we demonstrate speed-up factors between 33 and 14 727 for ablation analysis on various configuration scenarios from AI planning, SAT, ASP and mixed integer programming (MIP).",https://ojs.aaai.org/index.php/AAAI/article/view/10657
Frank Hutter,Large language models for automated data science: Introducing caafe for context-aware automated feature engineering,2024,Advances in Neural Information Processing Systems,59,"Noah Hollmann, Samuel Müller, Frank Hutter",Noah Hollmann,Frank Hutter,3,"As the field of automated machine learning (AutoML) advances, it becomes increasingly important to incorporate domain knowledge into these systems. We present an approach for doing so by harnessing the power of large language models (LLMs). Specifically, we introduce Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method for tabular datasets that utilizes an LLM to iteratively generate additional semantically meaningful features for tabular datasets based on the description of the dataset. The method produces both Python code for creating new features and explanations for the utility of the generated features. Despite being methodologically simple, CAAFE improves performance on 11 out of 14 datasets--boosting mean ROC AUC performance from 0.798 to 0.822 across all dataset-similar to the improvement achieved by using a random forest instead of logistic regression on our datasets. Furthermore, CAAFE is interpretable by providing a textual explanation for each generated feature. CAAFE paves the way for more extensive semi-automation in data science tasks and emphasizes the significance of context-aware solutions that can extend the scope of AutoML systems to semantic AutoML. We release our code, a simple demo and a python package.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/8c2df4c35cdbee764ebb9e9d0acd5197-Abstract-Conference.html
Frank Hutter,Efficient stochastic local search for MPE solving,2005,IJCAI,57,"Frank Hutter, Holger H Hoos, Thomas Stützle",Frank Hutter,Thomas Stützle,3,"Finding most probable explanations (MPEs) in graphical models, such as Bayesian belief networks, is a fundamental problem in reasoning under uncertainty, and much effort has been spent on developing effective algorithms for this NP-hard problem. Stochastic local search (SLS) approaches to MPE solving have previously been explored, but were found to be not competitive with state-of-theart branch & bound methods. In this work, we identify the shortcomings of earlier SLS algorithms for the MPE problem and demonstrate how these can be overcome, leading to an SLS algorithm that substantially improves the state-of-the-art in solving hard networks with many variables, large domain sizes, high degree, and, most importantly, networks with high induced width.",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=313409d0bbc130cc5af19a86e39415f5531edbc2
Frank Hutter,Nas-bench-suite: Nas evaluation is (now) surprisingly easy,2022,arXiv preprint arXiv:2201.13396,56,"Yash Mehta, Colin White, Arber Zela, Arjun Krishnakumar, Guri Zabergja, Shakiba Moradian, Mahmoud Safari, Kaicheng Yu, Frank Hutter",Yash Mehta,Frank Hutter,9,"The release of tabular benchmarks, such as NAS-Bench-101 and NAS-Bench-201, has significantly lowered the computational overhead for conducting scientific research in neural architecture search (NAS). Although they have been widely adopted and used to tune real-world NAS algorithms, these benchmarks are limited to small search spaces and focus solely on image classification. Recently, several new NAS benchmarks have been introduced that cover significantly larger search spaces over a wide range of tasks, including object detection, speech recognition, and natural language processing. However, substantial differences among these NAS benchmarks have so far prevented their widespread adoption, limiting researchers to using just a few benchmarks. In this work, we present an in-depth analysis of popular NAS algorithms and performance prediction methods across 25 different combinations of search spaces and datasets, finding that many conclusions drawn from a few NAS benchmarks do not generalize to other benchmarks. To help remedy this problem, we introduce NAS-Bench-Suite, a comprehensive and extensible collection of NAS benchmarks, accessible through a unified interface, created with the aim to facilitate reproducible, generalizable, and rapid NAS research. Our code is available at https://github.com/automl/naslib.",https://arxiv.org/abs/2201.13396
Frank Hutter,Fixing weight decay regularization in adam. arXiv 2017,2017,arXiv preprint arXiv:1711.05101,55,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=6563696938409754603&hl=en&oi=scholarr
Frank Hutter,Sample-efficient automated deep reinforcement learning,2020,arXiv preprint arXiv:2009.01555,53,"Jörg KH Franke, Gregor Köhler, André Biedenkapp, Frank Hutter",Jörg KH Franke,Frank Hutter,4,"Despite significant progress in challenging problems across various domains, applying state-of-the-art deep reinforcement learning (RL) algorithms remains challenging due to their sensitivity to the choice of hyperparameters. This sensitivity can partly be attributed to the non-stationarity of the RL problem, potentially requiring different hyperparameter settings at various stages of the learning process. Additionally, in the RL setting, hyperparameter optimization (HPO) requires a large number of environment interactions, hindering the transfer of the successes in RL to real-world applications. In this work, we tackle the issues of sample-efficient and dynamic HPO in RL. We propose a population-based automated RL (AutoRL) framework to meta-optimize arbitrary off-policy RL algorithms. In this framework, we optimize the hyperparameters and also the neural architecture while simultaneously training the agent. By sharing the collected experience across the population, we substantially increase the sample efficiency of the meta-optimization. We demonstrate the capabilities of our sample-efficient AutoRL approach in a case study with the popular TD3 algorithm in the MuJoCo benchmark suite, where we reduce the number of environment interactions needed for meta-optimization by up to an order of magnitude compared to population-based training.",https://arxiv.org/abs/2009.01555
Frank Hutter,Boah: A tool suite for multi-fidelity bayesian optimization & analysis of hyperparameters,2019,arXiv preprint arXiv:1908.06756,53,"Marius Lindauer, Katharina Eggensperger, Matthias Feurer, André Biedenkapp, Joshua Marben, Philipp Müller, Frank Hutter",Marius Lindauer,Frank Hutter,7,"Hyperparameter optimization and neural architecture search can become prohibitively expensive for regular black-box Bayesian optimization because the training and evaluation of a single model can easily take several hours. To overcome this, we introduce a comprehensive tool suite for effective multi-fidelity Bayesian optimization and the analysis of its runs. The suite, written in Python, provides a simple way to specify complex design spaces, a robust and efficient combination of Bayesian optimization and HyperBand, and a comprehensive analysis of the optimization process and its outcomes.",https://arxiv.org/abs/1908.06756
Frank Hutter,Spear theorem prover,2008,Proc. of the SAT,51,"Domagoj Babic, Frank Hutter",Domagoj Babic,Frank Hutter,2,"SPEAR is a modular arithmetic theorem prover designed for proving software verification conditions. The core of the theorem prover is a fast and simple SAT solver, which is described in this paper.",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=11def6e8e673d8572a52a0c1011efb02c977d9ce
Frank Hutter,Meta-surrogate benchmarking for hyperparameter optimization,2019,Advances in Neural Information Processing Systems,50,"Aaron Klein, Zhenwen Dai, Frank Hutter, Neil Lawrence, Javier Gonzalez",Aaron Klein,Javier Gonzalez,5,"Despite the recent progress in hyperparameter optimization (HPO), available benchmarks that resemble real-world scenarios consist of a few and very large problem instances that are expensive to solve. This blocks researchers and practitioners no only from systematically running large-scale comparisons that are needed to draw statistically significant results but also from reproducing experiments that were conducted before. This work proposes a method to alleviate these issues by means of a meta-surrogate model for HPO tasks trained on off-line generated data. The model combines a probabilistic encoder with a multi-task model such that it can generate inexpensive and realistic tasks of the class of problems of interest. We demonstrate that benchmarking HPO methods on samples of the generative model allows us to draw more coherent and statistically significant conclusions that can be reached orders of magnitude faster than using the original tasks. We provide evidence of our findings for various HPO methods on a wide class of problems.",https://proceedings.neurips.cc/paper/2019/hash/0668e20b3c9e9185b04b3d2a9dc8fa2d-Abstract.html
Frank Hutter,Bayesian optimization with a prior for the optimum,2021,"Machine Learning and Knowledge Discovery in Databases. Research Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13–17, 2021, Proceedings, Part III 21",49,"Artur Souza, Luigi Nardi, Leonardo B Oliveira, Kunle Olukotun, Marius Lindauer, Frank Hutter",Artur Souza,Frank Hutter,6,"While Bayesian Optimization (BO) is a very popular method for optimizing expensive black-box functions, it fails to leverage the experience of domain experts. This causes BO to waste function evaluations on bad design choices (e.g., machine learning hyperparameters) that the expert already knows to work poorly. To address this issue, we introduce Bayesian Optimization with a Prior for the Optimum (BOPrO). BOPrO allows users to inject their knowledge into the optimization process in the form of priors about which parts of the input space will yield the best performance, rather than BO’s standard priors over functions, which are much less intuitive for users. BOPrO then combines these priors with BO’s standard probabilistic model to form a pseudo-posterior used to select which points to evaluate next. We show that BOPrO is around  faster than state-of-the-art methods on a common suite of …",https://link.springer.com/chapter/10.1007/978-3-030-86523-8_17
Frank Hutter,"CAVE: Configuration assessment, visualization and evaluation",2019,"Learning and Intelligent Optimization: 12th International Conference, LION 12, Kalamata, Greece, June 10–15, 2018, Revised Selected Papers 12",47,"André Biedenkapp, Joshua Marben, Marius Lindauer, Frank Hutter",André Biedenkapp,Frank Hutter,4,"To achieve peak performance of an algorithm (in particular for problems in AI), algorithm configuration is often necessary to determine a well-performing parameter configuration. So far, most studies in algorithm configuration focused on proposing better algorithm configuration procedures or on improving a particular algorithm’s performance. In contrast, we use all the collected empirical performance data gathered during algorithm configuration runs to generate extensive insights into an algorithm, given problem instances and the used configurator. To this end, we provide a tool, called CAVE, that automatically generates comprehensive reports and insightful figures from all available empirical data. CAVE aims to help algorithm and configurator developers to better understand their experimental setup in an automated fashion. We showcase its use by thoroughly analyzing the well studied SAT solver spear …",https://link.springer.com/chapter/10.1007/978-3-030-05348-2_10
Frank Hutter,Bayesian optimization with censored response data,2013,arXiv preprint arXiv:1310.1947,47,"Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"Bayesian optimization (BO) aims to minimize a given blackbox function using a model that is updated whenever new evidence about the function becomes available. Here, we address the problem of BO under partially right-censored response data, where in some evaluations we only obtain a lower bound on the function value. The ability to handle such response data allows us to adaptively censor costly function evaluations in minimization problems where the cost of a function evaluation corresponds to the function value. One important application giving rise to such censored data is the runtime-minimizing variant of the algorithm configuration problem: finding settings of a given parametric algorithm that minimize the runtime required for solving problem instances from a given distribution. We demonstrate that terminating slow algorithm runs prematurely and handling the resulting right-censored observations can substantially improve the state of the art in model-based algorithm configuration.",https://arxiv.org/abs/1310.1947
Frank Hutter,Nas-bench-suite-zero: Accelerating research on zero cost proxies,2022,Advances in Neural Information Processing Systems,45,"Arjun Krishnakumar, Colin White, Arber Zela, Renbo Tu, Mahmoud Safari, Frank Hutter",Arjun Krishnakumar,Frank Hutter,6,"Zero-cost proxies (ZC proxies) are a recent architecture performance prediction technique aiming to significantly speed up algorithms for neural architecture search (NAS). Recent work has shown that these techniques show great promise, but certain aspects, such as evaluating and exploiting their complementary strengths, are under-studied. In this work, we create NAS-Bench-Suite: we evaluate 13 ZC proxies across 28 tasks, creating by far the largest dataset (and unified codebase) for ZC proxies, enabling orders-of-magnitude faster experiments on ZC proxies, while avoiding confounding factors stemming from different implementations. To demonstrate the usefulness of NAS-Bench-Suite, we run a large-scale analysis of ZC proxies, including a bias analysis, and the first information-theoretic analysis which concludes that ZC proxies capture substantial complementary information. Motivated by these findings, we present a procedure to improve the performance of ZC proxies by reducing biases such as cell size, and we also show that incorporating all 13 ZC proxies into the surrogate models used by NAS algorithms can improve their predictive performance by up to 42%. Our code and datasets are available at https://github. com/automl/naslib/tree/zerocost.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/b3835dd49b7d5bb062aecccc14d8a675-Abstract-Datasets_and_Benchmarks.html
Frank Hutter,Optimizing neural networks for patent classification,2019,,45,"Louay Abdelgawad, Peter Kluegl, Erdan Genc, Stefan Falkner, Frank Hutter",Louay Abdelgawad,Frank Hutter,5," A great number of patents is filed everyday to the patent offices worldwide. Each of these patents has to be labeled by domain experts with one or many of thousands of categories. This process is not only extremely expensive but also overwhelming for the experts, due to the considerable increase of filed patents over the years and the increasing complexity of the hierarchical categorization structure. Therefore, it is critical to automate the manual classification process using a classification model. In this paper, the automation of the task is carried out based on recent advances in deep learning for NLP and compared to customized approaches. Moreover, an extensive optimization analysis grants insights about hyperparameter importance. Our optimized convolutional neural network achieves a new state-of-the-art performance of  accuracy on the public Wipo-Alpha dataset.",https://link.springer.com/chapter/10.1007/978-3-030-46133-1_41
Frank Hutter,On the effective configuration of planning domain models,2015,International Joint Conference on Artificial Intelligence (IJCAI),45,"Mauro Vallati, Frank Hutter, Lukáš Chrpa, Thomas Leo McCluskey",Mauro Vallati,Thomas Leo McCluskey,4,"The development of domain-independent planners within the AI Planning community is leading to “off the shelf” technology that can be used in a wide range of applications. Moreover, it allows a modular approach – in which planners and domain knowledge are modules of larger software applications – that facilitates substitutions or improvements of individual modules without changing the rest of the system. This approach also supports the use of reformulation and configuration techniques, which transform how a model is represented in order to improve the efficiency of plan generation. In this paper, we investigate how the performance of planners is affected by domain model configuration. We introduce a fully automated method for this configuration task, and show in an extensive experimental analysis with six planners and seven domains that this process (which can, in principle, be combined with other forms of reformulation and configuration) can have a remarkable impact on performance across planners. Furthermore, studying the obtained domain model configurations can provide useful information to effectively engineer planning domain models.",https://eprints.hud.ac.uk/id/eprint/24352/
Frank Hutter,Differential evolution for neural architecture search,2020,arXiv preprint arXiv:2012.06400,44,"Noor Awad, Neeratyoy Mallik, Frank Hutter",Noor Awad,Frank Hutter,3,"Neural architecture search (NAS) methods rely on a search strategy for deciding which architectures to evaluate next and a performance estimation strategy for assessing their performance (e.g., using full evaluations, multi-fidelity evaluations, or the one-shot model). In this paper, we focus on the search strategy. We introduce the simple yet powerful evolutionary algorithm of differential evolution to the NAS community. Using the simplest performance evaluation strategy of full evaluations, we comprehensively compare this search strategy to regularized evolution and Bayesian optimization and demonstrate that it yields improved and more robust results for 13 tabular NAS benchmarks based on NAS-Bench-101, NAS-Bench-1Shot1, NAS-Bench-201 and NAS-HPO bench.",https://arxiv.org/abs/2012.06400
Frank Hutter,Sequential model-based parameter optimization: An experimental investigation of automated and interactive approaches,2010,Experimental Methods for the Analysis of Optimization Algorithms,44,"Frank Hutter, Thomas Bartz-Beielstein, Holger H Hoos, Kevin Leyton-Brown, Kevin P Murphy",Frank Hutter,Kevin P Murphy,5,"This work experimentally investigates model-based approaches for optimizing the performance of parameterized randomized algorithms. Such approaches build a response surface model and use this model for finding good parameter settings of the given algorithm. We evaluated two methods from the literature that are based on Gaussian process models: sequential parameter optimization (SPO) (Bartz-Beielstein et al. 2005) and sequential Kriging optimization (SKO) (Huang et al. 2006). SPO performed better “out-of-the-box,” whereas SKO was competitive when response values were log transformed. We then investigated key design decisions within the SPO paradigm, characterizing the performance consequences of each. Based on these findings, we propose a new version of SPO, dubbed SPO+, which extends SPO with a novel intensification procedure and a log-transformed objective function. In a …",https://link.springer.com/chapter/10.1007/978-3-642-02538-9_15
Frank Hutter,Tradeoffs in the empirical evaluation of competing algorithm designs,2010,Annals of Mathematics and Artificial Intelligence,43,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"We propose an empirical analysis approach for characterizing tradeoffs between different methods for comparing a set of competing algorithm designs. Our approach can provide insight into performance variation both across candidate algorithms and across instances. It can also identify the best tradeoff between evaluating a larger number of candidate algorithm designs, performing these evaluations on a larger number of problem instances, and allocating more time to each algorithm run. We applied our approach to a study of the rich algorithm design spaces offered by three highly-parameterized, state-of-the-art algorithms for satisfiability and mixed integer programming, considering six different distributions of problem instances. We demonstrate that the resulting algorithm design scenarios differ in many ways, with important consequences for both automatic and manual algorithm design. We expect that …",https://link.springer.com/article/10.1007/s10472-010-9191-0
Frank Hutter,Efficient on-line fault diagnosis for non-linear systems,2003,"Proceedings of the 7th international symposium on artificial intelligence, robotics and automation in space",43,"Frank Hutter, Richard Dearden",Frank Hutter,Richard Dearden,2,"Fault diagnosis is a critical task for autonomous operation of systems such as spacecraft and planetary rovers, and must often be performed on-board. Unfortunately, these systems frequently also have relatively little computational power to devote to diagnosis. For this reason, algorithms for these applications must be extremely efficient, and preferably anytime.In this paper we introduce the Gaussian particle filter (GPF), an efficient variant on the particle filtering algorithm for non-linear hybrid systems. Each particle samples a discrete mode and approximates the continuous variables by a multivariate Gaussian that is updated at each time-step using an unscented Kalman filter. The algorithm is closely related to Rao-Blackwellized Particle Filtering and equally efficient, but is more broadly applicable. We show that given the same computation time GPF performs diagnosis with a significantly lower rate of incorrect diagnoses and with a much lower error on the continuous parameters. We also use the GPF to diagnose data from the K-9 rover at NASA Ames Research Center.",https://www.academia.edu/download/43564218/isairas03-gpf.pdf
Frank Hutter,Practical transfer learning for bayesian optimization,2018,arXiv preprint arXiv:1802.02219,42,"Matthias Feurer, Benjamin Letham, Frank Hutter, Eytan Bakshy",Matthias Feurer,Eytan Bakshy,4,"When hyperparameter optimization of a machine learning algorithm is repeated for multiple datasets it is possible to transfer knowledge to an optimization run on a new dataset. We develop a new hyperparameter-free ensemble model for Bayesian optimization that is a generalization of two existing transfer learning extensions to Bayesian optimization and establish a worst-case bound compared to vanilla Bayesian optimization. Using a large collection of hyperparameter optimization benchmark problems, we demonstrate that our contributions substantially reduce optimization time compared to standard Gaussian process-based Bayesian optimization and improve over the current state-of-the-art for transfer hyperparameter optimization.",https://arxiv.org/abs/1802.02219
Frank Hutter,From sequential algorithm selection to parallel portfolio selection,2015,"Learning and Intelligent Optimization: 9th International Conference, LION 9, Lille, France, January 12-15, 2015. Revised Selected Papers 9",40,"Marius Lindauer, Holger Hoos, Frank Hutter",Marius Lindauer,Frank Hutter,3,"In view of the increasing importance of hardware parallelism, a natural extension of per-instance algorithm selection is to select a set of algorithms to be run in parallel on a given problem instance, based on features of that instance. Here, we explore how existing algorithm selection techniques can be effectively parallelized. To this end, we leverage the machine learning models used by existing sequential algorithm selectors, such as 3S, ISAC, SATzilla and ME-ASP, and modify their selection procedures to produce a ranking of the given candidate algorithms; we then select the top n algorithms under this ranking to be run in parallel on n processing units. Furthermore, we adapt the pre-solving schedules obtained by aspeed to be effective in a parallel setting with different time budgets for each processing unit. Our empirical results demonstrate that, using 4 processing units, the best of our methods achieves …",https://link.springer.com/chapter/10.1007/978-3-319-19084-6_1
Frank Hutter,Automated dynamic algorithm configuration,2022,Journal of Artificial Intelligence Research,39,"Steven Adriaensen, André Biedenkapp, Gresa Shala, Noor Awad, Theresa Eimer, Marius Lindauer, Frank Hutter",Steven Adriaensen,Frank Hutter,7,"The performance of an algorithm often critically depends on its parameter configuration. While a variety of automated algorithm configuration methods have been proposed to relieve users from the tedious and error-prone task of manually tuning parameters, there is still a lot of untapped potential as the learned configuration is static, ie, parameter settings remain fixed throughout the run. However, it has been shown that some algorithm parameters are best adjusted dynamically during execution. Thus far, this is most commonly achieved through hand-crafted heuristics. A promising recent alternative is to automatically learn such dynamic parameter adaptation policies from data. In this article, we give the first comprehensive account of this new field of automated dynamic algorithm configuration (DAC), present a series of recent advances, and provide a solid foundation for future research in this field. Specifically, we (i) situate DAC in the broader historical context of AI research;(ii) formalize DAC as a computational problem;(iii) identify the methods used in prior art to tackle this problem; and (iv) conduct empirical case studies for using DAC in evolutionary optimization, AI planning, and machine learning.",https://www.jair.org/index.php/jair/article/view/13922
Frank Hutter,Contextualize Me--The Case for Context in Reinforcement Learning,2022,arXiv preprint arXiv:2202.04500,39,"Carolin Benjamins, Theresa Eimer, Frederik Schubert, Aditya Mohan, Sebastian Döhler, André Biedenkapp, Bodo Rosenhahn, Frank Hutter, Marius Lindauer",Carolin Benjamins,Marius Lindauer,9,"While Reinforcement Learning ( RL) has made great strides towards solving increasingly complicated problems, many algorithms are still brittle to even slight environmental changes. Contextual Reinforcement Learning (cRL) provides a framework to model such changes in a principled manner, thereby enabling flexible, precise and interpretable task specification and generation. Our goal is to show how the framework of cRL contributes to improving zero-shot generalization in RL through meaningful benchmarks and structured reasoning about generalization tasks. We confirm the insight that optimal behavior in cRL requires context information, as in other related areas of partial observability. To empirically validate this in the cRL framework, we provide various context-extended versions of common RL environments. They are part of the first benchmark library, CARL, designed for generalization based on cRL extensions of popular benchmarks, which we propose as a testbed to further study general agents. We show that in the contextual setting, even simple RL environments become challenging - and that naive solutions are not enough to generalize across complex context spaces.",https://arxiv.org/abs/2202.04500
Frank Hutter,Learning step-size adaptation in CMA-ES,2020,"Parallel Problem Solving from Nature–PPSN XVI: 16th International Conference, PPSN 2020, Leiden, The Netherlands, September 5-9, 2020, Proceedings, Part I 16",39,"Gresa Shala, André Biedenkapp, Noor Awad, Steven Adriaensen, Marius Lindauer, Frank Hutter",Gresa Shala,Frank Hutter,6,"An algorithm’s parameter setting often affects its ability to solve a given problem, e.g., population-size, mutation-rate or crossover-rate of an evolutionary algorithm. Furthermore, some parameters have to be adjusted dynamically, such as lowering the mutation-strength over time. While hand-crafted heuristics offer a way to fine-tune and dynamically configure these parameters, their design is tedious, time-consuming and typically involves analyzing the algorithm’s behavior on simple problems that may not be representative for those that arise in practice. In this paper, we show that formulating dynamic algorithm configuration as a reinforcement learning problem allows us to automatically learn policies that can dynamically configure the mutation step-size parameter of Covariance Matrix Adaptation Evolution Strategy (CMA-ES). We evaluate our approach on a wide range of black-box optimization problems, and show …",https://link.springer.com/chapter/10.1007/978-3-030-58112-1_48
Frank Hutter,Combining hyperband and bayesian optimization,2017,NIPS 2017 Bayesian Optimization Workshop (Dec 2017),39,"Stefan Falkner, Aaron Klein, Frank Hutter",Stefan Falkner,Frank Hutter,3,"Proper hyperparameter optimization is computationally very costly for expensive machine learning methods, such as deep neural networks; the same holds true for neural architecture search. Recently, the bandit-based strategy Hyperband has shown superior performance to vanilla Bayesian optimization methods that are limited to the traditional problem formulation of expensive blackbox optimization. However, while Hyperband has strong anytime performance for finding configurations with acceptable results, it relies on random search and therefore does not find the best configurations quickly. We propose to combine Hyperband with Bayesian optimization by maintaining a probabilistic model that captures the density of good configurations in the input space and samples from this model instead of sampling uniformly at random. We empirically show that our new method combines Hyperband’s strong anytime performance with the strong eventual performance of Bayesian optimization.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/17-BayesOpt-BOHB.pdf
Frank Hutter,Nas-bench-x11 and the power of learning curves,2021,Advances in Neural Information Processing Systems,37,"Shen Yan, Colin White, Yash Savani, Frank Hutter",Shen Yan,Frank Hutter,4,"While early research in neural architecture search (NAS) required extreme computational resources, the recent releases of tabular and surrogate benchmarks have greatly increased the speed and reproducibility of NAS research. However, two of the most popular benchmarks do not provide the full training information for each architecture. As a result, on these benchmarks it is not possible to evaluate many types of multi-fidelity algorithms, such as learning curve extrapolation, that require evaluating architectures at arbitrary epochs. In this work, we present a method using singular value decomposition and noise modeling to create surrogate benchmarks, NAS-Bench-111, NAS-Bench-311, and NAS-Bench-NLP11, that output the full training information for each architecture, rather than just the final validation accuracy. We demonstrate the power of using the full training information by introducing a learning curve extrapolation framework to modify single-fidelity algorithms, showing that it leads to improvements over popular single-fidelity algorithms which claimed to be state-of-the-art upon release.",https://proceedings.neurips.cc/paper/2021/hash/be3159ad04564bfb90db9e32851ebf9c-Abstract.html
Frank Hutter,"Decoupled weight decay regularization, January 2019",,URL http://arxiv. org/abs/1711.05101,37,"Ilya Loshchilov, Frank Hutter",Ilya Loshchilov,Frank Hutter,2,,https://scholar.google.com/scholar?cluster=11359692925027692135&hl=en&oi=scholarr
Frank Hutter,TempoRL: Learning when to act,2021,International Conference on Machine Learning,36,"André Biedenkapp, Raghu Rajan, Frank Hutter, Marius Lindauer",André Biedenkapp,Marius Lindauer,4,"Reinforcement learning is a powerful approach to learn behaviour through interactions with an environment. However, behaviours are usually learned in a purely reactive fashion, where an appropriate action is selected based on an observation. In this form, it is challenging to learn when it is necessary to execute new decisions. This makes learning inefficient especially in environments that need various degrees of fine and coarse control. To address this, we propose a proactive setting in which the agent not only selects an action in a state but also for how long to commit to that action. Our TempoRL approach introduces skip connections between states and learns a skip-policy for repeating the same action along these skips. We demonstrate the effectiveness of TempoRL on a variety of traditional and deep RL environments, showing that our approach is capable of learning successful policies up to an order of magnitude faster than vanilla Q-learning.",https://proceedings.mlr.press/v139/biedenkapp21a.html
Frank Hutter,Towards further automation in automl,2018,ICML AutoML workshop,35,"Matthias Feurer, Frank Hutter",Matthias Feurer,Frank Hutter,2,"Even though recent AutoML systems have been successful in various applications, they introduce new hyper-hyperparameters of their own, including the choice of the evaluation strategy used in the loss function, time budgets to use and the optimization strategy with its hyper-hyperparameters. We study whether it is possible to make these choices in a data-driven way for a dataset at hand. Using 437 datasets from OpenML, we demonstrate the possibility of automating these choices, that this improves over picking a fixed strategy and that for different time horizons different strategies are necessary.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/18-AUTOML-AutoAutoML.pdf
Frank Hutter,Towards efficient Bayesian optimization for big data,2015,NIPS 2015 Bayesian Optimization Workshop,35,"Aaron Klein, Simon Bartels, Stefan Falkner, Philipp Hennig, Frank Hutter",Aaron Klein,Frank Hutter,5,"We present a new Bayesian optimization method, environmental entropy search (EnvES), suited for optimizing the hyperparameters of machine learning algorithms on large datasets. EnvES executes fast algorithm runs on subsets of the data and probabilistically extrapolates their performance to reason about performance on the entire dataset. It considers the dataset size as an additional degree of freedom to choose freely at each step of the optimization, and sets it adaptively to trade off expected information gain about the location of the best configuration vs. expected time spent. We empirically evaluate EnvES for optimizing the hyperparameters of a support vector machine, showing that extrapolating performance from small to large datasets can yield a considerable speedup over standard Bayesian optimization methods.",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/15-BayesOpt-EnvES.pdf
Frank Hutter,Winning solutions and post-challenge analyses of the ChaLearn AutoDL challenge 2019,2021,IEEE Transactions on Pattern Analysis and Machine Intelligence,34,"Zhengying Liu, Adrien Pavao, Zhen Xu, Sergio Escalera, Fabio Ferreira, Isabelle Guyon, Sirui Hong, Frank Hutter, Rongrong Ji, Julio CS Jacques Junior, Ge Li, Marius Lindauer, Zhipeng Luo, Meysam Madadi, Thomas Nierhoff, Kangning Niu, Chunguang Pan, Danny Stoll, Sebastien Treguer, Jin Wang, Peng Wang, Chenglin Wu, Youcheng Xiong, Arbër Zela, Yang Zhang",Zhengying Liu,Yang Zhang,25,"This paper reports the results and post-challenge analyses of ChaLearn’s AutoDL challenge series, which helped sorting out a profusion of AutoML solutions for Deep Learning (DL) that had been introduced in a variety of settings, but lacked fair comparisons. All input data modalities (time series, images, videos, text, tabular) were formatted as tensors and all tasks were multi-label classification problems. Code submissions were executed on hidden tasks, with limited time and computational resources, pushing solutions that get results quickly. In this setting, DL methods dominated, though popular Neural Architecture Search (NAS) was impractical. Solutions relied on fine-tuned pre-trained networks, with architectures matching data modality. Post-challenge tests did not reveal improvements beyond the imposed time limit. While no component is particularly original or novel, a high level modular organization …",https://ieeexplore.ieee.org/abstract/document/9415128/
Frank Hutter,Multi-objective architecture search for cnns,2018,arXiv preprint arXiv:1804.09081,34,"Thomas Elsken, Jan Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,3,"Architecture search aims at automatically finding neural architectures that are competitive with architectures designed by human experts. While recent approaches have come close to matching the predictive performance of manually designed architectures for image recognition, these approaches are problematic under constrained resources for two reasons: first, the architecture search itself requires vast computational resources for most proposed methods. Secondly, the found neural architectures are solely optimized for high predictive performance without penalizing excessive resource consumption. We address the first shortcoming by proposing NASH, an architecture search which considerable reduces the computational resources required for training novel architectures by applying network morphisms and aggressive learning rate schedules. On CIFAR10, NASH finds architectures with errors below 4% in only 3 days. We address the second shortcoming by proposing Pareto-NASH, a method for multi-objective architecture search that allows approximating the Pareto-front of architectures under multiple objective, such as predictive performance and number of parameters, in a single run of the method. Within 56 GPU days of architecture search, Pareto-NASH finds a model with 4M parameters and test error of 3.5%, as well as a model with less than 1M parameters and test error of 4.6%.",https://scholar.google.com/scholar?cluster=9183930110894803426&hl=en&oi=scholarr
Frank Hutter,Joint entropy search for maximally-informed Bayesian optimization,2022,Advances in Neural Information Processing Systems,33,"Carl Hvarfner, Frank Hutter, Luigi Nardi",Carl Hvarfner,Luigi Nardi,3,"Information-theoretic Bayesian optimization techniques have become popular for optimizing expensive-to-evaluate black-box functions due to their non-myopic qualities. Entropy Search and Predictive Entropy Search both consider the entropy over the optimum in the input space, while the recent Max-value Entropy Search considers the entropy over the optimal value in the output space. We propose Joint Entropy Search (JES), a novel information-theoretic acquisition function that considers an entirely new quantity, namely the entropy over the joint optimal probability density over both input and output space. To incorporate this information, we consider the reduction in entropy from conditioning on fantasized optimal input/output pairs. The resulting approach primarily relies on standard GP machinery and removes complex approximations typically associated with information-theoretic methods. With minimal computational overhead, JES shows superior decision-making, and yields state-of-the-art performance for information-theoretic approaches across a wide suite of tasks. As a light-weight approach with superior results, JES provides a new go-to acquisition function for Bayesian optimization.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/4b03821747e89ce803b2dac590f6a39b-Abstract-Conference.html
Frank Hutter,Learning heuristic selection with dynamic algorithm configuration,2021,Proceedings of the International Conference on Automated Planning and Scheduling,33,"David Speck, André Biedenkapp, Frank Hutter, Robert Mattmüller, Marius Lindauer",David Speck,Marius Lindauer,5,"A key challenge in satisficing planning is to use multiple heuristics within one heuristic search. An aggregation of multiple heuristic estimates, for example by taking the maximum, has the disadvantage that bad estimates of a single heuristic can negatively affect the whole search. Since the performance of a heuristic varies from instance to instance, approaches such as algorithm selection can be successfully applied. In addition, alternating between multiple heuristics during the search makes it possible to use all heuristics equally and improve performance. However, all these approaches ignore the internal search dynamics of a planning system, which can help to select the most useful heuristics for the current expansion step. We show that dynamic algorithm configuration can be used for dynamic heuristic selection which takes into account the internal search dynamics of a planning system. Furthermore, we prove that this approach generalizes over existing approaches and that it can exponentially improve the performance of the heuristic search. To learn dynamic heuristic selection, we propose an approach based on reinforcement learning and show empirically that domain-wise learned policies, which take the internal search dynamics of a planning system into account, can exceed existing approaches.",https://ojs.aaai.org/index.php/ICAPS/article/view/16008
Frank Hutter,Is mamba capable of in-context learning?,2024,arXiv preprint arXiv:2402.03170,32,"Riccardo Grazzi, Julien Siems, Simon Schrodi, Thomas Brox, Frank Hutter",Riccardo Grazzi,Frank Hutter,5,"This work provides empirical evidence that Mamba, a newly proposed selective structured state space model, has similar in-context learning (ICL) capabilities as transformers. We evaluated Mamba on tasks involving simple function approximation as well as more complex natural language processing problems. Our results demonstrate that across both categories of tasks, Mamba matches the performance of transformer models for ICL. Further analysis reveals that like transformers, Mamba appears to solve ICL problems by incrementally optimizing its internal representations. Overall, our work suggests that Mamba can be an efficient alternative to transformers for ICL tasks involving longer input sequences.",https://arxiv.org/abs/2402.03170
Frank Hutter,Don’t rule out simple models prematurely: a large scale benchmark comparing linear and non-linear classifiers in OpenML,2018,"Advances in Intelligent Data Analysis XVII: 17th International Symposium, IDA 2018,’s-Hertogenbosch, The Netherlands, October 24–26, 2018, Proceedings 17",32,"Benjamin Strang, Peter van der Putten, Jan N van Rijn, Frank Hutter",Benjamin Strang,Frank Hutter,4,"A basic step for each data-mining or machine learning task is to determine which model to choose based on the problem and the data at hand. In this paper we investigate when non-linear classifiers outperform linear classifiers by means of a large scale experiment. We benchmark linear and non-linear versions of three types of classifiers (support vector machines; neural networks; and decision trees), and analyze the results to determine on what type of datasets the non-linear version performs better. To the best of our knowledge, this work is the first principled and large scale attempt to support the common assumption that non-linear classifiers excel only when large amounts of data are available.",https://link.springer.com/chapter/10.1007/978-3-030-01768-2_25
Frank Hutter,Neural networks for predicting algorithm runtime distributions,2017,arXiv preprint arXiv:1709.07615,32,"Katharina Eggensperger, Marius Lindauer, Frank Hutter",Katharina Eggensperger,Frank Hutter,3,"Many state-of-the-art algorithms for solving hard combinatorial problems in artificial intelligence (AI) include elements of stochasticity that lead to high variations in runtime, even for a fixed problem instance. Knowledge about the resulting runtime distributions (RTDs) of algorithms on given problem instances can be exploited in various meta-algorithmic procedures, such as algorithm selection, portfolios, and randomized restarts. Previous work has shown that machine learning can be used to individually predict mean, median and variance of RTDs. To establish a new state-of-the-art in predicting RTDs, we demonstrate that the parameters of an RTD should be learned jointly and that neural networks can do this well by directly optimizing the likelihood of an RTD given runtime observations. In an empirical study involving five algorithms for SAT solving and AI planning, we show that neural networks predict the true RTDs of unseen instances better than previous methods, and can even do so when only few runtime observations are available per training instance.",https://arxiv.org/abs/1709.07615
Frank Hutter,A kernel for hierarchical parameter spaces,2013,arXiv preprint arXiv:1310.5738,32,"Frank Hutter, Michael A Osborne",Frank Hutter,Michael A Osborne,2,We define a family of kernels for mixed continuous/discrete hierarchical parameter spaces and show that they are positive definite.,https://arxiv.org/pdf/1310.5738
Frank Hutter,Pfns4bo: In-context learning for bayesian optimization,2023,International Conference on Machine Learning,31,"Samuel Müller, Matthias Feurer, Noah Hollmann, Frank Hutter",Samuel Müller,Frank Hutter,4,"In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) through in-context learning on any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code alongside trained models at https://github. com/automl/PFNs4BO.",https://proceedings.mlr.press/v202/muller23a.html
Frank Hutter,Self-paced context evaluation for contextual reinforcement learning,2021,International Conference on Machine Learning,30,"Theresa Eimer, André Biedenkapp, Frank Hutter, Marius Lindauer",Theresa Eimer,Marius Lindauer,4,"Reinforcement learning (RL) has made a lot of advances for solving a single problem in a given environment; but learning policies that generalize to unseen variations of a problem remains challenging. To improve sample efficiency for learning on such instances of a problem domain, we present Self-Paced Context Evaluation (SPaCE). Based on self-paced learning, SPaCE automatically generates instance curricula online with little computational overhead. To this end, SPaCE leverages information contained in state values during training to accelerate and improve training performance as well as generalization capabilities to new\tasks from the same problem domain. Nevertheless, SPaCE is independent of the problem domain at hand and can be applied on top of any RL agent with state-value function approximation. We demonstrate SPaCE’s ability to speed up learning of different value-based RL agents on two environments, showing better generalization capabilities and up to 10x faster learning compared to naive approaches such as round robin or SPDRL, as the closest state-of-the-art approach.",http://proceedings.mlr.press/v139/eimer21a.html
Frank Hutter,Hyperparameter importance for image classification by residual neural networks,2019,"Discovery Science: 22nd International Conference, DS 2019, Split, Croatia, October 28–30, 2019, Proceedings 22",30,"Abhinav Sharma, Jan N van Rijn, Frank Hutter, Andreas Müller",Abhinav Sharma,Andreas Müller,4," Residual neural networks (ResNets) are among the state-of-the-art for image classification tasks. With the advent of automated machine learning (AutoML), automated hyperparameter optimization methods are by now routinely used for tuning various network types. However, in the thriving field of deep neural networks, this progress is not yet matched by equal progress on rigorous techniques that yield information beyond performance-optimizing hyperparameter settings. In this work, we aim to answer the following question: Given a residual neural network architecture, what are generally (across datasets) its most important hyperparameters? In order to answer this question, we assembled a benchmark suite containing 10 image classification datasets. For each of these datasets, we analyze which of the hyperparameters were most influential using the functional ANOVA framework. This experiment both …",https://link.springer.com/chapter/10.1007/978-3-030-33778-0_10
Frank Hutter,Efficient bayesian learning curve extrapolation using prior-data fitted networks,2024,Advances in Neural Information Processing Systems,27,"Steven Adriaensen, Herilalaina Rakotoarison, Samuel Müller, Frank Hutter",Steven Adriaensen,Frank Hutter,4,"Learning curve extrapolation aims to predict model performance in later epochs of training, based on the performance in earlier epochs. In this work, we argue that, while the inherent uncertainty in the extrapolation of learning curves warrants a Bayesian approach, existing methods are (i) overly restrictive, and/or (ii) computationally expensive. We describe the first application of prior-data fitted neural networks (PFNs) in this context. A PFN is a transformer, pre-trained on data generated from a prior, to perform approximate Bayesian inference in a single forward pass. We propose LC-PFN, a PFN trained to extrapolate 10 million artificial right-censored learning curves generated from a parametric prior proposed in prior art using MCMC. We demonstrate that LC-PFN can approximate the posterior predictive distribution more accurately than MCMC, while being over 10 000 times faster. We also show that the same LC-PFN achieves competitive performance extrapolating a total of 20 000 real learning curves from four learning curve benchmarks (LCBench, NAS-Bench-201, Taskset, and PD1) that stem from training a wide range of model architectures (MLPs, CNNs, RNNs, and Transformers) on 53 different datasets with varying input modalities (tabular, image, text, and protein data). Finally, we investigate its potential in the context of model selection and find that a simple LC-PFN based predictive early stopping criterion obtains 2-6x speed-ups on 45 of these datasets, at virtually no overhead.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/3f1a5e8bfcc3005724d246abe454c1e5-Abstract-Conference.html
Frank Hutter,Practical hyperparameter optimization for deep learning,2018,,27,"Stefan Falkner, Aaron Klein, Frank Hutter",Stefan Falkner,Frank Hutter,3,"Recently, the bandit-based strategy Hyperband (HB) was shown to yield good hyperparameter settings of deep neural networks faster than vanilla Bayesian optimization (BO). However, for larger budgets, HB is limited by its random search component, and BO works better. We propose to combine the benefits of both approaches to obtain a new practical state-of-the-art hyperparameter optimization method, which we show to consistently outperform both HB and BO on a range of problem types, including feed-forward neural networks, Bayesian neural networks,  and deep reinforcement learning. Our method is robust and versatile, while at the same time being conceptually simple and easy to implement.",https://openreview.net/forum?id=HJMudFkDf
Frank Hutter,Carl: A benchmark for contextual and adaptive reinforcement learning,2021,arXiv preprint arXiv:2110.02102,26,"Carolin Benjamins, Theresa Eimer, Frederik Schubert, André Biedenkapp, Bodo Rosenhahn, Frank Hutter, Marius Lindauer",Carolin Benjamins,Marius Lindauer,7,"While Reinforcement Learning has made great strides towards solving ever more complicated tasks, many algorithms are still brittle to even slight changes in their environment. This is a limiting factor for real-world applications of RL. Although the research community continuously aims at improving both robustness and generalization of RL algorithms, unfortunately it still lacks an open-source set of well-defined benchmark problems based on a consistent theoretical framework, which allows comparing different approaches in a fair, reliable and reproducibleway. To fill this gap, we propose CARL, a collection of well-known RL environments extended to contextual RL problems to study generalization. We show the urgent need of such benchmarks by demonstrating that even simple toy environments become challenging for commonly used approaches if different contextual instances of this task have to be considered. Furthermore, CARL allows us to provide first evidence that disentangling representation learning of the states from the policy learning with the context facilitates better generalization. By providing variations of diverse benchmarks from classic control, physical simulations, games and a real-world application of RNA design, CARL will allow the community to derive many more such insights on a solid empirical foundation.",https://arxiv.org/abs/2110.02102
Frank Hutter,SpySMAC: Automated Configuration and Performance Analysis of SAT Solvers,2015,,25,"Stefan Falkner, Marius Lindauer, Frank Hutter",Stefan Falkner,Frank Hutter,3,"Most modern SAT solvers expose a range of parameters to allow some customization for improving performance on specific types of instances. Performing this customization manually can be challenging and time-consuming, and as a consequence several automated algorithm configuration methods have been developed for this purpose. Although automatic algorithm configuration has already been applied successfully to many different SAT solvers, a comprehensive analysis of the configuration process is usually not readily available to users. Here, we present SpySMAC to address this gap by providing a lightweight and easy-to-use toolbox for (i) automatic configuration of SAT solvers in different settings, (ii) a thorough performance analysis comparing the best found configuration to the default one, and (iii) an assessment of each parameter’s importance using the fANOVA framework. To showcase our tool, we …",https://link.springer.com/chapter/10.1007/978-3-319-24318-4_16
Frank Hutter,Jahs-bench-201: A foundation for research on joint architecture and hyperparameter search,2022,Advances in Neural Information Processing Systems,24,"Archit Bansal, Danny Stoll, Maciej Janowski, Arber Zela, Frank Hutter",Archit Bansal,Frank Hutter,5,"The past few years have seen the development of many benchmarks for Neural Architecture Search (NAS), fueling rapid progress in NAS research. However, recent work, which shows that good hyperparameter settings can be more important than using the best architecture, calls for a shift in focus towards Joint Architecture and Hyperparameter Search (JAHS). Therefore, we present JAHS-Bench-201, the first collection of surrogate benchmarks for JAHS, built to also facilitate research on multi-objective, cost-aware and (multi) multi-fidelity optimization algorithms. To the best of our knowledge, JAHS-Bench-201 is based on the most extensive dataset of neural network performance data in the public domain. It is composed of approximately 161 million data points and 20 performance metrics for three deep learning tasks, while featuring a 14-dimensional search and fidelity space that extends the popular NAS-Bench-201 space. With JAHS-Bench-201, we hope to democratize research on JAHS and lower the barrier to entry of an extremely compute intensive field, eg, by reducing the compute time to run a JAHS algorithm from 5 days to only a few seconds.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/fd78f2f65881c1c7ce47e26b040cf48f-Abstract-Datasets_and_Benchmarks.html
Frank Hutter,An empirical study of per-instance algorithm scheduling,2016,"Learning and Intelligent Optimization: 10th International Conference, LION 10, Ischia, Italy, May 29--June 1, 2016, Revised Selected Papers 10",24,"Marius Lindauer, Rolf-David Bergdoll, Frank Hutter",Marius Lindauer,Frank Hutter,3,"Algorithm selection is a prominent approach to improve a system’s performance by selecting a well-performing algorithm from a portfolio for an instance at hand. One extension of the traditional algorithm selection problem is to not only select one single algorithm but a schedule of algorithms to increase robustness. Some approaches exist for solving this problem of selecting schedules on a per-instance basis (e.g., the Sunny and 3S systems), but to date, a fair and thorough comparison of these is missing. In this work, we implement Sunny’s approach and dynamic schedules inspired by 3S in the flexible algorithm selection framework flexfolio to use the same code base for a fair comparison. Based on the algorithm selection library (ASlib), we perform the first thorough empirical study on the strengths and weaknesses of per-instance algorithm schedules. We observe that on some domains it is crucial to use …",https://link.springer.com/chapter/10.1007/978-3-319-50349-3_20
Frank Hutter,DACBench: A benchmark library for dynamic algorithm configuration,2021,arXiv preprint arXiv:2105.08541,23,"Theresa Eimer, André Biedenkapp, Maximilian Reimer, Steven Adriaensen, Frank Hutter, Marius Lindauer",Theresa Eimer,Marius Lindauer,6,"Dynamic Algorithm Configuration (DAC) aims to dynamically control a target algorithm's hyperparameters in order to improve its performance. Several theoretical and empirical results have demonstrated the benefits of dynamically controlling hyperparameters in domains like evolutionary computation, AI Planning or deep learning. Replicating these results, as well as studying new methods for DAC, however, is difficult since existing benchmarks are often specialized and incompatible with the same interfaces. To facilitate benchmarking and thus research on DAC, we propose DACBench, a benchmark library that seeks to collect and standardize existing DAC benchmarks from different AI domains, as well as provide a template for new ones. For the design of DACBench, we focused on important desiderata, such as (i) flexibility, (ii) reproducibility, (iii) extensibility and (iv) automatic documentation and visualization. To show the potential, broad applicability and challenges of DAC, we explore how a set of six initial benchmarks compare in several dimensions of difficulty.",https://arxiv.org/abs/2105.08541
Frank Hutter,On the promise of the stochastic generalized Gauss-Newton method for training DNNs,2020,arXiv preprint arXiv:2006.02409,23,"Matilde Gargiani, Andrea Zanelli, Moritz Diehl, Frank Hutter",Matilde Gargiani,Frank Hutter,4,"Following early work on Hessian-free methods for deep learning, we study a stochastic generalized Gauss-Newton method (SGN) for training DNNs. SGN is a second-order optimization method, with efficient iterations, that we demonstrate to often require substantially fewer iterations than standard SGD to converge. As the name suggests, SGN uses a Gauss-Newton approximation for the Hessian matrix, and, in order to compute an approximate search direction, relies on the conjugate gradient method combined with forward and reverse automatic differentiation. Despite the success of SGD and its first-order variants, and despite Hessian-free methods based on the Gauss-Newton Hessian approximation having been already theoretically proposed as practical methods for training DNNs, we believe that SGN has a lot of undiscovered and yet not fully displayed potential in big mini-batch scenarios. For this setting, we demonstrate that SGN does not only substantially improve over SGD in terms of the number of iterations, but also in terms of runtime. This is made possible by an efficient, easy-to-use and flexible implementation of SGN we propose in the Theano deep learning platform, which, unlike Tensorflow and Pytorch, supports forward automatic differentiation. This enables researchers to further study and improve this promising optimization technique and hopefully reconsider stochastic second-order methods as competitive optimization techniques for training DNNs; we also hope that the promise of SGN may lead to forward automatic differentiation being added to Tensorflow or Pytorch. Our results also show that in big mini-batch scenarios …",https://arxiv.org/abs/2006.02409
Frank Hutter,Naslib: A modular and flexible neural architecture search library,2020,,23,"Michael Ruchte, Arber Zela, Julien Niklas Siems, Josif Grabocka, Frank Hutter",Michael Ruchte,Frank Hutter,5,"Neural Architecture Search (NAS) is one of the focal points for the Deep Learning community, but reproducing NAS methods is extremely challenging due to numerous low-level implementation details. To alleviate this problem we introduce NASLib, a NAS library built upon PyTorch. This framework offers high-level abstractions for designing and reusing search spaces, interfaces to benchmarks and evaluation pipelines, enabling the implementation and extension of state-of-the-art NAS methods with a few lines of code. The modularized nature of NASlib  allows researchers to easily innovate on individual components (e.g., define a new search space while reusing an optimizer and evaluation pipeline, or propose a new optimizer with existing search spaces). As a result, NASLib has the potential to facilitate NAS research by allowing fast advances and evaluations that are by design free of confounding factors. To demonstrate that NASLib is a sound library, we implement and achieve state-of-the-art results with one-shot NAS optimizers (DARTS and GDAS) over the DARTS search space and the popular NAS-Bench-201 benchmark. Last but not least, we showcase how easily novel approaches are coded in NASLib, by training DARTS on a hierarchical search space.",https://openreview.net/forum?id=EohGx2HgNsA
Frank Hutter,Towards assessing the impact of bayesian optimization's own hyperparameters,2019,arXiv preprint arXiv:1908.06674,23,"Marius Lindauer, Matthias Feurer, Katharina Eggensperger, André Biedenkapp, Frank Hutter",Marius Lindauer,Frank Hutter,5,"Bayesian Optimization (BO) is a common approach for hyperparameter optimization (HPO) in automated machine learning. Although it is well-accepted that HPO is crucial to obtain well-performing machine learning models, tuning BO's own hyperparameters is often neglected. In this paper, we empirically study the impact of optimizing BO's own hyperparameters and the transferability of the found settings using a wide range of benchmarks, including artificial functions, HPO and HPO combined with neural architecture search. In particular, we show (i) that tuning can improve the any-time performance of different BO approaches, that optimized BO settings also perform well (ii) on similar problems and (iii) partially even on problems from other problem families, and (iv) which BO hyperparameters are most important.",https://arxiv.org/abs/1908.06674
Frank Hutter,User guide for auto-WEKA version 2.6,2017,"Dept. Comput. Sci., Univ. British Columbia, BETA lab, Vancouver, BC, Canada, Tech. Rep",23,"Lars Kotthoff, Chris Thornton, Frank Hutter",Lars Kotthoff,Frank Hutter,3,"Auto-WEKA is a tool that performs combined algorithm selection and hyperparameter optimisation over the classification and regression algorithms implements in WEKA. More specifically, given a specific dataset, Auto-WEKA explores hyperparameter settings for many algorithms and recommends to a user which method will likely have good generalisation performance, using model based optimisation techniques.",https://www.cs.ubc.ca/labs/algorithms/Projects/autoweka/manual.pdf
Frank Hutter,Smooth variational graph embeddings for efficient neural architecture search,2021,2021 International Joint Conference on Neural Networks (IJCNN),22,"Jovita Lukasik, David Friede, Arber Zela, Frank Hutter, Margret Keuper",Jovita Lukasik,Margret Keuper,5,"Neural architecture search (NAS) has recently been addressed from various directions, including discrete, sampling-based methods and efficient differentiable approaches. While the former are notoriously expensive, the latter suffer from imposing strong constraints on the search space. Architecture optimization from a learned embedding space for example through graph neural network based variational autoencoders builds a middle ground and leverages advantages from both sides. Such approaches have recently shown good performance on several benchmarks. Yet, their stability and predictive power heavily depends on their capacity to reconstruct networks from the embedding space. In this paper, we propose a two-sided variational graph autoencoder, which allows to smoothly encode and accurately reconstruct neural architectures from various search spaces. We evaluate the proposed approach on …",https://ieeexplore.ieee.org/abstract/document/9534092/
Frank Hutter,An Empirical Study of Hyperparameter Importance Across Datasets.,2017,AutoML@ PKDD/ECML,22,"Jan N Van Rijn, Frank Hutter",Jan N Van Rijn,Frank Hutter,2,"With the advent of automated machine learning, automated hyperparameter optimization methods are by now routinely used. However, this progress is not yet matched by equal progress on automatic analyses that yield information beyond performance-optimizing hyperparameter settings. Various post-hoc analysis techniques exist to analyze hyperparameter importance, but to the best of our knowledge, so far these have only been applied at a very small scale. To fill this gap, we conduct a large scale experiment to discover general trends across 100 datasets. The results in case studies with random forests and Adaboost show that the same hyperparameters typically remain most important across datasets. Overall, these results, obtained fully automatically, provide a quantitative basis to focus efforts in both manual algorithm design and in automated hyperparameter optimization.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/17-AutoML-fanova.pdf
Frank Hutter,Can fairness be automated? Guidelines and opportunities for fairness-aware AutoML,2024,Journal of Artificial Intelligence Research,21,"Hilde Weerts, Florian Pfisterer, Matthias Feurer, Katharina Eggensperger, Edward Bergman, Noor Awad, Joaquin Vanschoren, Mykola Pechenizkiy, Bernd Bischl, Frank Hutter",Hilde Weerts,Frank Hutter,10,"The field of automated machine learning (AutoML) introduces techniques that automate parts of the development of machine learning (ML) systems, accelerating the process and reducing barriers for novices. However, decisions derived from ML models can reproduce, amplify, or even introduce unfairness in our societies, causing harm to (groups of) individuals. In response, researchers have started to propose AutoML systems that jointly optimize fairness and predictive performance to mitigate fairness-related harm. However, fairness is a complex and inherently interdisciplinary subject, and solely posing it as an optimization problem can have adverse side effects. With this work, we aim to raise awareness among developers of AutoML systems about such limitations of fairness-aware AutoML, while also calling attention to the potential of AutoML as a tool for fairness research. We present a comprehensive overview of different ways in which fairness-related harm can arise and the ensuing implications for the design of fairness-aware AutoML. We conclude that while fairness cannot be automated, fairness-aware AutoML can play an important role in the toolbox of ML practitioners. We highlight several open technical challenges for future work in this direction. Additionally, we advocate for the creation of more user-centered assistive systems designed to tackle challenges encountered in fairness work.",http://www.jair.org/index.php/jair/article/view/14747
Frank Hutter,Priorband: Practical hyperparameter optimization in the age of deep learning,2023,Advances in Neural Information Processing Systems,21,"Neeratyoy Mallik, Edward Bergman, Carl Hvarfner, Danny Stoll, Maciej Janowski, Marius Lindauer, Luigi Nardi, Frank Hutter",Neeratyoy Mallik,Frank Hutter,8,"Hyperparameters of Deep Learning (DL) pipelines are crucial for their downstream performance. While a large number of methods for Hyperparameter Optimization (HPO) have been developed, their incurred costs are often untenable for modern DL. Consequently, manual experimentation is still the most prevalent approach to optimize hyperparameters, relying on the researcher's intuition, domain knowledge, and cheap preliminary explorations. To resolve this misalignment between HPO algorithms and DL researchers, we propose PriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs and cheap proxy tasks. Empirically, we demonstrate PriorBand's efficiency across a range of DL benchmarks and show its gains under informative expert input and robustness against poor expert beliefs.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/1704fe7aaff33a54802b83a016050ab8-Abstract-Conference.html
Frank Hutter,Automatic bone parameter estimation for skeleton tracking in optical motion capture,2016,2016 IEEE International Conference on Robotics and Automation (ICRA),20,"Tobias Schubert, Katharina Eggensperger, Alexis Gkogkidis, Frank Hutter, Tonio Ball, Wolfram Burgard",Tobias Schubert,Wolfram Burgard,6,"Motion analysis is important in a broad range of contexts, including animation, bio-mechanics, robotics and experiments investigating animal behavior. For applications, in which tracking accuracy is one of the main requirements, passive optical motion capture systems are widely used. Many skeleton tracking methods based on such systems use a predefined skeleton model, which is scaled once in the initialization step to the individual size of the character to be tracked. However, there are remarkable differences in the bone length relations across gender and even more across mammal races. In practice, the optimal skeleton model has to be determined in a manual and time-consuming process. In this paper, we reformulate this task as an optimization problem aiming to rescale a rough hierarchical skeleton structure to optimize probabilistic skeleton tracking performance. We solve this optimization problem by …",https://ieeexplore.ieee.org/abstract/document/7487771/
Frank Hutter,Autofolio: Algorithm configuration for algorithm selection,2015,Workshops at the Twenty-Ninth AAAI Conference on Artificial Intelligence,20,"Marius Lindauer, Holger H Hoos, Frank Hutter, Torsten Schaub",Marius Lindauer,Torsten Schaub,4,"Algorithm selection (AS) techniques–which involve choosing from a set of algorithms the one expected to solve a given problem instance most efficiently–have substantially improved the state-of-the-art in solving many prominent AI problems, such as SAT, CSP, ASP, MAXSAT, and QBF. Although several AS procedures have been introduced, not too surprisingly, none of them dominates all others across all AS scenarios. Furthermore, these procedures have parameters whose optimal values vary across AS scenarios. This holds specifically for the machine learning techniques that form the core of current AS procedures and for their hyperparameters. Therefore, to successfully apply AS to new problems, algorithms and benchmark sets, two questions need to be answered:(i) how to select an AS approach and (ii) how to set its parameters effectively. We address both of these problems simultaneously by using automated algorithm configuration. Specifically, we demonstrate that we can use algorithm configurators to automatically configure claspfolio 2, which implements a large variety of different AS approaches and their respective parameters in a single highly parameterized algorithm framework. We demonstrate that this approach, dubbed AutoFolio, can significantly improve the performance of claspfolio 2 on 11 out of the 12 scenarios from the Algorithm Selection Library and leads to new state-of-the-art algorithm selectors for 9 of these scenarios.",https://cdn.aaai.org/ocs/ws/ws0051/10106-45886-1-PB.pdf
Frank Hutter,Surrogate Benchmarks for Hyperparameter Optimization.,2014,MetaSel@ ECAI,20,"Katharina Eggensperger, Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Katharina Eggensperger,Kevin Leyton-Brown,4,"Since hyperparameter optimization is crucial for achieving peak performance with many machine learning algorithms, an active research community has formed around this problem in the last few years. The evaluation of new hyperparameter optimization techniques against the state of the art requires a set of benchmarks. Because such evaluations can be very expensive, early experiments are often performed using synthetic test functions rather than using real-world hyperparameter optimization problems. However, there can be a wide gap between the two kinds of problems. In this work, we introduce another option: cheap-to-evaluate surrogates of real hyperparameter optimization benchmarks that share the same hyperparameter spaces and feature similar response surfaces. Specifically, we train regression models on data describing a machine learning algorithm’s performance under a wide range of hyperparameter configurations, and then cheaply evaluate hyperparameter optimization methods using the model’s performance predictions in lieu of the real algorithm. We evaluate the effectiveness for using a wide range of regression techniques to build these surrogate benchmarks, both in terms of how well they predict the performance of new configurations and of how much they affect the overall performance of hyperparameter optimizers. Overall, we found that surrogate benchmarks based on random forests performed best: for benchmarks with few hyperparameters they yielded almost perfect surrogates, and for benchmarks with more complex hyperparameter spaces they still yielded surrogates that were qualitatively similar to the real …",https://repositorio.inesctec.pt/bitstream/123456789/4540/1/P-00G-699.pdf#page=29
Frank Hutter,Features for SAT,2012,"University of British Columbia,, Tech. Rep",20,"Lin Xu, Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"For the propositional satisfiability (SAT) problem we used the 138 features listed in Figure 1. Since a preprocessing step can significantly reduce the size of the CNF formula (especially for industrial-like instances), we chose to apply the preprocessing procedure SATElite [1] on all instances first, and then to compute instance features on the preprocessed instances. The first 90 features, except Features 22–31, were introduced by [5]. They can be categorized as problem size features (1–7), graph-based features (8–21), balance features (37–49), proximity to horn formula features (50–55), DPLL probing features (56–62), and local search probing features (69–90).",https://www.cs.ubc.ca/labs/algorithms/Projects/SATzilla/Report_SAT_features.pdf
Frank Hutter,On the importance of hyperparameters and data augmentation for self-supervised learning,2022,arXiv preprint arXiv:2207.07875,19,"Diane Wagner, Fabio Ferreira, Danny Stoll, Robin Tibor Schirrmeister, Samuel Müller, Frank Hutter",Diane Wagner,Frank Hutter,6,"Self-Supervised Learning (SSL) has become a very active area of Deep Learning research where it is heavily used as a pre-training method for classification and other tasks. However, the rapid pace of advancements in this area comes at a price: training pipelines vary significantly across papers, which presents a potentially crucial confounding factor. Here, we show that, indeed, the choice of hyperparameters and data augmentation strategies can have a dramatic impact on performance. To shed light on these neglected factors and help maximize the power of SSL, we hyperparameterize these components and optimize them with Bayesian optimization, showing improvements across multiple datasets for the SimSiam SSL approach. Realizing the importance of data augmentations for SSL, we also introduce a new automated data augmentation algorithm, GroupAugment, which considers groups of augmentations and optimizes the sampling across groups. In contrast to algorithms designed for supervised learning, GroupAugment achieved consistently high linear evaluation accuracy across all datasets we considered. Overall, our results indicate the importance and likely underestimated role of data augmentation for SSL.",https://arxiv.org/abs/2207.07875
Frank Hutter,Bag of baselines for multi-objective joint neural architecture search and hyperparameter optimization,2021,arXiv preprint arXiv:2105.01015,19,"Julia Guerrero-Viu, Sven Hauns, Sergio Izquierdo, Guilherme Miotto, Simon Schrodi, Andre Biedenkapp, Thomas Elsken, Difan Deng, Marius Lindauer, Frank Hutter",Julia Guerrero-Viu,Frank Hutter,10,"Neural architecture search (NAS) and hyperparameter optimization (HPO) make deep learning accessible to non-experts by automatically finding the architecture of the deep neural network to use and tuning the hyperparameters of the used training pipeline. While both NAS and HPO have been studied extensively in recent years, NAS methods typically assume fixed hyperparameters and vice versa - there exists little work on joint NAS + HPO. Furthermore, NAS has recently often been framed as a multi-objective optimization problem, in order to take, e.g., resource requirements into account. In this paper, we propose a set of methods that extend current approaches to jointly optimize neural architectures and hyperparameters with respect to multiple objectives. We hope that these methods will serve as simple baselines for future research on multi-objective joint NAS + HPO. To facilitate this, all our code is available at https://github.com/automl/multi-obj-baselines.",https://arxiv.org/abs/2105.01015
Frank Hutter,Towards reproducible neural architecture and hyperparameter search,2018,,19,"Aaron Klein, Eric Christiansen, Kevin Murphy, Frank Hutter",Aaron Klein,Frank Hutter,4,"Recent advances in neural architecture and hyperparameter search demand tremendous computational resources which makes it almost impossible to reproduce experiments. We argue that this hinders the progress in this subfield since new methods can not be thoroughly compared to already existing methods. In this work, we generated a new benchmark for neural architecture search and hyperparameter optimization which is based on tabular data for a feed forward neural network. Each function evaluation is just a simple table look up and thus takes only milliseconds but mimics the true underlying optimization problem. Furthermore, we analyze the properties of this benchmark and compare a range of state-of-the-art neural architecture and hyperparameter search methods.",https://openreview.net/forum?id=rJeMCSnml7
Frank Hutter,Uncertainty estimates for optical flow with multi-hypotheses networks,2018,arXiv preprint arXiv:1802.07095,19,"Eddy Ilg, Özgün Çiçek, Silvio Galesso, Aaron Klein, Osama Makansi, Frank Hutter, Thomas Brox",Eddy Ilg,Thomas Brox,7,"Recent work has shown that optical flow estimation can be formulated as an end-to-end supervised learning problem, which yields estimates with a superior accuracyruntime tradeoff compared to alternative methodology. In this paper, we make the network estimate its local uncertainty about the correctness of its prediction, which is vital information when building decisions on top of the estimated optical flow. For the first time we compare several strategies and techniques to estimate uncertainty in a large-scale computer vision task like optical flow estimation. Moreover, we introduce a new network architecture that enforces complementary hypotheses and provides uncertainty estimates efficiently within a single forward pass without the need for sampling or ensembles. We demonstrate high-quality uncertainty estimates that clearly improve over previous confidence measures on optical flow and allow for interactive frame rates.",https://scholar.google.com/scholar?cluster=16371365858050933662&hl=en&oi=scholarr
Frank Hutter,Efficient automated deep learning for time series forecasting,2022,,18,"Difan Deng, Florian Karl, Frank Hutter, Bernd Bischl, Marius Lindauer",Difan Deng,Marius Lindauer,5,"Recent years have witnessed tremendously improved efficiency of Automated Machine Learning (AutoML), especially Automated Deep Learning (AutoDL) systems, but recent work focuses on tabular, image, or NLP tasks. So far, little attention has been paid to general AutoDL frameworks for time series forecasting, despite the enormous success in applying different novel architectures to such tasks. In this paper, we propose an efficient approach for the joint optimization of neural architecture and hyperparameters of the entire data processing pipeline for time series forecasting. In contrast to common NAS search spaces, we designed a novel neural architecture search space covering various state-of-the-art architectures, allowing for an efficient macro-search over different DL approaches. To efficiently search in such a large configuration space, we use Bayesian optimization with multi-fidelity optimization. We …",https://link.springer.com/chapter/10.1007/978-3-031-26409-2_40
Frank Hutter,Fast downward cedalion,2014,International Planning Competition Planning and Learning Part: planner abstracts,18,"Jendrik Seipp, Silvan Sievers, Frank Hutter",Jendrik Seipp,Frank Hutter,3,"To avoid duplication of content we only give a high-level overview of our algorithm here and refer to a technical report for details on our methodology (Seipp, Sievers, and Hutter 2013). An extended version of that report is forthcoming. The paper at hand focuses mostly on the configuration setup we used for generating portfolios for IPC 2014.",https://ai.dmi.unibas.ch/papers/seipp-et-al-ipc2014b.pdf
Frank Hutter,Transfer NAS with meta-learned bayesian surrogates,2023,The Eleventh International Conference on Learning Representations,17,"Gresa Shala, Thomas Elsken, Frank Hutter, Josif Grabocka",Gresa Shala,Josif Grabocka,4,"While neural architecture search (NAS) is an intensely-researched area, approaches typically still suffer from either (i) high computational costs or (ii) lack of robustness across datasets and experiments. Furthermore, most methods start searching for an optimal architecture from scratch, ignoring prior knowledge. This is in contrast to the manual design process by researchers and engineers that leverage previous deep learning experiences by, e.g., transferring architectures from previously solved, related problems. We propose to adopt this human design strategy and introduce a novel surrogate for NAS, that is meta-learned across prior architecture evaluations across different datasets. We utilizes Bayesian Optimization (BO) with deep-kernel Gaussian Processes,  graph neural networks for the architecture embeddings and a transformer-based set encoder of datasets. As a result, our method consistently achieves state-of-the-art results on six computer vision datasets, while being as fast as one-shot NAS methods.",https://openreview.net/forum?id=paGvsrl4Ntr
Frank Hutter,Deepcave: An interactive analysis tool for automated machine learning,2022,arXiv preprint arXiv:2206.03493,17,"René Sass, Eddie Bergman, André Biedenkapp, Frank Hutter, Marius Lindauer",René Sass,Marius Lindauer,5,"Automated Machine Learning (AutoML) is used more than ever before to support users in determining efficient hyperparameters, neural architectures, or even full machine learning pipelines. However, users tend to mistrust the optimization process and its results due to a lack of transparency, making manual tuning still widespread. We introduce DeepCAVE, an interactive framework to analyze and monitor state-of-the-art optimization procedures for AutoML easily and ad hoc. By aiming for full and accessible transparency, DeepCAVE builds a bridge between users and AutoML and contributes to establishing trust. Our framework's modular and easy-to-extend nature provides users with automatically generated text, tables, and graphic visualizations. We show the value of DeepCAVE in an exemplary use-case of outlier detection, in which our framework makes it easy to identify problems, compare multiple runs and interpret optimization processes. The package is freely available on GitHub https://github.com/automl/DeepCAVE.",https://arxiv.org/abs/2206.03493
Frank Hutter,PED-ANOVA: efficiently quantifying hyperparameter importance in arbitrary subspaces,2023,arXiv preprint arXiv:2304.10255,15,"Shuhei Watanabe, Archit Bansal, Frank Hutter",Shuhei Watanabe,Frank Hutter,3,"The recent rise in popularity of Hyperparameter Optimization (HPO) for deep learning has highlighted the role that good hyperparameter (HP) space design can play in training strong models. In turn, designing a good HP space is critically dependent on understanding the role of different HPs. This motivates research on HP Importance (HPI), e.g., with the popular method of functional ANOVA (f-ANOVA). However, the original f-ANOVA formulation is inapplicable to the subspaces most relevant to algorithm designers, such as those defined by top performance. To overcome this issue, we derive a novel formulation of f-ANOVA for arbitrary subspaces and propose an algorithm that uses Pearson divergence (PED) to enable a closed-form calculation of HPI. We demonstrate that this new algorithm, dubbed PED-ANOVA, is able to successfully identify important HPs in different subspaces while also being extremely computationally efficient.",https://arxiv.org/abs/2304.10255
Frank Hutter,Speeding up multi-objective hyperparameter optimization by task similarity-based meta-learning for the tree-structured parzen estimator,2022,arXiv preprint arXiv:2212.06751,15,"Shuhei Watanabe, Noor Awad, Masaki Onishi, Frank Hutter",Shuhei Watanabe,Frank Hutter,4,"Hyperparameter optimization (HPO) is a vital step in improving performance in deep learning (DL). Practitioners are often faced with the trade-off between multiple criteria, such as accuracy and latency. Given the high computational needs of DL and the growing demand for efficient HPO, the acceleration of multi-objective (MO) optimization becomes ever more important. Despite the significant body of work on meta-learning for HPO, existing methods are inapplicable to MO tree-structured Parzen estimator (MO-TPE), a simple yet powerful MO-HPO algorithm. In this paper, we extend TPE's acquisition function to the meta-learning setting using a task similarity defined by the overlap of top domains between tasks. We also theoretically analyze and address the limitations of our task similarity. In the experiments, we demonstrate that our method speeds up MO-TPE on tabular HPO benchmarks and attains state-of-the-art performance. Our method was also validated externally by winning the AutoML 2022 competition on ""Multiobjective Hyperparameter Optimization for Transformers"".",https://arxiv.org/abs/2212.06751
Frank Hutter,Zero-shot AutoML with pretrained models,2022,International Conference on Machine Learning,15,"Ekrem Öztürk, Fabio Ferreira, Hadi Jomaa, Lars Schmidt-Thieme, Josif Grabocka, Frank Hutter",Ekrem Öztürk,Frank Hutter,6,"Given a new dataset D and a low compute budget, how should we choose a pre-trained model to fine-tune to D, and set the fine-tuning hyperparameters without risking overfitting, particularly if D is small? Here, we extend automated machine learning (AutoML) to best make these choices. Our domain-independent meta-learning approach learns a zero-shot surrogate model which, at test time, allows to select the right deep learning (DL) pipeline (including the pre-trained model and fine-tuning hyperparameters) for a new dataset D given only trivial meta-features describing D such as image resolution or the number of classes. To train this zero-shot model, we collect performance data for many DL pipelines on a large collection of datasets and meta-train on this data to minimize a pairwise ranking objective. We evaluate our approach under the strict time limit of the vision track of the ChaLearn AutoDL challenge benchmark, clearly outperforming all challenge contenders.",https://proceedings.mlr.press/v162/ozturk22a.html
Frank Hutter,Rethinking bias mitigation: Fairer architectures make for fairer face recognition,2024,Advances in Neural Information Processing Systems,14,"Samuel Dooley, Rhea Sukthanker, John Dickerson, Colin White, Frank Hutter, Micah Goldblum",Samuel Dooley,Micah Goldblum,6,"Face recognition systems are widely deployed in safety-critical applications, including law enforcement, yet they exhibit bias across a range of socio-demographic dimensions, such as gender and race. Conventional wisdom dictates that model biases arise from biased training data. As a consequence, previous works on bias mitigation largely focused on pre-processing the training data, adding penalties to prevent bias from effecting the model during training, or post-processing predictions to debias them, yet these approaches have shown limited success on hard problems such as face recognition. In our work, we discover that biases are actually inherent to neural network architectures themselves. Following this reframing, we conduct the first neural architecture search for fairness, jointly with a search for hyperparameters. Our search outputs a suite of models which Pareto-dominate all other high-performance architectures and existing bias mitigation methods in terms of accuracy and fairness, often by large margins, on the two most widely used datasets for face identification, CelebA and VGGFace2. Furthermore, these models generalize to other datasets and sensitive attributes. We release our code, models and raw data files at https://github. com/dooleys/FR-NAS.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/eb3c42ddfa16d8421fdba13528107cc1-Abstract-Conference.html
Frank Hutter,Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification,2022,NeurIPS 2021 Competitions and Demonstrations Track,14,"Adrian El Baz, Ihsan Ullah, Edesio Alcobaça, André CPLF Carvalho, Hong Chen, Fabio Ferreira, Henry Gouk, Chaoyu Guan, Isabelle Guyon, Timothy Hospedales, Shell Hu, Mike Huisman, Frank Hutter, Zhengying Liu, Felix Mohr, Ekrem Öztürk, Jan N van Rijn, Haozhe Sun, Xin Wang, Wenwu Zhu",Adrian El Baz,Wenwu Zhu,20,"Although deep neural networks are capable of achieving performance superior to humans on various tasks, they are notorious for requiring large amounts of data and computing resources, restricting their success to domains where such resources are available. Meta-learning methods can address this problem by transferring knowledge from related tasks, thus reducing the amount of data and computing resources needed to learn new tasks. We organize the MetaDL competition series, which provide opportunities for research groups all over the world to create and experimentally assess new meta-(deep) learning solutions for real problems. In this paper, authored collaboratively between the competition organizers and the top-ranked participants, we describe the design of the competition, the datasets, the best experimental results, as well as the top-ranked methods in the NeurIPS 2021 challenge, which attracted 15 active teams who made it to the final phase (by outperforming the baseline), making over 100 code submissions during the feedback phase. The solutions of the top participants have been open-sourced. The lessons learned include that learning good representations is essential for effective transfer learning.",https://proceedings.mlr.press/v176/el-baz22a.html
Frank Hutter,Masif: Meta-learned algorithm selection using implicit fidelity information,2022,Transactions on Machine Learning Research,14,"Tim Ruhkopf, Aditya Mohan, Difan Deng, Alexander Tornede, Frank Hutter, Marius Lindauer",Tim Ruhkopf,Marius Lindauer,6,"Selecting a well-performing algorithm for a given task or dataset can be time-consuming and tedious, but is crucial for the successful day-to-day business of developing new AI & ML applications. Algorithm Selection (AS) mitigates this through a meta-model leveraging meta-information about previous tasks. However, most of the available AS methods are error-prone because they characterize a task by either cheap-to-compute properties of the dataset or evaluations of cheap proxy algorithms, called landmarks. In this work, we extend the classical AS data setup to include multi-fidelity information and empirically demonstrate how meta-learning on algorithms’ learning behaviour allows us to exploit cheap test-time evidence effectively and combat myopia significantly. We further postulate a budget-regret trade-off w.r.t. the selection process. Our new selector MASIF is able to jointly interpret online evidence on a task in form of varying-length learning curves without any parametric assumption by leveraging a transformer-based encoder. This opens up new possibilities for guided rapid prototyping in data science on cheaply observed partial learning curves.",https://openreview.net/forum?id=5aYGXxByI6
Frank Hutter,Bag of baselines for multi-objective joint neural architecture search and hyperparameter optimization,2021,8th ICML Workshop on Automated Machine Learning (AutoML),14,"Sergio Izquierdo, Julia Guerrero-Viu, Sven Hauns, Guilherme Miotto, Simon Schrodi, André Biedenkapp, Thomas Elsken, Difan Deng, Marius Lindauer, Frank Hutter",Sergio Izquierdo,Frank Hutter,10,"While both neural architecture search (NAS) and hyperparameter optimization (HPO) have been studied extensively in recent years, NAS methods typically assume fixed hyperparameters and vice versa. Furthermore, NAS has recently often been framed as a multi-objective optimization problem, in order to take, eg, resource requirements into account. In this paper, we propose a set of methods that extend current approaches to jointly optimize neural architectures and hyperparameters with respect to multiple objectives. We hope that these methods will serve as simple baselines for future research on multi-objective joint NAS+ HPO.",https://lmb.informatik.uni-freiburg.de/Publications/2021/Sch21/paper-bag-of-baselines.pdf
Frank Hutter,Automated configuration and selection of SAT solvers,2021,,14,"Holger H Hoos, Frank Hutter, Kevin Leyton-Brown",Holger H Hoos,Kevin Leyton-Brown,3,"This chapter provides an introduction to the automated configuration and selection of SAT algorithms and gives an overview of the most prominent approaches. Since the early 2000s, these so-called meta-algorithmic approaches have played a major role in advancing the state of the art in SAT solving, giving rise to new ways of using and evaluating SAT solvers. At the same time, SAT has proven to be particularly fertile ground for research and development in the area of automated configuration and selection, and methods developed there have meanwhile achieved impact far beyond SAT, across a broad range of computationally challenging problems. Conceptually more complex approaches that go beyond “pure” algorithm configuration and selection are also discussed, along with some open challenges related to meta-algorithmic approaches, such as automated algorithm configuration and selection, to the tools …",https://ebooks.iospress.nl/doi/10.3233/FAIA200995
Frank Hutter,Probabilistic transformer: Modelling ambiguities and distributions for rna folding and molecule design,2022,Advances in Neural Information Processing Systems,13,"Jörg Franke, Frederic Runge, Frank Hutter",Jörg Franke,Frank Hutter,3,"Our world is ambiguous and this is reflected in the data we use to train our algorithms. This is particularly true when we try to model natural processes where collected data is affected by noisy measurements and differences in measurement techniques. Sometimes, the process itself is ambiguous, such as in the case of RNA folding, where the same nucleotide sequence can fold into different structures. This suggests that a predictive model should have similar probabilistic characteristics to match the data it models. Therefore, we propose a hierarchical latent distribution to enhance one of the most successful deep learning models, the Transformer, to accommodate ambiguities and data distributions. We show the benefits of our approach (1) on a synthetic task that captures the ability to learn a hidden data distribution,(2) with state-of-the-art results in RNA folding that reveal advantages on highly ambiguous data, and (3) demonstrating its generative capabilities on property-based molecule design by implicitly learning the underlying distributions and outperforming existing work.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/abf0ea3ae33d1a931483e327ff8d94f8-Abstract-Conference.html
Frank Hutter,Why do machine learning practitioners still use manual tuning? A qualitative study,2022,arXiv preprint arXiv:2203.01717,13,"Niklas Hasebrook, Felix Morsbach, Niclas Kannengießer, Jörg Franke, Frank Hutter, Ali Sunyaev",Niklas Hasebrook,Ali Sunyaev,6,"Current advanced hyperparameter optimization (HPO) methods, such as Bayesian optimization, have high sampling efficiency and facilitate replicability. Nonetheless, machine learning (ML) practitioners (eg, engineers, scientists) mostly apply less advanced HPO methods, which can increase resource consumption during HPO or lead to underoptimized ML models. Therefore, we suspect that practitioners choose their HPO method to achieve different goals, such as decrease practitioner effort and target audience compliance. To develop HPO methods that align with such goals, the reasons why practitioners decide for specific HPO methods must be unveiled and thoroughly understood. Because qualitative research is most suitable to uncover such reasons and find potential explanations for them, we conducted semi-structured interviews to explain why practitioners choose different HPO methods. The interviews revealed six principal practitioner goals (eg, increasing model comprehension), and eleven key factors that impact decisions for HPO methods (eg, available computing resources). We deepen the understanding about why practitioners decide for different HPO methods and outline recommendations for improvements of HPO methods by aligning them with practitioner goals.",https://scholar.archive.org/work/o5onyc7xj5grrj6pu7bq3i6vwe/access/wayback/https://publikationen.bibliothek.kit.edu/1000143445/148456686
Frank Hutter,c-TPE: generalizing tree-structured Parzen estimator with inequality constraints for continuous and categorical hyperparameter optimization,2022,arXiv preprint arXiv:2211.14411,13,"Shuhei Watanabe, Frank Hutter",Shuhei Watanabe,Frank Hutter,2,"Gardner et al.➢ Modify the AF and the split of good and bad groups to enhance the performance 1. Use relative density ratios instead of density ratio 2. Take a certain number of feasible solutions instead of just taking top solutions➢ Demonstrate that our method exhibits: 1. much better performance than a naïve extension, 2. the best average rank among various methods.",https://gp-seminar-series.github.io/neurips-2022/assets/camera_ready/5_poster.pdf
Frank Hutter,Probabilistic rollouts for learning curve extrapolation across hyperparameter settings,2019,arXiv preprint arXiv:1910.04522,13,"Matilde Gargiani, Aaron Klein, Stefan Falkner, Frank Hutter",Matilde Gargiani,Frank Hutter,4,"We propose probabilistic models that can extrapolate learning curves of iterative machine learning algorithms, such as stochastic gradient descent for training deep networks, based on training data with variable-length learning curves. We study instantiations of this framework based on random forests and Bayesian recurrent neural networks. Our experiments show that these models yield better predictions than state-of-the-art models from the hyperparameter optimization literature when extrapolating the performance of neural networks trained with different hyperparameter settings.",https://arxiv.org/abs/1910.04522
Frank Hutter,Neural architecture search for dense prediction tasks in computer vision,2023,International Journal of Computer Vision,12,"Rohit Mohan, Thomas Elsken, Arber Zela, Jan Hendrik Metzen, Benedikt Staffler, Thomas Brox, Abhinav Valada, Frank Hutter",Rohit Mohan,Frank Hutter,8,"The success of deep learning in recent years has lead to a rising demand for neural network architecture engineering. As a consequence, neural architecture search (NAS), which aims at automatically designing neural network architectures in a data-driven manner rather than manually, has evolved as a popular field of research. With the advent of weight sharing strategies across architectures, NAS has become applicable to a much wider range of problems. In particular, there are now many publications for dense prediction tasks in computer vision that require pixel-level predictions, such as semantic segmentation or object detection. These tasks come with novel challenges, such as higher memory footprints due to high-resolution data, learning multi-scale representations, longer training times, and more complex and larger neural architectures. In this manuscript, we provide an overview of NAS for dense …",https://link.springer.com/article/10.1007/s11263-023-01785-y
Frank Hutter,TuneTables: Context Optimization for Scalable Prior-Data Fitted Networks,2024,arXiv preprint arXiv:2402.11137,11,"Benjamin Feuer, Robin Tibor Schirrmeister, Valeriia Cherepanova, Chinmay Hegde, Frank Hutter, Micah Goldblum, Niv Cohen, Colin White",Benjamin Feuer,Colin White,8,"While tabular classification has traditionally relied on from-scratch training, a recent breakthrough called prior-data fitted networks (PFNs) challenges this approach. Similar to large language models, PFNs make use of pretraining and in-context learning to achieve strong performance on new tasks in a single forward pass. However, current PFNs have limitations that prohibit their widespread adoption. Notably, TabPFN achieves very strong performance on small tabular datasets but is not designed to make predictions for datasets of size larger than 1000. In this work, we overcome these limitations and substantially improve the performance of PFNs by developing context optimization techniques for PFNs. Specifically, we propose TuneTables, a novel prompt-tuning strategy that compresses large datasets into a smaller learned context. TuneTables scales TabPFN to be competitive with state-of-the-art tabular classification methods on larger datasets, while having a substantially lower inference time than TabPFN. Furthermore, we show that TuneTables can be used as an interpretability tool and can even be used to mitigate biases by optimizing a fairness objective.",https://arxiv.org/abs/2402.11137
Frank Hutter,An Evolution Strategy with Progressive Episode Lengths for Playing Games.,2019,IJCAI,11,"Lior Fuks, Noor H Awad, Frank Hutter, Marius Lindauer",Lior Fuks,Marius Lindauer,4,"Recently, Evolution Strategies (ES) have been successfully applied to solve problems commonly addressed by reinforcement learning (RL). Due to the simplicity of ES approaches, their runtime is often dominated by the RL-task at hand (eg, playing a game). In this work, we introduce Progressive Episode Lengths (PEL) as a new technique and incorporate it with ES. The main objective is to allow the agent to play short and easy tasks with limited lengths, and then use the gained knowledge to further solve long and hard tasks with progressive lengths. Hence allowing the agent to perform many function evaluations and find a good solution for short time horizons before adapting the strategy to tackle larger time horizons. We evaluated PEL on a subset of Atari games from OpenAI Gym, showing that it can substantially improve the optimization speed, stability and final score of canonical ES. Specifically, we show average improvements of 80%(32%) after 2 hours (10 hours) compared to canonical ES.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/19-IJCAI_PEL.pdf?ref=https://githubhelp.com
Frank Hutter,SGDR: stochastic gradient descent with warm restarts. arXiv,2016,arXiv: 1608,11,"I Loshchilov, F Hutter",I Loshchilov,F Hutter,2,,https://scholar.google.com/scholar?cluster=9415670527172369793&hl=en&oi=scholarr
Frank Hutter,Automatic machine learning (automl),2015,"ICML 2015 Workshop on Resource-Efficient Machine Learning, 32nd International Conference on Machine Learning",11,"F Hutter, Balázs Kégl, R Caruana, I Guyon, H Larochelle, E Viegas",F Hutter,E Viegas,6,"The success of machine learning in many domains crucially relies on human machine learning experts, who select appropriate features, workflows, machine learning paradigms, algorithms, and their hyperparameters. The rapid growth of machine learning applications has created a demand for off-the-shelf machine learning methods that can be used easily and without expert knowledge. We call the resulting research area that targets progressive automation of machine learning AutoML. For example, a recent instantiation of AutoML we’ll discuss is the ongoing ChaLearn AutoML challenge (http://codalab.org/AutoML).",https://hal.univ-smb.fr/INRIA/in2p3-01171463
Frank Hutter,Manual for SMAC version v2. 10.03-master,2015,Vancouver: Department of Computer Science University of British Columbia,11,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [?](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.10.03/manual.pdf
Frank Hutter,Diffusion-based neural network weights generation,2024,arXiv preprint arXiv:2402.18153,10,"Bedionita Soro, Bruno Andreis, Hayeon Lee, Wonyong Jeong, Song Chong, Frank Hutter, Sung Ju Hwang",Bedionita Soro,Sung Ju Hwang,7,"Transfer learning has gained significant attention in recent deep learning research due to its ability to accelerate convergence and enhance performance on new tasks. However, its success is often contingent on the similarity between source and target data, and training on numerous datasets can be costly, leading to blind selection of pretrained models with limited insight into their effectiveness. To address these challenges, we introduce D2NWG, a diffusion-based neural network weights generation technique that efficiently produces high-performing weights for transfer learning, conditioned on the target dataset. Our method extends generative hyper-representation learning to recast the latent diffusion paradigm for neural network weights generation, learning the weight distributions of models pretrained on various datasets. This allows for automatic generation of weights that generalize well across both seen and unseen tasks, outperforming state-of-the-art meta-learning methods and pretrained models. Moreover, our approach is scalable to large architectures such as large language models (LLMs), overcoming the limitations of current parameter generation techniques that rely on task-specific model collections or access to original training data. By modeling the parameter distribution of LLMs, D2NWG enables task-specific parameter generation without requiring additional fine-tuning or large collections of model variants. Extensive experiments show that our method consistently enhances the performance of diverse base models, regardless of their size or complexity, positioning it as a robust solution for scalable transfer learning.",https://arxiv.org/abs/2402.18153
Frank Hutter,Quick-tune: Quickly learning which pretrained model to finetune and how,2023,arXiv preprint arXiv:2306.03828,10,"Sebastian Pineda Arango, Fabio Ferreira, Arlind Kadra, Frank Hutter, Josif Grabocka",Sebastian Pineda Arango,Josif Grabocka,5,"With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We meta-learn a multi-fidelity performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a new dataset together with its optimal hyperparameters.",https://arxiv.org/abs/2306.03828
Frank Hutter,Hyperparameter transfer across developer adjustments,2020,arXiv preprint arXiv:2010.13117,10,"Danny Stoll, Jörg KH Franke, Diane Wagner, Simon Selg, Frank Hutter",Danny Stoll,Frank Hutter,5,"After developer adjustments to a machine learning (ML) algorithm, how can the results of an old hyperparameter optimization (HPO) automatically be used to speedup a new HPO? This question poses a challenging problem, as developer adjustments can change which hyperparameter settings perform well, or even the hyperparameter search space itself. While many approaches exist that leverage knowledge obtained on previous tasks, so far, knowledge from previous development steps remains entirely untapped. In this work, we remedy this situation and propose a new research framework: hyperparameter transfer across adjustments (HT-AA). To lay a solid foundation for this research framework, we provide four simple HT-AA baseline algorithms and eight benchmarks changing various aspects of ML algorithms, their hyperparameter search spaces, and the neural architectures used. The best baseline, on average and depending on the budgets for the old and new HPO, reaches a given performance 1.2--2.6x faster than a prominent HPO algorithm without transfer. As HPO is a crucial step in ML development but requires extensive computational resources, this speedup would lead to faster development cycles, lower costs, and reduced environmental impacts. To make these benefits available to ML developers off-the-shelf and to facilitate future research on HT-AA, we provide python packages for our baselines and benchmarks.",https://arxiv.org/abs/2010.13117
Frank Hutter,Prior-guided bayesian optimization,2020,,10,"Artur Souza, Luigi Nardi, Leonardo Oliveira, Kunle Olukotun, Marius Lindauer, Frank Hutter",Artur Souza,Frank Hutter,6,"While Bayesian Optimization (BO) is a very popular method for optimizing expensive black-box functions, it fails to leverage the experience of domain experts. This causes BO to waste function evaluations on bad design choices (e.g., machine learning hyperparameters) that the expert already knows to work poorly.  To address this issue, we introduce Prior-guided Bayesian Optimization (PrBO). PrBO allows users to inject their knowledge into the optimization process in the form of priors about which parts of the input space will yield the best performance, rather than BO’s standard priors over functions (which are much less intuitive for users). PrBO then combines these priors with BO’s standard probabilistic model to form a pseudo-posterior used to select which points to evaluate next. We show that PrBO is around 12x faster than state-of-the-art methods without user priors and 10,000x faster than random search on a common suite of benchmarks, and achieves a new state-of-the-art performance on a real-world hardware design application. We also show that PrBO converges faster even if the user priors are not entirely accurate and that it robustly recovers from misleading priors.",https://openreview.net/forum?id=4SZ9Ft--pDl
Frank Hutter,Oasc-2017:* zilla submission,2017,Open Algorithm Selection Challenge 2017,10,"Chris Cameron, Holger H Hoos, Kevin Leyton-Brown, Frank Hutter",Chris Cameron,Frank Hutter,4,"* Zilla is a model-based approach for algorithm selection and the most recent iteration of the well-known SATzilla project. The new* Zilla system has increased flexibility for the user and is configurable to run with many machine learning models and alternatives for various pre/post processing steps (eg, presolver selection, feature completion prediction, and solver subset selection). The main additions to our* Zilla pipeline are automated procedures for feature group selection, hyper-parameter tuning, and solver subsampling prior to model building. We submit two versions for the competition that are equivalent except for the choice of per-instance machine learning model. For our first submission, we use a weighted pairwise random forest classifier. For our second submission, we test an experimental approach that offline, builds a weighted pairwise random forest classifier and online, finds the nearest instances based on the average path lengths across trees and optimizes a schedule over those instances.",https://proceedings.mlr.press/v79/cameron17a
Frank Hutter,Scalable deep learning for RNA secondary structure prediction,2023,arXiv preprint arXiv:2307.10073,9,"Jörg KH Franke, Frederic Runge, Frank Hutter",Jörg KH Franke,Frank Hutter,3,"The field of RNA secondary structure prediction has made significant progress with the adoption of deep learning techniques. In this work, we present the RNAformer, a lean deep learning model using axial attention and recycling in the latent space. We gain performance improvements by designing the architecture for modeling the adjacency matrix directly in the latent space and by scaling the size of the model. Our approach achieves state-of-the-art performance on the popular TS0 benchmark dataset and even outperforms methods that use external information. Further, we show experimentally that the RNAformer can learn a biophysical model of the RNA folding process.",https://arxiv.org/abs/2307.10073
Frank Hutter,Theory-inspired parameter control benchmarks for dynamic algorithm configuration,2022,,9,"André Biedenkapp, Nguyen Dang, Martin S Krejca, Frank Hutter, Carola Doerr",André Biedenkapp,Carola Doerr,5,"It has long been observed that the performance of evolutionary algorithms and other randomized search heuristics can benefit from a non-static choice of the parameters that steer their optimization behavior. Mechanisms that identify suitable configurations on the fly (""parameter control"") or via a dedicated training process (""dynamic algorithm configuration"") are thus an important component of modern evolutionary computation frameworks. Several approaches to address the dynamic parameter setting problem exist, but we barely understand which ones to prefer for which applications. As in classical benchmarking, problem collections with a known ground truth can offer very meaningful insights in this context. Unfortunately, settings with well-understood control policies are very rare.One of the few exceptions for which we know which parameter settings minimize the expected runtime is the LeadingOnes problem …",https://dl.acm.org/doi/abs/10.1145/3512290.3528846
Frank Hutter,Towards temporl: Learning when to act,2020,"Workshop on Inductive Biases, Invariances and Generalization in Reinforcement Learning (BIG@ ICML’20)",9,"André Biedenkapp, Raghu Rajan, Frank Hutter, Marius Lindauer",André Biedenkapp,Marius Lindauer,4,"Reinforcement Learning is a powerful approach to learning behaviour through interactions with an environment. However, behaviours are learned in a purely reactive fashion, where an appropriate action is selected based on an observation. In this form, it is challenging to learn when it is necessary to make new decisions. This makes learning inefficient especially in environments with with very fine-grained time steps. Instead we propose a more proactive setting in which not only an action is chosen in a state but also for how long to commit to that action. We demonstrate the effectiveness of our proposed approach on a set of small grid worlds, showing that our approach is capable of learning successful policies much faster than vanilla Q-learning.",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/20-BIG-TempoRL.pdf
Frank Hutter,Training generative reversible networks,2018,arXiv preprint arXiv:1806.01610,9,"Robin Tibor Schirrmeister, Patryk Chrabąszcz, Frank Hutter, Tonio Ball",Robin Tibor Schirrmeister,Tonio Ball,4,"Generative models with an encoding component such as autoencoders currently receive great interest. However, training of autoencoders is typically complicated by the need to train a separate encoder and decoder model that have to be enforced to be reciprocal to each other. To overcome this problem, by-design reversible neural networks (RevNets) had been previously used as generative models either directly optimizing the likelihood of the data under the model or using an adversarial approach on the generated data. Here, we instead investigate their performance using an adversary on the latent space in the adversarial autoencoder framework. We investigate the generative performance of RevNets on the CelebA dataset, showing that generative RevNets can generate coherent faces with similar quality as Variational Autoencoders. This first attempt to use RevNets inside the adversarial autoencoder framework slightly underperformed relative to recent advanced generative models using an autoencoder component on CelebA, but this gap may diminish with further optimization of the training setup of generative RevNets. In addition to the experiments on CelebA, we show a proof-of-principle experiment on the MNIST dataset suggesting that adversary-free trained RevNets can discover meaningful latent dimensions without pre-specifying the number of dimensions of the latent sampling distribution. In summary, this study shows that RevNets can be employed in different generative training settings. Source code for this study is at https://github.com/robintibor/generative-reversible",https://arxiv.org/abs/1806.01610
Frank Hutter,Meta-learning System for Automated Clustering.,2017,AutoML@ PKDD/ECML,9,"Sergey Muravyov, Andrey Filchenkov, P Brazdil, J Vanschoren, F Hutter, H Hoos",Sergey Muravyov,H Hoos,6,"Conclusion. We proposed a full model selection system for clustering. The system contains three components that predict appropriate CVI, clustering al-1 https://archive. ics. uci. edu/ml/datasets. html 2 http://sci2s. ugr. es/keel/datasets. php",https://www.academia.edu/download/86839857/paper_10.pdf
Frank Hutter,Algorithm configuration in the cloud: A feasibility study,2014,"Learning and Intelligent Optimization: 8th International Conference, Lion 8, Gainesville, FL, USA, February 16-21, 2014. Revised Selected Papers 8",9,"Daniel Geschwender, Frank Hutter, Lars Kotthoff, Yuri Malitsky, Holger H Hoos, Kevin Leyton-Brown",Daniel Geschwender,Kevin Leyton-Brown,6,"Configuring algorithms automatically to achieve high performance is becoming increasingly relevant and important in many areas of academia and industry. Algorithm configuration methods take a parameterized target algorithm, a performance metric and a set of example data, and aim to find a parameter configuration that performs as well as possible on a given data set.",https://link.springer.com/chapter/10.1007/978-3-319-09584-4_5
Frank Hutter,Stochastic Local Search for Solving the Most Probable Explanation Problem in Bayesian Networks,2004,,9,Frank Hutter,Frank Hutter,Frank Hutter,1,,https://scholar.google.com/scholar?cluster=2713187460197334019&hl=en&oi=scholarr
Frank Hutter,In-Context Freeze-Thaw Bayesian Optimization for Hyperparameter Optimization,2024,arXiv preprint arXiv:2404.16795,8,"Herilalaina Rakotoarison, Steven Adriaensen, Neeratyoy Mallik, Samir Garibov, Edward Bergman, Frank Hutter",Herilalaina Rakotoarison,Frank Hutter,6,"With the increasing computational costs associated with deep learning, automated hyperparameter optimization methods, strongly relying on black-box Bayesian optimization (BO), face limitations. Freeze-thaw BO offers a promising grey-box alternative, strategically allocating scarce resources incrementally to different configurations. However, the frequent surrogate model updates inherent to this approach pose challenges for existing methods, requiring retraining or fine-tuning their neural network surrogates online, introducing overhead, instability, and hyper-hyperparameters. In this work, we propose FT-PFN, a novel surrogate for Freeze-thaw style BO. FT-PFN is a prior-data fitted network (PFN) that leverages the transformers' in-context learning ability to efficiently and reliably do Bayesian learning curve extrapolation in a single forward pass. Our empirical analysis across three benchmark suites shows that the predictions made by FT-PFN are more accurate and 10-100 times faster than those of the deep Gaussian process and deep ensemble surrogates used in previous work. Furthermore, we show that, when combined with our novel acquisition mechanism (MFPI-random), the resulting in-context freeze-thaw BO method (ifBO), yields new state-of-the-art performance in the same three families of deep learning HPO benchmarks considered in prior work.",https://arxiv.org/abs/2404.16795
Frank Hutter,Self-correcting bayesian optimization through bayesian active learning,2024,Advances in Neural Information Processing Systems,8,"Carl Hvarfner, Erik Hellsten, Frank Hutter, Luigi Nardi",Carl Hvarfner,Luigi Nardi,4,"Gaussian processes are the model of choice in Bayesian optimization and active learning. Yet, they are highly dependent on cleverly chosen hyperparameters to reach their full potential, and little effort is devoted to finding good hyperparameters in the literature. We demonstrate the impact of selecting good hyperparameters for GPs and present two acquisition functions that explicitly prioritize hyperparameter learning. Statistical distance-based Active Learning (SAL) considers the average disagreement between samples from the posterior, as measured by a statistical distance. SAL outperforms the state-of-the-art in Bayesian active learning on several test functions. We then introduce Self-Correcting Bayesian Optimization (SCoreBO), which extends SAL to perform Bayesian optimization and active learning simultaneously. SCoreBO learns the model hyperparameters at improved rates compared to vanilla BO, while outperforming the latest Bayesian optimization methods on traditional benchmarks. Moreover, we demonstrate the importance of self-correction on atypical Bayesian optimization tasks.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/fa55bf1947530fc9567059ff42a806c2-Abstract-Conference.html
Frank Hutter,"Automl decathlon: Diverse tasks, modern methods, and efficiency at scale",2023,NeurIPS 2022 Competition Track,8,"Nicholas Roberts, Samuel Guo, Cong Xu, Ameet Talwalkar, David Lander, Lvfang Tao, Linhang Cai, Shuaicheng Niu, Jianyu Heng, Hongyang Qin, Minwen Deng, Johannes Hog, Alexander Pfefferle, Sushil Ammanaghatta Shivakumar, Arjun Krishnakumar, Yubo Wang, Rhea Sukthanker, Frank Hutter, Euxhen Hasanaj, Tien-Dung Le, Mikhail Khodak, Yuriy Nevmyvaka, Kashif Rasul, Frederic Sala, Anderson Schneider, Junhong Shen, Evan Sparks",Nicholas Roberts,Evan Sparks,27,"The vision of Automated Machine Learning (AutoML) is to produce high performing ML pipelines that require very little human involvement or domain expertise to use. Competitions and benchmarks have been critical tools for accelerating progress in AutoML. However, much of the prior work on AutoML competitions has focused on well-studied domains in machine learning such as vision and language—these are domains which have benefited from several years of ML pipeline design by domain experts, which brings the usage of AutoML into question in the first place. Recently, AutoML for diverse tasks has emerged as an important research area that aims to bring AutoML to the domains where it can have the most impact: the long tail of ML tasks beyond vision and language. We present a retrospective report of the AutoML Decathlon—an AutoML for diverse tasks competition hosted at NeurIPS 2022. The AutoML Decathlon presented participants with a set of 10 machine learning tasks that are diverse along several axes: domain, input dimension, output dimension, output type, objective function, and scale. Participants were tasked with developing AutoML methods that performed well on a separate set of 10 hidden diverse test tasks within a certain time budget, so as to discourage overfitting to the initial set of tasks and to encourage efficiency. In this report, we outline the details of the competition, discuss the top-5 submissions, analyze the results, and compare top submissions to additional state-of-the-art baselines designed specifically for diverse tasks. We conclude that the combination of existing efficient AutoML techniques with modern …",https://proceedings.mlr.press/v220/roberts23a.html
Frank Hutter,c-TPE: Tree-structured Parzen estimator with inequality constraints for expensive hyperparameter optimization,2022,arXiv preprint arXiv:2211.14411,8,"Shuhei Watanabe, Frank Hutter",Shuhei Watanabe,Frank Hutter,2,"Hyperparameter optimization (HPO) is crucial for strong performance of deep learning algorithms and real-world applications often impose some constraints, such as memory usage, or latency on top of the performance requirement. In this work, we propose constrained TPE (c-TPE), an extension of the widely-used versatile Bayesian optimization method, tree-structured Parzen estimator (TPE), to handle these constraints. Our proposed extension goes beyond a simple combination of an existing acquisition function and the original TPE, and instead includes modifications that address issues that cause poor performance. We thoroughly analyze these modifications both empirically and theoretically, providing insights into how they effectively overcome these challenges. In the experiments, we demonstrate that c-TPE exhibits the best average rank performance among existing methods with statistical significance on 81 expensive HPO with inequality constraints. Due to the lack of baselines, we only discuss the applicability of our method to hard-constrained optimization in Appendix D.",https://arxiv.org/abs/2211.14411
Frank Hutter,On the importance of architectures and hyperparameters for fairness in face recognition,2022,,8,"Rhea Sanjay Sukthanker, Samuel Dooley, John P Dickerson, Colin White, Frank Hutter, Micah Goldblum",Rhea Sanjay Sukthanker,Micah Goldblum,6,"Face recognition systems are deployed across the world by government agencies and contractors for sensitive and impactful tasks, such as surveillance and database matching.  Despite their widespread use, these systems are known to exhibit bias across a range of sociodemographic dimensions, such as gender and race.  Nonetheless, an array of works proposing pre-processing, training, and post-processing methods have failed to close these gaps. Here, we take a very different approach to this problem, identifying that both architectures and hyperparameters of neural networks are instrumental in reducing bias. We first run a large-scale analysis of the impact of architectures and training hyperparameters on several common fairness metrics and show that the implicit convention of choosing high-accuracy architectures may be suboptimal for fairness. Motivated by our findings, we run the first neural architecture search for fairness, jointly with a search for hyperparameters. We output a suite of models which Pareto-dominate all other competitive architectures in terms of accuracy and fairness. Furthermore, we show that these models transfer well to other face recognition datasets with similar and distinct protected attributes. We release our code and raw result files so that researchers and practitioners can replace our fairness metrics with a bias measure of their choice.",https://openreview.net/forum?id=iiRDsy85uXi
Frank Hutter,Multi-headed neural ensemble search,2021,arXiv preprint arXiv:2107.04369,8,"Ashwin Raaghav Narayanan, Arber Zela, Tonmoy Saikia, Thomas Brox, Frank Hutter",Ashwin Raaghav Narayanan,Frank Hutter,5,"Ensembles of CNN models trained with different seeds (also known as Deep Ensembles) are known to achieve superior performance over a single copy of the CNN. Neural Ensemble Search (NES) can further boost performance by adding architectural diversity. However, the scope of NES remains prohibitive under limited computational resources. In this work, we extend NES to multi-headed ensembles, which consist of a shared backbone attached to multiple prediction heads. Unlike Deep Ensembles, these multi-headed ensembles can be trained end to end, which enables us to leverage one-shot NAS methods to optimize an ensemble objective. With extensive empirical evaluations, we demonstrate that multi-headed ensemble search finds robust ensembles 3 times faster, while having comparable performance to other ensemble search methods, in both predictive performance and uncertainty calibration.",https://arxiv.org/abs/2107.04369
Frank Hutter,Neural architecture evolution in deep reinforcement learning for continuous control,2019,arXiv preprint arXiv:1910.12824,8,"Jörg KH Franke, Gregor Köhler, Noor Awad, Frank Hutter",Jörg KH Franke,Frank Hutter,4,"Current Deep Reinforcement Learning algorithms still heavily rely on handcrafted neural network architectures. We propose a novel approach to automatically find strong topologies for continuous control tasks while only adding a minor overhead in terms of interactions in the environment. To achieve this, we combine Neuroevolution techniques with off-policy training and propose a novel architecture mutation operator. Experiments on five continuous control benchmarks show that the proposed Actor-Critic Neuroevolution algorithm often outperforms the strong Actor-Critic baseline and is capable of automatically finding topologies in a sample-efficient manner which would otherwise have to be found by expensive architecture search.",https://arxiv.org/abs/1910.12824
Frank Hutter,Correction to: Neural architecture search,2019,"Automated Machine Learning: Methods, Systems, Challenges",8,"Thomas Elsken, Jan Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,3,The original version of this chapter was inadvertently published without the author “Thomas Elsken” primary affiliation. The affiliation has now been updated as below.,https://link.springer.com/content/pdf/10.1007/978-3-030-05318-5_11.pdf
Frank Hutter,Fast downward SMAC,2014,"Planner abstract, IPC",8,"Jendrik Seipp, Silvan Sievers, Frank Hutter",Jendrik Seipp,Frank Hutter,3,"Fast Downward SMAC uses the SMAC algorithm configurator (Hutter, Hoos, and Leyton-Brown 2011) to find a single configuration of Fast Downward (Helmert 2006) for a given planning domain. It closely follows the methodology used by Fawcett et al.(2011), but employs the newer modelbased algorithm configurator SMAC instead of ParamILS (Hutter et al. 2009) to optimize Fast Downward for each domain of the IPC 2014 learning track. In the following we will describe our configuration setup.",https://rlplab.com/papers/seipp-et-al-ipc2014d.pdf
Frank Hutter,Incremental thin junction trees for dynamic Bayesian networks,2004,"Darmstadt University of Technology, Tech. Rep",8,"Frank Hutter, Brenda Ng, Richard Dearden",Frank Hutter,Richard Dearden,3,"In this paper, we present Incremental Thin Junction Trees, a general framework for approximate inference in static and dynamic Bayesian Networks. This framework incrementally builds junction trees representing probability distributions over a dynamically changing set of variables. Variables and their conditional probability tables can be introduced into the junction tree Υ, they can be summed out of Υ and Υ can be approximated by splitting clusters for computational efficiency. As one of many possible applications of this general framework in dynamic Bayesian Networks, we automatically generate conditionally independent clusters for the prominent Boyen-Koller (BK) algorithm. Theoretical work by Boyen and Koller [BK99] showed that using conditionally independent clusters strongly improves BK’s error bounds. We show how to identify these conditionally independent clusters automatically and that the theoretical results carry over to practice. We achieve a contract anytime algorithm which is superior to BK with marginally independent clusters.",http://www.fhutter.de/itjt-bf.pdf
Frank Hutter,RNAformer: A Simple Yet Effective Deep Learning Model for RNA Secondary Structure Prediction,2024,bioRxiv,7,"Joerg KH Franke, Frederic Runge, Ryan Koeksal, Rolf Backofen, Frank Hutter",Joerg KH Franke,Frank Hutter,5,"Traditional RNA secondary structure prediction methods, based on dynamic programming, often fall short in accuracy. Recent advances in deep learning have aimed to address this, but may not adequately learn the biophysical model of RNA folding. Many deep learning approaches are also too complex, incorporating multi-model systems, ensemble strategies, or requiring external data like multiple sequence alignments. In this study, we demonstrate that a single deep learning model, relying solely on RNA sequence input, can effectively learn a biophysical model and outperform existing deep learning methods in standard benchmarks, as well as achieve comparable results to methods that utilize multi-sequence alignments. We dub this model ""RNAformer"" and achieve these benefits by a two-dimensional latent space, axial attention, and recycling in the latent space. Further, we found that our model performance improves when we scale it up. We also demonstrate how to refine a pre-trained RNAformer with fine-tuning techniques, which are particularly efficient when applied to a limited amount of high-quality data. A further aspect of our work is addressing the challenges in dataset curation in deep learning, especially regarding data homology. We tackle this through an advanced data processing pipeline that allows for training and evaluation of our model across various levels of sequence similarity. Our models and datasets are openly accessible, offering a simplified yet effective tool for RNA secondary structure prediction.",https://www.biorxiv.org/content/10.1101/2024.02.12.579881.abstract
Frank Hutter,Mind the gap: Measuring generalization performance across multiple objectives,2023,,7,"Matthias Feurer, Katharina Eggensperger, Edward Bergman, Florian Pfisterer, Bernd Bischl, Frank Hutter",Matthias Feurer,Frank Hutter,6,"Modern machine learning models are often constructed taking into account multiple objectives, e.g., minimizing inference time while also maximizing accuracy. Multi-objective hyperparameter optimization (MHPO) algorithms return such candidate models, and the approximation of the Pareto front is used to assess their performance. In practice, we also want to measure generalization when moving from the validation to the test set. However, some of the models might no longer be Pareto-optimal which makes it unclear how to quantify the performance of the MHPO method when evaluated on the test set. To resolve this, we provide a novel evaluation protocol that allows measuring the generalization performance of MHPO methods and studying its capabilities for comparing two optimization experiments.",https://link.springer.com/chapter/10.1007/978-3-031-30047-9_11
Frank Hutter,Neural architecture search for dense prediction tasks in computer vision,2022,arXiv preprint arXiv:2202.07242,7,"Thomas Elsken, Arber Zela, Jan Hendrik Metzen, Benedikt Staffler, Thomas Brox, Abhinav Valada, Frank Hutter",Thomas Elsken,Frank Hutter,7,"The success of deep learning in recent years has lead to a rising demand for neural network architecture engineering. As a consequence, neural architecture search (NAS), which aims at automatically designing neural network architectures in a data-driven manner rather than manually, has evolved as a popular field of research. With the advent of weight sharing strategies across architectures, NAS has become applicable to a much wider range of problems. In particular, there are now many publications for dense prediction tasks in computer vision that require pixel-level predictions, such as semantic segmentation or object detection. These tasks come with novel challenges, such as higher memory footprints due to high-resolution data, learning multi-scale representations, longer training times, and more complex and larger neural architectures. In this manuscript, we provide an overview of NAS for dense prediction tasks by elaborating on these novel challenges and surveying ways to address them to ease future research and application of existing methods to novel problems.",https://arxiv.org/abs/2202.07242
Frank Hutter,On the importance of domain model configuration for automated planning engines,2021,Journal of Automated Reasoning,7,"Mauro Vallati, Lukáš Chrpa, Thomas Leo McCluskey, Frank Hutter",Mauro Vallati,Frank Hutter,4,"The development of domain-independent planners within the AI planning community is leading to “off-the-shelf” technology that can be used in a wide range of applications. Moreover, it allows a modular approach—in which planners and domain knowledge are modules of larger software applications—that facilitates substitutions or improvements of individual modules without changing the rest of the system. This approach also supports the use of reformulation and configuration techniques, which transform how a model is represented in order to improve the efficiency of plan generation. In this article, we investigate how the performance of domain-independent planners is affected by domain model configuration, i.e. the order in which elements are ordered in the model, particularly in the light of planner comparisons. We then introduce techniques for the online and offline configuration of domain models, and we …",https://link.springer.com/article/10.1007/s10817-021-09592-1
Frank Hutter,Bag of tricks for neural architecture search,2021,arXiv preprint arXiv:2107.03719,7,"Thomas Elsken, Benedikt Staffler, Arber Zela, Jan Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,5,"While neural architecture search methods have been successful in previous years and led to new state-of-the-art performance on various problems, they have also been criticized for being unstable, being highly sensitive with respect to their hyperparameters, and often not performing better than random search. To shed some light on this issue, we discuss some practical considerations that help improve the stability, efficiency and overall performance.",https://arxiv.org/abs/2107.03719
Frank Hutter,Deep learning with convolutional neural networks for decoding and visualization of eeg pathology,2017,arXiv e-prints,7,"Robin Tibor Schirrmeister, Lukas Gemein, Katharina Eggensperger, Frank Hutter, Tonio Ball",Robin Tibor Schirrmeister,Tonio Ball,5,"We apply convolutional neural networks (ConvNets) to the task of distinguishing pathological from normal EEG recordings in the Temple University Hospital EEG Abnormal Corpus. We use two basic, shallow and deep ConvNet architectures recently shown to decode task-related information from EEG at least as well as established algorithms designed for this purpose. In decoding EEG pathology, both ConvNets reached substantially better accuracies (about 6% better,~ 85% vs.~ 79%) than the only published result for this dataset, and were still better when using only 1 minute of each recording for training and only six seconds of each recording for testing. We used automated methods to optimize architectural hyperparameters and found intriguingly different ConvNet architectures, eg, with max pooling as the only nonlinearity. Visualizations of the ConvNet decoding behavior showed that they used spectral power …",https://ui.adsabs.harvard.edu/abs/2017arXiv170808012T/abstract
Frank Hutter,RnaBench: A Comprehensive Library for In Silico RNA Modelling,2024,bioRxiv,6,"Frederic Runge, Karim Farid, Jörg KH Franke, Frank Hutter",Frederic Runge,Frank Hutter,4,"RNA is a crucial regulator in living organisms and malfunctions can lead to severe diseases. To explore RNA-based therapeutics and applications, computational structure prediction and design approaches play a vital role. Among these approaches, deep learning (DL) algorithms show great promise. However, the adoption of DL methods in the RNA community is limited due to various challenges. DL practitioners often underestimate data homologies, causing skepticism in the field. Additionally, the absence of standardized benchmarks hampers result comparison, while tackling low-level tasks requires significant effort. Moreover, assessing performance and visualizing results prove to be non-trivial and task-dependent. To address these obstacles, we introduce RnaBench (RnB), an open-source RNA library designed specifically for the development of deep learning algorithms that mitigate the challenges during data generation, evaluation, and visualization. It provides meticulously curated homology-aware RNA datasets and standardized RNA benchmarks, including a pioneering RNA design benchmark suite featuring a novel real-world RNA design problem. Furthermore, RnB offers baseline algorithms, both existing and novel performance measures, as well as data utilities and a comprehensive visualization module, all accessible through a user-friendly interface. By leveraging RnB, DL practitioners can rapidly develop innovative algorithms, potentially revolutionizing the field of computational RNA research.",https://www.biorxiv.org/content/10.1101/2024.01.09.574794.abstract
Frank Hutter,Practitioner motives to select hyperparameter optimization methods,2022,arXiv preprint arXiv:2203.01717,6,"Niklas Hasebrook, Felix Morsbach, Niclas Kannengießer, Marc Zöller, Jörg Franke, Marius Lindauer, Frank Hutter, Ali Sunyaev",Niklas Hasebrook,Ali Sunyaev,8,"Advanced programmatic hyperparameter optimization (HPO) methods, such as Bayesian optimization, have high sample efficiency in reproducibly finding optimal hyperparameter values of machine learning (ML) models. Yet, ML practitioners often apply less sample-efficient HPO methods, such as grid search, which often results in under-optimized ML models. As a reason for this behavior, we suspect practitioners choose HPO methods based on individual motives, consisting of contextual factors and individual goals. However, practitioners' motives still need to be clarified, hindering the evaluation of HPO methods for achieving specific goals and the user-centered development of HPO tools. To understand practitioners' motives for using specific HPO methods, we used a mixed-methods approach involving 20 semi-structured interviews and a survey study with 71 ML experts to gather evidence of the external validity of the interview results. By presenting six main goals (e.g., improving model understanding) and 14 contextual factors affecting practitioners' selection of HPO methods (e.g., available computer resources), our study explains why practitioners use HPO methods that seem inappropriate at first glance. This study lays a foundation for designing user-centered and context-adaptive HPO tools and, thus, linking social and technical research on HPO.",https://arxiv.org/abs/2203.01717
Frank Hutter,AutoRL-Bench 1.0,2022,Sixth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems,6,"Gresa Shala, Sebastian Pineda Arango, André Biedenkapp, Frank Hutter, Josif Grabocka",Gresa Shala,Josif Grabocka,5,"It is well established that Reinforcement Learning (RL)  is very brittle and sensitive to the choice of hyperparameters. This prevents RL methods from being usable out of the box. The field of automated RL (AutoRL) aims at automatically configuring the RL pipeline, to both make RL usable by a broader audience, as well as reveal its full potential.  Still, there has been little progress towards this goal as new AutoRL methods often are evaluated with incompatible experimental protocols. Furthermore, the typically high cost of experimentation prevents a thorough and meaningful comparison of different AutoRL methods or established hyperparameter optimization (HPO) methods from the automated Machine Learning (AutoML) community. To alleviate these issues, we propose the first tabular AutoRL Benchmark for studying the hyperparameters of RL algorithms. We consider the hyperparameter search spaces of five well established RL methods (PPO, DDPG, A2C, SAC, TD3) across 22 environments for which we compute and provide the reward curves. This enables HPO methods to simply query our benchmark as a lookup table, instead of actually training agents. Thus, our benchmark offers a testbed for very fast, fair, and reproducible experimental protocols for comparing future black-box, gray-box, and online HPO methods for RL.",https://openreview.net/forum?id=RyAl60VhTcG
Frank Hutter,Towards discovering neural architectures from scratch,2022,,6,"Simon Schrodi, Danny Stoll, Binxin Ru, Rhea Sanjay Sukthanker, Thomas Brox, Frank Hutter",Simon Schrodi,Frank Hutter,6,"The discovery of neural architectures from scratch is the long-standing goal of Neural Architecture Search (NAS). Searching over a wide spectrum of neural architectures can facilitate the discovery of previously unconsidered but well-performing architectures. In this work, we take a large step towards discovering neural architectures from scratch by expressing architectures algebraically. This algebraic view leads to a more general method for designing search spaces, which allows us to compactly represent search spaces that are 100s of orders of magnitude larger than common spaces from the literature. Further, we propose a Bayesian Optimization strategy to efficiently search over such huge spaces, and demonstrate empirically that both our search space design and our search strategy can be superior to existing baselines. We open source our algebraic NAS approach and provide APIs for PyTorch and TensorFlow.",https://openreview.net/forum?id=UIpwFLrJiDi
Frank Hutter,Learning synthetic environments for reinforcement learning with evolution strategies,2021,arXiv preprint arXiv:2101.09721,6,"Fabio Ferreira, Thomas Nierhoff, Frank Hutter",Fabio Ferreira,Frank Hutter,3,"This work explores learning agent-agnostic synthetic environments (SEs) for Reinforcement Learning. SEs act as a proxy for target environments and allow agents to be trained more efficiently than when directly trained on the target environment. We formulate this as a bi-level optimization problem and represent an SE as a neural network. By using Natural Evolution Strategies and a population of SE parameter vectors, we train agents in the inner loop on evolving SEs while in the outer loop we use the performance on the target task as a score for meta-updating the SE population. We show empirically that our method is capable of learning SEs for two discrete-action-space tasks (CartPole-v0 and Acrobot-v1) that allow us to train agents more robustly and with up to 60% fewer steps. Not only do we show in experiments with 4000 evaluations that the SEs are robust against hyperparameter changes such as the learning rate, batch sizes and network sizes, we also show that SEs trained with DDQN agents transfer in limited ways to a discrete-action-space version of TD3 and very well to Dueling DDQN.",https://arxiv.org/abs/2101.09721
Frank Hutter,Neural model-based optimization with right-censored observations,2020,arXiv preprint arXiv:2009.13828,6,"Katharina Eggensperger, Kai Haase, Philipp Müller, Marius Lindauer, Frank Hutter",Katharina Eggensperger,Frank Hutter,5,"In many fields of study, we only observe lower bounds on the true response value of some experiments. When fitting a regression model to predict the distribution of the outcomes, we cannot simply drop these right-censored observations, but need to properly model them. In this work, we focus on the concept of censored data in the light of model-based optimization where prematurely terminating evaluations (and thus generating right-censored data) is a key factor for efficiency, e.g., when searching for an algorithm configuration that minimizes runtime of the algorithm at hand. Neural networks (NNs) have been demonstrated to work well at the core of model-based optimization procedures and here we extend them to handle these censored observations. We propose (i)~a loss function based on the Tobit model to incorporate censored samples into training and (ii) use an ensemble of networks to model the posterior distribution. To nevertheless be efficient in terms of optimization-overhead, we propose to use Thompson sampling s.t. we only need to train a single NN in each iteration. Our experiments show that our trained regression models achieve a better predictive quality than several baselines and that our approach achieves new state-of-the-art performance for model-based optimization on two optimization problems: minimizing the solution time of a SAT solver and the time-to-accuracy of neural networks.",https://arxiv.org/abs/2009.13828
Frank Hutter,Partial RNA design,2024,Bioinformatics,5,"Frederic Runge, Jörg Franke, Daniel Fertmann, Rolf Backofen, Frank Hutter",Frederic Runge,Frank Hutter,5,"RNA design is a key technique to achieve new functionality in fields like synthetic biology or biotechnology. Computational tools could help to find such RNA sequences but they are often limited in their formulation of the search space.In this work, we propose partial RNA design, a novel RNA design paradigm that addresses the limitations of current RNA design formulations. Partial RNA design describes the problem of designing RNAs from arbitrary RNA sequences and structure motifs with multiple design goals. By separating the design space from the objectives, our formulation enables the design of RNAs with variable lengths and desired properties, while still allowing precise control over sequence and structure constraints at individual positions. Based on this formulation, we introduce a new algorithm, libLEARNA, capable of efficiently solving different …",https://academic.oup.com/bioinformatics/article-abstract/40/Supplement_1/i437/7700895
Frank Hutter,Construction of hierarchical neural architecture search spaces based on context-free grammars,2024,Advances in Neural Information Processing Systems,5,"Simon Schrodi, Danny Stoll, Binxin Ru, Rhea Sukthanker, Thomas Brox, Frank Hutter",Simon Schrodi,Frank Hutter,6,"The discovery of neural architectures from simple building blocks is a long-standing goal of Neural Architecture Search (NAS). Hierarchical search spaces are a promising step towards this goal but lack a unifying search space design framework and typically only search over some limited aspect of architectures. In this work, we introduce a unifying search space design framework based on context-free grammars that can naturally and compactly generate expressive hierarchical search spaces that are 100s of orders of magnitude larger than common spaces from the literature. By enhancing and using their properties, we effectively enable search over the complete architecture and can foster regularity. Further, we propose an efficient hierarchical kernel design for a Bayesian Optimization search strategy to efficiently search over such huge spaces. We demonstrate the versatility of our search space design framework and show that our search strategy can be superior to existing NAS approaches. Code is available at https://github. com/automl/hierarchicalnasconstruction.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/4869f3f967dfe954439408dd92c50ee1-Abstract-Conference.html
Frank Hutter,Method and apparatus for automatically producing an artificial neural network,2023,,5,"Frank Hutter, Jan Hendrik Metzen, Thomas Elsken",Frank Hutter,Thomas Elsken,3,"A method for automatically generating an artificial neural network that encompasses modules and connections that link those modules, successive modules and/or connections being added to a current starting network. Modules and/or connections that are to be added are selected randomly from a predefinable plurality of possible modules and connections that can be added. A plurality of possible refinements of the current starting network respectively are generated by adding to the starting network modules and/or connections that are to be added. One of the refinements from the plurality of possible refinements is then selected in order to serve as a current starting network in a subsequent execution of the method.",https://patents.google.com/patent/US11727277B2/en
Frank Hutter,On the importance of architectures and hyperparameters for fairness in face recognition,2022,"Workshop on Trustworthy and Socially Responsible Machine Learning, NeurIPS 2022",5,"Samuel Dooley, Rhea Sanjay Sukthanker, John P Dickerson, Colin White, Frank Hutter, Micah Goldblum",Samuel Dooley,Micah Goldblum,6,"Face recognition systems are used widely but are known to exhibit bias across a range of sociodemographic dimensions, such as gender and race.  An array of works proposing pre-processing, training, and post-processing methods have failed to close these gaps. Here, we take a very different approach to this problem, identifying that both architectures and hyperparameters of neural networks are instrumental in reducing bias. We first run a large-scale analysis of the impact of architectures and training hyperparameters on several common fairness metrics and show that the implicit convention of choosing high-accuracy architectures may be suboptimal for fairness. Motivated by our findings, we run the first neural architecture search for fairness, jointly with a search for hyperparameters. We output a suite of models which Pareto-dominate all other competitive architectures in terms of accuracy and fairness. Furthermore, we show that these models transfer well to other face recognition datasets with similar and distinct protected attributes. We release our code and raw result files so that researchers and practitioners can replace our fairness metrics with a bias measure of their choice.",https://openreview.net/forum?id=NpuYNxmIHrc
Frank Hutter,"Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2020, Ghent, Belgium, September 14–18, 2020, Proceedings, Part I",2021,,5,"Frank Hutter, Kristian Kersting, Jefrey Lijffijt, Isabel Valera",Frank Hutter,Isabel Valera,4,"The 5-volume proceedings, LNAI 12457 until 12461 constitutes the refereed proceedings of the European Conference on Machine Learning and Knowledge Discovery in Databases, ECML PKDD 2020, which was held during September 14-18, 2020. The conference was planned to take place in Ghent, Belgium, but had to change to an online format due to the COVID-19 pandemic. The 232 full papers and 10 demo papers presented in this volume were carefully reviewed and selected for inclusion in the proceedings. The volumes are organized in topical sections as follows: Part I: Pattern Mining; clustering; privacy and fairness;(social) network analysis and computational social science; dimensionality reduction and autoencoders; domain adaptation; sketching, sampling, and binary projections; graphical models and causality;(spatio-) temporal data and recurrent neural networks; collaborative filtering and matrix completion. Part II: deep learning optimization and theory; active learning; adversarial learning; federated learning; Kernel methods and online learning; partial label learning; reinforcement learning; transfer and multi-task learning; Bayesian optimization and few-shot learning. Part III: Combinatorial optimization; large-scale optimization and differential privacy; boosting and ensemble methods; Bayesian methods; architecture of neural networks; graph neural networks; Gaussian processes; computer vision and image processing; natural language processing; bioinformatics. Part IV: applied data science: recommendation; applied data science: anomaly detection; applied data science: Web mining; applied data science: transportation …",https://books.google.com/books?hl=en&lr=&id=YhwgEAAAQBAJ&oi=fnd&pg=PR5&dq=info:yVvtxi1KTXIJ:scholar.google.com&ots=QjTeaoxJyR&sig=JARY6Q6QwKBsjmwYHmsc67Z2EPw
Frank Hutter,Transformers can do bayesian-inference by meta-learning on prior-data,2021,Fifth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems,5,"Samuel Müller, Noah Hollmann, Sebastian Pineda Arango, Josif Grabocka, Frank Hutter",Samuel Müller,Frank Hutter,5,"Currently, it is hard to reap the benefits of deep learning for Bayesian methods. We present Prior-Data Fitted Networks (PFNs), a method that allows to employ large-scale machine learning techniques to approximate a large set of posteriors. The only requirement for PFNs is the ability to sample from a prior distribution over supervised learning tasks (or functions). The method repeatedly draws a task (or function) from this prior, draws a set of data points and their labels from it, masks one of the labels and learns to make probabilistic predictions for it based on the set-valued input of the rest of the data points. Presented with samples from a new supervised learning task as input, it can then make probabilistic predictions for arbitrary other data points in a single forward propagation, effectively having learned to perform Bayesian inference. We demonstrate that PFNs can near-perfectly mimic Gaussian processes and also enable efficient Bayesian inference for intractable problems, with over 200-fold speedups in multiple setups compared to current methods.  We obtain strong results in such diverse areas as Gaussian process regression and Bayesian neural networks, demonstrating the generality of PFNs.",https://openreview.net/forum?id=h9yIMMjRoje
Frank Hutter,Squirrel: a switching hyperparameter optimizer,2020,arXiv preprint arXiv:2012.08180,5,"Noor Awad, Gresa Shala, Difan Deng, Neeratyoy Mallik, Matthias Feurer, Katharina Eggensperger, Andre' Biedenkapp, Diederick Vermetten, Hao Wang, Carola Doerr, Marius Lindauer, Frank Hutter",Noor Awad,Frank Hutter,12,"In this short note, we describe our submission to the NeurIPS 2020 BBO challenge. Motivated by the fact that different optimizers work well on different problems, our approach switches between different optimizers. Since the team names on the competition's leaderboard were randomly generated ""alliteration nicknames"", consisting of an adjective and an animal with the same initial letter, we called our approach the Switching Squirrel, or here, short, Squirrel.",https://arxiv.org/abs/2012.08180
Frank Hutter,Foundations of Artificial Intelligence,2017,Foundations,5,"Joschka Boedecker, Wolfram Burgard, Bernhard Nebel",Joschka Boedecker,Bernhard Nebel,3,"Foundations of Artificial Intelligence Page 1 Foundations of Artificial Intelligence 11. Making 
Simple Decisions under Uncertainty Probability Theory, Bayesian Networks, Other Approaches 
Joschka Boedecker and Wolfram Burgard and Frank Hutter and Bernhard Nebel and Michael 
Tangermann Albert-Ludwigs-Universität Freiburg June 19, 2019 Page 2 Contents 1 Motivation 
2 Foundations of Probability Theory 3 Probabilistic Inference 4 Bayesian Networks 5 
Alternative Approaches (University of Freiburg) Foundations of AI June 19, 2019 2 / 72 Page 3 
Lecture Overview 1 Motivation 2 Foundations of Probability Theory 3 Probabilistic Inference 4 
Bayesian Networks 5 Alternative Approaches (University of Freiburg) Foundations of AI June 
19, 2019 3 / 72 Page 4 Motivation In many cases, our knowledge of the world is incomplete 
(not enough information) or uncertain (sensors are unreliable). Often, rules about the …",http://ais.informatik.uni-freiburg.de/teaching/ss19/ki/slides/ai11_making_simple_decisions_under_uncertainty.pdf
Frank Hutter,Simple and efficient architecture search for CNNs,2017,Workshop on Meta-Learning at NIPS,5,"Thomas Elsken, Jan-Hendrik Metzen, Frank Hutter",Thomas Elsken,Frank Hutter,3,"CNNs have recently had a lot of success. However, CNN architectures that perform well are still typically designed manually by experts in a cumbersome trial-and-error process. We propose a new method to automatically search for well-performing CNN architectures based on a simple hill climbing procedure whose operators apply network morphisms, followed by short optimization runs by cosine annealing. Surprisingly, this simple method yields competitive results, despite only requiring resources in the same order of magnitude as training a single network.",https://meta-learn.github.io/2017/papers/metalearn17_elsken.pdf
Frank Hutter,Satzilla2007: a new & improved algorithm portfolio for SAT,2007,"Solver description, SAT competition",5,"Lin Xu, Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"Empirical studies often observe that the performance of algorithms across problem domains can be quite uncorrelated. When this occurs, it seems practical to investigate the use of algorithm portfolios that draw on the strengths of multiple algorithms. SATzilla is such an algorithm portfolio for SAT problems; it was first deployed in the 2004 SAT competition [4]. SATzilla is based on empirical hardness models [3, 5], learned predictors that estimate each algorithm’s runtime on a given SAT instance. SATzilla2007 is a new version of SATzilla that incorporates new research on empirical hardness models:",https://www.researchgate.net/profile/Kevin-Leyton-Brown/publication/228820702_Satzilla2007_a_new_improved_algorithm_portfolio_for_SAT/links/0912f508ebd0d06dda000000/Satzilla2007-a-new-improved-algorithm-portfolio-for-SAT.pdf
Frank Hutter,Multi-objective Differentiable Neural Architecture Search,2024,arXiv preprint arXiv:2402.18213,4,"Rhea Sanjay Sukthanker, Arber Zela, Benedikt Staffler, Samuel Dooley, Josif Grabocka, Frank Hutter",Rhea Sanjay Sukthanker,Frank Hutter,6,"Pareto front profiling in multi-objective optimization (MOO), i.e. finding a diverse set of Pareto optimal solutions, is challenging, especially with expensive objectives like neural network training. Typically, in MOO neural architecture search (NAS), we aim to balance performance and hardware metrics across devices. Prior NAS approaches simplify this task by incorporating hardware constraints into the objective function, but profiling the Pareto front necessitates a search for each constraint. In this work, we propose a novel NAS algorithm that encodes user preferences for the trade-off between performance and hardware metrics, and yields representative and diverse architectures across multiple devices in just one search run. To this end, we parameterize the joint architectural distribution across devices and multiple objectives via a hypernetwork that can be conditioned on hardware features and preference vectors, enabling zero-shot transferability to new devices. Extensive experiments with up to 19 hardware devices and 3 objectives showcase the effectiveness and scalability of our method. Finally, we show that, without additional costs, our method outperforms existing MOO NAS methods across qualitatively different search spaces and datasets, including MobileNetV3 on ImageNet-1k and a Transformer space on machine translation.",https://arxiv.org/abs/2402.18213
Frank Hutter,A general framework for user-guided bayesian optimization,2023,arXiv preprint arXiv:2311.14645,4,"Carl Hvarfner, Frank Hutter, Luigi Nardi",Carl Hvarfner,Luigi Nardi,3,"The optimization of expensive-to-evaluate black-box functions is prevalent in various scientific disciplines. Bayesian optimization is an automatic, general and sample-efficient method to solve these problems with minimal knowledge of the underlying function dynamics. However, the ability of Bayesian optimization to incorporate prior knowledge or beliefs about the function at hand in order to accelerate the optimization is limited, which reduces its appeal for knowledgeable practitioners with tight budgets. To allow domain experts to customize the optimization routine, we propose ColaBO, the first Bayesian-principled framework for incorporating prior beliefs beyond the typical kernel structure, such as the likely location of the optimizer or the optimal value. The generality of ColaBO makes it applicable across different Monte Carlo acquisition functions and types of user beliefs. We empirically demonstrate ColaBO's ability to substantially accelerate optimization when the prior information is accurate, and to retain approximately default performance when it is misleading.",https://arxiv.org/abs/2311.14645
Frank Hutter,T3VIP: Transformation-based  Video Prediction,2022,2022 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),4,"Iman Nematollahi, Erick Rosete-Beas, Seyed Mahdi B Azad, Raghu Rajan, Frank Hutter, Wolfram Burgard",Iman Nematollahi,Wolfram Burgard,6,"For autonomous skill acquisition, robots have to learn about the physical rules governing the 3D world dynamics from their own past experience to predict and reason about plausible future outcomes. To this end, we propose a transformation-based 3D video prediction (T3VIP) approach that explicitly models the 3D motion by decomposing a scene into its object parts and predicting their corresponding rigid transformations. Our model is fully unsupervised, captures the stochastic nature of the real world, and the observational cues in image and point cloud domains constitute its learning signals. To fully leverage all the 2D and 3D observational signals, we equip our model with automatic hyperparameter optimization (HPO) to interpret the best way of learning from them. To the best of our knowledge, our model is the first generative model that provides an RGB-D video prediction of the future for a static camera. Our …",https://ieeexplore.ieee.org/abstract/document/9981187/
Frank Hutter,Method and device for transfer learning between modified tasks,2022,,4,"Danny Stoll, Diane Wagner, Frank Hutter, Joerg Franke, Simon Selg",Danny Stoll,Simon Selg,5,"A method for the transfer learning of hyperparameters of a machine learning algorithm. The method includes providing a current search space and a previous search space. A reduced search space is then created and candidate configurations are drawn repeatedly at random from the reduced search space and from the current search space, and the machine learning algorithm, parameterized in each case with the candidate configurations, is applied. A Tree Parzen Estimator (TPE) is then created as a function of the candidate solutions and the results of the machine learning algorithm parameterized with the candidate configurations, and the drawing of further candidate configurations from the current search space using the TPE is repeated multiple times, the TPE being updated upon each drawing.",https://patents.google.com/patent/US20220051138A1/en
Frank Hutter,Multi-objective tree-structured parzen estimator meets meta-learning,2022,Sixth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems,4,"Shuhei Watanabe, Noor Awad, Masaki Onishi, Frank Hutter",Shuhei Watanabe,Frank Hutter,4,"Hyperparameter optimization (HPO) is essential for the better performance of deep learning, and practitioners often need to consider the trade-off between multiple metrics, such as error rate, latency, memory requirements, robustness, and algorithmic fairness. Due to this demand and the heavy computation of deep learning, the acceleration of multi-objective (MO) optimization becomes ever more important. Although meta-learning has been extensively studied to speedup HPO, existing methods are not applicable to the MO tree-structured parzen estimator (MO-TPE), a simple yet powerful MO HPO algorithm. In this paper, we extend TPE’s acquisition function to the meta-learning setting, using a task similarity defined by the overlap in promising regions of each task. In a comprehensive set of experiments, we demonstrate that our method accelerates MO-TPE on tabular HPO benchmarks and yields state-of-the-art performance. Our method was also validated externally by winning the AutoML 2022 competition on ""Multiobjective Hyperparameter Optimization for Transformers"".",https://openreview.net/forum?id=vBcKu0UL3A9
Frank Hutter,Learning Domain-Independent Policies for Open List Selection,2022,,4,"André Biedenkapp, David Speck, Silvan Sievers, Frank Hutter, Marius Lindauer, Jendrik Seipp",André Biedenkapp,Jendrik Seipp,6,"Since its proposal over a decade ago, LAMA has been considered one of the best-performing satisficing classical planners. Its key component is heuristic search with multiple open lists, each using a different heuristic function to order states. Even with a very simple, ad-hoc policy for open list selection, LAMA achieves state-of-the-art results. In this paper, we propose to use dynamic algorithm configuration to learn such policies in a principled and data-driven manner. On the learning side, we show how to train a reinforcement learning agent over several heterogeneous environments, aiming at zero-shot generalization to new related domains. On the planning side, our experimental results show that the trained policies often reach the performance of LAMA, and sometimes even perform better. Furthermore, our analysis of different policies shows that prioritizing states reached via preferred operators is crucial, explaining the strong performance of LAMA.",https://edoc.unibas.ch/93633/
Frank Hutter,Method and device for ascertaining a network configuration of a neural network,2021,,4,"Thomas Elsken, Frank Hutter, Jan Hendrik Metzen",Thomas Elsken,Jan Hendrik Metzen,3,"BACKGROUND INFORMATION [0002] The properties of neural networks are determined primarily by their architecture. The architecture of a neural network is defined, for example, by its network configura tion, which is specified, among other things, by the number of neuron layers, the type of neuron layers (linear transfor mations, nonlinear transformations, normalization, linkage with further neuron layers, etc.), and the like. In particular with increasing complexity of the applications and of the tasks to be performed, randomly finding suitable network configurations is laborious, since each candidate of a net work configuration must initially be trained to allow its performance to be evaluated.[0003] To improve the search for a suitable network configuration, expert knowledge is generally applied in order to reduce the number of candidates for possible network configurations prior to their training. In this way, a search …",https://patents.google.com/patent/US20210012183A1/en
Frank Hutter,MDP playground: A design and debug testbed for reinforcement learning,2021,,4,"Raghu Rajan, Jessica Lizeth Borja Diaz, Suresh Guttikonda, Fabio Ferreira, André Biedenkapp, Jan Ole von Hartz, Frank Hutter",Raghu Rajan,Frank Hutter,7,"We present \emph{MDP Playground}, an efficient testbed for Reinforcement Learning (RL) agents with \textit{orthogonal} dimensions that can be controlled independently to challenge agents in different ways and obtain varying degrees of hardness in generated environments. We consider and allow control over a wide variety of dimensions, including \textit{delayed rewards}, \textit{rewardable sequences}, \textit{density of rewards}, \textit{stochasticity}, \textit{image representations}, \textit{irrelevant features}, \textit{time unit}, \textit{action range} and more. We define a parameterised collection of fast-to-run toy environments in \textit{OpenAI Gym} by varying these dimensions and propose to use these for the initial design and development of agents. We also provide wrappers that inject these dimensions into complex environments from \textit{Atari} and \textit{Mujoco} to allow for evaluating agent robustness. We further provide various example use-cases and instructions on how to use \textit{MDP Playground} to design and debug agents. We believe that \textit{MDP Playground} is a valuable testbed for researchers designing new, adaptive and intelligent RL agents and those wanting to unit test their agents.",https://openreview.net/forum?id=VtqyY2dvE6h
Frank Hutter,Towards white-box benchmarks for algorithm control,2019,arXiv preprint arXiv:1906.07644,4,"André Biedenkapp, H Furkan Bozkurt, Frank Hutter, Marius Lindauer",André Biedenkapp,Marius Lindauer,4,"The performance of many algorithms in the fields of hard combinatorial problem solving, machine learning or AI in general depends on tuned hyperparameter configurations. Automated methods have been proposed to alleviate users from the tedious and error-prone task of manually searching for performance-optimized configurations across a set of problem instances. However there is still a lot of untapped potential through adjusting an algorithm's hyperparameters online since different hyperparameters are potentially optimal at different stages of the algorithm. We formulate the problem of adjusting an algorithm's hyperparameters for a given instance on the fly as a contextual MDP, making reinforcement learning (RL) the prime candidate to solve the resulting algorithm control problem in a data-driven way. Furthermore, inspired by applications of algorithm configuration, we introduce new white-box benchmarks suitable to study algorithm control. We show that on short sequences, algorithm configuration is a valid choice, but that with increasing sequence length a black-box view on the problem quickly becomes infeasible and RL performs better.",https://arxiv.org/abs/1906.07644
Frank Hutter,Meta-learning acquisition functions for bayesian optimization,2019,CoRR,4,"Michael Volpp, Lukas P Fröhlich, Andreas Doerr, Frank Hutter, Christian Daniel",Michael Volpp,Christian Daniel,5,"Transferring knowledge across tasks to improve data-efficiency is one of the open key challenges in the field of global black-box optimization. Readily available algorithms are typically designed to be universal optimizers and, therefore, often suboptimal for specific tasks. We propose a novel transfer learning method to obtain customized optimizers within the well-established framework of Bayesian optimization, allowing our algorithm to utilize the proven generalization capabilities of Gaussian processes. Using reinforcement learning to meta-train an acquisition function (AF) on a set of related tasks, the proposed method learns to extract implicit structural information and to exploit it for improved data-efficiency. We present experiments on a simulation-to-real transfer task as well as on several synthetic functions and on two hyperparameter search problems. The results show that our algorithm (1) automatically …",https://openreview.net/forum?id=YE23udKue4
Frank Hutter,Selection and configuration of parallel portfolios,2018,Handbook of Parallel Constraint Reasoning,4,"Marius Lindauer, Holger Hoos, Frank Hutter, Kevin Leyton-Brown",Marius Lindauer,Kevin Leyton-Brown,4,"In recent years the availability of parallel computation resources has grown rapidly. Nevertheless, even for the most widely studied constraint programming problems such as SAT, solver development and applications remain largely focussed on sequential rather than parallel approaches. To ease the burden usually associated with designing, implementing and testing parallel solvers, in this chapter, we demonstrate how methods from automatic algorithm design can be used to construct effective parallel portfolio solvers from sequential components. Specifically, we discuss two prominent approaches for this problem. (I) Parallel portfolio selection involves selecting a parallel portfolio consisting of complementary sequential solvers for a specific instance to be solved (as characterised by cheaply computable instance features). Applied to a broad set of sequential SAT solvers from SAT competitions, we show …",https://link.springer.com/chapter/10.1007/978-3-319-63516-3_15
Frank Hutter,Towards a data science collaboratory,2015,,4,"Joaquin Vanschoren, Bernd Bischl, Frank Hutter, Michele Sebag, Balazs Kegl, Matthias Schmid, Giulio Napolitano, Katy Wolstencroft, Alan R Williams, Neil Lawrence",Joaquin Vanschoren,Neil Lawrence,10,"Data-driven research requires many people from different domains to collaborate efficiently. The domain scientist collects and analyzes scientific data, the data scientist develops new techniques, and the tool developer implements, optimizes and maintains existing techniques to be used throughout science and industry. Today, however, this data science expertise lies fragmented in loosely connected communities and scattered over many people, making it very hard to find the right expertise, data and tools at the right time. Collaborations are typically small and cross-domain knowledge transfer through the literature is slow. Although progress has been made, it is far from easy for one to build on the latest results of the other and collaborate effortlessly across domains. This slows down data-driven research and innovation, drives up costs and exacerbates the risks associated with the inappropriate use of data science techniques.We propose to create an open, online collaboration platform, a ‘collaboratory’for data-driven research, that brings together data scientists, domain scientists and tool developers on the same platform. It will enable data scientists to evaluate their latest techniques on many current scientific datasets, allow domain scientists to discover which techniques work best on their data, and engage tool developers to share in the latest developments. It will change the scale of collaborations from small to potentially massive, and from periodic to real-time. This will be an inclusive movement operating across academia, healthcare, and industry, and empower more students to engage in data science.",https://research.tue.nl/files/56901844/vanstowa2015.pdf
Frank Hutter,Scaling and probabilistic smoothing (saps),2004,SAT,4,"Dave AD Tompkins, Frank Hutter, Holger H Hoos",Dave AD Tompkins,Holger H Hoos,3,"The SAPS algorithm is a Dynamic Local Search (DLS) algorithm conceptually closely related to the Exponentiated Sub-Gradient (ESG) algorithm developed by Schuurmans, Southey and Holte [3]. When introducing SAPS, our major contributions were a reduction in the algorithmic complexity as compared to the ESG algorithm and a new perspective on how the two algorithms were behaving. The SAPS algorithm is described in detail in our paper [2] and Figure 1 contains a pseudo-code representation that accurately reflects how the SAPS algorithm has been implemented in practice. Similar to most DLS algorithms, SAPS assigns a clause penalty clp to each clause, and the search evaluation function of SAPS is the sum of the clause penalties of unsatisfied clauses. The core search procedure is a greedy descent without sideways steps. Whenever a local minimum occurs (no step improvement in the evaluation function greater than SAPSthresh is possible) a random walk step occurs with probability wp. Otherwise, a scaling step occurs, where the penalties for unsatisfied clauses are multiplied by the scaling factor α (ie clp:= α· clp). After a scaling step, a smoothing step occurs with probability Psmooth. In a smoothing step, all penalties are adjusted according to the mean penalty value clp and the smoothing factor ρ (ie clp:= clp+(1− ρ)· clp). Along with the SAPS algorithm, we also developed a reactive variant (RSAPS)[2] that reactively changes the smoothing parameter ρ during the search process whenever search stagnation is detected, using the same adaptive mechanism as Adaptive Novelty+[1]. More recently we have developed a de …",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=b51c0d21beaa917812c17dcf8a8aafc3b9ddda32
Frank Hutter,Don't Waste Your Time: Early Stopping Cross-Validation,2024,arXiv preprint arXiv:2405.03389,3,"Edward Bergman, Lennart Purucker, Frank Hutter",Edward Bergman,Frank Hutter,3,"State-of-the-art automated machine learning systems for tabular data often employ cross-validation; ensuring that measured performances generalize to unseen data, or that subsequent ensembling does not overfit. However, using k-fold cross-validation instead of holdout validation drastically increases the computational cost of validating a single configuration. While ensuring better generalization and, by extension, better performance, the additional cost is often prohibitive for effective model selection within a time budget. We aim to make model selection with cross-validation more effective. Therefore, we study early stopping the process of cross-validation during model selection. We investigate the impact of early stopping on random search for two algorithms, MLP and random forest, across 36 classification datasets. We further analyze the impact of the number of folds by considering 3-, 5-, and 10-folds. In addition, we investigate the impact of early stopping with Bayesian optimization instead of random search and also repeated cross-validation. Our exploratory study shows that even a simple-to-understand and easy-to-implement method consistently allows model selection to converge faster; in ~94% of all datasets, on average by ~214%. Moreover, stopping cross-validation enables model selection to explore the search space more exhaustively by considering +167% configurations on average within one hour, while also obtaining better overall performance.",https://arxiv.org/abs/2405.03389
Frank Hutter,Towards Quantifying the Effect of Datasets for Benchmarking: A Look at Tabular Machine Learning,2024,,3,"Ravin Kohli, Matthias Feurer, Katharina Eggensperger, Bernd Bischl, Frank Hutter",Ravin Kohli,Frank Hutter,5,"Data in tabular form makes up a large part of real-world ML applications, and thus, there has been a strong interest in developing novel deep learning (DL) architectures for supervised learning on tabular data in recent years. As a result, there is a debate as to whether DL methods are superior to the ubiquitous ensembles of boosted decision trees. Very often, the advantage of one model class over the other is claimed based on an empirical evaluation, where different variations of both model classes are compared on a set of benchmark datasets that supposedly resemble relevant real-world tabular data. While the landscape of state-of-the-art models for tabular data changed, one factor has remained largely constant over the years: The datasets. Here, we examine  recent publications using a total of  different datasets in terms of age, study size and relevance. We found that the average study used less than  datasets and that \% of the datasets are older than a current first-year student (born in 1994). Our insights raise questions about the conclusions drawn from previous studies and urge the research community to develop and publish recent, challenging and relevant datasets and ML tasks for supervised learning on tabular data.",https://openreview.net/forum?id=ACLLU9nQ2E
Frank Hutter,Constrained Parameter Regularization,2023,,3,"Jörg KH Franke, Michael Hefenbrock, Gregor Koehler, Frank Hutter",Jörg KH Franke,Frank Hutter,4,"In this work, we present constrained parameter regularization (CPR), an alternative to traditional weight decay. Instead of applying a constant penalty uniformly to all parameters, we enforce an upper bound on a statistical measure (e.g., the L2-norm) of parameter groups. Consequently, learning becomes a constraint optimization problem, which we address by an adaptation of the augmented Lagrangian method. This formulation permits varying regularization strengths for each parameter group, eliminating the need for explicit penalty coefficients for regularization terms. CPR only requires two hyperparameters and incurs no measurable runtime overhead. Additionally, we propose a simple but efficient mechanism to adapt the upper bounds during the optimization. We provide empirical evidence of CPR's efficacy in experiments on the ``grokking'' phenomenon, computer vision, and language modeling tasks. Our results demonstrate that CPR counteracts the effects of grokking and consistently matches or outperforms traditional weight decay.",https://openreview.net/forum?id=9GviaQcGnx
Frank Hutter,MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning,2023,Journal of Artificial Intelligence Research,3,"Raghu Rajan, Jessica Lizeth Borja Diaz, Suresh Guttikonda, Fabio Ferreira, André Biedenkapp, Jan Ole von Hartz, Frank Hutter",Raghu Rajan,Frank Hutter,7,"We present MDP Playground, a testbed for Reinforcement Learning (RL) agents with dimensions of hardness that can be controlled independently to challenge agents in different ways and obtain varying degrees of hardness in toy and complex RL environments. We consider and allow control over a wide variety of dimensions, including delayed rewards, sequence lengths, reward density, stochasticity, image representations, irrelevant features, time unit, action range and more. We define a parameterised collection of fast-to-run toy environments in OpenAI Gym by varying these dimensions and propose to use these to understand agents better. We then show how to design experiments using MDP Playground to gain insights on the toy environments. We also provide wrappers that can inject many of these dimensions into any Gym environment. We experiment with these wrappers on Atari and Mujoco to allow for understanding the effects of these dimensions on environments that are more complex than the toy environments. We also compare the effect of the dimensions on the toy and complex environments. Finally, we show how to use MDP Playground to debug agents, to study the interaction of multiple dimensions and describe further use-cases.",https://www.jair.org/index.php/jair/article/download/14314/26946/35075
Frank Hutter,Learning synthetic environments and reward networks for reinforcement learning,2022,arXiv preprint arXiv:2202.02790,3,"Fabio Ferreira, Thomas Nierhoff, Andreas Sälinger, Frank Hutter",Fabio Ferreira,Frank Hutter,4,"We introduce Synthetic Environments (SEs) and Reward Networks (RNs), represented by neural networks, as proxy environment models for training Reinforcement Learning (RL) agents. We show that an agent, after being trained exclusively on the SE, is able to solve the corresponding real environment. While an SE acts as a full proxy to a real environment by learning about its state dynamics and rewards, an RN is a partial proxy that learns to augment or replace rewards. We use bi-level optimization to evolve SEs and RNs: the inner loop trains the RL agent, and the outer loop trains the parameters of the SE / RN via an evolution strategy. We evaluate our proposed new concept on a broad range of RL algorithms and classic control environments. In a one-to-one comparison, learning an SE proxy requires more interactions with the real environment than training agents only on the real environment. However, once such an SE has been learned, we do not need any interactions with the real environment to train new agents. Moreover, the learned SE proxies allow us to train agents with fewer interactions while maintaining the original task performance. Our empirical results suggest that SEs achieve this result by learning informed representations that bias the agents towards relevant states. Moreover, we find that these proxies are robust against hyperparameter variation and can also transfer to unseen agents.",https://arxiv.org/abs/2202.02790
Frank Hutter,Convergence analysis of homotopy-sgd for non-convex optimization,2020,arXiv preprint arXiv:2011.10298,3,"Matilde Gargiani, Andrea Zanelli, Quoc Tran-Dinh, Moritz Diehl, Frank Hutter",Matilde Gargiani,Frank Hutter,5,"First-order stochastic methods for solving large-scale non-convex optimization problems are widely used in many big-data applications, e.g. training deep neural networks as well as other complex and potentially non-convex machine learning models. Their inexpensive iterations generally come together with slow global convergence rate (mostly sublinear), leading to the necessity of carrying out a very high number of iterations before the iterates reach a neighborhood of a minimizer. In this work, we present a first-order stochastic algorithm based on a combination of homotopy methods and SGD, called Homotopy-Stochastic Gradient Descent (H-SGD), which finds interesting connections with some proposed heuristics in the literature, e.g. optimization by Gaussian continuation, training by diffusion, mollifying networks. Under some mild assumptions on the problem structure, we conduct a theoretical analysis of the proposed algorithm. Our analysis shows that, with a specifically designed scheme for the homotopy parameter, H-SGD enjoys a global linear rate of convergence to a neighborhood of a minimum while maintaining fast and inexpensive iterations. Experimental evaluations confirm the theoretical results and show that H-SGD can outperform standard SGD.",https://arxiv.org/abs/2011.10298
Frank Hutter,Designing and understanding convolutional networks for decoding executed movements from eeg,2017,The First Biannual Neuroadaptive Technology Conference,3,"Robin Tibor Schirrmeister, Lukas Dominique Josef Fiederer, Jost Tobias Springenberg, Martin Glasstetter, Katharina Eggensperger, Michael Tangermann, Frank Hutter, Wolfram Burgard, Tonio Ball",Robin Tibor Schirrmeister,Tonio Ball,9,"We used deep and shallow convolutional neural networks (CNNs) to decode executed movements from the raw time-domain EEG signal. Our CNNs yielded competitive decoding accuracies compared with filter bank common spatial patterns (FBCSP)[1]. Additionally, we developed visualization methods to understand the trained CNNs, including spatial maps that showed how band power features in different frequencies affected the CNN predictions.",https://espace.library.uq.edu.au/view/UQ:03cc344/NAT17_Berlin_Conference_Programme-1.pdf#page=147
Frank Hutter,Reports on the 2015 aaai workshop program,2015,Ai Magazine,3,"Stefano V Albrecht, J Christopher Beck, David L Buckeridge, Adi Botea, Cornelia Caragea, Chi-hung Chi, Theodoros Damoulas, Bistra Dilkina, Eric Eaton, Pooyan Fazli, Sam Ganzfried, C Lee Giles, Sébastian Guillet, Robert Holte, Frank Hutter, Thorsten Koch, Matteo Leonetti, Marius Lindauer, Marlos C Machado, Yui Malitsky, Gary Marcus, Sebastiaan Meijer, Francesca Rossi, Arash Shaban-Nejad, Sylvie Thiebaux, Manuela Veloso, Toby Walsh, Can Wang, Jie Zhang, Yu Zheng",Stefano V Albrecht,Yu Zheng,30,"AAAI's 2015 Workshop Program was held Sunday and Monday, January 25–26, 2015 at the Hyatt Regency Austin Hotel in Austion, Texas, USA. The AAAI-15 workshop program included 15 workshops covering a wide range of topics in artificial intelligence. Most workshops were held on a single day. The titles of the workshops included AI and Ethics, AI for Cities, AI for Transportation: Advice, Interactivity and Actor Modeling, Algorithm Configuration, Artificial Intelligence Applied to Assistive Technologies and Smart Environments, Beyond the Turing Test, Computational Sustainability, Computer Poker and Imperfect Information, Incentive and Trust in E-Communities, Multiagent Interaction without Prior Coordination, Planning, Search, and Optimization, Scholarly Big Data: AI Perspectives, Challenges, and Ideas, Trajectory-Based Behaviour Analytics, World Wide Web and Public Health Intelligence, Knowledge, Skill, and Behavior Transfer in Autonomous Robots, and Learning for General Competency in Video Games.",https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/2590
Frank Hutter,Results of the configurable SAT solver challenge 2014,2014,,3,"Frank Hutter, Marius Lindauer, Sam Bayless, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,5,Solver CSSC Results Solver defaults#(timeouts) avg. time for solved#(timeouts) avg. time for solved lingeling 115 12.78 136 16.35 riss3g 117 10.18 122 10.80 Solver43 127 13.17 127 14.46 forl-nodrup 128 15.07 152 19.01 simpsat 128 20.27 134 19.59 clasp-cssc 130 9.97 163 11.21 sat4j 176 19.46 184 21.37 gnovelty+ GCwa 1090 23.88 1131 7.30 gnovelty+ PCL 1099 9.62 1101 14.07 gnovelty+ GCa 1104 10.97 1129 14.81 riss3gExt (hors concours) 82 8.25 123 10.53,https://tr.informatik.uni-freiburg.de/reports/report276/report00276.pdf
Frank Hutter,Detailed SATzilla results from the data analysis track of the 2011 SAT competition,2011,14th International Conference on Theory and Applications of Satisfiability Testing,3,"Lin Xu, Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Lin Xu,Kevin Leyton-Brown,4,"Methods We used the new SATzilla procedure (based on cost-sensitive classification models). 1We used 10-fold cross validation to obtain an unbiased estimate of SATzilla’s performance. First, we eliminated all",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/11-SATzilla.pdf
Frank Hutter,On the potential of automatic algorithm configuration,2007,SLS-DS2007: Doctoral Symposium on Engineering Stochastic Local Search Algorithms,3,Frank Hutter,Frank Hutter,Frank Hutter,1,"Design and implementation of efficient and robust algorithms are core topics of computer science and operations research, and the determination of appropriate values for free algorithm parameters is a challenging and tedious task in the design of effective algorithms for hard problems. Such parameters include categorical choices (eg, neighborhood structure in local search or variable/value ordering heuristics in tree search), as well as numerical parameters (eg, noise or restart timing). In practice, tuning of these parameters is largely carried out manually by applying rules of thumb and crude heuristics, while more principled approaches are only rarely used. In this paper, we study some tuning scenarios in more detail and demonstrate the large potential of even very simple automatic algorithm configuration approaches.",https://www.academia.edu/download/30765209/10.1.1.69.5416.pdf#page=44
Frank Hutter,HW-GPT-Bench: Hardware-Aware Architecture Benchmark for Language Models,2024,arXiv preprint arXiv:2405.10299,2,"Rhea Sanjay Sukthanker, Arber Zela, Benedikt Staffler, Aaron Klein, Lennart Purucker, Jörg KH Franke, Frank Hutter",Rhea Sanjay Sukthanker,Frank Hutter,7,"The increasing size of language models necessitates a thorough analysis across multiple dimensions to assess trade-offs among crucial hardware metrics such as latency, energy consumption, GPU memory usage, and performance. Identifying optimal model configurations under specific hardware constraints is becoming essential but remains challenging due to the computational load of exhaustive training and evaluation on multiple devices. To address this, we introduce HW-GPT-Bench, a hardware-aware benchmark that utilizes surrogate predictions to approximate various hardware metrics across 13 devices of architectures in the GPT-2 family, with architectures containing up to 1.55B parameters. Our surrogates, via calibrated predictions and reliable uncertainty estimates, faithfully model the heteroscedastic noise inherent in the energy and latency measurements. To estimate perplexity, we employ weight-sharing techniques from Neural Architecture Search (NAS), inheriting pretrained weights from the largest GPT-2 model. Finally, we demonstrate the utility of HW-GPT-Bench by simulating optimization trajectories of various multi-objective optimization algorithms in just a few seconds.",https://arxiv.org/abs/2405.10299
Frank Hutter,Surprisingly Strong Performance Prediction with Neural Graph Features,2024,arXiv preprint arXiv:2404.16551,2,"Gabriela Kadlecová, Jovita Lukasik, Martin Pilát, Petra Vidnerová, Mahmoud Safari, Roman Neruda, Frank Hutter",Gabriela Kadlecová,Frank Hutter,7,"Performance prediction has been a key part of the neural architecture search (NAS) process, allowing to speed up NAS algorithms by avoiding resource-consuming network training. Although many performance predictors correlate well with ground truth performance, they require training data in the form of trained networks. Recently, zero-cost proxies have been proposed as an efficient method to estimate network performance without any training. However, they are still poorly understood, exhibit biases with network properties, and their performance is limited. Inspired by the drawbacks of zero-cost proxies, we propose neural graph features (GRAF), simple to compute properties of architectural graphs. GRAF offers fast and interpretable performance prediction while outperforming zero-cost proxies and other common encodings. In combination with other zero-cost proxies, GRAF outperforms most existing performance predictors at a fraction of the cost.",https://arxiv.org/abs/2404.16551
Frank Hutter,DAFT: Data-aware fine-tuning of foundation models for efficient and effective medical image segmentation,2024,CVPR 2024: Segment Anything In Medical Images On Laptop,2,"Alexander Pfefferle, Lennart Purucker, Frank Hutter",Alexander Pfefferle,Frank Hutter,3,"Efficient and effective medical image segmentation supports faster and better decision-making of medical experts.  In this work, we propose data-aware fine-tuning (DAFT), a method for enabling efficient and effective inference with foundation models, and apply it to medical image segmentation tasks. Following concepts from meta-learning for algorithm selection and dynamic selection, DAFT aims to fine-tune several versions of a foundation model on subsets of all available data instead of fine-tuning just one larger model. Then, at inference time, we select which fine-tuned model to use for the prediction depending on the distribution of the input data.  DAFT enables us to create more efficient and effective models for each subset than when creating one model for all data.  In our implementation of DAFT for the ""Segment Anything In Medical Images On Laptop"" competition as part of the CVPR24 Workshop on ""Foundation Models for Medical Vision"", we use the EfficientViT architecture, knowledge distillation, and OpenVINO runtime to further improve the inference.  Additionally, we optimized the efficiency of our method through a flood of improvements, including an optimized inference runtime, caching, optimizing the docker deployment container, and better inference code. DAFT improved the average dice similarity coefficient from 78.64% to 83.29% and the normalized surface distance from 80.58% to 85.59% compared to the baseline on the test data. Our final submission secured first place on the post-challenge leaderboard. Finally, and more importantly, we improved the average inference speed over the baseline by a factor of 6.5 (14.69 to 2.25 …",https://openreview.net/forum?id=PObXviy706
Frank Hutter,Weight-Entanglement Meets Gradient-Based Neural Architecture Search,2023,arXiv preprint arXiv:2312.10440,2,"Rhea Sanjay Sukthanker, Arjun Krishnakumar, Mahmoud Safari, Frank Hutter",Rhea Sanjay Sukthanker,Frank Hutter,4,"Weight sharing is a fundamental concept in neural architecture search (NAS), enabling gradient-based methods to explore cell-based architecture spaces significantly faster than traditional blackbox approaches. In parallel, weight \emph{entanglement} has emerged as a technique for intricate parameter sharing among architectures within macro-level search spaces. %However, the macro structure of such spaces poses compatibility challenges for gradient-based NAS methods. %As a result, blackbox optimization methods have been commonly employed, particularly in conjunction with supernet training, to maintain search efficiency. %Due to the inherent differences in the structure of these search spaces, these Since weight-entanglement poses compatibility challenges for gradient-based NAS methods, these two paradigms have largely developed independently in parallel sub-communities. This paper aims to bridge the gap between these sub-communities by proposing a novel scheme to adapt gradient-based methods for weight-entangled spaces. This enables us to conduct an in-depth comparative assessment and analysis of the performance of gradient-based NAS in weight-entangled search spaces. Our findings reveal that this integration of weight-entanglement and gradient-based NAS brings forth the various benefits of gradient-based methods (enhanced performance, improved supernet training properties and superior any-time performance), while preserving the memory efficiency of weight-entangled spaces. The code for our work is openly accessible \href{https://anonymous.4open.science/r/TangleNAS-527C}{here}",https://arxiv.org/abs/2312.10440
Frank Hutter,Rethinking performance measures of rna secondary structure problems,2023,arXiv preprint arXiv:2401.05351,2,"Frederic Runge, Jörg KH Franke, Daniel Fertmann, Frank Hutter",Frederic Runge,Frank Hutter,4,"Accurate RNA secondary structure prediction is vital for understanding cellular regulation and disease mechanisms. Deep learning (DL) methods have surpassed traditional algorithms by predicting complex features like pseudoknots and multi-interacting base pairs. However, traditional distance measures can hardly deal with such tertiary interactions and the currently used evaluation measures (F1 score, MCC) have limitations. We propose the Weisfeiler-Lehman graph kernel (WL) as an alternative metric. Embracing graph-based metrics like WL enables fair and accurate evaluation of RNA structure prediction algorithms. Further, WL provides informative guidance, as demonstrated in an RNA design experiment.",https://arxiv.org/abs/2401.05351
Frank Hutter,Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How,2023,arXiv e-prints,2,"Sebastian Pineda Arango, Fabio Ferreira, Arlind Kadra, Frank Hutter, Josif Grabocka",Sebastian Pineda Arango,Josif Grabocka,5,"With the ever-increasing number of pretrained models, machine learning practitioners are continuously faced with which pretrained model to use, and how to finetune it for a new dataset. In this paper, we propose a methodology that jointly searches for the optimal pretrained model and the hyperparameters for finetuning it. Our method transfers knowledge about the performance of many pretrained models with multiple hyperparameter configurations on a series of datasets. To this aim, we evaluated over 20k hyperparameter configurations for finetuning 24 pretrained image classification models on 87 datasets to generate a large-scale meta-dataset. We meta-learn a multi-fidelity performance predictor on the learning curves of this meta-dataset and use it for fast hyperparameter optimization on new datasets. We empirically demonstrate that our resulting approach can quickly select an accurate pretrained model for a …",https://ui.adsabs.harvard.edu/abs/2023arXiv230603828P/abstract
Frank Hutter,Gray-Box Gaussian Processes for Automated Reinforcement Learning,2023,The Eleventh International Conference on Learning Representations,2,"Gresa Shala, André Biedenkapp, Frank Hutter, Josif Grabocka",Gresa Shala,Josif Grabocka,4,"Despite having achieved spectacular milestones in an array of important real-world applications, most Reinforcement Learning (RL) methods are very brittle concerning their hyperparameters. Notwithstanding the crucial importance of setting the hyperparameters in training state-of-the-art agents, the task of hyperparameter optimization (HPO) in RL is understudied. In this paper, we propose a novel gray-box Bayesian Optimization technique for HPO in RL, that enriches Gaussian Processes with reward curve estimations based on generalized logistic functions. In a very large-scale experimental protocol, comprising 5 popular RL methods (DDPG, A2C, PPO, SAC, TD3), dozens of environments (Atari, Mujoco), and 7 HPO baselines, we demonstrate that our method significantly outperforms current HPO practices in RL.",https://openreview.net/forum?id=rmoMvptXK7M
Frank Hutter,"Method, device and computer program for producing a strategy for a robot",2023,,2,"Frank Hutter, Lior Fuks, Marius Lindauer, Noor Awad",Frank Hutter,Noor Awad,4,"A method for producing a strategy for a robot. The method includes the following steps: initializing the strategy and an episode length; repeated execution of the loop including the following steps: producing a plurality of further strategies as a function of the strategy; applying the plurality of the further strategies for the length of the episode length; ascertaining respectively a cumulative reward, which is obtained in the application of the respective further strategy; updating the strategy as a function of a second plurality of the further strategies that obtained the greatest cumulative rewards. After each execution of the loop, the episode length is increased. A computer program, a device for carrying out the method, and a machine-readable memory element on which the computer program is stored, are also described.",https://patents.google.com/patent/US11628562B2/en
Frank Hutter,CAAFE: Combining Large Language Models with Tabular Predictors for Semi-Automated Data Science,2023,1st Workshop on the Synergy of Scientific and Machine Learning Modeling@ ICML2023,2,"Noah Hollmann, Samuel Müller, Frank Hutter",Noah Hollmann,Frank Hutter,3,"As the field of automated machine learning (AutoML) advances, it becomes increasingly important to incorporate domain knowledge into these systems. Our approach combines the advantages of classical ML classifiers (robustness, predictability and a level of interpretability) and LLMs (domain-knowledge and creativity). We introduce Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method for tabular datasets that utilizes an LLM to iteratively generate additional semantically meaningful features for tabular datasets based on the description of the dataset. The method produces both Python code for creating new features and explanations for the utility of the generated features. Despite being methodologically simple, CAAFE improves performance on 11 out of 14 datasets - boosting mean ROC AUC performance from 0.798 to 0.822 across all dataset - similar to the improvement achieved by using a random forest instead of logistic regression on our datasets. Furthermore, CAAFE is interpretable by providing a textual explanation for each generated feature. CAAFE paves the way for more extensive semi-automation in data science tasks and emphasizes the significance of context-aware solutions that can extend the scope of AutoML systems to semantic AutoML. We release our code, a simple demo and a python package.",https://openreview.net/forum?id=59TY0RW6Po
Frank Hutter,Device and computer-implemented method for the processing of digital sensor data and training method therefor,2022,,2,"Danny Oliver Stoll, Frank Hutter, Jan Hendrik Metzen, Thomas Elsken",Danny Oliver Stoll,Thomas Elsken,4,"A device, computer-implemented method for the processing of digital sensor data and training methods therefor. A plurality of training tasks from a distribution of training tasks are provided, the training tasks characterizing the processing of digital sensor data. A parameter set for an architecture and for weights of an artificial neural network are determined with a first gradient-based learning algorithm and with a second gradient-based algorithm as a function of at least one first training task from the distribution of training tasks. The artificial neural network is trained with the first gradient-based learning algorithm as a function of the parameter set and as a function of a second training task.",https://patents.google.com/patent/US20220292349A1/en
Frank Hutter,Priorband: Hyperband+ human expert knowledge,2022,Sixth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems,2,"Neeratyoy Mallik, Carl Hvarfner, Danny Stoll, Maciej Janowski, Eddie Bergman, Marius Lindauer, Luigi Nardi, Frank Hutter",Neeratyoy Mallik,Frank Hutter,8,"Hyperparameters of Deep Learning (DL) pipelines are crucial for their performance. While a large number of methods for hyperparameter optimization (HPO) have been developed, they are misaligned with the desiderata of a modern DL researcher. Since often only a few trials are possible in the development of new DL methods, manual experimentation is still the most prevalent approach to set hyperparameters, relying on the researcher’s intuition and cheap preliminary explorations. To resolve this shortcoming of HPO for DL, we propose PriorBand, an HPO algorithm tailored to DL, able to utilize both expert beliefs and cheap proxy tasks. Empirically, we demonstrate the efficiency of PriorBand across a range of DL models and tasks using as little as the cost of 10 training runs and show its robustness against poor expert beliefs and misleading proxy tasks.",https://openreview.net/forum?id=ds21dwfBBH
Frank Hutter,In-loop meta-learning with gradient-alignment reward,2021,arXiv preprint arXiv:2102.03275,2,"Samuel Müller, André Biedenkapp, Frank Hutter",Samuel Müller,Frank Hutter,3,"At the heart of the standard deep learning training loop is a greedy gradient step minimizing a given loss. We propose to add a second step to maximize training generalization. To do this, we optimize the loss of the next training step. While computing the gradient for this generally is very expensive and many interesting applications consider non-differentiable parameters (e.g. due to hard samples), we present a cheap-to-compute and memory-saving reward, the gradient-alignment reward (GAR), that can guide the optimization. We use this reward to optimize multiple distributions during model training. First, we present the application of GAR to choosing the data distribution as a mixture of multiple dataset splits in a small scale setting. Second, we show that it can successfully guide learning augmentation strategies competitive with state-of-the-art augmentation strategies on CIFAR-10 and CIFAR-100.",https://arxiv.org/abs/2102.03275
Frank Hutter,Transferring optimality across data distributions via homotopy methods,2020,International Conference on Learning Representations,2,"Matilde Gargiani, Andrea Zanelli, Quoc Tran Dinh, Moritz Diehl, Frank Hutter",Matilde Gargiani,Frank Hutter,5,"Homotopy methods, also known as continuation methods, are a powerful mathematical tool to efficiently solve various problems in numerical analysis, including complex non-convex optimization problems where no or only little prior knowledge regarding the localization of the solutions is available.  In this work, we propose a novel homotopy-based numerical method that can be used to transfer knowledge regarding the localization of an optimum across different task distributions in deep learning applications. We validate the proposed methodology with some empirical evaluations in the regression and classification scenarios, where it shows that superior numerical performance can be achieved in popular deep learning benchmarks, i.e. FashionMNIST, CIFAR-10, and draw connections with the widely used fine-tuning heuristic. In addition, we give more insights on the properties of a general homotopy method when used in combination with Stochastic Gradient Descent by conducting a general local theoretical analysis in a simplified setting.",https://openreview.net/forum?id=S1gEIerYwH
Frank Hutter,Auto-WEKA: Automatic model selection and hyperparameter optimization in WEKA,2019,,2,"Lars Kotthoff, Chris Thornton, Holger H Hoos, Frank Hutter, Kevin Leyton-Brown",Lars Kotthoff,Kevin Leyton-Brown,5,,
Frank Hutter,P64. Deep learning for EEG diagnostics,2018,Clinical Neurophysiology,2,"RT Schirrmeister, L Gemein, K Eggensberger, F Hutter, T Ball",RT Schirrmeister,T Ball,5,"Machine learning as a tool for medical diagnostics is gaining increasing interest. For example, a deep convolutional neural network (deep ConvNets) performed at least as well as dermatologists in the diagnosis of different types of skin cancer from images and another deep ConvNet segmented retinal vessels better than human annotators. Therefore, we investigated the potential of deep ConvNets for diagnosis from electroencephalography (EEG) recordings. We used two recently proposed ConvNet architectures that were shown to decode task-related information from EEG at least as well as other established machine learning methods. The ConvNets were trained to distinguish pathological and normal EEG recordings in the Temple University Hospital EEG Abnormal Corpus that contains about 3000 recordings from more than 10 years of clinical practice. The EEG recordings were labelled normal or …",https://www.sciencedirect.com/science/article/pii/S1388245718310095
Frank Hutter,Predicting runtime distributions using deep neural networks,2017,arXiv preprint arXiv:1709.07615,2,"Katharina Eggensperger, Marius Lindauer, Frank Hutter",Katharina Eggensperger,Frank Hutter,3,"Many state-of-the-art algorithms for solving hard combinatorial problems include elements of stochasticity that lead to high variations in runtime, even for a fixed problem instance, across runs with different pseudo-random number seeds. Knowledge about the runtime distributions (RTDs) of algorithms on given problem instances can be exploited in various meta-algorithmic procedures, such as algorithm selection, portfolios, and randomized restarts. Previous work has shown that machine learning can be used to individually predict mean, median and variance of RTDs. To establish a new state-of-the-art in predicting RTDs, we demonstrate that the parameters of an RTD should be learned jointly and that neural networks can do this well by directly optimizing the likelihood of an RTD given runtime observations. In an empirical study involving four algorithms for SAT solving and AI planning, we show that our neural networks predict the true RTDs of unseen instances better than previous methods. As an exemplary application of RTD predictions, we show that our RTD models also yield good predictions of running these algorithms in parallel.",https://scholar.google.com/scholar?cluster=7093564931769973624&hl=en&oi=scholarr
Frank Hutter,Asynchronous stochastic gradient MCMC with elastic coupling,2016,arXiv preprint arXiv:1612.00767,2,"Jost Tobias Springenberg, Aaron Klein, Stefan Falkner, Frank Hutter",Jost Tobias Springenberg,Frank Hutter,4,"We consider parallel asynchronous Markov Chain Monte Carlo (MCMC) sampling for problems where we can leverage (stochastic) gradients to define continuous dynamics which explore the target distribution. We outline a solution strategy for this setting based on stochastic gradient Hamiltonian Monte Carlo sampling (SGHMC) which we alter to include an elastic coupling term that ties together multiple MCMC instances. The proposed strategy turns inherently sequential HMC algorithms into asynchronous parallel versions. First experiments empirically show that the resulting parallel sampler significantly speeds up exploration of the target distribution, when compared to standard SGHMC, and is less prone to the harmful effects of stale gradients than a naive parallelization approach.",https://arxiv.org/abs/1612.00767
Frank Hutter,Online appendix for aij article “algorithm runtime prediction: Methods & evaluation”,2013,,2,"Frank Hutter, Lin Xu, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,4,"In this online appendix, we provide supplementary material for our AIJ article “Algorithm Runtime Prediction: Methods & Evaluation”. Specifically, we provide the proof of Proposition 1, details on ridge regression variant RR-el, details on the data used, and additional experimental results.",https://scholar.google.com/scholar?cluster=17528948886940331796&hl=en&oi=scholarr
Frank Hutter,An efficient approach for assessing parameter importance in bayesian optimization,2013,Proceedings of the NIPS workshop on Bayesian Optimization in Theory and Practice,2,"Frank Hutter, Holger H Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"We describe a method for quantifying the importance of a blackbox function’s input parameters and their interactions, based on function evaluations obtained by running a Bayesian optimization procedure. We focus on high-dimensional functions with mixed discrete/continuous as well as conditional inputs, and therefore employ random forest models. We derive the first exact and efficient approach for computing efficient marginal predictions over subsets of inputs in random forests, enabling an exact quantification of parameter importance in the functional ANOVA framework. We demonstrate these techniques by assessing the importance of parameters in several recent applications of Bayesian optimization.",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/13-BayesOpt_fANOVA.pdf
Frank Hutter,Automated Configuration of MIP solvers,,,2,"Frank Hutter, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,3,"Automated Configuration of MIP solvers Page 1 Automated Configuration of MIP solvers Frank 
Hutter, Holger Hoos, and Kevin Leyton-Brown Department of Computer Science University of 
British Columbia Vancouver, Canada {hutter,hoos,kevinlb}@cs.ubc.ca CPAIOR 2010, June 
16 Page 2 Parameters in Algorithms Most algorithms have parameters ▶ Decisions that are 
left open during algorithm design – numerical parameters (eg, real-valued thresholds) – 
categorical parameters (eg, which heuristic to use) ▶ Set to optimize empirical performance 
2 Page 3 Parameters in Algorithms Most algorithms have parameters ▶ Decisions that are 
left open during algorithm design – numerical parameters (eg, real-valued thresholds) – 
categorical parameters (eg, which heuristic to use) ▶ Set to optimize empirical performance 
Prominent parameters in MIP solvers ▶ Preprocessing ▶ Which type of cuts to apply ▶ MIP …",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/10-CPAIOR-MIP-Config-slides.pdf
Frank Hutter,Accurate predictions on small data with a tabular foundation model,2025,Nature,1,"Noah Hollmann, Samuel Müller, Lennart Purucker, Arjun Krishnakumar, Max Körfer, Shi Bin Hoo, Robin Tibor Schirrmeister, Frank Hutter",Noah Hollmann,Frank Hutter,8,"Tabular data, spreadsheets organized in rows and columns, are ubiquitous across scientific fields, from biomedicine to particle physics to economics and climate science,. The fundamental prediction task of filling in missing values of a label column based on the rest of the columns is essential for various applications as diverse as biomedical risk models, drug discovery and materials science. Although deep learning has revolutionized learning from raw data and led to numerous high-profile success stories, –, gradient-boosted decision trees, , – have dominated tabular data for the past 20 years. Here we present the Tabular Prior-data Fitted Network (TabPFN), a tabular foundation model that outperforms all previous methods on datasets with up to 10,000 samples by a wide margin, using substantially less training time. In 2.8 s, TabPFN outperforms an ensemble of the strongest baselines tuned for 4 h in a …",https://www.nature.com/articles/s41586-024-08328-6
Frank Hutter,The tabular foundation model TabPFN outperforms specialized time series forecasting models based on simple features,2025,arXiv preprint arXiv:2501.02945,1,"Shi Bin Hoo, Samuel Müller, David Salinas, Frank Hutter",Shi Bin Hoo,Frank Hutter,4,"Foundation models have become popular in forecasting due to their ability to make accurate predictions, even with minimal fine-tuning on specific datasets. In this paper, we demonstrate how the newly released regression variant of TabPFN, a general tabular foundation model, can be applied to time series forecasting. We propose a straightforward approach, TabPFN-TS, which pairs TabPFN with simple feature engineering to achieve strong forecasting performance. Despite its simplicity and with only 11M parameters, TabPFN-TS outperforms Chronos-Mini, a model of similar size, and matches or even slightly outperforms Chronos-Large, which has 65-fold more parameters. A key strength of our method lies in its reliance solely on artificial data during pre-training, avoiding the need for large training datasets and eliminating the risk of benchmark contamination.",https://arxiv.org/abs/2501.02945
Frank Hutter,Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues,2024,arXiv preprint arXiv:2411.12537,1,"Riccardo Grazzi, Julien Siems, Jörg KH Franke, Arber Zela, Frank Hutter, Massimiliano Pontil",Riccardo Grazzi,Massimiliano Pontil,6,"Linear Recurrent Neural Networks (LRNNs) such as Mamba, RWKV, GLA, mLSTM, and DeltaNet have emerged as efficient alternatives to Transformers in large language modeling, offering linear scaling with sequence length and improved training efficiency. However, LRNNs struggle to perform state-tracking which may impair performance in tasks such as code evaluation or tracking a chess game. Even parity, the simplest state-tracking task, which non-linear RNNs like LSTM handle effectively, cannot be solved by current LRNNs. Recently, Sarrof et al. (2024) demonstrated that the failure of LRNNs like Mamba to solve parity stems from restricting the value range of their diagonal state-transition matrices to  and that incorporating negative values can resolve this issue. We extend this result to non-diagonal LRNNs, which have recently shown promise in models such as DeltaNet. We prove that finite precision LRNNs with state-transition matrices having only positive eigenvalues cannot solve parity, while complex eigenvalues are needed to count modulo . Notably, we also prove that LRNNs can learn any regular language when their state-transition matrices are products of identity minus vector outer product matrices, each with eigenvalues in the range . Our empirical results confirm that extending the eigenvalue range of models like Mamba and DeltaNet to include negative values not only enables them to solve parity but consistently improves their performance on state-tracking tasks. Furthermore, pre-training LRNNs with an extended eigenvalue range for language modeling achieves comparable performance and stability while …",https://arxiv.org/abs/2411.12537
Frank Hutter,Drift-resilient tabPFN: In-context learning temporal distribution shifts on tabular data,2024,arXiv preprint arXiv:2411.10634,1,"Kai Helli, David Schnurr, Noah Hollmann, Samuel Müller, Frank Hutter",Kai Helli,Frank Hutter,5,"While most ML models expect independent and identically distributed data, this assumption is often violated in real-world scenarios due to distribution shifts, resulting in the degradation of machine learning model performance. Until now, no tabular method has consistently outperformed classical supervised learning, which ignores these shifts. To address temporal distribution shifts, we present Drift-Resilient TabPFN, a fresh approach based on In-Context Learning with a Prior-Data Fitted Network that learns the learning algorithm itself: it accepts the entire training dataset as input and makes predictions on the test set in a single forward pass. Specifically, it learns to approximate Bayesian inference on synthetic datasets drawn from a prior that specifies the model's inductive bias. This prior is based on structural causal models (SCM), which gradually shift over time. To model shifts of these causal models, we use a secondary SCM, that specifies changes in the primary model parameters. The resulting Drift-Resilient TabPFN can be applied to unseen data, runs in seconds on small to moderately sized datasets and needs no hyperparameter tuning. Comprehensive evaluations across 18 synthetic and real-world datasets demonstrate large performance improvements over a wide range of baselines, such as XGB, CatBoost, TabPFN, and applicable methods featured in the Wild-Time benchmark. Compared to the strongest baselines, it improves accuracy from 0.688 to 0.744 and ROC AUC from 0.786 to 0.832 while maintaining stronger calibration. This approach could serve as significant groundwork for further research on out-of-distribution prediction.",https://arxiv.org/abs/2411.10634
Frank Hutter,Machine learning for RNA design: Learna,2024,,1,"Frederic Runge, Frank Hutter",Frederic Runge,Frank Hutter,2,"Machine learning algorithms, and in particular deep learning approaches, have recently garnered attention in the field of molecular biology due to remarkable results. In this chapter, we describe machine learning approaches specifically developed for the design of RNAs, with a focus on the learna_tools Python package, a collection of automated deep reinforcement learning algorithms for secondary structure-based RNA design. We explain the basic concepts of reinforcement learning and its extension, automated reinforcement learning, and outline how these concepts can be successfully applied to the design of RNAs. The chapter is structured to guide through the usage of the different programs with explicit examples, highlighting particular applications of the individual tools.",https://link.springer.com/protocol/10.1007/978-1-0716-4079-1_5
Frank Hutter,AMLTK: A Modular Automl Toolkit in Python,2024,Journal of Open Source Software,1,"Edward Bergman, Matthias Feurer, Aron Bahram, Amir Rezaei Balef, Lennart Purucker, Sarah Segel, Marius Lindauer, Frank Hutter, Katharina Eggensperger",Edward Bergman,Katharina Eggensperger,9,"Machine Learning is a core building block in novel data-driven applications. Practitioners face many ambiguous design decisions while developing practical machine learning (ML) solutions. Automated machine learning (AutoML) facilitates the development of machine learning applications by providing efficient methods for optimizing hyperparameters, searching for neural architectures, or constructing whole ML pipelines (Hutter et al., 2019). Thereby, design decisions such as the choice of modelling, pre-processing, and training algorithm are crucial to obtaining well-performing solutions. By automatically obtaining ML solutions, AutoML aims to lower the barrier to leveraging machine learning and reduce the time needed to develop or adapt ML solutions for new domains or data.Highly performant software packages for automatically building ML pipelines given data, so-called AutoML systems, are available and can be used off-the-shelf. Typically, AutoML systems evaluate ML models sequentially to return a well-performing single best model or multiple models combined into an ensemble. Existing AutoML systems are typically highly engineered monolithic software developed for specific use cases to perform well and robustly under various conditions.",https://joss.theoj.org/papers/10.21105/joss.06367.pdf
Frank Hutter,Position: A Call to Action for a Human-Centered AutoML Paradigm,2024,arXiv preprint arXiv:2406.03348,1,"Marius Lindauer, Florian Karl, Anne Klier, Julia Moosbauer, Alexander Tornede, Andreas Mueller, Frank Hutter, Matthias Feurer, Bernd Bischl",Marius Lindauer,Bernd Bischl,9,"Automated machine learning (AutoML) was formed around the fundamental objectives of automatically and efficiently configuring machine learning (ML) workflows, aiding the research of new ML algorithms, and contributing to the democratization of ML by making it accessible to a broader audience. Over the past decade, commendable achievements in AutoML have primarily focused on optimizing predictive performance. This focused progress, while substantial, raises questions about how well AutoML has met its broader, original goals. In this position paper, we argue that a key to unlocking AutoML's full potential lies in addressing the currently underexplored aspect of user interaction with AutoML systems, including their diverse roles, expectations, and expertise. We envision a more human-centered approach in future AutoML research, promoting the collaborative design of ML systems that tightly integrates the complementary strengths of human expertise and AutoML methodologies.",https://arxiv.org/abs/2406.03348
Frank Hutter,HPO-RL-Bench: A zero-cost benchmark for HPO in reinforcement learning,2024,AutoML Conference 2024 (ABCD Track),1,"Gresa Shala, Sebastian Pineda Arango, André Biedenkapp, Frank Hutter, Josif Grabocka",Gresa Shala,Josif Grabocka,5,"Despite the undeniable importance of optimizing the hyperparameters of RL algorithms, existing state-of-the-art Hyperparameter Optimization (HPO) techniques are not frequently utilized by RL researchers. To catalyze HPO research in RL, we present a new large-scale benchmark that includes pre-computed reward curve evaluations of hyperparameter configurations for six established RL algorithms (PPO, DDPG, A2C, SAC, TD3, DQN) on 22 environments (Atari, Mujoco, Control), repeated for multiple seeds. We exhaustively computed the reward curves of all possible combinations of hyperparameters for the considered hyperparameter spaces for each RL algorithm in each environment. As a result, our benchmark permits zero-cost experiments for deploying and comparing new HPO methods. In addition, the benchmark offers a set of integrated HPO methods, enabling plug-and-play tuning of the hyperparameters of new RL algorithms, while pre-computed evaluations allow a zero-cost comparison of a new RL algorithm against the tuned RL baselines in our benchmark.",https://openreview.net/forum?id=MlB61zPAeR
Frank Hutter,Towards Generative RNA Design With Tertiary Interactions,2024,bioRxiv,1,"Sharat Patil, Frederic Runge, Jörg KH Franke, Frank Hutter",Sharat Patil,Frank Hutter,4,"The design of RNAs that fulfill desired functions is one of the major challenges in computational biology. The function of an RNA molecule depends on its structure and a strong structure-to-function relationship is already achieved on the secondary structure level of RNA. Therefore, computational RNA design is often interpreted as the inversion of a folding algorithm: Given a target secondary structure, find an RNA sequence that folds into the desired structure. However, existing RNA design approaches cannot invert state-of-the-art folding algorithms because they can only predict a limited set of base interactions. In this work, we propose RNAinformer, a novel generative transformer based approach to the inverse RNA folding problem. Leveraging axial attention, we are able to process secondary structures represented as adjacency matrices, which allows us to invert state-of-the-art folding algorithms. Consequently, RNAinformer is the first model capable of designing RNAs from secondary structures without base pair restrictions. We demonstrate RNAinformer’s strong performance across different RNA design benchmarks and showcase its novelty by inverting a state-of-the-art deep learning based secondary structure prediction algorithm.",https://www.biorxiv.org/content/10.1101/2024.03.09.584209.abstract
Frank Hutter,Quick-tune-tool: A practical tool and its user guide for automatically finetuning pretrained models,2024,AutoML Conference 2024 (Workshop Track),1,"Ivo Rapant, Lennart Purucker, Fabio Ferreira, Sebastian Pineda Arango, Arlind Kadra, Josif Grabocka, Frank Hutter",Ivo Rapant,Frank Hutter,7,"Pretrained models have become essential tools for machine learning practitioners across various domains including image classification, segmentation, and natural language processing. However, the complexity of selecting the appropriate pretrained model and finetuning strategy remains a significant challenge. In this paper, we present Quick-Tune-Tool, an automated solution to guide practitioners in selecting and finetuning pretrained models. Leveraging the Quick-Tune algorithm, Quick-Tune-Tool abstracts intricate research-level code into a user-friendly tool. Our contributions include the release of Quick-Tune-Tool, a detailed architectural overview, a user guide for image classification, and empirical evaluations. In experiments on four vision dataset, our results underscore the effectiveness and practicality of Quick-Tune-Tool for automating model selection and finetuning.",https://openreview.net/forum?id=d0Hapti3Uc
Frank Hutter,Towards Automated Design of Riboswitches,2023,arXiv preprint arXiv:2307.08801,1,"Frederic Runge, Jörg KH Franke, Frank Hutter",Frederic Runge,Frank Hutter,3,"Experimental screening and selection pipelines for the discovery of novel riboswitches are expensive, time-consuming, and inefficient. Using computational methods to reduce the number of candidates for the screen could drastically decrease these costs. However, existing computational approaches do not fully satisfy all requirements for the design of such initial screening libraries. In this work, we present a new method, libLEARNA, capable of providing RNA focus libraries of diverse variable-length qualified candidates. Our novel structure-based design approach considers global properties as well as desired sequence and structure features. We demonstrate the benefits of our method by designing theophylline riboswitch libraries, following a previously published protocol, and yielding 30% more unique high-quality candidates.",https://arxiv.org/abs/2307.08801
Frank Hutter,MO-DEHB: Evolutionary-based Hyperband for Multi-Objective Optimization,2023,arXiv preprint arXiv:2305.04502,1,"Noor Awad, Ayushi Sharma, Philipp Muller, Janek Thomas, Frank Hutter",Noor Awad,Frank Hutter,5,"Hyperparameter optimization (HPO) is a powerful technique for automating the tuning of machine learning (ML) models. However, in many real-world applications, accuracy is only one of multiple performance criteria that must be considered. Optimizing these objectives simultaneously on a complex and diverse search space remains a challenging task. In this paper, we propose MO-DEHB, an effective and flexible multi-objective (MO) optimizer that extends the recent evolutionary Hyperband method DEHB. We validate the performance of MO-DEHB using a comprehensive suite of 15 benchmarks consisting of diverse and challenging MO problems, including HPO, neural architecture search (NAS), and joint NAS and HPO, with objectives including accuracy, latency and algorithmic fairness. A comparative study against state-of-the-art MO optimizers demonstrates that MO-DEHB clearly achieves the best performance across our 15 benchmarks.",https://arxiv.org/abs/2305.04502
Frank Hutter,Method and device for learning a strategy and for implementing the strategy,2022,,1,"Steven Adriaenssen, Andre Biedenkapp, Frank Hutter, Gresa Shala, Marius Lindauer, Noor Awad",Steven Adriaenssen,Noor Awad,6,"G06Q—INFORMATION AND COMMUNICATION TECHNOLOGY [ICT] SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES; SYSTEMS OR METHODS SPECIALLY ADAPTED FOR ADMINISTRATIVE, COMMERCIAL, FINANCIAL, MANAGERIAL OR SUPERVISORY PURPOSES, NOT OTHERWISE PROVIDED FOR",https://patents.google.com/patent/US20220027743A1/en
Frank Hutter,Meta-Learning a Real-Time Tabular AutoML Method For Small Data.,2022,arXiv preprint arXiv:2207.01848,1,"Noah Hollmann, Samuel Müller, Katharina Eggensperger, Frank Hutter",Noah Hollmann,Frank Hutter,4,,https://scholar.google.com/scholar?cluster=17460992524045404744&hl=en&oi=scholarr
Frank Hutter,"reinforcement learning, autonomous agents, neural networks",2022,JOURNAL OF ARTIFICIAL INTELLIGENCE RESEARCH,1,"Jack Parker-Holder, Raghu Rajan, Xingyou Song, Andre Biedenkapp, Yingjie Miao, Theresa Eimer, Baohe Zhang, Vu Nguyen, Roberto Calandra, Aleksandra Faust, Frank Hutter, Marius Lindauer",Jack Parker-Holder,Marius Lindauer,12,"The combination of Reinforcement Learning (RL) with deep learning has led to a series of impressive feats, with many believing (deep) RL provides a path towards generally capable agents. However, the success of RL agents is often highly sensitive to design choices in the training process, which may require tedious and error-prone manual tuning. This makes it challenging to use RL for new problems and also limits its full potential. In many other areas of machine learning, AutoML has shown that it is possible to automate such design choices, and AutoML has also yielded promising initial results when applied to RL. However, Automated Reinforcement Learning (AutoRL) involves not only standard applications of AutoML but also includes additional challenges unique to RL, that naturally produce a different set of methods. As such, AutoRL has been emerging as an important area of research in RL, providing …",https://scholar.google.com/scholar?cluster=17512916668153911575&hl=en&oi=scholarr
Frank Hutter,"Method, device and computer program for predicting a suitable configuration of a machine learning system for a training data set",2021,,1,"Arber Zela, Frank Hutter, Julien Siems, Lucas Zimmer",Arber Zela,Lucas Zimmer,4,"A method for predicting a suitable configuration of a machine learning system for a first training data set. The method starts by training a plurality of machine learning systems on the first training data set, the machine learning systems and/or the training methods used being configured differently. This is followed by a creation of a second training data set including ascertained performances of the trained machine learning systems and the assigned configuration of the particular machine learning systems and/or training methods. This is followed by a training of a graph isomorphism network, depending on the second training data set, and a prediction in each case of the performance of a plurality of configurations not used for the training, with the aid of the GIN. A computer program and a device for carrying out the method and a machine-readable memory element, on which the computer program is stored, are also …",https://patents.google.com/patent/US20210264256A1/en
Frank Hutter,Method and device for ascertaining a network configuration of a neural network,2020,,1,"Thomas Elsken, Frank Hutter, Jan Hendrik Metzen",Thomas Elsken,Jan Hendrik Metzen,3,"A method for ascertaining a suitable network configuration for a neural network for a predefined application that is determined in the form of training data. The method includes: a) starting from an instantaneous network configu ration, generating multiple network configurations which differ in a portion of the instantaneous network configuration by applying approximate network morphisms; b) ascertain ing affected network portions of the network configurations; c) multiphase training of each of the network configurations to be evaluated, under predetermined training conditions, in a first phase, in each case network parameters of a portion that is not changed by applying the particular approximate network morphism remaining unconsidered during the train ing, and all network parameters being trained in at least one further phase, d) determining a resulting prediction error for each of the network configurations to be …",https://patents.google.com/patent/US20200410347A1/en
Frank Hutter,Mdp playground: Meta-features in reinforcement learning,2019,NeurIPS Deep RL Workshop,1,"Raghu Rajan, Frank Hutter",Raghu Rajan,Frank Hutter,2,"Reinforcement Learning (RL) algorithms usually do not try to identify specific features of environments which could help them perform better. Here, we present a few key meta-features of environments: delayed rewards, specific reward sequences, sparsity of rewards, and stochasticity of environments, adapting to which should help RL agents perform better. While it is very time consuming to run RL algorithms on standard benchmarks, we define a parameterised collection of fastto-run toy benchmarks in OpenAI Gym by varying these meta-features. Despite their toy nature and low compute requirements, we show that these benchmarks present substantial difficulties to current RL algorithms. Furthermore, since we can generate environments with a desired value for each of the meta-features, we have fine-grained control over the environments’ difficulty and also have the ground truth available for evaluating algorithms. We believe that devising algorithms that can detect such meta-features of environments and adapt to them will be key to creating robust RL algorithms that work in a variety of different real-world problems.",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/19-NeurIPS-Workshop-MDP_Playground.pdf
Frank Hutter,Summary of evolutionary computation for wind farm layout optimization,2018,,1,"Dennis G Wilson, Silvio Rodrigues, Carlos Segura, Ilya Loshchilov, Frank Hutter, Guillermo López Buenfil, Ahmed Kheiri, Ed Keedwell, Mario Ocampo-Pineda, Ender Özcan, Sergio Iwan Valdez Pea, Brian Goldman, Salvador Botello Rionda, Arturo Hernndez-Aguirre, Kalyan Veeramachaneni, Sylvain Cussat-Blanc",Dennis G Wilson,Sylvain Cussat-Blanc,16,"This paper presents the results of the second edition of the Wind Farm Layout Optimization Competition, which was held at the 22nd Genetic and Evolutionary Computation COnference (GECCO) in 2015. During this competition, competitors were tasked with optimizing the layouts of five generated wind farms based on a simplified cost of energy evaluation function of the wind farm layouts. Online and offline APIs were implemented in C++, Java, Matlab and Python for this competition to offer a common framework for the competitors. The top four approaches out of eight participating teams are presented in this paper and their results are compared. All of the competitors' algorithms use evolutionary computation.",https://dl.acm.org/doi/abs/10.1145/3205651.3208208
Frank Hutter,Hyperparameter optimization for machine learning problems in BCI,2016,"Proceedings of the 6th International Brain-Computer Interface Meeting: BCI Past, Present, and Future",1,"A Meinel, K Eggensperger, M Tangermann, F Hutter",A Meinel,F Hutter,4,"Introduction: Pipelines for BCI data analysis comprise several building blocks, such as signal preprocessing, feature extraction, decoding of features and output shaping for the BCI application at hand. These components contain many hyperparameters, such as frequency bands, time intervals, regularization factors, adaptation parameters, etc., which need to be chosen carefully in order to obtain optimal overall performance. As even simple BCI setups comprise tens of mutually dependent (discrete or continuous) hyperparameters, the search space is too large for a full grid search. Even though experts can tune most parameters based on experience, the inter-subject variability inherent to BCIs is likely to reward a subject-dependent optimization strategy.Material, Methods and Results: 20 healthy volunteers participated in a cued isometric force task of the hand (SVIPT,[1]) while EEG signals were recorded (64 passive channels, BrainAmp DC). A full setup is described in [2]. Comparable to a motor imagery processing pipeline, oscillatory EEG bandpower of a narrow frequency band within a (pre-trial) time interval was investigated. The analysis aimed at extracting supervised EEG subspaces (SPoC,[3]) which maximize the predictive squared correlation of their bandpower with continuous labels. The latter were obtained from a task-related motor performance metric. Overall, the processing pipeline comprised one nominal and three integer continuous hyperparameters resulting in 242,730 possible configurations. We investigated the performance and time requirements of four automatic methods for hyperparameter learning (SMAC [4], TPE [5 …",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/16-BCIMeeting-HypOpt.pdf
Frank Hutter,Automatic configuration of sequential planning portfolios: Generated portfolios,2014,,1,"Jendrik Seipp, Silvan Sievers, Malte Helmert, Frank Hutter",Jendrik Seipp,Frank Hutter,4,"Each portfolio is a sequence of< configuration, runtime> pairs, and our textual description in this report lists each such pair in its one paragraph. Each paragraph states the runtime (in seconds), followed by the configuration (in the form of Fast Downward command line options). The configurations are specified in the syntax of Fast Downward revision 767b52f0c0ea (http://fast-downward. org) For example, the portfolio for satisficing planning has 48 components, the first 4 of which are only run for one second each. The fourth configuration to be run uses enforced hill climbing search (ehc) with the STRIPS heuristic (goalcount) and assigns all operators their original costs (cost type= 0).",https://rlplab.com/papers/seipp-et-al-tr2014.pdf
Frank Hutter,Bayesian Optimization for More Automatic Machine Learning.,2014,MetaSel@ ECAI,1,Frank Hutter,Frank Hutter,Frank Hutter,1,"Bayesian optimization (see, eg,[2]) is a framework for the optimization of expensive blackbox functions that combines prior assumptions about the shape of a function with evidence gathered by evaluating the function at various points. In this talk, I will briefly describe the basics of Bayesian optimization and how to scale it up to handle structured high-dimensional optimization problems in the sequential model-based algorithm configuration framework SMAC [6]. Then, I will discuss applications of SMAC to two structured highdimensional optimization problems from the growing field of automatic machine learning:• Feature selection, learning algorithm selection, and optimization of its hyperparameters are crucial for achieving good performance in practical applications of machine learning. We demonstrate that a combined optimization over all of these choices can be carried out effectively by formulating the problem of finding a good instantiation of the popular WEKA framework as a 768-dimensional optimization problem. The resulting Auto-WEKA framework [7] allows non-experts with some available compute time to achieve state-of-the-art learning performance on the push of a button.• Deep learning has celebrated many recent successes, but its performance is known to be very sensitive to architectural choices and hyperparameter settings. Therefore, so far its potential could only be unleashed by deep learning experts. We formulated the combined problem of selecting the right neural network architecture and its associated hyperparameters as a 81-dimensional optimization problem and showed that an automated procedure could find a network …",https://www.academia.edu/download/84877796/MetaSel2014-complete.pdf#page=7
Frank Hutter,Manual for SMAC version v2. 06.01-master,2013,,1,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [2](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S.",https://aclib.net/SMAC/v2.06.01/manual.pdf
Frank Hutter,Configurable sat solver challenge 2014,2013,,1,"Frank Hutter, Adrian Balint",Frank Hutter,Adrian Balint,2,2. ResultsA performance is shown in boldface if it is significant better (according to a permutation test with 100 000 permutations and significance level α= 0.05).,https://aclib.net/cssc2014/cssc14-final.pdf
Frank Hutter,Quick start guide for ParamILS,2007,Department of Computer Science. University of British Columbia,1,Frank Hutter,Frank Hutter,Frank Hutter,1,"ParamILS is a tool for parameter optimization. It works for any parameterized algorithm whose parameters can be discretized. ParamILS searches through the space of possible parameter configurations, evaluating configurations by running the algorithm to be optimized on a set of benchmark instances. Users provide• a parametric algorithm A (executable to be called from the command line),• all parameters and their possible values (parameters need to be configurable from the command line), and• a set of benchmark problems, S.",https://www.cs.ubc.ca/labs/algorithms/Projects/ParamILS/ParamILS-Quickstart.pdf
Frank Hutter,A New SLS Algorithm for RNA Secondary Structure Design,2002,,1,"Mirela Andronescu, Anthony P Fejes, Firas Hamze, Frank Hutter, Holger H Hoos, Anne Condon",Mirela Andronescu,Anne Condon,6,"Ribonucleic acids (RNAs) are amongst the most important molecular components of all biological organisms. Similar to proteins, their function often depends crucially on their structure. Hence, computational methods for design of RNA molecules with specific structural properties are of considerable interest for biological and biomedical research. In this paper, we propose a new algorithm for the RNA Secondary Structure Design Problem: Given any RNA secondary structure, ie, a specification of base pairing interactions within an RNA strand, find an RNA strand that folds into this structure. This problem can be seen as a complex constraint satisfaction problem with interesting general properties. Our new stochastic local search (SLS) algorithm is based on a combination of problem-specific insights and state-of-the-art techniques for solving CSPs and other hard combinatorial problems. A thorough empirical …",https://scholar.google.com/scholar?cluster=1496392096554310146&hl=en&oi=scholarr
Frank Hutter,Preserving Principal Subspaces to Reduce Catastrophic Forgetting in Fine-tuning,,,1,"Jörg KH Franke, Michael Hefenbrock, Frank Hutter",Jörg KH Franke,Frank Hutter,3,"In this paper, we address catastrophic forgetting in fine-tuning Large Language Models (LLMs), a process where LLMs lose knowledge and capabilities upon learning new information. Traditional solutions mostly rely on reusing old training data. Such methods are often limited by knowledge about previously used data and possibly limited access to it. In contrast to these approaches, we propose a new strategy focusing on the model's weight matrices. Using Singular Value Decomposition (SVD), we seek to identify and preserve key components within these matrices, particularly the highest magnitude directions, to preserve the most sensitive characteristics. Our approach thus uniquely focuses updates on the space spanned by lower-impact directions. This methodology efficiently mitigates catastrophic forgetting and does not require access to the original training data, offering a more practical solution for LLM fine-tuning applications as it is simpler and more training data efficient. We show the benefit of our approach by fine-tuning an LLM and reducing the performance drop on benchmark tasks induced by fine-tuning.",https://openreview.net/forum?id=XoWtroECJU
Frank Hutter,Warmstarting for Scaling Language Models,2024,arXiv preprint arXiv:2411.07340,0,"Neeratyoy Mallik, Maciej Janowski, Johannes Hog, Herilalaina Rakotoarison, Aaron Klein, Josif Grabocka, Frank Hutter",Neeratyoy Mallik,Frank Hutter,7,"Scaling model sizes to scale performance has worked remarkably well for the current large language models paradigm. The research and empirical findings of various scaling studies led to novel scaling results and laws that guides subsequent research. High training costs for contemporary scales of data and models result in a lack of thorough understanding of how to tune and arrive at such training setups. One direction to ameliorate the cost of pretraining large models is to warmstart the large-scale training from smaller models that are cheaper to tune. In this work, we attempt to understand if the behavior of optimal hyperparameters can be retained under warmstarting for scaling. We explore simple operations that allow the application of theoretically motivated methods of zero-shot transfer of optimal hyperparameters using {\mu}Transfer. We investigate the aspects that contribute to the speedup in convergence and the preservation of stable training dynamics under warmstarting with {\mu}Transfer. We find that shrinking smaller model weights, zero-padding, and perturbing the resulting larger model with scaled initialization from {\mu}P enables effective warmstarting of $\mut{}$.",https://arxiv.org/abs/2411.07340
Frank Hutter,Transfer Learning for Finetuning Large Language Models,2024,arXiv preprint arXiv:2411.01195,0,"Tobias Strangmann, Lennart Purucker, Jörg KH Franke, Ivo Rapant, Fabio Ferreira, Frank Hutter",Tobias Strangmann,Frank Hutter,6,"As the landscape of large language models expands, efficiently finetuning for specific tasks becomes increasingly crucial. At the same time, the landscape of parameter-efficient finetuning methods rapidly expands. Consequently, practitioners face a multitude of complex choices when searching for an optimal finetuning pipeline for large language models. To reduce the complexity for practitioners, we investigate transfer learning for finetuning large language models and aim to transfer knowledge about configurations from related finetuning tasks to a new task. In this work, we transfer learn finetuning by meta-learning performance and cost surrogate models for grey-box meta-optimization from a new meta-dataset. Counter-intuitively, we propose to rely only on transfer learning for new datasets. Thus, we do not use task-specific Bayesian optimization but prioritize knowledge transferred from related tasks over task-specific feedback. We evaluate our method on eight synthetic question-answer datasets and a meta-dataset consisting of 1,800 runs of finetuning Microsoft's Phi-3. Our transfer learning is superior to zero-shot, default finetuning, and meta-optimization baselines. Our results demonstrate the transferability of finetuning to adapt large language models more effectively.",https://arxiv.org/abs/2411.01195
Frank Hutter,Ensembling Finetuned Language Models for Text Classification,2024,arXiv preprint arXiv:2410.19889,0,"Sebastian Pineda Arango, Maciej Janowski, Lennart Purucker, Arber Zela, Frank Hutter, Josif Grabocka",Sebastian Pineda Arango,Josif Grabocka,6,"Finetuning is a common practice widespread across different communities to adapt pretrained models to particular tasks. Text classification is one of these tasks for which many pretrained models are available. On the other hand, ensembles of neural networks are typically used to boost performance and provide reliable uncertainty estimates. However, ensembling pretrained models for text classification is not a well-studied avenue. In this paper, we present a metadataset with predictions from five large finetuned models on six datasets, and report results of different ensembling strategies from these predictions. Our results shed light on how ensembling can improve the performance of finetuned text classifiers and incentivize future adoption of ensembles in such tasks.",https://arxiv.org/abs/2410.19889
Frank Hutter,Large Language Models Engineer Too Many Simple Features for Tabular Data,2024,arXiv preprint arXiv:2410.17787,0,"Jaris Küken, Lennart Purucker, Frank Hutter",Jaris Küken,Frank Hutter,3,"Tabular machine learning problems often require time-consuming and labor-intensive feature engineering. Recent efforts have focused on using large language models (LLMs) to capitalize on their potential domain knowledge. At the same time, researchers have observed ethically concerning negative biases in other LLM-related use cases, such as text generation. These developments motivated us to investigate whether LLMs exhibit a bias that negatively impacts the performance of feature engineering. While not ethically concerning, such a bias could hinder practitioners from fully utilizing LLMs for automated data science. Therefore, we propose a method to detect potential biases by detecting anomalies in the frequency of operators (e.g., adding two features) suggested by LLMs when engineering new features. Our experiments evaluate the bias of four LLMs, two big frontier and two small open-source models, across 27 tabular datasets. Our results indicate that LLMs are biased toward simple operators, such as addition, and can fail to utilize more complex operators, such as grouping followed by aggregations. Furthermore, the bias can negatively impact the predictive performance when using LLM-generated features. Our results call for mitigating bias when using LLMs for feature engineering.",https://arxiv.org/abs/2410.17787
Frank Hutter,A Human-in-the-Loop Fairness-Aware Model Selection Framework for Complex Fairness Objective Landscapes,2024,"Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society",0,"Jake Robertson, Thorsten Schmidt, Frank Hutter, Noor Awad",Jake Robertson,Noor Awad,4,"Fairness-aware Machine Learning (FairML) applications are often characterized by complex social objectives and legal requirements, frequently involving multiple, potentially conflicting notions of fairness. Despite the well-known Impossibility Theorem of Fairness and extensive theoretical research on the statistical and socio-technical trade-offs between fairness metrics, many FairML tools still optimize or constrain for a single fairness objective. However, this one-sided optimization can inadvertently lead to violations of other relevant notions of fairness. In this socio-technical and empirical study, we frame fairness as a Many-Objective (MaO) problem by treating fairness metrics as conflicting objectives in a multi-objective (MO) sense. We introduce ManyFairHPO, a human-in-the-loop, fairness-aware model selection framework that enables practitioners to effectively navigate complex and nuanced fairness objective landscapes. ManyFairHPO aids in the identification, evaluation, and balancing of fairness metric conflicts and their related social consequences, leading to more informed and socially responsible model-selection decisions. Through a comprehensive empirical evaluation and a case study on the Law School Admissions problem, we demonstrate the effectiveness of ManyFairHPO in balancing multiple fairness objectives, mitigating risks such as self-fulfilling prophecies, and providing interpretable insights to guide stakeholders in making fairness-aware modeling decisions.",https://ojs.aaai.org/index.php/AIES/article/view/31719
Frank Hutter,Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models,2024,arXiv preprint arXiv:2410.09385,0,"Sathya Kamesh Bhethanabhotla, Omar Swelam, Julien Siems, David Salinas, Frank Hutter",Sathya Kamesh Bhethanabhotla,Frank Hutter,5,"This paper introduces Mamba4Cast, a zero-shot foundation model for time series forecasting. Based on the Mamba architecture and inspired by Prior-data Fitted Networks (PFNs), Mamba4Cast generalizes robustly across diverse time series tasks without the need for dataset specific fine-tuning. Mamba4Cast's key innovation lies in its ability to achieve strong zero-shot performance on real-world datasets while having much lower inference times than time series foundation models based on the transformer architecture. Trained solely on synthetic data, the model generates forecasts for entire horizons in a single pass, outpacing traditional auto-regressive approaches. Our experiments show that Mamba4Cast performs competitively against other state-of-the-art foundation models in various data sets while scaling significantly better with the prediction length. The source code can be accessed at https://github.com/automl/Mamba4Cast.",https://arxiv.org/abs/2410.09385
Frank Hutter,Large Language Model Compression with Neural Architecture Search,2024,arXiv preprint arXiv:2410.06479,0,"Rhea Sanjay Sukthanker, Benedikt Staffler, Frank Hutter, Aaron Klein",Rhea Sanjay Sukthanker,Aaron Klein,4,"Large language models (LLMs) exhibit remarkable reasoning abilities, allowing them to generalize across a wide range of downstream tasks, such as commonsense reasoning or instruction following. However, as LLMs scale, inference costs become increasingly prohibitive, accumulating significantly over their life cycle. This poses the question: Can we compress pre-trained LLMs to meet diverse size and latency requirements? We leverage Neural Architecture Search (NAS) to compress LLMs by pruning structural components, such as attention heads, neurons, and layers, aiming to achieve a Pareto-optimal balance between performance and efficiency. While NAS already achieved promising results on small language models in previous work, in this paper we propose various extensions that allow us to scale to LLMs. Compared to structural pruning baselines, we show that NAS improves performance up to 3.4% on MMLU with an on-device latency speedup.",https://arxiv.org/abs/2410.06479
Frank Hutter,GAMformer: In-Context Learning for Generalized Additive Models,2024,arXiv preprint arXiv:2410.04560,0,"Andreas Mueller, Julien Siems, Harsha Nori, David Salinas, Arber Zela, Rich Caruana, Frank Hutter",Andreas Mueller,Frank Hutter,7,"Generalized Additive Models (GAMs) are widely recognized for their ability to create fully interpretable machine learning models for tabular data. Traditionally, training GAMs involves iterative learning algorithms, such as splines, boosted trees, or neural networks, which refine the additive components through repeated error reduction. In this paper, we introduce GAMformer, the first method to leverage in-context learning to estimate shape functions of a GAM in a single forward pass, representing a significant departure from the conventional iterative approaches to GAM fitting. Building on previous research applying in-context learning to tabular data, we exclusively use complex, synthetic data to train GAMformer, yet find it extrapolates well to real-world data. Our experiments show that GAMformer performs on par with other leading GAMs across various classification benchmarks while generating highly interpretable shape functions.",https://arxiv.org/abs/2410.04560
Frank Hutter,Dynamic Post-Hoc Neural Ensemblers,2024,arXiv preprint arXiv:2410.04520,0,"Sebastian Pineda Arango, Maciej Janowski, Lennart Purucker, Arber Zela, Frank Hutter, Josif Grabocka",Sebastian Pineda Arango,Josif Grabocka,6,"Ensemble methods are known for enhancing the accuracy and robustness of machine learning models by combining multiple base learners. However, standard approaches like greedy or random ensembles often fall short, as they assume a constant weight across samples for the ensemble members. This can limit expressiveness and hinder performance when aggregating the ensemble predictions. In this study, we explore employing neural networks as ensemble methods, emphasizing the significance of dynamic ensembling to leverage diverse model predictions adaptively. Motivated by the risk of learning low-diversity ensembles, we propose regularizing the model by randomly dropping base model predictions during the training. We demonstrate this approach lower bounds the diversity within the ensemble, reducing overfitting and improving generalization capabilities. Our experiments showcase that the dynamic neural ensemblers yield competitive results compared to strong baselines in computer vision, natural language processing, and tabular data.",https://arxiv.org/abs/2410.04520
Frank Hutter,Bayes' Power for Explaining In-Context Learning Generalizations,2024,arXiv preprint arXiv:2410.01565,0,"Samuel Müller, Noah Hollmann, Frank Hutter",Samuel Müller,Frank Hutter,3,"Traditionally, neural network training has been primarily viewed as an approximation of maximum likelihood estimation (MLE). This interpretation originated in a time when training for multiple epochs on small datasets was common and performance was data bound; but it falls short in the era of large-scale single-epoch trainings ushered in by large self-supervised setups, like language models. In this new setup, performance is compute-bound, but data is readily available. As models became more powerful, in-context learning (ICL), i.e., learning in a single forward-pass based on the context, emerged as one of the dominant paradigms. In this paper, we argue that a more useful interpretation of neural network behavior in this era is as an approximation of the true posterior, as defined by the data-generating process. We demonstrate this interpretations' power for ICL and its usefulness to predict generalizations to previously unseen tasks. We show how models become robust in-context learners by effectively composing knowledge from their training data. We illustrate this with experiments that reveal surprising generalizations, all explicable through the exact posterior. Finally, we show the inherent constraints of the generalization capabilities of posteriors and the limitations of neural networks in approximating these posteriors.",https://arxiv.org/abs/2410.01565
Frank Hutter,Ensembling Finetuned Language Models for Text Classification,2024,arXiv e-prints,0,"Sebastian Pineda Arango, Maciej Janowski, Lennart Purucker, Arber Zela, Frank Hutter, Josif Grabocka",Sebastian Pineda Arango,Josif Grabocka,6,"Finetuning is a common practice widespread across different communities to adapt pretrained models to particular tasks. Text classification is one of these tasks for which many pretrained models are available. On the other hand, ensembles of neural networks are typically used to boost performance and provide reliable uncertainty estimates. However, ensembling pretrained models for text classification is not a well-studied avenue. In this paper, we present a metadataset with predictions from five large finetuned models on six datasets, and report results of different ensembling strategies from these predictions. Our results shed light on how ensembling can improve the performance of finetuned text classifiers and incentivize future adoption of ensembles in such tasks.",https://ui.adsabs.harvard.edu/abs/2024arXiv241019889P/abstract
Frank Hutter,Dynamic Post-Hoc Neural Ensemblers,2024,arXiv e-prints,0,"Sebastian Pineda Arango, Maciej Janowski, Lennart Purucker, Arber Zela, Frank Hutter, Josif Grabocka",Sebastian Pineda Arango,Josif Grabocka,6,"Ensemble methods are known for enhancing the accuracy and robustness of machine learning models by combining multiple base learners. However, standard approaches like greedy or random ensembles often fall short, as they assume a constant weight across samples for the ensemble members. This can limit expressiveness and hinder performance when aggregating the ensemble predictions. In this study, we explore employing neural networks as ensemble methods, emphasizing the significance of dynamic ensembling to leverage diverse model predictions adaptively. Motivated by the risk of learning low-diversity ensembles, we propose regularizing the model by randomly dropping base model predictions during the training. We demonstrate this approach lower bounds the diversity within the ensemble, reducing overfitting and improving generalization capabilities. Our experiments showcase that the …",https://ui.adsabs.harvard.edu/abs/2024arXiv241004520P/abstract
Frank Hutter,Mamba4Cast: Efficient Zero-Shot Time Series Forecasting with State Space Models,2024,arXiv e-prints,0,"Sathya Kamesh Bhethanabhotla, Omar Swelam, Julien Siems, David Salinas, Frank Hutter",Sathya Kamesh Bhethanabhotla,Frank Hutter,5,"This paper introduces Mamba4Cast, a zero-shot foundation model for time series forecasting. Based on the Mamba architecture and inspired by Prior-data Fitted Networks (PFNs), Mamba4Cast generalizes robustly across diverse time series tasks without the need for dataset specific fine-tuning. Mamba4Cast's key innovation lies in its ability to achieve strong zero-shot performance on real-world datasets while having much lower inference times than time series foundation models based on the transformer architecture. Trained solely on synthetic data, the model generates forecasts for entire horizons in a single pass, outpacing traditional auto-regressive approaches. Our experiments show that Mamba4Cast performs competitively against other state-of-the-art foundation models in various data sets while scaling significantly better with the prediction length. The source code can be accessed at https://github. com …",https://ui.adsabs.harvard.edu/abs/2024arXiv241009385K/abstract
Frank Hutter,LLM Compression with Neural Architecture Search,2024,arXiv e-prints,0,"Rhea Sanjay Sukthanker, Benedikt Staffler, Frank Hutter, Aaron Klein",Rhea Sanjay Sukthanker,Aaron Klein,4,"Large language models (LLMs) exhibit remarkable reasoning abilities, allowing them to generalize across a wide range of downstream tasks, such as commonsense reasoning or instruction following. However, as LLMs scale, inference costs become increasingly prohibitive, accumulating significantly over their life cycle. This poses the question: Can we compress pre-trained LLMs to meet diverse size and latency requirements? We leverage Neural Architecture Search (NAS) to compress LLMs by pruning structural components, such as attention heads, neurons, and layers, aiming to achieve a Pareto-optimal balance between performance and efficiency. While NAS already achieved promising results on small language models in previous work, in this paper we propose various extensions that allow us to scale to LLMs. Compared to structural pruning baselines, we show that NAS improves performance up to 3.4 …",https://ui.adsabs.harvard.edu/abs/2024arXiv241006479S/abstract
Frank Hutter,ARLBench: Flexible and Efficient Benchmarking for Hyperparameter Optimization in Reinforcement Learning,2024,arXiv preprint arXiv:2409.18827,0,"Jannis Becktepe, Julian Dierkes, Carolin Benjamins, Aditya Mohan, David Salinas, Raghu Rajan, Frank Hutter, Holger Hoos, Marius Lindauer, Theresa Eimer",Jannis Becktepe,Theresa Eimer,10,"Hyperparameters are a critical factor in reliably training well-performing reinforcement learning (RL) agents. Unfortunately, developing and evaluating automated approaches for tuning such hyperparameters is both costly and time-consuming. As a result, such approaches are often only evaluated on a single domain or algorithm, making comparisons difficult and limiting insights into their generalizability. We propose ARLBench, a benchmark for hyperparameter optimization (HPO) in RL that allows comparisons of diverse HPO approaches while being highly efficient in evaluation. To enable research into HPO in RL, even in settings with low compute resources, we select a representative subset of HPO tasks spanning a variety of algorithm and environment combinations. This selection allows for generating a performance profile of an automated RL (AutoRL) method using only a fraction of the compute previously necessary, enabling a broader range of researchers to work on HPO in RL. With the extensive and large-scale dataset on hyperparameter landscapes that our selection is based on, ARLBench is an efficient, flexible, and future-oriented foundation for research on AutoRL. Both the benchmark and the dataset are available at https://github.com/automl/arlbench.",https://arxiv.org/abs/2409.18827
Frank Hutter,One-shot World Models Using a Transformer Trained on a Synthetic Prior,2024,arXiv preprint arXiv:2409.14084,0,"Fabio Ferreira, Moreno Schlageter, Raghu Rajan, André Biedenkapp, Frank Hutter",Fabio Ferreira,Frank Hutter,5,"A World Model is a compressed spatial and temporal representation of a real world environment that allows one to train an agent or execute planning methods. However, world models are typically trained on observations from the real world environment, and they usually do not enable learning policies for other real environments. We propose One-Shot World Model (OSWM), a transformer world model that is learned in an in-context learning fashion from purely synthetic data sampled from a prior distribution. Our prior is composed of multiple randomly initialized neural networks, where each network models the dynamics of each state and reward dimension of a desired target environment. We adopt the supervised learning procedure of Prior-Fitted Networks by masking next-state and reward at random context positions and query OSWM to make probabilistic predictions based on the remaining transition context. During inference time, OSWM is able to quickly adapt to the dynamics of a simple grid world, as well as the CartPole gym and a custom control environment by providing 1k transition steps as context and is then able to successfully train environment-solving agent policies. However, transferring to more complex environments remains a challenge, currently. Despite these limitations, we see this work as an important stepping-stone in the pursuit of learning world models purely from synthetic data.",https://arxiv.org/abs/2409.14084
Frank Hutter,Efficient Search for Customized Activation Functions with Gradient Descent,2024,arXiv preprint arXiv:2408.06820,0,"Lukas Strack, Mahmoud Safari, Frank Hutter",Lukas Strack,Frank Hutter,3,"Different activation functions work best for different deep learning models. To exploit this, we leverage recent advancements in gradient-based search techniques for neural architectures to efficiently identify high-performing activation functions for a given application. We propose a fine-grained search cell that combines basic mathematical operations to model activation functions, allowing for the exploration of novel activations. Our approach enables the identification of specialized activations, leading to improved performance in every model we tried, from image classification to language models. Moreover, the identified activations exhibit strong transferability to larger models of the same type, as well as new datasets. Importantly, our automated process for creating customized activation functions is orders of magnitude more efficient than previous approaches. It can easily be applied on top of arbitrary deep learning pipelines and thus offers a promising practical avenue for enhancing deep learning architectures.",https://arxiv.org/abs/2408.06820
Frank Hutter,LMEMs for post-hoc analysis of HPO Benchmarking,2024,arXiv preprint arXiv:2408.02533,0,"Anton Geburek, Neeratyoy Mallik, Danny Stoll, Xavier Bouthillier, Frank Hutter",Anton Geburek,Frank Hutter,5,"The importance of tuning hyperparameters in Machine Learning (ML) and Deep Learning (DL) is established through empirical research and applications, evident from the increase in new hyperparameter optimization (HPO) algorithms and benchmarks steadily added by the community. However, current benchmarking practices using averaged performance across many datasets may obscure key differences between HPO methods, especially for pairwise comparisons. In this work, we apply Linear Mixed-Effect Models-based (LMEMs) significance testing for post-hoc analysis of HPO benchmarking runs. LMEMs allow flexible and expressive modeling on the entire experiment data, including information such as benchmark meta-features, offering deeper insights than current analysis practices. We demonstrate this through a case study on the PriorBand paper's experiment data to find insights not reported in the original work.",https://arxiv.org/abs/2408.02533
Frank Hutter,FairPFN: Transformers Can do Counterfactual Fairness,2024,arXiv preprint arXiv:2407.05732,0,"Jake Robertson, Noah Hollmann, Noor Awad, Frank Hutter",Jake Robertson,Frank Hutter,4,"Machine Learning systems are increasingly prevalent across healthcare, law enforcement, and finance but often operate on historical data, which may carry biases against certain demographic groups. Causal and counterfactual fairness provides an intuitive way to define fairness that closely aligns with legal standards. Despite its theoretical benefits, counterfactual fairness comes with several practical limitations, largely related to the reliance on domain knowledge and approximate causal discovery techniques in constructing a causal model. In this study, we take a fresh perspective on counterfactually fair prediction, building upon recent work in in context learning (ICL) and prior fitted networks (PFNs) to learn a transformer called FairPFN. This model is pretrained using synthetic fairness data to eliminate the causal effects of protected attributes directly from observational data, removing the requirement of access to the correct causal model in practice. In our experiments, we thoroughly assess the effectiveness of FairPFN in eliminating the causal impact of protected attributes on a series of synthetic case studies and real world datasets. Our findings pave the way for a new and promising research area: transformers for causal and counterfactual fairness.",https://arxiv.org/abs/2407.05732
Frank Hutter,Fast Optimizer Benchmark,2024,arXiv preprint arXiv:2406.18701,0,"Simon Blauth, Tobias Bürger, Zacharias Häringer, Jörg Franke, Frank Hutter",Simon Blauth,Frank Hutter,5,"In this paper, we present the Fast Optimizer Benchmark (FOB), a tool designed for evaluating deep learning optimizers during their development. The benchmark supports tasks from multiple domains such as computer vision, natural language processing, and graph learning. The focus is on convenient usage, featuring human-readable YAML configurations, SLURM integration, and plotting utilities. FOB can be used together with existing hyperparameter optimization (HPO) tools as it handles training and resuming of runs. The modular design enables integration into custom pipelines, using it simply as a collection of tasks. We showcase an optimizer comparison as a usage example of our tool. FOB can be found on GitHub: https://github.com/automl/FOB.",https://arxiv.org/abs/2406.18701
Frank Hutter,Fast Benchmarking of Asynchronous Multi-Fidelity Optimization on Zero-Cost Benchmarks,2024,arXiv preprint arXiv:2403.01888,0,"Shuhei Watanabe, Neeratyoy Mallik, Edward Bergman, Frank Hutter",Shuhei Watanabe,Frank Hutter,4,"While deep learning has celebrated many successes, its results often hinge on the meticulous selection of hyperparameters (HPs). However, the time-consuming nature of deep learning training makes HP optimization (HPO) a costly endeavor, slowing down the development of efficient HPO tools. While zero-cost benchmarks, which provide performance and runtime without actual training, offer a solution for non-parallel setups, they fall short in parallel setups as each worker must communicate its queried runtime to return its evaluation in the exact order. This work addresses this challenge by introducing a user-friendly Python package that facilitates efficient parallel HPO with zero-cost benchmarks. Our approach calculates the exact return order based on the information stored in file system, eliminating the need for long waiting times and enabling much faster HPO evaluations. We first verify the correctness of our approach through extensive testing and the experiments with 6 popular HPO libraries show its applicability to diverse libraries and its ability to achieve over 1000x speedup compared to a traditional approach. Our package can be installed via pip install mfhpo-simulator.",https://arxiv.org/abs/2403.01888
Frank Hutter,KinPFN: Bayesian Approximation of RNA Folding Kinetics using Prior-Data Fitted Networks,2024,bioRxiv,0,"Dominik Scheuer, Frederic Runge, Joerg KH Franke, Michael T Wolfinger, Christoph Flamm, Frank Hutter",Dominik Scheuer,Frank Hutter,6,"RNA is a dynamic biomolecule crucial for cellular regulation, with its function largely determined by its folding into complex structures, while misfolding can lead to multifaceted biological sequelae. During the folding process, RNA traverses through a series of intermediate structural states, with each transition occurring at variable rates that collectively influence the time required to reach the functional form. Understanding these folding kinetics is vital for predicting RNA behavior and optimizing applications in synthetic biology and drug discovery. While in silico kinetic RNA folding simulators are often computationally intensive and time-consuming, accurate approximations of the folding times can already be very informative to assess the efficiency of the folding process. In this work, we present KinPFN, a novel approach that leverages prior-data fitted networks to directly model the posterior predictive distribution of RNA folding times. By training on synthetic data representing arbitrary prior folding times, KinPFN efficiently approximates the cumulative distribution function of RNA folding times in a single forward pass, given only a few initial folding time examples. Our method offers a modular extension to existing RNA kinetics algorithms, promising significant computational speed-ups orders of magnitude faster, while achieving comparable results. We showcase the effectiveness of KinPFN through extensive evaluations and real-world case studies, demonstrating its potential for RNA folding kinetics analysis, its practical relevance, and generalization to other biological data.",https://www.biorxiv.org/content/10.1101/2024.10.15.618378.abstract
Frank Hutter,RNA-Protein Interaction Classification via Sequence Embeddings,2024,bioRxiv,0,"Dominika Matus, Frederic Runge, Jörg KH Franke, Lars Gerne, Michael Uhl, Rolf Backofen, Frank Hutter",Dominika Matus,Frank Hutter,7,"RNA-protein interactions (RPI) are ubiquitous in cellular organisms and essential for gene regulation. In particular, protein interactions with non-coding RNAs (ncRNAs) play a critical role in these processes. Experimental analysis of RPIs is time-consuming and expensive, and existing computational methods rely on small and limited datasets. This work introduces RNAInterAct, a comprehensive RPI dataset, alongside RPIembeddor, a novel transformer-based model designed for classifying ncRNA-protein interactions. By leveraging two foundation models for sequence embedding, we incorporate essential structural and functional insights into our task. We demonstrate RPIembeddor's strong performance and generalization capability compared to state-of-the-art methods across different datasets and analyze the impact of the proposed embedding strategy on the performance in an ablation study.",https://www.biorxiv.org/content/10.1101/2024.11.08.622607.abstract
Frank Hutter,Method for training a machine learning algorithm taking into account at least one inequality constraint,2023,,0,"Frank Hutter, Suhei Watanabe",Frank Hutter,Suhei Watanabe,2,"A method for training a machine learning algorithm taking into account at least one inequality constraint. Each of the at least one inequality constraint represents a secondary constraint. The method includes: optimizing hyperparameters for the machine learning algorithm by applying a tree-structured Parzen estimator, wherein the tree-structured Parzen estimator is based on an acquisition function adapted on the basis of the at least one inequality constraint; and training the machine learning algorithm on the basis of the optimized hyperparameters.",https://patents.google.com/patent/US20230334371A1/en
Frank Hutter,Hard View Selection for Contrastive Learning,2023,arXiv preprint arXiv:2310.03940,0,"Fabio Ferreira, Ivo Rapant, Frank Hutter",Fabio Ferreira,Frank Hutter,3,"Many Contrastive Learning (CL) methods train their models to be invariant to different ""views"" of an image input for which a good data augmentation pipeline is crucial. While considerable efforts were directed towards improving pre-text tasks, architectures, or robustness (e.g., Siamese networks or teacher-softmax centering), the majority of these methods remain strongly reliant on the random sampling of operations within the image augmentation pipeline, such as the random resized crop or color distortion operation. In this paper, we argue that the role of the view generation and its effect on performance has so far received insufficient attention. To address this, we propose an easy, learning-free, yet powerful Hard View Selection (HVS) strategy designed to extend the random view generation to expose the pretrained model to harder samples during CL training. It encompasses the following iterative steps: 1) randomly sample multiple views and create pairs of two views, 2) run forward passes for each view pair on the currently trained model, 3) adversarially select the pair yielding the worst loss, and 4) run the backward pass with the selected pair. In our empirical analysis we show that under the hood, HVS increases task difficulty by controlling the Intersection over Union of views during pretraining. With only 300-epoch pretraining, HVS is able to closely rival the 800-epoch DINO baseline which remains very favorable even when factoring in the slowdown induced by the additional forwards of HVS. Additionally, HVS consistently achieves accuracy improvements on ImageNet between 0.55% and 1.9% on linear evaluation and similar improvements …",https://arxiv.org/abs/2310.03940
Frank Hutter,Hard View Selection for Self-Supervised Learning,2023,arXiv e-prints,0,"Fabio Ferreira, Ivo Rapant, Frank Hutter",Fabio Ferreira,Frank Hutter,3,"Many Self-Supervised Learning (SSL) methods train their models to be invariant to different"" views"" of an image input for which a good data augmentation pipeline is crucial. While considerable efforts were directed towards improving pre-text tasks, architectures, or robustness (eg, Siamese networks or teacher-softmax centering), the majority of these methods remain strongly reliant on the random sampling of operations within the image augmentation pipeline, such as the random resized crop or color distortion operation. In this paper, we argue that the role of the view generation and its effect on performance has so far received insufficient attention. To address this, we propose an easy, learning-free, yet powerful Hard View Selection (HVS) strategy designed to extend the random view generation to expose the pretrained model to harder samples during SSL training. It encompasses the following iterative steps: 1 …",https://ui.adsabs.harvard.edu/abs/2023arXiv231003940F/abstract
Frank Hutter,Method and device for determining an optimal architecture of a neural network,2023,,0,"Danny Stoll, Frank Hutter, Simon Schrodi",Danny Stoll,Simon Schrodi,3,"A method for determining an optimal architecture of a neural network. The method includes: defining a search space by means of a context-free grammar; training neural networks with candidate architectures on the training data, and validating the trained neural networks on the validation data; initializing a Gaussian process, wherein the Gaussian process comprises a Weisfeiler-Lehman graph kernel; adapting the Gaussian process such that given the candidate architectures, the Gaussian process predicts the validation achieved with these candidate architectures; and performing a Bayesian optimization for finding the candidate architecture that achieved the best performance.",https://patents.google.com/patent/US20230306265A1/en
Frank Hutter,Mind the Gap: Measuring Generalization Performance Across Multiple Objectives,2023,"Advances in Intelligent Data Analysis XXI: 21st International Symposium on Intelligent Data Analysis, IDA 2023, Louvain-la-Neuve, Belgium, April 12–14, 2023, Proceedings",0,"Florian Pfisterer, Bernd Bischl, Frank Hutter",Florian Pfisterer,Frank Hutter,3,"Modern machine learning models are often constructed taking into account multiple objectives, eg, minimizing inference time while also maximizing accuracy. Multi-objective hyperparameter optimization (MHPO) algorithms return such candidate models, and the approximation of the Pareto front is used to assess their performance. In practice, we also want to measure generalization when moving from the validation to the test set. However, some of the models might no longer be Pareto-optimal which makes it unclear how to quantify the performance of the MHPO method when evaluated on the test set. To resolve this, we provide a novel evaluation protocol that allows measuring the generalization performance of MHPO methods and studying its capabilities for comparing two optimization experiments.",https://books.google.com/books?hl=en&lr=&id=UyG3EAAAQBAJ&oi=fnd&pg=PA130&dq=info:LcTZRb5TV4sJ:scholar.google.com&ots=2LU8UGr6Ae&sig=tFkJdrzNINtF-knCRt58rPiEzNY
Frank Hutter,New Horizons in Parameter Regularization: A Constraint Approach,2023,OPT 2023: Optimization for Machine Learning,0,"Jörg KH Franke, Michael Hefenbrock, Gregor Koehler, Frank Hutter",Jörg KH Franke,Frank Hutter,4,"This work presents constrained parameter regularization (CPR), an alternative to traditional weight decay. Instead of applying a constant penalty uniformly to all parameters, we enforce an upper bound on a statistical measure (e.g., the L2-norm) of individual parameter groups. This reformulates learning as a constrained optimization problem. To solve this, we utilize an adaptation of the augmented Lagrangian method. Our approach allows for varying regularization strengths across different parameter groups, removing the need for explicit penalty coefficients in the regularization terms. CPR only requires two hyperparameters and introduces no measurable runtime overhead. We offer empirical evidence of CPR's effectiveness through experiments in the ""grokking"" phenomenon, object detection, and language modeling. Our findings show that CPR can counteract the effects of grokking, and it consistently matches or surpasses the performance of traditional weight decay.",https://openreview.net/forum?id=AyzhPfICBX
Frank Hutter,PFNs Are Flexible Models for Real-World Bayesian Optimization,2023,CoRR,0,"Samuel Müller, Matthias Feurer, Noah Hollmann, Frank Hutter",Samuel Müller,Frank Hutter,4,"In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) through in-context learning on any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples …",https://openreview.net/forum?id=WuqJDwSd5C
Frank Hutter,Method and control device for generating training data for training a machine learning algorithm,2022,,0,"Frank Hutter, Samuel Gabriel Mueller",Frank Hutter,Samuel Gabriel Mueller,2,"A method for generating training data for training a machine learning algorithm. The method includes the following steps: providing first training data and generating additional training data from at least one portion of the first training data, wherein the additional training data are generated in each case by applying, to all the training data included in the at least one portion of the first training data, an augmentation function randomly selected from a set of possible augmen tation functions; providing the first training data and the additional training data for training the machine learning algorithm.",https://patents.google.com/patent/US20220351498A1/en
Frank Hutter,Method for training a neural network,2022,,0,"Ben Wilhelm, Frank Hutter, Matilde Gargiani",Ben Wilhelm,Matilde Gargiani,3,"A method for training a neural network, which includes a first number of layers. In the method, in a training sequence, which includes a plurality of training patterns, using a backpropagation algorithm, when applying the backpropagation algorithm during each of the plurality of training patterns, in each case a second number of layers of the neural network being disregarded, an absolute value of the second number being variable and being randomly selected before each of the number of training patterns under the condition that the absolute value is greater than or equal to zero and simultaneously smaller than an absolute value of the first number, and the second number of layers being an input layer of the neural network and layers of the neural network immediately following the input layer.",https://patents.google.com/patent/US20220327390A1/en
Frank Hutter,Training of machine learning systems for image processing,2022,,0,"Samuel Gabriel Mueller, Andre Biedenkapp, Frank Hutter",Samuel Gabriel Mueller,Frank Hutter,3,"(57) ABSTRACT A computer-implemented method for training a machine learning system including: initializing parameters of the machine learning system and a metaparameter. Repeatedly carrying out the following as a loop: providing a batch of training data points and manipulating the provided training data points or a training method for optimizing the param eters of the machine learning system or a structure of the machine learning system based on the metaparameter. Ascertaining a cost function as a function of instantaneous parameters of the machine learning system and of the instantaneous metaparameters. Adapting the instantaneous parameters as a function of an ascertained first gradient, which has been ascertained with respect to the instantaneous parameters via the ascertained cost function for the training data points, and adapting the metaparameter as a function of a second gradient, which has …",https://patents.google.com/patent/US20220230416A1/en
Frank Hutter,Device and method to improve reinforcement learning with synthetic environment,2022,,0,"Thomas Nierhoff, Fabio Ferreira, Frank Hutter",Thomas Nierhoff,Frank Hutter,3,"A computer-implemented method for learning a strategy and/or method for learning a synthetic environment. The strategy is configured to control an agent, and the method includes: providing synthetic environment parameters and a real environment and a population of strategies. Subsequently, repeating the following steps for a predetermined number of repetitions as a first loop: carrying out for each strategy of the population of strategies subsequent steps as a second loop: disturb the synthetic environment parameters with random noise; train for a first given number of step the strategy on the disturbed synthetic environment; evaluate the trained strategy on the real environment by determining rewards of the trained strategies; updating the synthetic environment parameters depending on the noise and the rewards. Finally, outputting the evaluated strategy with the highest reward on the real environment or with the …",https://patents.google.com/patent/US20220222493A1/en
Frank Hutter,"Method, device and computer program for creating a neural network",2022,,0,"Arber Zela, Frank Hutter, Thomas Brox, Tonmoy Saikia, Yassine Marrakchi",Arber Zela,Yassine Marrakchi,5,It is presently extremely difficult if not impossible to optimize an architecture of neural networks that include an encoder and a decoder. The conventional methods are unable to carry out this complex optimization within a reasonable period of time using only a graphic card (GPU).,https://patents.google.com/patent/US20220114446A1/en
Frank Hutter,Method and device for ascertaining an rna sequence,2022,,0,"Rolf Backofen, Frank Hutter, Frederic Runge",Rolf Backofen,Frederic Runge,3,(54) METHOD AND DEVICE FOR ASCERTAINING AN RNA SEQUENCE (52) US CI. CPC G16B 15/10 (2019.02),https://patents.google.com/patent/US20220051753A1/en
Frank Hutter,Method and device for creating a system for the automated creation of machine learning systems,2022,,0,"Marius Lindauer, Arber Zela, Danny Oliver Stoll, Fabio Ferreira, Frank Hutter, Thomas Nierhoff",Marius Lindauer,Thomas Nierhoff,6,METHOD AND DEVICE FOR CREATING A SYSTEM FOR THE AUTOMATED CREATION OF MACHINE LEARNING SYSTEMS,https://patents.google.com/patent/US20220012636A1/en
Frank Hutter,AutoML: Online course for automated machine learning: Abschlussbericht: AutoML-KI-Campus: Verbundvorhaben: AutoML: Teilvorhaben: Hyperparameter optimization and neural architecture search: Berichtszeitraum: 01.08. 2020-31.08. 2021,2022,,0,Frank Hutter,Frank Hutter,Frank Hutter,1,,https://scholar.google.com/scholar?cluster=8718101807718836779&hl=en&oi=scholarr
Frank Hutter,Device and method for planning an operation of a technical system,2021,,0,"Jonathan Spitz, Andre Biedenkapp, David Speck, Frank Hutter, Marius Lindauer, Robert Mattmueller",Jonathan Spitz,Robert Mattmueller,6,"Appl. No.: 17/242,790 (22) Filed: Apr. 28, 2021 (30) Foreign Application Priority Data",https://patents.google.com/patent/US20210383245A1/en
Frank Hutter,Multi-headed Neural Ensemble Search,2021,arXiv e-prints,0,"Ashwin Raaghav Narayanan, Arber Zela, Tonmoy Saikia, Thomas Brox, Frank Hutter",Ashwin Raaghav Narayanan,Frank Hutter,5,"Ensembles of CNN models trained with different seeds (also known as Deep Ensembles) are known to achieve superior performance over a single copy of the CNN. Neural Ensemble Search (NES) can further boost performance by adding architectural diversity. However, the scope of NES remains prohibitive under limited computational resources. In this work, we extend NES to multi-headed ensembles, which consist of a shared backbone attached to multiple prediction heads. Unlike Deep Ensembles, these multi-headed ensembles can be trained end to end, which enables us to leverage one-shot NAS methods to optimize an ensemble objective. With extensive empirical evaluations, we demonstrate that multi-headed ensemble search finds robust ensembles 3 times faster, while having comparable performance to other ensemble search methods, in both predictive performance and uncertainty calibration.",https://ui.adsabs.harvard.edu/abs/2021arXiv210704369R/abstract
Frank Hutter,Group Sparsity: A Unified Framework for Network Pruning and Neural Architecture Search,2021,CVPR2021-NAS: Computer Society Conference on Computer Vision and Pattern Recognition: Workshop on Neural Architecture Search,0,"Avraam Chatzimichailidis, Shalini Shalini Arber Zela, Peter Labus, Janis Keuper, Frank Hutter, Yang Yang",Avraam Chatzimichailidis,Yang Yang,6,We demonstrate how to exploit group sparsity in order to bridge the areas of network pruning and neural architecture search (NAS). This results in a new one-shot NAS optimizer that casts the problem as a single-level optimization problem and does not suffer any performance degradation from discretizating the architecture.,https://ml.informatik.uni-freiburg.de/wp-content/uploads/2022/03/Group_Sparsity.pdf
Frank Hutter,"Machine learning and knowledge discovery in databases, European Conference, ECML PKDD 2020, Proceedings, Part II",2021,European Conference on Machine Learning and Principles and Practices of Knowledge Discovery in Data,0,"Frank Hutter, Kristian Kersting, Jefrey Lijffijt, Isabel Valera",Frank Hutter,Isabel Valera,4,"Machine learning and knowledge discovery in databases, European Conference, ECML 
PKDD 2020, Proceedings, Part II Universiteit Gent Add publications and datasets Lists Sign in 
Academic Bibliography Search 200 years of publications by Ghent University researchers. 
Search publications and datasets Advanced search 1 file | 1.08 MB Download Download ""(...).pdf"" 
See all downloads Add to list 1.Search results 2.Machine learning and knowledge discov... 
Machine learning and knowledge discovery in databases, European Conference, ECML 
PKDD 2020, Proceedings, Part II Frank Hutter, Kristian Kersting, Jefrey Lijffijt (UGent) and 
Isabel Valera (2021) In Lecture notes in computer science 12458. Editor Frank Hutter, Kristian 
Kersting, Jefrey Lijffijt (UGent) and Isabel Valera Organization Department of Electronics and 
information systems Project Research Programme Artificial Intelligence - 2021 Downloads …",https://biblio.ugent.be/publication/8696195
Frank Hutter,The locality dilemma of Sankoff-like RNA alignments,2020,Bioinformatics,0,"Teresa Müller, Milad Miladi, Frank Hutter, Ivo Hofacker, Sebastian Will, Rolf Backofen",Teresa Müller,Rolf Backofen,6,"Elucidating the functions of non-coding RNAs by homology has been strongly limited due to fundamental computational and modeling issues. While existing simultaneous alignment and folding (SA&F) algorithms successfully align homologous RNAs with precisely known boundaries (global SA&F), the more pressing problem of identifying new classes of homologous RNAs in the genome (local SA&F) is intrinsically more difficult and much less understood. Typically, the length of local alignments is strongly overestimated and alignment boundaries are dramatically mispredicted. We hypothesize that local SA&F approaches are compromised this way due to a score bias, which is caused by the contribution of RNA structure similarity to their overall alignment score.In the light of this hypothesis, we study pairwise local SA&F for the first time systematically—based …",https://academic.oup.com/bioinformatics/article-abstract/36/Supplement_1/i242/5870506
Frank Hutter,João André Correia Carvalho,2019,,0,Frank Hutter,Frank Hutter,Frank Hutter,1,"Das Policy Gradient Theorem bietet eine Grundlage zur Lösung der Aufgabe des Reinforcement Learning durch die gradientenbasierte Optimierung einer parametrisierten und differenzierbaren Policy im Bezug auf eine Zielfunktion. Die Schätzung dieses Gradienten beinhaltet eine Erwartung über die durch die aktuelle Policy induzierte Zustandsverteilung, was ein anspruchsvolles Problem darstellt, da es eine Funktion der Dynamik der Umgebung ist. Im Allgemeinen ist diese nicht bekannt, weshalb eine Möglichkeit darin besteht, den Policy Gradient durch direkte Interaktion mit der Umwelt zu schätzen. Die Notwendigkeit ständiger Interaktionen ist einer der Gründe für die hohe Sample-Komplexität von Policy Gradient-Algorhythmen und warum sie ihre direkte Anwendung in der Robotik behindert. Off-Policy Reinforcement Learning adressiert dieses Problem, indem es bessere Exploration, höhere Dateneffizienz und die Fähigkeit, von Demonstrationen von anderen Agenten oder Menschen zu lernen. Diese Arbeit schlägt einen anderen Weg vor, um die Dateneffizienz von Off-Policy-Algorithmen zu verbessern, indem sie eine vollständige Gradientenschätzung liefert. Dazu konstruieren wir eine nichtparametrische Bellman Gleichung mit expliziter Abhängigkeit von den Policy Parametern mittels Kernel Density Estimation und Regression, um die Systemdynamik und die Belohnungsfunktion zu modellieren. Das Ergebnis ist ein Nonparametric Off-Policy Policy Gradient (NOPG) Algorithmus, mit dem die Value Function und Policy Gradient in geschlossener Form berechnet werden können. Wir liefern empirische Ergebnisse, die zeigen, dass NOPG …",https://www.ias.informatik.tu-darmstadt.de/uploads/Site/EditPublication/carvalho_master_thesis.pdf
Frank Hutter,Auto-WEKA: Automatic model selection and hyperparameter optimization in WEKA,2019,,0,"Lars Kotthoff, Chris Thornton, Holger H Hoos, Frank Hutter, Kevin Leyton-Brown",Lars Kotthoff,Kevin Leyton-Brown,5,,
Frank Hutter,Training Generative Reversible Networks,2018,arXiv e-prints,0,"Robin Tibor Schirrmeister, Patryk Chrabąszcz, Frank Hutter, Tonio Ball",Robin Tibor Schirrmeister,Tonio Ball,4,"Generative models with an encoding component such as autoencoders currently receive great interest. However, training of autoencoders is typically complicated by the need to train a separate encoder and decoder model that have to be enforced to be reciprocal to each other. To overcome this problem, by-design reversible neural networks (RevNets) had been previously used as generative models either directly optimizing the likelihood of the data under the model or using an adversarial approach on the generated data. Here, we instead investigate their performance using an adversary on the latent space in the adversarial autoencoder framework. We investigate the generative performance of RevNets on the CelebA dataset, showing that generative RevNets can generate coherent faces with similar quality as Variational Autoencoders. This first attempt to use RevNets inside the adversarial autoencoder …",https://ui.adsabs.harvard.edu/abs/2018arXiv180601610T/abstract
Frank Hutter,Generative Reversible Networks.,2018,CoRR,0,"Robin Tibor Schirrmeister, Patryk Chrabaszcz, Frank Hutter, Tonio Ball",Robin Tibor Schirrmeister,Tonio Ball,4,,https://scholar.google.com/scholar?cluster=2141621179356987470&hl=en&oi=scholarr
Frank Hutter,The Configurable SAT Solver Challenge,2017,,0,"Frank Hutter, Marius Lindauer, Adrian Balint, Sam Bayless, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,6,"Frank Hutter, Marius Lindauer, Adrian Balint, Sam Bayless, Holger Hoos & Kevin Leyton-Brown, 
The Configurable SAT Solver Challenge - PhilPapers Sign in | Create an account PhilPapers 
PhilPeople PhilArchive PhilEvents PhilJobs PhilPapers home Syntax Advanced Search New All 
new items Books Journal articles Manuscripts Topics All Categories Metaphysics and 
Epistemology Metaphysics and Epistemology Epistemology Metaphilosophy Metaphysics 
Philosophy of Action Philosophy of Language Philosophy of Mind Philosophy of Religion M&E, 
Misc Value Theory Value Theory Aesthetics Applied Ethics Meta-Ethics Normative Ethics 
Philosophy of Gender, Race, and Sexuality Philosophy of Law Social and Political Philosophy 
Value Theory, Miscellaneous Science, Logic, and Mathematics Science, Logic, and Mathematics 
Logic and Philosophy of Logic Philosophy of Biology Philosophy of Cognitive Science …",https://philpapers.org/rec/HUTTCS-4
Frank Hutter,User Guide for Auto-WEKA version 1.0.,2016,,0,"Lars Kotthoff, Chris Thornton, Frank Hutter",Lars Kotthoff,Frank Hutter,3,"Auto-WEKA is a tool that performs combined algorithm selection and hyperparmeter optimisation over the classification and regression algorithms implements in WEKA. More specifically, given a specific dataset, Auto-WEKA explores hyperparameter settings for many algorithms and recommends to a user which method will likely have good generalization performance, using model based optimisation techniques.",https://scholar.google.com/scholar?cluster=6571151165995878589&hl=en&oi=scholarr
Frank Hutter,Supplementary Material for Lessons learned from the NeurIPS 2021 MetaDL challenge: Backbone fine-tuning without episodic meta-learning dominates for few-shot learning image classification,2016,Feedback,0,"Adrian El Baz, Ihsan Ullah, Edesio Alcobaça, André CPLF Carvalho, Hong Chen, Fabio Ferreira, Henry Gouk, Chaoyu Guan, Isabelle Guyon, Timothy Hospedales, Shell Hu, Mike Huisman, Frank Hutter, Zhengying Liu, Felix Mohr, Ekrem Oztürk, Jan N van Rijn, Haozhe Sun, Xin Wang, Wenwu Zhu",Adrian El Baz,Wenwu Zhu,20,Adrian El Baz∗ eb. adrian8@ gmail. com Ihsan Ullah ihsan2131@ gmail. com Edesio Alcobaça e. alcobaca@ gmail. com André CPLF Carvalho andre@ icmc. usp. br Hong Chen h-chen20@ mails. tsinghua. edu. cn Fabio Ferreira ferreira@ cs. uni-freiburg. de Henry Gouk henry. gouk@ ed. ac. uk Chaoyu Guan guancy19@ mails. tsinghua. edu. cn Isabelle Guyon guyon@ chalearn. org Timothy Hospedales t. hospedales@ ed. ac. uk Shell Hu shell. hu@ samsung. com Mike Huisman m. huisman@ liacs. leidenuniv. nl Frank Hutter fh@ cs. uni-freiburg. de Zhengying Liu zhengying. liu@ inria. fr Felix Mohr felix. mohr@ unisabana. edu. co Ekrem Oztürk ozturk@ informatik. uni-freiburg. de Jan N. van Rijn jn van. rijn@ liacs. leidenuniv. nl Haozhe Sun haozhe. sun@ universite-paris-saclay. fr Xin Wang xin wang@ tsinghua. edu. cn Wenwu Zhu wwzhu@ tsinghua. edu. cn,https://proceedings.mlr.press/v176/el-baz22a/el-baz22a-supp.pdf
Frank Hutter,"AutoML 2016 Workshop Proceedings: Proceedings of the Workshop on Automatic Machine Learning, 24 June 2016, New York, New York, USA",2016,,0,"F Hutter, L Kotthoff, J Vanschoren",F Hutter,J Vanschoren,3,"AutoML 2016 Workshop Proceedings: Proceedings of the Workshop on Automatic Machine 
Learning, 24 June 2016, New York, New York, USA — Eindhoven University of Technology 
research portal Skip to main navigation Skip to search Skip to main content Eindhoven University 
of Technology research portal Home Eindhoven University of Technology research portal Logo 
Help & FAQ English Nederlands Home Researchers Research output Organisational Units 
Activities Projects Prizes Press/Media Facilities / Equipment Datasets Courses Research areas 
Student theses Search by expertise, name or affiliation AutoML 2016 Workshop Proceedings: 
Proceedings of the Workshop on Automatic Machine Learning, 24 June 2016, New York, 
New York, USA F. Hutter (Editor), L. Kotthoff (Editor), J. Vanschoren (Editor) Data Mining 
Research output: Book/Report › Book editing › Academic › peer-review Overview Original …",https://research.tue.nl/en/publications/automl-2016-workshop-proceedings-proceedings-of-the-workshop-on-a
Frank Hutter,Global and Instance-Based Hyperparameter Optimization for Large Displacement Optical Flow,2015,,0,"Eddy Ilg, Frank Hutter, Thomas Brox",Eddy Ilg,Thomas Brox,3,"Many methods in computer vision require some manually set parameters. Most often these “hyperparameters” are “hand-tuned” by the developer and not adjusted for different scenarios. This work presents an automatic approach to optimize the choice of different hyperparameters based on the data presented to the algorithm. In particular, features of images are computed and used to select parameters for Large Displacement Optical Flow by employing a learned mapping. For finding this mapping, Sequential Model-Based Optimization for General Algorithm Configuration is used.",https://scholar.google.com/scholar?cluster=8832633395828818835&hl=en&oi=scholarr
Frank Hutter,Supplementary material for: Initializing Bayesian Hyperparameter Optimization via Meta-Learning,2015,,0,"Matthias Feurer, Jost Tobias Springenberg, Frank Hutter",Matthias Feurer,Frank Hutter,3,"To evaluate our approach in a realistic setting we implemented 46 metafeatures from the literature listed in Table 1. 1 These metafeatures are computed only for the training set. While most of them can be computed for a whole dataset, some of them (eg, skewness) are defined for each attribute of a dataset. In this case, we compute the metafeature for each attribute of the dataset and use the mean, standard deviation, minimum and maximum of the resulting vector as proposed in Reif, Shafait, and Dengel (2012b). Since previous empirical results suggested that landmarking metafeatures are superior to other metafeatures (Pfahringer, Bensusan, and Giraud-Carrier 2000; Reif, Shafait, and Dengel 2011; 2012a), we experimented with using only the landmarking features used in the first experiment of Pfahringer, Bensusan, and Giraud-Carrier (2000). We also experimented with the subsets of metafeatures used in previous works on collaborative SMBO (Bardenet et al. 2013; Yogatama and Mann 2014). The exact subset are:",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/15-AAAI-MI-SMBO-supplementary.pdf
Frank Hutter,Bayesian optimization for more automatic machine learning (extended abstract for invited talk),2014,,0,Frank Hutter,Frank Hutter,Frank Hutter,1,"Bayesian optimization for more automatic machine learning (extended abstract for invited talk) 
| Proceedings of the 2014 International Conference on Meta-learning and Algorithm Selection - 
Volume 1201 skip to main content ACM Digital Library home ACM home Google, Inc. (search) 
Advanced Search Browse About Sign in Register Advanced Search Journals Magazines 
Proceedings Books SIGs Conferences People More Search ACM Digital Library SearchSearch 
Advanced Search Browse Browse Digital Library Collections More Home Browse by Title 
Proceedings MLAS'14 Bayesian optimization for more automatic machine learning (extended 
abstract for invited talk) Article Share on Bayesian optimization for more automatic machine 
learning (extended abstract for invited talk) Author: Frank Hutter University of Freiburg, 
Germany University of Freiburg, Germany View Profile Authors Info & Claims MLAS'14: …",https://dl.acm.org/doi/abs/10.5555/3015544.3015547
Frank Hutter,Manual for SMAC version v2. 08.00-master,2014,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [2](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.08.00/manual.pdf
Frank Hutter,Fast Downward Cedalion (IPC planner abstract),2014,,0,"Jendrik Seipp, Silvan Sievers, Frank Hutter",Jendrik Seipp,Frank Hutter,3,"Fast Downward Cedalion (IPC planner abstract) - edoc Logo edoc Home Policies About 
Statistics Contact Login Fast Downward Cedalion (IPC planner abstract) Seipp, Jendrik and 
Sievers, Silvan and Hutter, Frank. (2014) Fast Downward Cedalion (IPC planner abstract). 
Full text not available from this repository. Official URL: http://edoc.unibas.ch/42865/ 
Downloads: Statistics Overview Faculties and Departments: 05 Faculty of Science > 
Departement Mathematik und Informatik > Informatik > Artificial Intelligence (Helmert) 
UniBasel Contributors: Seipp, Jendrik and Sievers, Silvan Item Type: Other Number of 
Pages: 11 Note: Publication type according to Uni Basel Research Database: Other 
publications Last Modified: 04 May 2021 11:58 Deposited On: 04 May 2021 11:56 
Repository Staff Only: item control page edoc is powered by EPrints 3 which is developed 
by the School of Electronics and Computer Science at …",https://edoc.unibas.ch/42865/
Frank Hutter,FAQ for SMAC version v2. 06.01-master,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"Consult the logs, and see what error messages are recorded. In some cases you may have to turn on additional options such as--logAllProcessOutput, and see what information is available. If it’s not clear what the problem is consult the logs to determine the call string used (available from the logs), and try executing the target algorithm directly on the environment that it failed on. If direct execution fails, then the problem is specific to the target algorithm and/or your scenario options ie The algorithm executable cannot be found. Using the smac-algotest utility may make it easier to reproduce and diagnose the problem (see section 3.2).",https://aclib.net/SMAC/v2.06.01/faq.pdf
Frank Hutter,Quickstart Guide for SMAC version v2. 06.01-master,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [1](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S. The goal of this quickstart guide is to get you off the ground quickly; for more detailed information, please see the comprehensive manual.",https://aclib.net/SMAC/v2.06.01/quickstart.pdf
Frank Hutter,Quickstart Guide for SMAC version v2. 06.00-master,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [1](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S. The goal of this quickstart guide is to get you off the ground quickly; for more detailed information, please see the comprehensive manual.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.06.00/quickstart.pdf
Frank Hutter,Manual for SMAC version v2. 06.00-master,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [2](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.06.00/manual.pdf
Frank Hutter,Manual for SMAC version v2. 06.00 b-development,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [2](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.06.00b/manual.pdf
Frank Hutter,Quickstart Guide for SMAC version v2. 06.00 b-development,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [1](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S. The goal of this quickstart guide is to get you off the ground quickly; for more detailed information, please see the comprehensive manual.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.06.00b/quickstart.pdf
Frank Hutter,Manual for SMAC version v2. 04.02-master,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [2](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.04.02/manual.pdf
Frank Hutter,Manual for SMAC version v2. 04.01-master,2013,,0,"Frank Hutter, Steve Ramage",Frank Hutter,Steve Ramage,2,"This document is the manual for SMAC [2](an acronym for Sequential Model-based Algorithm Configuration). SMAC aims to solve the following algorithm configuration problem: Given a binary of a parameterized algorithm A, a set of instances S of the problem A solves, and a performance metric m, find parameter settings of A optimizing m across S.",https://www.cs.ubc.ca/labs/algorithms/Projects/SMAC/v2.04.01/manual.pdf
Frank Hutter,Reports on the Twenty-First National Conference on Artificial Intelligence (AAAI-06) Workshop Program,2006,AI Magazine,0,"Wolfgang Achtner, Esma Aimeur, Sarabjot Singh Anand, Doug Appelt, Naveen Ashish, Tiffany Barnes, Joseph E Beck, M Bernardine Dias, Prashant Doshi, Chris Drummond, William Elazmeh, Ariel Felner, Dayne Freitag, Hector Geffner, Christopher W Geib, Richard Goodwin, Robert C Holte, Frank Hutter, Fair Isaac, Nathalie Japkowicz, Gal A Kaminka, Sven Koenig, Michail G Lagoudakis, David B Leake, Lundy Lewis, Hugo Liu, Ted Metzler, Rada Mihalcea, Bamshad Mobasher, Pascal Poupart, David V Pynadath, Thomas Roth-Berghofer, Wheeler Ruml, Stefan Schulz, Sven Schwarz, Stephanie Seneff, Amit Sheth, Ron Sun, Michael Thielscher, Afzal Upal, Jason Williams, Steve Young, Dmitry Zelenko",Wolfgang Achtner,Dmitry Zelenko,43,"The Workshop program of the Twenty-First Conference on Artificial Intelligence was held July 16-17, 2006 in Boston, Massachusetts. The program was chaired by Joyce Chai and Keith Decker. The titles of the 17 workshops were AIDriven Technologies for Service-Oriented Computing; Auction Mechanisms for Robot Coordination; Cognitive Modeling and Agent-Based Social Simulations, Cognitive Robotics; Computational Aesthetics: Artificial Intelligence Approaches to Beauty and Happiness; Educational Data Mining; Evaluation Methods for Machine Learning; Event Extraction and Synthesis; Heuristic Search, Memory-Based Heuristics, and Their Applications; Human Implications of Human-Robot Interaction; Intelligent Techniques in Web Personalization; Learning for Search; Modeling and Retrieval of Context; Modeling Others from Observations; and Statistical and Empirical Approaches for Spoken Dialogue Systems.",https://ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1912
Frank Hutter,Drift-Resilient TabPFN: In-Context Learning Temporal Distribution Shifts on Tabular Data,,NeurIPS 2024 Third Table Representation Learning Workshop,0,"David Schnurr, Kai Helli, Noah Hollmann, Samuel Müller, Frank Hutter",David Schnurr,Frank Hutter,5,"While most ML models expect independent and identically distributed data, this assumption is often violated in real-world scenarios due to distribution shifts, resulting in the degradation of machine learning model performance. Until now, no tabular method has consistently outperformed classical supervised learning, which ignores these shifts. To address temporal distribution shifts, we present Drift-Resilient TabPFN, a fresh approach based on In-Context Learning with a Prior-Data Fitted Network that learns the learning algorithm itself: it accepts the entire training dataset as input and makes predictions on the test set in a single forward pass. Specifically, it learns to approximate Bayesian inference on synthetic datasets drawn from a prior that specifies the model's inductive bias. This prior is based on structural causal models (SCM), which gradually shift over time. To model shifts of these causal models, we use a secondary SCM, that specifies changes in the primary model parameters. The resulting Drift-Resilient TabPFN can be applied to unseen data, runs in seconds on small to moderately sized datasets and needs no hyperparameter tuning. Comprehensive evaluations across 18 synthetic and real-world datasets demonstrate large performance improvements over a wide range of baselines, such as XGB, CatBoost, TabPFN, and applicable methods featured in the Wild-Time benchmark. Compared to the strongest baselines, it improves accuracy from 0.688 to 0.744 and ROC AUC from 0.786 to 0.832 while maintaining stronger calibration. This approach could serve as significant groundwork for further research on out-of-distribution prediction.",https://openreview.net/forum?id=ud5YBKY1vJ
Frank Hutter,Improving Deep Learning Optimization through Constrained Parameter Regularization,,The Thirty-eighth Annual Conference on Neural Information Processing Systems,0,"Jörg KH Franke, Michael Hefenbrock, Gregor Koehler, Frank Hutter",Jörg KH Franke,Frank Hutter,4,"Regularization is a critical component in deep learning. The most commonly used approach, weight decay, applies a constant penalty coefficient uniformly across all parameters. This may be overly restrictive for some parameters, while insufficient for others. To address this, we present Constrained Parameter Regularization (CPR) as an alternative to traditional weight decay. Unlike the uniform application of a single penalty, CPR enforces an upper bound on a statistical measure, such as the L-norm, of individual parameter matrices. Consequently, learning becomes a constraint optimization problem, which we tackle using an adaptation of the augmented Lagrangian method. CPR introduces only a minor runtime overhead and only requires setting an upper bound. We propose simple yet efficient mechanisms for initializing this bound, making CPR rely on no hyperparameter or one, akin to weight decay. Our empirical studies on computer vision and language modeling tasks demonstrate CPR's effectiveness. The results show that CPR can outperform traditional weight decay and increase performance in pre-training and fine-tuning.",https://openreview.net/forum?id=rCXTkIhkbF
Frank Hutter,GAMformer: Exploring In-Context Learning for Generalized Additive Models,,NeurIPS 2024 Third Table Representation Learning Workshop,0,"Andreas C Mueller, Julien Siems, Harsha Nori, David Salinas, Arber Zela, Rich Caruana, Frank Hutter",Andreas C Mueller,Frank Hutter,7,"Generalized Additive Models (GAMs) are widely recognized for their ability to create fully interpretable machine learning models for tabular data. Traditionally, training GAMs involves iterative learning algorithms, such as splines, boosted trees, or neural networks, which refine the additive components through repeated error reduction. In this paper, we introduce GAMformer, the first method to leverage in-context learning to estimate shape functions of a GAM in a single forward pass, representing a significant departure from the conventional iterative approaches to GAM fitting. Building on previous research applying in-context learning to tabular data, we exclusively use complex, synthetic data to train GAMformer, yet find it to extrapolate well to real-world data. Our experiments show that GAMformer performs on par with other leading GAMs across various classification benchmarks while generating highly interpretable shape functions.",https://openreview.net/forum?id=W2CkzaqQnG
Frank Hutter,Towards Efficient Search for Customized Activation Functions With Gradient Descent,,AutoML Conference 2024 (Workshop Track),0,"Lukas Strack, Mahmoud Safari, Frank Hutter",Lukas Strack,Frank Hutter,3,"We leverage recent advancements in gradient-based search techniques for neural architectures to efficiently identify high-performing activation functions for a given application. We propose a fine-grained search cell that combines basic mathematical operations to model activation functions, allowing for the exploration of novel activations. Our approach enables the identification of specialized activations, leading to improved performance in every model we tried, from image classification to language models. Moreover, the identified activations exhibit strong transferability to larger models of the same type, as well as new datasets. Importantly, our automated process is orders of magnitude more efficient than previous approaches. It can easily be applied on top of arbitrary deep learning pipelines and thus offers a promising practical avenue for enhancing deep learning architectures.",https://openreview.net/forum?id=GDSrWrDYW3
Frank Hutter,LoRA-DARTS: Low Rank Adaptation for Differentiable Architecture Search,,AutoML Conference 2024 (Workshop Track),0,"Arjun Krishnakumar, Abhash Kumar Jha, Shakiba Moradian, Martin Rapp, Frank Hutter",Arjun Krishnakumar,Frank Hutter,5,"Gradient-based one-shot neural architecture search (NAS) methods, such as Differentiable Architecture Search (DARTS), have emerged as computationally feasible techniques to explore large search spaces. However, DARTS still suffers from failure modes, such as choosing architectures that prefer skip connections over learnable operations. In this work, we propose that the use of a low-rank adaptation (LoRA) of the weights of the candidate operations can address this failure mode without introducing new regularization terms or significant changes to the DARTS search technique. The code for our work is available at https://github.com/automl/LoRA-DARTS.",https://openreview.net/forum?id=YNyTumD0U9
Frank Hutter,Beyond Graph-Based Modeling for Hierarchical Neural Architecture Search,,AutoML Conference 2024 (Workshop Track),0,"Lum Birinxhiku, Danny Stoll, Simon Schrodi, Frank Hutter",Lum Birinxhiku,Frank Hutter,4,"Neural Architecture Search (NAS) seeks to automate the discovery of well-performing neural architectures. Recently, a hierarchical approach to NAS (hNAS) has been shown to allow for high search space expressiveness and efficient searching. However, BOHNAS, the current best strategy for hNAS requires the conversion of sampled networks from their native string representations to graphs, complicating the extension of hierarchical search spaces to include not only architectures, but also other pipeline components, such as hyperparameters, learning rate schedules and data augmentation. In this work, we introduce hNASK, a string kernel that operates on such string representations, is able to take advantage of the hierarchical structure of the search space and preserves the performance of BOHNAS on the performed architecture search experiments. As such, this kernel opens the door for future work in hNAS without being constrained to graph-based modeling of search spaces. Code is available at https://github.com/automl/hnas_with_string_kernels.",https://openreview.net/forum?id=gze7ISazsz
Frank Hutter,NOSBench-101: Towards Reproducible Neural Optimizer Search,,AutoML Conference 2024 (Workshop Track),0,"Goktug Karakasli, Steven Adriaensen, Frank Hutter",Goktug Karakasli,Frank Hutter,3,"Recent advances in neural network architecture and hardware have revolutionized deep learning and made it a pervasive technology. Nonetheless, it is crucial to acknowledge that the achievement of training neural networks with millions and billions of parameters would not have been feasible without the advancement of effective optimization techniques. This has motivated the search for new efficient optimization algorithms that can improve the performance of deep learning networks even more. Despite the considerable manual (re)search effort, few of these methods have found their way into deep learning practice. Recently, various researchers have explored different search methods to learn/discover novel optimizers in an automated way, but the associated computational costs and lack of a standardized evaluation protocol have hindered progress in this field. Motivated by the success of Neural Architecture Search (NAS), which benefits from established and compute-efficient benchmarks like NASBench, we introduce a benchmark called NOSBench that can be used to test different Neural Optimizer Search (NOS) methods on the same tasks. We compare different NOS methods on a Prior-Data Fitted Networks (PFNs) meta-training task and show that the optimizer found transfer to other PFN training tasks (e.g., TabPFN, LC-PFN, PFNs4BO). Our experiments show that the NOSBench provides a useful way to compare and contrast different approaches in this field efficiently by caching and identifying identical optimizers, which we believe can help researchers identify promising search strategies as they search for new optimizers automatically …",https://openreview.net/forum?id=5Lm2ghxMlp
Frank Hutter,From Epoch to Sample Size: Developing New Data-driven Priors for Learning Curve Prior-Fitted Networks,,AutoML Conference 2024 (Workshop Track),0,"Tom Julian Viering, Steven Adriaensen, Herilalaina Rakotoarison, Frank Hutter",Tom Julian Viering,Frank Hutter,4,"Learning Curve Prior-Fitted Networks (LC-PFNs) perform Bayesian learning curve extrapolation for epoch learning curves. This paper explores designing new priors for LC-PFNs, focusing on sample-size learning curves that relate training set size to performance. We use the Learning Curve Database (LCDB), which contains diverse learning curve data for machine learning models on tabular data, to develop two data-driven priors. The first method fits MMF4 and WBL4 parametric curve models to the LCDB and uses a Gaussian mixture model to represent the prior over parametric curve parameters. The second method directly trains the LCPFNs on the LCDB curves, which we call the Real Data LC-PFN. We set up a proper meta-learning curve extrapolation benchmark with cross-validation on the LCDB for a careful evaluation. We show that both proposed priors improve upon the original LC-PFN, with the Real Data LC-PFN providing best results, improving in 78\% of the experiments upon the old prior for extrapolating learning curves. Our study illustrates how to systematically design new priors for LC-PFN's in a metalearning framework, opening up their use for various curve modeling tasks in machine learning and beyond.",https://openreview.net/forum?id=neEKHQDTHV
Frank Hutter,CoordConformer: Heterogenous EEG datasets decoding using Transformers,,ICML 2024 Workshop on Geometry-grounded Representation Learning and Generative Modeling,0,"Sharat Patil, Robin Tibor Schirrmeister, Frank Hutter, Tonio Ball",Sharat Patil,Tonio Ball,4,"Transfer Learning and meta-learning have been effective in improving performance across multiple domains. It has also been applied successfully to EEG decoding where there is a lack of data. However, there are unique challenges for transfer learning with EEG data across datasets due to differences in experimental setup, like different numbers of electrodes, different positions of the electrodes, and different task definitions. To tackle the issue of cross-dataset training across heterogeneous electrode configuration EEG datasets we introduce a novel method, CoordinateAttention, that uses 3-D coordinates of the electrode sensors to learn the spatial relationship between the electrode's positions to dynamically generate spatial convolution kernels for feature extraction. We show that our model has good performance in EEG decoding across settings and is robust to data corruption. CoordinateAttention is a general-purpose method for feature extraction and data fusion using geometric positional information.",https://openreview.net/forum?id=RlYWwZXlsJ
Frank Hutter,A Retrospective on the CP 2006 paper “Performance Prediction and Automated Tuning of Randomized and Parametric Algorithms”,,,0,"Frank Hutter, Youssef Hamadi, AI Uber, Holger Hoos, Kevin Leyton-Brown",Frank Hutter,Kevin Leyton-Brown,5,"Over the past decades, a considerable body of work has shown how to use supervised machine learning methods to build regression models that can predict the running time of blackbox algorithms based on observed performance data. Such empirical performance models (EPMs) are useful in many practical contexts:Algorithm selection. One widely adopted approach to the classic problem of selecting the best from a given set of algorithms on a per-instance basis [Rice, 1976] is to use EPMs to predict the performance of all candidate algorithms and select the one predicted to perform best [see, eg, Brewer, 1995; Allen and Minton, 1996; Lobjois and Lemaıtre, 1998; Fink, 1998; Howe et al., 2000; Nudelman et al., 2003; Roberts and Howe, 2007; Xu et al., 2008; Kotthoff et al., 2012]",https://freuder.wordpress.com/wp-content/uploads/2019/09/2006-cp25_performanceprediction_2006.pdf
Frank Hutter,RNA-Protein Interaction Prediction via Sequence Embeddings,,,0,"Dominika Matus, Frederic Runge, Jörg KH Franke, Lars Gerne, Michael Uhl, Frank Hutter, Rolf Backofen, Georges-Köhler Allee",Dominika Matus,Georges-Köhler Allee,8,"RNA-protein interactions (RPI) are ubiquitous in cellular organisms and essential for gene regulation. In particular, protein interactions with non-coding RNAs (ncRNAs) play a critical role in these processes. Experimental analysis of RPIs is time-consuming and expensive, and existing computational methods rely on small and limited datasets. This work introduces RNAInterAct, a comprehensive RPI dataset, alongside RPIembeddor, a novel transformer-based model designed for classifying ncRNA-protein interactions. By leveraging two foundation models for sequence embedding, we incorporate essential structural and functional insights into our task. We demonstrate RPIembeddor’s strong performance and generalization capability compared to state-of-the-art methods across different datasets and analyze the impact of the proposed embedding strategy on the performance in an ablation study.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/2024/03/2024_ICLR_GEM_RPI-1.pdf
Frank Hutter,Understanding the Empirical Hardness of NP-Complete Problems Using machine learning to predict algorithm runtime.,,,0,"Kevin Leyton-Brown, Holger H Hoos, Frank Hutter, Lin Xu",Kevin Leyton-Brown,Lin Xu,4,"Problems are intractable when they “can be solved, but not fast enough for the solution to be usable.” 13 NP-complete problems are commonly said to be intractable; however, the reality is more complex. All known algorithms for solving NP-complete problems require exponential time in the worst case; however, these algorithms nevertheless solve many problems of practical importance astoundingly quickly, and are hence relied upon in a broad range of applications. The propositional satisfiability problem (SAT) serves as a good example. One of the most popular approaches for the formal verification of hardware and software relies on general-purpose SAT solvers and SAT encodings, typically with hundreds of thousands of variables. These instances can often be solved in seconds, even though the same solvers can be stymied by handcrafted instances involving only hundreds of variables.Clearly, we could benefit from a more nuanced understanding of algorithm behavior than is offered by asymptotic, worst-case analysis. Our work asks the question most relevant to an end user:“How hard is it to solve a given family of problem instances, using the best available methods?” Formal, complexity-theoretic analysis of this question seems hopeless: the best available algorithms are highly complex (and, in some cases, only available in compiled form), and instance distributions representative of practical applications are heterogeneous and richly structured. For this reason, we turn to statistical, rather than combinatorial, analysis.",https://cacm.acm.org/research/understanding-the-empirical-hardness-of-np-complete-problems/
Frank Hutter,Fairness Metric Impossibility: Investigating and Addressing Conflicts,,,0,"Jake Robertson, Noor Awad, Thorsten L Schmidt, Frank Hutter",Jake Robertson,Frank Hutter,4,"Fairness-aware ML (FairML) applications are often characterized by intricate social objectives and legal requirements, often encompassing multiple, potentially conflicting notions of fairness. Despite the well-known Impossibility Theorem of Fairness and vast theoretical research on the statistical and socio-technical trade-offs between fairness metrics, many FairML approaches still optimize for a single, user-defined fairness objective. However, this one-sided optimization can inadvertently lead to violations of other pertinent notions of fairness, resulting in adverse social consequences. In this exploratory and empirical study, we address the presence of fairness-metric conflicts by treating fairness metrics as conflicting objectives in a multi-objective (MO) sense. To efficiently explore multiple fairness-accuracy trade-offs and effectively balance conflicts between various fairness objectives, we introduce the ManyFairHPO framework, a novel many-objective (MaO) hyper-parameter optimization (HPO) approach. By enabling fairness practitioners to specify and explore complex and multiple fairness objectives, we open the door to further socio-technical research on effectively combining the complementary benefits of different notions of fairness.",https://openreview.net/forum?id=LIBZ7Mp0OJ
Frank Hutter,3.12 AutoML–with a focus on deep learning,,Automated Algorithm Selection and Configuration,0,Frank Hutter,Frank Hutter,Frank Hutter,1,"The rapid growth of machine learning (ML) applications has created a demand for off-theshelf ML methods that can be used easily and without expert knowledge. I first briefly review the successful approach of casting this problem as an optimization problem on top of a highly-parameterized ML framework. Then, I focus on possible extensions of this approach that could scale it up to achieve fully automated deep learning: reasoning across datasets, subsets of data, and initial time steps; online hyperparameter control; and automatically deriving insights. Many of these extensions have a direct correspondence in optimizing hard combinatorial problem solvers.",https://scholar.archive.org/work/qiqlrysg4nhlrjqsemvxwmwbsa/access/wayback/https://drops.dagstuhl.de/opus/volltexte/2017/6956/pdf/dagrep_v006_i010_p033_s16412.pdf#page=17
Frank Hutter,On the Importance of Hyperparameter Optimization in Model-based Reinforcement Learning,,,0,"Frank Hutter, Roberto Calandra",Frank Hutter,Roberto Calandra,2,"Background● MBRL: We use Probabilistic ensembles with trajectory sampling (PETS)(Chua et al., 2018) as our MBRL algorithm because of its state-of-the-art performance.",https://andrebiedenkapp.github.io/assets/pdf/poster/HPO_in_MBRL_AISTATS_2021_poster.pdf
Frank Hutter,Automated Reinforcement Learning (AutoRL): A Survey and Open Problems,,AutoML Conference 2023 (Journal Track),0,"Raghu Rajan, Jack Parker-Holder, Xingyou Song, André Biedenkapp, Yingjie Miao, Theresa Eimer, Baohe Zhang, Vu Nguyen, Roberto Calandra, Aleksandra Faust, Frank Hutter, Marius Lindauer",Raghu Rajan,Marius Lindauer,12,"Automated Reinforcement Learning (AutoRL): A Survey and Open Problems | OpenReview 
OpenReview.net Login Open Peer Review. Open Publishing. Open Access. Open Discussion. 
Open Recommendations. Open Directory. Open API. Open Source. Automated Reinforcement 
Learning (AutoRL): A Survey and Open Problems Raghu Rajan, Jack Parker-Holder, Xingyou 
Song, André Biedenkapp, Yingjie Miao, Theresa Eimer, Baohe Zhang, Vu Nguyen, Roberto 
Calandra, Aleksandra Faust, Frank Hutter, Marius Lindauer Published: 15 Aug 2023, Last 
Modified: 15 Aug 2023AutoML 2023 (Journal Track)EveryoneRevisionsBibTeX Paper URL: 
https://www.jair.org/index.php/jair/article/view/13596 Broader Impact Statement: pdf Paper 
Availability And License: Yes Code Of Conduct: Yes TLDR: Discusses various components 
of the RL pipeline that can be automated and surveys how existing approaches automate …",https://openreview.net/forum?id=zkcub7dZ24
Frank Hutter,Supplementary material for MO-DEHB: Evolutionary-based Hyperband for Multi-Objective Optimization,,,0,"Noor Awad, Ayushi Sharma, Frank Hutter",Noor Awad,Frank Hutter,3,"In our experiments, we use default settings to run the baselines methods as it is reported in their papers or implementations such as [Blank and Deb, 2020],[Balandat et al., 2020]. Random Search (RS) In each generation, random architectures are sampled from the configuration space using a uniform distribution.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/2023/05/MO_DEHB_Arxiv23_Appendix-3.pdf
Frank Hutter,Bayesian Optimization with a Neural Network Meta-learned on Synthetic Data Only,,Sixth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems,0,"Samuel Müller, Sebastian Pineda Arango, Matthias Feurer, Josif Grabocka, Frank Hutter",Samuel Müller,Frank Hutter,5,"Bayesian Optimization (BO) is an effective approach to optimize black-box functions, relying on a probabilistic surrogate to model the response surface. In this work, we propose to use a Prior-data Fitted Network (PFN) as a cheap and flexible surrogate. PFNs are neural networks that approximate the Posterior Predictive Distribution (PPD) in a single forward-pass. Most importantly, they can approximate the PPD for any prior distribution that we can sample from efficiently. Additionally, we show what is required for PFNs to be used in a standard BO setting with common acquisition functions. We evaluated the performance of a PFN surrogate for Hyperparameter optimization (HPO), a major application of BO. While the method can still fail for some search spaces, we fare comparable or better than the state-of-the-art on the HPO-B and PD1 benchmark.",https://openreview.net/forum?id=9xCudkMSkC
Frank Hutter,GraViT-E: Gradient-based Vision Transformer Search with Entangled Weights,,Sixth Workshop on Meta-Learning at the Conference on Neural Information Processing Systems,0,"Rhea Sanjay Sukthanker, Arjun Krishnakumar, Sharat Patil, Frank Hutter",Rhea Sanjay Sukthanker,Frank Hutter,4,"Differentiable one-shot neural architecture search methods have recently become popular since they can exploit weight-sharing to efficiently search in large architectural search spaces. These methods traditionally perform a continuous relaxation of the discrete search space to search for an optimal architecture. However, they suffer from large memory requirements, making their application to parameter-heavy architectures like transformers difficult. Recently, single-path one-shot methods have been introduced which often use weight entanglement to alleviate this issue by sampling the weights of the sub-networks from the largest model, which is itself the supernet. In this work, we propose a continuous relaxation of  weight entanglement-based architectural representation. Our Gradient-based Vision Transformer Search with Entangled Weights (GraViT-E) combines the best properties of both differentiable one-shot NAS and weight entanglement. We observe that our method imparts much better regularization properties and memory efficiency to the trained supernet. We study three one-shot optimizers on the Vision Transformer search space and observe that our method outperforms existing baselines on multiple datasets while being upto 35% more parameter efficient on ImageNet-1k.",https://openreview.net/forum?id=dm8WcWiuvd
Frank Hutter,Regularization Cocktails for Tabular Datasets,,,0,"Arlind Kadra, Marius Lindauer, Frank Hutter, Josif Grabocka",Arlind Kadra,Josif Grabocka,4,"The regularization of prediction models is arguably the most crucial ingredient that allows Machine Learning solutions to generalize well on unseen data. Several types of regularization are popular in the Deep Learning community (e.g., weight decay, drop-out, early stopping, etc.), but so far these are selected on an ad-hoc basis, and there is no systematic study as to how different regularizers should be combined into the best “cocktail”. In this paper, we fill this gap, by considering the cocktails of 13 different regularization methods and framing the question of how to best combine them as a standard hyperparameter optimization problem. We perform a large-scale empirical study on 40 tabular datasets, concluding that, firstly, regularization cocktails substantially outperform individual regularization methods, even if the hyperparameters of the latter are carefully tuned; secondly, the optimal regularization cocktail depends on the dataset; and thirdly, regularization cocktails yield the state-of-the-art in classifying tabular datasets by outperforming Gradient-Boosted Decision Trees.",https://openreview.net/forum?id=2d34y5bRWxB
Frank Hutter,MDP Playground: Controlling Orthogonal Dimensions of Hardness in Toy Environments,,,0,"Raghu Rajan, Jessica Lizeth Borja Diaz, Suresh Guttikonda, Fabio Ferreira, André Biedenkapp, Frank Hutter",Raghu Rajan,Frank Hutter,6,"We present MDP Playground, an efficient benchmark for Reinforcement Learning (RL) algorithms with various dimensions of hardness that can be controlled independently to challenge algorithms in different ways and to obtain varying degrees of hardness in generated environments. We consider and allow control over a wide variety of key hardness dimensions, including delayed rewards, rewardable sequences, sparsity of rewards, stochasticity, image representations, irrelevant features, time unit, and action max. While it is very time consuming to run RL algorithms on standard benchmarks, we define a parameterised collection of fast-to-run toy benchmarks in OpenAI Gym by varying these dimensions. Despite their toy nature and low compute requirements, we show that these benchmarks present substantial challenges to current RL algorithms. Furthermore, since we can generate environments with a desired value for each of the dimensions, in addition to having fine-grained control over the environments' hardness, we also have the ground truth available for evaluating algorithms. Finally, we evaluate the kinds of transfer for these dimensions that may be expected from our benchmarks to more complex benchmarks. We believe that MDP Playground is a valuable testbed for researchers designing new, adaptive and intelligent RL algorithms and those wanting to unit test their algorithms.",https://openreview.net/forum?id=axNDkxU9-6z
Frank Hutter,"Supplementary material for DEHB: Evolutionary Hyperband for Scalable, Robust and Efficient Hyperparameter Optimization",,,0,"Noor Awad, Neeratyoy Mallik, Frank Hutter",Noor Awad,Frank Hutter,3,"Differential Evolution (DE) is a simple, well-performing evolutionary algorithm to solve a variety of optimization problems [K. Price and Lampinen, 2006][Das et al., 2016]. This algorithm was originally introduced in 1995 by Storn and Price [Storn and Price, 1997], and later attracted the attention of many researchers to propose new improved state-of-the-art algorithms [Chakraborty, 2008]. DE is based on four steps: initialization, mutation, crossover and selection. Algorithm 1 presents the DE pseudo-code.",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/21-IJCAI-DEHB-supplementary.pdf
Frank Hutter,Bayesian Optimization with Robust Bayesian Neural Networks,,,0,"Jost Tobias Springenberg Aaron Klein Stefan, Falkner Frank Hutter",Jost Tobias Springenberg Aaron Klein Stefan,Falkner Frank Hutter,2,"Bayesian optimization is a prominent method for optimizing expensive-to-evaluate black-box functions that is widely applied to tuning the hyperparameters of machine learning algorithms. Despite its successes, the prototypical Bayesian optimization approach–using Gaussian process models–does not scale well to either many hyperparameters or many function evaluations. Attacking this lack of scalability and flexibility is thus one of the key challenges of the field. We present a general approach for using flexible parametric models (neural networks) for Bayesian optimization, staying as close to a truly Bayesian treatment as possible. We obtain scalability through stochastic gradient Hamiltonian Monte Carlo, whose robustness we improve via a scale adaptation. Experiments including multi-task Bayesian optimization with 21 tasks, parallel optimization of deep neural networks and deep reinforcement learning show the power and flexibility of this approach.",https://aad.informatik.uni-freiburg.de/wp-content/uploads/papers/16-NIPS-BOHamiANN.pdf
Frank Hutter,Towards Self-Paced Context Evaluation for Contextual Reinforcement Learning,,,0,"Theresa Eimer, André Biedenkapp, Frank Hutter, Marius Lindauer",Theresa Eimer,Marius Lindauer,4,"Reinforcement Learning has performed very well on games and lab-based tasks. However, learning policies across a distribution of instances of the same task still remains challenging. Recent approaches assume either little variation between instances or an unlimited amount of training examples from a given distribution. Both properties are not always feasible in real-world applications. Thus, we need methods that enable agents to generalize from a limited set of example instances or experiences. We present an approach, based on self-paced learning, that allows to exploit the information contained in state values during training to accelerate and improve training performance as well as generalization capabilities, independent of the problem domain at hand. The proposed Self-Paced Context Evaluation (SPaCE) provides a way to automatically generate instance curricula online with little computational overhead.",https://ml.informatik.uni-freiburg.de/wp-content/uploads/papers/20-BIG-SPaCE.pdf
Frank Hutter,Towards Benchmarking and Dissecting One-shot Neural Architecture Search,,Cell,0,"Julien Siems, Arber Zela, Frank Hutter",Julien Siems,Frank Hutter,3,"One-shot neural architecture search (NAS) has played a crucial role in making NAS methods computationally feasible in practice. Nevertheless, there is still a lack of understanding on how these weight-sharing algorithms exactly work due to the many factors controlling the dynamics of the process. In order to allow a scientific study of these components, we introduce a general framework for one-shot NAS that can be instantiated to many recently-introduced variants and introduce a general benchmarking framework that draws on the recent large-scale tabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot NAS methods. To showcase the framework, we compare several state-of-the-art one-shot NAS methods, examine how sensitive they are to their hyperparameters and how they can be improved by tuning their hyperparameters, and compare their performance to that of blackbox optimizers for NAS-Bench-101.",https://meta-learn.github.io/2019/papers/metalearn2019-siems.pdf
Frank Hutter,Exercise Sheet 6,,,0,"J Boedecker, W Burgard, F Hutter, B Nebel, M Krawez, T Schulte",J Boedecker,T Schulte,6,"Allen’s interval calculus is closed under composition which means that every composition of Allen relations (also for unions of the 13 base relations) can be represented as union of base relations. For example, f◦ s= d because for arbitrary intervals A, B and C with AfB and BsC it must hold that AdC. Note that in general the composition of two base relations needs not to result in a single base relation, as you can see from the example f− 1◦ d=(o, d, s). Determine the following compositions:(1) o◦ m (2) m◦ f (3)(o, f− 1)◦ f",http://ais.informatik.uni-freiburg.de/teaching/ss16/ki/exercises/sheet05-english.pdf
Frank Hutter,4.9 Pitfalls and Best Practices for Algorithm Configuration,,Automated Algorithm Selection and Configuration,0,"Marius Lindauer, Frank Hutter",Marius Lindauer,Frank Hutter,2,"Automatic algorithm configuration [4] helps developers and users of all types of algorithms to tune their parameters (eg, options of search heuristics or hyperparameters of machine learning algorithms). This can often substantially improve performance (eg, running time or prediction error). Applying and comparing automatic algorithm configuration tools (such as ParamILS [4], irace [8], SMAC [3] and GGA [1]) is related to empirical benchmarking and can include many subtle pitfalls, even if reliable benchmark libraries such as AClib [6] are used. In the following, we summarize the discussion on this topic in a breakout session at the Dagstuhl seminar “Automated Algorithm Selection and Configuration”. A common mistake in tuning parameters (also in manual tuning and development of algorithms) is to optimize parameters on the same instances that are used later to evaluate their performance. This can lead to overoptimistic performance estimates and over-tuning effects [5]. To avoid this problem, we recommend to first split the available instances into a training and test set, using the training instances for tuning and the test instances to report the performance on. Using an outer cross-validation would estimate the individual performances with lower variance, but it is typically infeasible in algorithm configuration since each single algorithm configuration run is already very expensive. Also, if the computational budget allows for more than one algorithm configuration experiment, we recommend to rather",https://ada.liacs.leidenuniv.nl/papers/HooEtAl16.pdf#page=38
Frank Hutter,Report on the Mars Technology Program Task,,,0,"Frank Hutter, Sebastian Thrun",Frank Hutter,Sebastian Thrun,2,"An increased level of autonomy is critical for meeting many of the goals of advanced planetary rover missions such as NASA’s 2009 Mars Science Lab. One important component of this is state estimation, and in particular fault detection on-board the rover. ln this paper we describe the results of a project funded by the Mars Technology Program at NASA, aimed at developing algorithms to meet this requirement. We describe a number of particle ﬁltering-based algorithms for state estimation which we have demonstrated successfully on diagnosis problems including the K-9 rover at NASA Ames Research Center and the Hyperion rover at CMU. Because of the close interaction between a rover and its environment, traditional discrete approaches to diagnosis are impractical for this domain. Therefore we model rover subsystems as hybrid discrete/continuous systems. There are three major challenges to make particle …",http://www.thrun.org/papers/Dearden04a.ps.gz
Frank Hutter,A general framework for comparing (approximate) inference algorithms,,,0,"Frank Hutter, Sohrab Shah",Frank Hutter,Sohrab Shah,2,"Conclusive comparisons of approximate inference algorithms are difficult due a number of handicaps. The main problem is that most algorithms were developed independently for different domains and consequently have different input and output representations and formulations, for example, Bayesian networks vs Markov random fields (MRFs)[13]. Thus, researchers usually only compare novel approximate inference algorithms against a small subset of well-known algorithms instead of the current state-of-the-art. Analogously, practitioners usually employ well-known algorithms developed for their problem at hand, ignoring potentially superior algorithms that only require a slightly modified problem formulation.We developed a simple framework that automates the task of converting between different problem formulations and offers a unified interface to a variety of approximate inference algorithms. This framework promises to facilitate straightforward comparisons of an arbitrary set of approximate inference algorithms which to date could only be done with considerable overhead. Consequently, a new algorithm’s performance can now be compared against other published solutions in a standard way with minimal overhead. Furthermore, when assessing the best algorithm for a given problem, one can simply call the desired set of algorithms with a unified interface and compare the results.",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=c9f99704fa7ed49d1c07f9db4cbb273a04e859d7
Erik Cambria,Recent Trends in Deep Learning Based Natural Language Processing,2018,IEEE Computational Intelligence Magazine,4128,"Tom Young, Devamanyu Hazarika, Soujanya Poria, Erik Cambria",Tom Young,Erik Cambria,4,"Deep learning methods employ multiple processing layers to learn hierarchical representations of data, and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.",https://ieeexplore.ieee.org/abstract/document/8416973/
Erik Cambria,"A Survey on Knowledge Graphs: Representation, Acquisition and Applications",2022,IEEE Transactions on Neural Networks and Learning Systems,2598,"Shaoxiong Ji, Shirui Pan, Erik Cambria, Pekka Marttinen, Philip S Yu",Shaoxiong Ji,Philip S Yu,5,"Human knowledge provides a formal understanding of the world. Knowledge graphs that represent structural relations between entities have become an increasingly popular research direction toward cognition and human-level intelligence. In this survey, we provide a comprehensive review of the knowledge graph covering overall research topics about: 1) knowledge graph representation learning; 2) knowledge acquisition and completion; 3) temporal knowledge graph; and 4) knowledge-aware applications and summarize recent breakthroughs and perspective directions to facilitate future research. We propose a full-view categorization and new taxonomies on these topics. Knowledge graph embedding is organized from four aspects of representation space, scoring function, encoding models, and auxiliary information. For knowledge acquisition, especially knowledge graph completion, embedding methods …",https://ieeexplore.ieee.org/abstract/document/9416312/
Erik Cambria,Deep Learning based Text Classification: A Comprehensive Review,2021,ACM Computing Surveys,1915,"Shervin Minaee, Nal Kalchbrenner, Erik Cambria, Narjes Nikzad, Meysam Chenaghlu, Jianfeng Gao",Shervin Minaee,Jianfeng Gao,6,"Deep learning--based models have surpassed classical machine learning--based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this article, we provide a comprehensive review of more than 150 deep learning--based models for text classification developed in recent years, and we discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and we discuss future research directions.",https://dl.acm.org/doi/abs/10.1145/3439726
Erik Cambria,Affective Computing and Sentiment Analysis,2016,IEEE Intelligent Systems,1813,Erik Cambria,Erik Cambria,Erik Cambria,1,"Understanding emotions is one of the most important aspects of personal development and growth and, as such, it is a key tile for the emulation of human intelligence. Besides being a important for the advancement of AI, emotion processing is also important for the closely related task of polarity detection. The opportunity automatically to capture the sentiments of the general public about social events, political movements, marketing campaigns, and product preferences, in fact, has raised increasing interest both in the scientific community, for the exciting open challenges, and in the business world, for the remarkable fallouts in marketing and financial market prediction. This has led to the emerging fields of affective computing and sentiment analysis, which leverage on human-computer interaction, information retrieval, and multimodal signal processing for distilling people’s sentiments from the ever-growing …",https://link.springer.com/chapter/10.1007/978-3-319-55394-8_1
Erik Cambria,New Avenues in Opinion Mining and Sentiment Analysis,2013,IEEE Intelligent Systems,1684,"Erik Cambria, Björn Schuller, Yunqing Xia, Catherine Havasi",Erik Cambria,Catherine Havasi,4,"The Web holds valuable, vast, and unstructured information about public opinion. Here, the history, current use, and future of opinion mining and sentiment analysis are discussed, along with relevant techniques and tools.",https://ieeexplore.ieee.org/abstract/document/6468032/
Erik Cambria,Tensor Fusion Network for Multimodal Sentiment Analysis,2017,Proceedings of EMNLP,1675,"Amir Zadeh, Minghai Chen, Soujanya Poria, Erik Cambria, Louis-Philippe Morency",Amir Zadeh,Louis-Philippe Morency,5,"Multimodal sentiment analysis is an increasingly popular research area, which extends the conventional language-based definition of sentiment analysis to a multimodal setup where other relevant modalities accompany language. In this paper, we pose the problem of multimodal sentiment analysis as modeling intra-modality and inter-modality dynamics. We introduce a novel model, termed Tensor Fusion Network, which learns both such dynamics end-to-end. The proposed approach is tailored for the volatile nature of spoken language in online videos as well as accompanying gestures and voice. In the experiments, our model outperforms state-of-the-art approaches for both multimodal and unimodal sentiment analysis.",https://arxiv.org/abs/1707.07250
Erik Cambria,Jumping NLP Curves: A Review of Natural Language Processing Research,2014,IEEE Computational Intelligence Magazine,1672,"Erik Cambria, Bebo White",Erik Cambria,Bebo White,2,"Natural language processing (NLP) is a theory-motivated range of computational techniques for the automatic analysis and representation of human language. NLP research has evolved from the era of punch cards and batch processing (in which the analysis of a sentence could take up to 7 minutes) to the era of Google and the likes of it (in which millions of webpages can be processed in less than a second). This review paper draws on recent developments in NLP research to look at the past, present, and future of NLP technology in a new light. Borrowing the paradigm of `jumping curves' from the field of business management and marketing prediction, this survey article reinterprets the evolution of NLP research as the intersection of three overlapping curves-namely Syntactics, Semantics, and Pragmatics Curveswhich will eventually lead NLP research to evolve into natural language understanding.",https://ieeexplore.ieee.org/abstract/document/6786458/
Erik Cambria,A Review of Affective Computing: From Unimodal Analysis to Multimodal Fusion,2017,Information Fusion,1602,"Soujanya Poria, Erik Cambria, Rajiv Bajpai, Amir Hussain",Soujanya Poria,Amir Hussain,4,"Affective computing is an emerging interdisciplinary research field bringing together researchers and practitioners from various fields, ranging from artificial intelligence, natural language processing, to cognitive and social sciences. With the proliferation of videos posted online (e.g., on YouTube, Facebook, Twitter) for product reviews, movie reviews, political views, and more, affective computing research has increasingly evolved from conventional unimodal analysis to more complex forms of multimodal analysis. This is the primary motivation behind our first of its kind, comprehensive literature review of the diverse field of affective computing. Furthermore, existing literature surveys lack a detailed discussion of state of the art in multimodal affect analysis frameworks, which this review aims to address. Multimodality is defined by the presence of more than one modality or channel, e.g., visual, audio, text, gestures, and …",https://www.sciencedirect.com/science/article/pii/S1566253517300738
Erik Cambria,Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph,2018,Proceedings of ACL,1302,"Amirali Zadeh, Paul Pu Liang, Soujanya Poria, Erik Cambria, Louis-Philippe Morency",Amirali Zadeh,Louis-Philippe Morency,5,"Analyzing human multimodal language is an emerging area of research in NLP. Intrinsically this language is multimodal (heterogeneous), sequential and asynchronous; it consists of the language (words), visual (expressions) and acoustic (paralinguistic) modalities all in the form of asynchronous coordinated sequences. From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of this form of language. In this paper we introduce CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), the largest dataset of sentiment analysis and emotion recognition to date. Using data from CMU-MOSEI and a novel multimodal fusion technique called the Dynamic Fusion Graph (DFG), we conduct experimentation to exploit how modalities interact with each other in human multimodal language. Unlike previously proposed fusion techniques, DFG is highly interpretable and achieves competative performance when compared to the previous state of the art.",https://aclanthology.org/P18-1208/
Erik Cambria,MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations,2019,Proceedings of ACL,1290,"Soujanya Poria, Devamanyu Hazarika, Navonil Majumder, Gautam Naik, Erik Cambria, Rada Mihalcea",Soujanya Poria,Rada Mihalcea,6,"Emotion recognition in conversations is a challenging task that has recently gained popularity due to its potential applications. Until now, however, a large-scale multimodal multi-party emotional conversational database containing more than two speakers per dialogue was missing. Thus, we propose the Multimodal EmotionLines Dataset (MELD), an extension and enhancement of EmotionLines. MELD contains about 13,000 utterances from 1,433 dialogues from the TV-series Friends. Each utterance is annotated with emotion and sentiment labels, and encompasses audio, visual and textual modalities. We propose several strong multimodal baselines and show the importance of contextual and multimodal information for emotion recognition in conversations. The full dataset is available for use at http:// affective-meld.github.io.",https://arxiv.org/abs/1810.02508
Erik Cambria,Aspect Extraction for Opinion Mining with a Deep Convolutional Neural Network,2016,Knowledge-Based Systems,1024,"Soujanya Poria, Erik Cambria, Alexander Gelbukh",Soujanya Poria,Alexander Gelbukh,3,"In this paper, we present the first deep learning approach to aspect extraction in opinion mining. Aspect extraction is a subtask of sentiment analysis that consists in identifying opinion targets in opinionated text, i.e., in detecting the specific aspects of a product or service the opinion holder is either praising or complaining about. We used a 7-layer deep convolutional neural network to tag each word in opinionated sentences as either aspect or non-aspect word. We also developed a set of linguistic patterns for the same purpose and combined them with the neural network. The resulting ensemble classifier, coupled with a word-embedding model for sentiment analysis, allowed our approach to obtain significantly better accuracy than state-of-the-art methods.",https://www.sciencedirect.com/science/article/pii/S0950705116301721
Erik Cambria,Context-Dependent Sentiment Analysis in User-Generated Videos,2017,Proceedings of ACL,946,"Soujanya Poria, Erik Cambria, Devamanyu Hazarika, Navonil Majumder, Amir Zadeh, Louis-Philippe Morency",Soujanya Poria,Louis-Philippe Morency,6,"Multimodal sentiment analysis is a developing area of research, which involves the identification of sentiments in videos. Current research considers utterances as independent entities, ie, ignores the interdependencies and relations among the utterances of a video. In this paper, we propose a LSTM-based model that enables utterances to capture contextual information from their surroundings in the same video, thus aiding the classification process. Our method shows 5-10% performance improvement over the state of the art and high robustness to generalizability.",https://aclanthology.org/P17-1081/
Erik Cambria,DialogueRNN: An Attentive RNN for Emotion Detection in Conversations,2019,Proceedings of AAAI,838,"Navonil Majumder, Soujanya Poria, Devamanyu Hazarika, Rada Mihalcea, Alexander Gelbukh, Erik Cambria",Navonil Majumder,Erik Cambria,6,"Emotion detection in conversations is a necessary step for a number of applications, including opinion mining over chat history, social media threads, debates, argumentation mining, understanding consumer feedback in live conversations, and so on. Currently systems do not treat the parties in the conversation individually by adapting to the speaker of each utterance. In this paper, we describe a new method based on recurrent neural networks that keeps track of the individual party states throughout the conversation and uses this information for emotion classification. Our model outperforms the state-of-the-art by a significant margin on two different datasets.",https://ojs.aaai.org/index.php/AAAI/article/view/4657
Erik Cambria,Memory Fusion Network for Multi-View Sequential Learning,2018,Proceedings of AAAI,819,"Amir Zadeh, Paul Pu Liang, Navonil Majumder, Soujanya Poria, Erik Cambria, Louis-Philippe Morency",Amir Zadeh,Louis-Philippe Morency,6,"Multi-view sequential learning is a fundamental problem in machine learning dealing with multi-view sequences. In a multi-view sequence, there exists two forms of interactions between different views: view-specific interactions and cross-view interactions. In this paper, we present a new neural architecture for multi-view sequential learning called the Memory Fusion Network (MFN) that explicitly accounts for both interactions in a neural architecture and continuously models them through time. The first component of the MFN is called the System of LSTMs, where view-specific interactions are learned in isolation through assigning an LSTM function to each view. The cross-view interactions are then identified using a special attention mechanism called the Delta-memory Attention Network (DMAN) and summarized through time with a Multi-view Gated Memory. Through extensive experimentation, MFN is compared to various proposed approaches for multi-view sequential learning on multiple publicly available benchmark datasets. MFN outperforms all the multi-view approaches. Furthermore, MFN outperforms all current state-of-the-art models, setting new state-of-the-art results for all three multi-view datasets.",https://ojs.aaai.org/index.php/AAAI/article/view/12021
Erik Cambria,ABCDM: An Attention-based Bidirectional CNN-RNN Deep Model for Sentiment Analysis,2021,Future Generation Computer Systems,763,"Mohammad Ehsan Basiri, Shahla Nemati, Moloud Abdar, Erik Cambria, U Rajendra Acharya",Mohammad Ehsan Basiri,U Rajendra Acharya,5,"Sentiment analysis has been a hot research topic in natural language processing and data mining fields in the last decade. Recently, deep neural network (DNN) models are being applied to sentiment analysis tasks to obtain promising results. Among various neural architectures applied for sentiment analysis, long short-term memory (LSTM) models and its variants such as gated recurrent unit (GRU) have attracted increasing attention. Although these models are capable of processing sequences of arbitrary length, using them in the feature extraction layer of a DNN makes the feature space high dimensional. Another drawback of such models is that they consider different features equally important. To address these problems, we propose an Attention-based Bidirectional CNN-RNN Deep Model (ABCDM). By utilizing two independent bidirectional LSTM and GRU layers, ABCDM will extract both past and future …",https://www.sciencedirect.com/science/article/pii/S0167739X20309195
Erik Cambria,Targeted Aspect-Based Sentiment Analysis via Embedding Commonsense Knowledge into an Attentive LSTM,2018,Proceedings of AAAI,710,"Yukun Ma, Haiyun Peng, Erik Cambria",Yukun Ma,Erik Cambria,3,"Analyzing people’s opinions and sentiments towards certain aspects is an important task of natural language understanding. In this paper, we propose a novel solution to targeted aspect-based sentiment analysis, which tackles the challenges of both aspect-based sentiment analysis and targeted sentiment analysis by exploiting commonsense knowledge. We augment the long short-term memory (LSTM) network with a hierarchical attention mechanism consisting of a target-level attention and a sentence-level attention. Commonsense knowledge of sentiment-related concepts is incorporated into the end-to-end training of a deep neural network for sentiment classification. In order to tightly integrate the commonsense knowledge into the recurrent encoder, we propose an extension of LSTM, termed Sentic LSTM. We conduct experiments on two publicly released datasets, which show that the combination of the proposed attention architecture and Sentic LSTM can outperform state-of-the-art methods in targeted aspect sentiment tasks.",https://ojs.aaai.org/index.php/AAAI/article/view/12048
Erik Cambria,Convolutional MKL Based Multimodal Emotion Recognition and Sentiment Analysis,2016,Proceedings of ICDM,688,"Soujanya Poria, Iti Chaturvedi, Erik Cambria, Amir Hussain",Soujanya Poria,Amir Hussain,4,"Technology has enabled anyone with an Internet connection to easily create and share their ideas, opinions and content with millions of other people around the world. Much of the content being posted and consumed online is multimodal. With billions of phones, tablets and PCs shipping today with built-in cameras and a host of new video-equipped wearables like Google Glass on the horizon, the amount of video on the Internet will only continue to increase. It has become increasingly difficult for researchers to keep up with this deluge of multimodal content, let alone organize or make sense of it. Mining useful knowledge from video is a critical need that will grow exponentially, in pace with the global growth of content. This is particularly important in sentiment analysis, as both service and product reviews are gradually shifting from unimodal to multimodal. We present a novel method to extract features from visual …",https://ieeexplore.ieee.org/abstract/document/7837868/
Erik Cambria,Deep Learning-Based Document Modeling for Personality Detection from Text,2017,IEEE Intelligent Systems,682,"Navonil Majumder, Soujanya Poria, Alexander Gelbukh, Erik Cambria",Navonil Majumder,Erik Cambria,4,"This article presents a deep learning based method for determining the author's personality type from text: given a text, the presence or absence of the Big Five traits is detected in the author's psychological profile. For each of the five traits, the authors train a separate binary classifier, with identical architecture, based on a novel document modeling technique. Namely, the classifier is implemented as a specially designed deep convolutional neural network, with injection of the document-level Mairesse features, extracted directly from the text, into an inner layer. The first layers of the network treat each sentence of the text separately; then the sentences are aggregated into the document vector. Filtering out emotionally neutral input sentences improved the performance. This method outperformed the state of the art for all five traits, and the implementation is freely available for research purposes.",https://ieeexplore.ieee.org/abstract/document/7887639/
Erik Cambria,Deep Convolutional Neural Network Textual Features and Multiple Kernel Learning for Utterance-Level Multimodal Sentiment Analysis,2015,Proceedings of EMNLP,620,"Soujanya Poria, Erik Cambria, Alexander Gelbukh",Soujanya Poria,Alexander Gelbukh,3,"We present a novel way of extracting features from short texts, based on the activation values of an inner layer of a deep convolutional neural network. We use the extracted features in multimodal sentiment analysis of short video clips representing one sentence each. We use the combined feature vectors of textual, visual, and audio modalities to train a classifier based on multiple kernel learning, which is known to be good at heterogeneous data. We obtain 14% performance improvement over the state of the art and present a parallelizable decision-level data fusion method, which is much faster, though slightly less accurate.",https://aclanthology.org/D15-1303.pdf
Erik Cambria,"Fusing Audio, Visual and Textual Clues for Sentiment Analysis from Multimodal Content",2016,Neurocomputing,614,"Soujanya Poria, Erik Cambria, Newton Howard, Guang-Bin Huang, Amir Hussain",Soujanya Poria,Amir Hussain,5,"A huge number of videos are posted every day on social media platforms such as Facebook and YouTube. This makes the Internet an unlimited source of information. In the coming decades, coping with such information and mining useful knowledge from it will be an increasingly difficult task. In this paper, we propose a novel methodology for multimodal sentiment analysis, which consists in harvesting sentiments from Web videos by demonstrating a model that uses audio, visual and textual modalities as sources of information. We used both feature- and decision-level fusion methods to merge affective information extracted from multiple modalities. A thorough comparison with existing works in this area is carried out throughout the paper, which demonstrates the novelty of our approach. Preliminary comparative experiments with the YouTube dataset show that the proposed multimodal system achieves an accuracy …",https://www.sciencedirect.com/science/article/pii/S0925231215011297
Erik Cambria,SenticNet 3: A Common and Common-Sense Knowledge Base for Cognition-Driven Sentiment Analysis,2014,Proceedings of AAAI,589,"E Cambria, D Olsher, D Rajagopal",E Cambria,D Rajagopal,3,"SenticNet is a publicly available semantic and affective resource for concept-level sentiment analysis. Rather than using graph-mining and dimensionality-reduction techniques, SenticNet 3 makes use of"" energy flows"" to connect various parts of extended common and common-sense knowledge representations to one another. SenticNet 3 models nuanced semantics and sentics (that is, the conceptual and affective information associated with multi-word natural language expressions), representing information with a symbolic opacity of an intermediate nature between that of neural networks and typical symbolic systems.",https://ojs.aaai.org/index.php/AAAI/article/view/8928
Erik Cambria,Multi-Attention Recurrent Network for Human Communication Comprehension,2018,Proceedings of AAAI,567,"Amir Zadeh, Paul Pu Liang, Soujanya Poria, Prateek Vij, Erik Cambria, Louis-Philippe Morency",Amir Zadeh,Louis-Philippe Morency,6,"Human face-to-face communication is a complex multimodal signal. We use words (language modality), gestures (vision modality) and changes in tone (acoustic modality) to convey our intentions. Humans easily process and understand face-to-face communication, however, comprehending this form of communication remains a significant challenge for Artificial Intelligence (AI). AI must understand each modality and the interactions between them that shape the communication. In this paper, we present a novel neural architecture for understanding human communication called the Multi-attention Recurrent Network (MARN). The main strength of our model comes from discovering interactions between modalities through time using a neural component called the Multi-attention Block (MAB) and storing them in the hybrid memory of a recurrent component called the Long-short Term Hybrid Memory (LSTHM). We perform extensive comparisons on six publicly available datasets for multimodal sentiment analysis, speaker trait recognition and emotion recognition. MARN shows state-of-the-art results performance in all the datasets.",https://ojs.aaai.org/index.php/AAAI/article/view/12024
Erik Cambria,SenticNet 6: Ensemble Application of Symbolic and Subsymbolic AI for Sentiment Analysis,2020,Proceedings of CIKM,530,"Erik Cambria, Yang Li, Frank Xing, Soujanya Poria, Kenneth Kwok",Erik Cambria,Kenneth Kwok,5,"Deep learning has unlocked new paths towards the emulation of the peculiarly-human capability of learning from examples. While this kind of bottom-up learning works well for tasks such as image classification or object detection, it is not as effective when it comes to natural language processing. Communication is much more than learning a sequence of letters and words: it requires a basic understanding of the world and social norms, cultural awareness, commonsense knowledge, etc.; all things that we mostly learn in a top-down manner. In this work, we integrate top-down and bottom-up learning via an ensemble of symbolic and subsymbolic AI tools, which we apply to the interesting problem of polarity detection from text. In particular, we integrate logical reasoning within deep learning architectures to build a new version of SenticNet, a commonsense knowledge base for sentiment analysis.",https://dl.acm.org/doi/abs/10.1145/3340531.3412003
Erik Cambria,Sentiment Analysis is a Big Suitcase,2017,IEEE Intelligent Systems,505,"Erik Cambria, Soujanya Poria, Alexander Gelbukh, Mike Thelwall",Erik Cambria,Mike Thelwall,4,"Although most works approach it as a simple categorization problem, sentiment analysis is actually a suitcase research problem that requires tackling many natural language processing (NLP) tasks. The expression “sentiment analysis” itself is a big suitcase (like many others related to affective computing, such as emotion recognition or opinion mining) that all of us use to encapsulate our jumbled idea about how our minds convey emotions and opinions through natural language. The authors address the composite nature of the problem via a three-layer structure inspired by the “jumping NLP curves” paradigm. In particular, they argue that there are (at least) 15 NLP problems that need to be solved to achieve human-like performance in sentiment analysis.",https://ieeexplore.ieee.org/abstract/document/8267597/
Erik Cambria,Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos,2018,Proceedings of NAACL,499,"Devamanyu Hazarika, Soujanya Poria, Amir Zadeh, Erik Cambria, Louis-Philippe Morency, Roger Zimmermann",Devamanyu Hazarika,Roger Zimmermann,6,"Emotion recognition in conversations is crucial for the development of empathetic machines. Present methods mostly ignore the role of inter-speaker dependency relations while classifying emotions in conversations. In this paper, we address recognizing utterance-level emotions in dyadic conversational videos. We propose a deep neural framework, termed conversational memory network, which leverages contextual information from the conversation history. The framework takes a multimodal approach comprising audio, visual and textual features with gated recurrent units to model past utterances of each speaker into memories. Such memories are then merged using attention-based hops to capture inter-speaker dependencies. Experiments show an accuracy improvement of 3–4% over the state of the art.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7098709/
Erik Cambria,SenticNet 5: Discovering Conceptual Primitives for Sentiment Analysis by Means of Context Embeddings,2018,Proceedings of AAAI,493,"Erik Cambria, Soujanya Poria, Devamanyu Hazarika, Kenneth Kwok",Erik Cambria,Kenneth Kwok,4,"With the recent development of deep learning, research in AI has gained new vigor and prominence. While machine learning has succeeded in revitalizing many research fields, such as computer vision, speech recognition, and medical diagnosis, we are yet to witness impressive progress in natural language understanding. One of the reasons behind this unmatched expectation is that, while a bottom-up approach is feasible for pattern recognition, reasoning and understanding often require a top-down approach. In this work, we couple sub-symbolic and symbolic AI to automatically discover conceptual primitives from text and link them to commonsense concepts and named entities in a new three-level knowledge representation for sentiment analysis. In particular, we employ recurrent neural networks to infer primitives by lexical substitution and use them for grounding common and commonsense knowledge by means of multi-dimensional scaling.",https://ojs.aaai.org/index.php/AAAI/article/view/11559
Erik Cambria,The Hourglass of Emotions,2012,,485,"Erik Cambria, Andrew Livingstone, Amir Hussain",Erik Cambria,Amir Hussain,3,"Human emotions and their modelling are increasingly understood to be a crucial aspect in the development of intelligent systems. Over the past years, in fact, the adoption of psychological models of emotions has become a common trend among researchers and engineers working in the sphere of affective computing. Because of the elusive nature of emotions and the ambiguity of natural language, however, psychologists have developed many different affect models, which often are not suitable for the design of applications in fields such as affective HCI, social data mining, and sentiment analysis. To this end, we propose a novel biologically-inspired and psychologically-motivated emotion categorisation model that goes beyond mere categorical and dimensional approaches. Such model represents affective states both through labels and through four independent but concomitant affective dimensions …",https://link.springer.com/chapter/10.1007/978-3-642-34584-5_11
Erik Cambria,Natural Language Based Financial Forecasting: A Survey,2018,Artificial Intelligence Review,477,"Frank Xing, Erik Cambria, Roy Welsch",Frank Xing,Roy Welsch,3,"Natural language processing (NLP), or the pragmatic research perspective of computational linguistics, has become increasingly powerful due to data availability and various techniques developed in the past decade. This increasing capability makes it possible to capture sentiments more accurately and semantics in a more nuanced way. Naturally, many applications are starting to seek improvements by adopting cutting-edge NLP techniques. Financial forecasting is no exception. As a result, articles that leverage NLP techniques to predict financial markets are fast accumulating, gradually establishing the research field of natural language based financial forecasting (NLFF), or from the application perspective, stock market prediction. This review article clarifies the scope of NLFF research by ordering and structuring techniques and applications from related work. The survey also aims to increase the …",https://link.springer.com/article/10.1007/s10462-017-9588-9
Erik Cambria,SenticNet: A Publicly Available Semantic Resource for Opinion Mining,2010,Proceedings of Commonsense Knowledge Symposium,468,"Erik Cambria, Robert Speer, Catherine Havasi, Amir Hussain",Erik Cambria,Amir Hussain,4,"Today millions of web-users express their opinions about many topics through blogs, wikis, fora, chats and social networks. For sectors such as e-commerce and e-tourism, it is very useful to automatically analyze the huge amount of social information available on the Web, but the extremely unstructured nature of these contents makes it a difficult task. SenticNet is a publicly available resource for opinion mining built exploiting AI and Semantic Web techniques. It uses dimensionality reduction to infer the polarity of common sense concepts and hence provide a public resource for mining opinions from natural language text at a semantic, rather than just syntactic, level.",https://cdn.aaai.org/ocs/2216/2216-9491-2-PB.pdf
Erik Cambria,Extreme Learning Machines,2013,IEEE Intelligent Systems,458,"Erik Cambria, Qiang Liu, Kuan Li, Victor CM Leung, Liang Feng, Yew-Soon Ong, Meng-Hiot Lim, Anton Akusok, Amaury Lendasse, Francesco Corona, Rui Nian, Guang-Bin Huang, Yoan Miche, Paolo Gastaldo, Rodolfo Zunino, Sergio Decherchi, Xuefeng Yang, Kezhi Mao, Beom-Seok Oh, Jehyoung Jeon, Kar-Ann Toh, Liyanaarachchi Lekamalage Chamara Kasun, Andrew Beng Jin Teoh, Jaihie Kim, Hanchao Yu, Yiqiang Chen, Junfa Liu, Hongming Zhou, Chi Man Vong, Jiarun Lin, Jianping Yin, Zhiping Cai",Erik Cambria,Zhiping Cai,32,"This special issue includes eight original works that detail the further developments of ELMs in theories, applications, and hardware implementation. In ""Representational Learning with ELMs for Big Data,"" Liyanaarachchi Lekamalage Chamara Kasun, Hongming Zhou, Guang-Bin Huang, and Chi Man Vong propose using the ELM as an auto-encoder for learning feature representations using singular values. In ""A Secure and Practical Mechanism for Outsourcing ELMs in Cloud Computing,"" Jiarun Lin, Jianping Yin, Zhiping Cai, Qiang Liu, Kuan Li, and Victor C.M. Leung propose a method for handling large data applications by outsourcing to the cloud that would dramatically reduce ELM training time. In ""ELM-Guided Memetic Computation for Vehicle Routing,"" Liang Feng, Yew-Soon Ong, and Meng-Hiot Lim consider the ELM as an engine for automating the encapsulation of knowledge memes from past problem …",https://ieeexplore.ieee.org/abstract/document/6733226/
Erik Cambria,Sentic Patterns: Dependency-Based Rules for Concept-Level Sentiment Analysis,2014,Knowledge-Based Systems,452,"Soujanya Poria, Erik Cambria, Grégoire Winterstein, Guang-Bin Huang",Soujanya Poria,Guang-Bin Huang,4,"The Web is evolving through an era where the opinions of users are getting increasingly important and valuable. The distillation of knowledge from the huge amount of unstructured information on the Web can be a key factor for tasks such as social media marketing, branding, product positioning, and corporate reputation management. These online social data, however, remain hardly accessible to computers, as they are specifically meant for human consumption. The automatic analysis of online opinions involves a deep understanding of natural language text by machines, from which we are still very far. To this end, concept-level sentiment analysis aims to go beyond a mere word-level analysis of text and provide novel approaches to opinion mining and sentiment analysis that enable a more efficient passage from (unstructured) textual information to (structured) machine-processable data. A recent knowledge …",https://www.sciencedirect.com/science/article/pii/S095070511400183X
Erik Cambria,Learning Community Embedding with Community Detection and Node Embedding on Graphs,2017,Proceedings of CIKM,446,"Sandro Cavallari, Vincent W Zheng, Hongyun Cai, Kevin Chen-Chuan Chang, Erik Cambria",Sandro Cavallari,Erik Cambria,5,"In this paper, we study an important yet largely under-explored setting of graph embedding, i.e., embedding communities instead of each individual nodes. We find that community embedding is not only useful for community-level applications such as graph visualization, but also beneficial to both community detection and node classification. To learn such embedding, our insight hinges upon a closed loop among community embedding, community detection and node embedding. On the one hand, node embedding can help improve community detection, which outputs good communities for fitting better community embedding. On the other hand, community embedding can be used to optimize the node embedding by introducing a community-aware high-order proximity. Guided by this insight, we propose a novel community embedding framework that jointly solves the three tasks together. We evaluate such a …",https://dl.acm.org/doi/abs/10.1145/3132847.3132925
Erik Cambria,Aspect-Based Sentiment Analysis via Affective Knowledge Enhanced Graph Convolutional Networks,2022,Knowledge-Based Systems,445,"Bin Liang, Hang Su, Lin Gui, Erik Cambria, Ruifeng Xu",Bin Liang,Ruifeng Xu,5,"Aspect-based sentiment analysis is a fine-grained sentiment analysis task, which needs to detection the sentiment polarity towards a given aspect. Recently, graph neural models over the dependency tree are widely applied for aspect-based sentiment analysis. Most existing works, however, they generally focus on learning the dependency information from contextual words to aspect words based on the dependency tree of the sentence, which lacks the exploitation of contextual affective knowledge with regard to the specific aspect. In this paper, we propose a graph convolutional network based on SenticNet to leverage the affective dependencies of the sentence according to the specific aspect, called Sentic GCN. To be specific, we explore a novel solution to construct the graph neural networks via integrating the affective knowledge from SenticNet to enhance the dependency graphs of sentences. Based on it …",https://www.sciencedirect.com/science/article/pii/S0950705121009059
Erik Cambria,ICON: Interactive Conversational Memory Network for Multimodal Emotion Detection,2018,Proceedings of EMNLP,432,"Devamanyu Hazarika, Soujanya Poria, Rada Mihalcea, Erik Cambria, Roger Zimmermann",Devamanyu Hazarika,Roger Zimmermann,5,"Emotion recognition in conversations is crucial for building empathetic machines. Present works in this domain do not explicitly consider the inter-personal influences that thrive in the emotional dynamics of dialogues. To this end, we propose Interactive COnversational memory Network (ICON), a multimodal emotion detection framework that extracts multimodal features from conversational videos and hierarchically models the self-and inter-speaker emotional influences into global memories. Such memories generate contextual summaries which aid in predicting the emotional orientation of utterance-videos. Our model outperforms state-of-the-art networks on multiple classification and regression tasks in two benchmark datasets.",https://aclanthology.org/D18-1280/
Erik Cambria,SenticNet 4: A Semantic Resource for Sentiment Analysis Based on Conceptual Primitives,2016,Proceedings of COLING,427,"Erik Cambria, Soujanya Poria, Rajiv Bajpai, Björn Schuller",Erik Cambria,Björn Schuller,4,"An important difference between traditional AI systems and human intelligence is the human ability to harness commonsense knowledge gleaned from a lifetime of learning and experience to make informed decisions. This allows humans to adapt easily to novel situations where AI fails catastrophically due to a lack of situation-specific rules and generalization capabilities. Commonsense knowledge also provides background information that enables humans to successfully operate in social situations where such knowledge is typically assumed. Since commonsense consists of information that humans take for granted, gathering it is an extremely difficult task. Previous versions of SenticNet were focused on collecting this kind of knowledge for sentiment analysis but they were heavily limited by their inability to generalize. SenticNet 4 overcomes such limitations by leveraging on conceptual primitives automatically generated by means of hierarchical clustering and dimensionality reduction.",https://opus.bibliothek.uni-augsburg.de/opus4/files/72175/C16-1251.pdf
Erik Cambria,A Deeper Look into Sarcastic Tweets Using Deep Convolutional Neural Networks,2016,Proceedings of COLING,423,"Soujanya Poria, Erik Cambria, Devamanyu Hazarika, Prateek Vij",Soujanya Poria,Prateek Vij,4,"Sarcasm detection is a key task for many natural language processing tasks. In sentiment analysis, for example, sarcasm can flip the polarity of an ""apparently positive"" sentence and, hence, negatively affect polarity detection performance. To date, most approaches to sarcasm detection have treated the task primarily as a text categorization problem. Sarcasm, however, can be expressed in very subtle ways and requires a deeper understanding of natural language that standard text categorization techniques cannot grasp. In this work, we develop models based on a pre-trained convolutional neural network for extracting sentiment, emotion and personality features for sarcasm detection. Such features, along with the network's baseline features, allow the proposed models to outperform the state of the art on benchmark datasets. We also address the often ignored generalizability issue of classifying data that have not been seen by the models at learning phase.",https://arxiv.org/abs/1610.08815
Erik Cambria,"Sentic computing: Techniques, tools, and applications",2012,,393,"Erik Cambria, Amir Hussain",Erik Cambria,Amir Hussain,2,"In this book common sense computing techniques are further developed and applied to bridge the semantic gap between word-level natural language data and the concept-level opinions conveyed by these. In particular, the ensemble application of graph mining and multi-dimensionality reduction techniques is exploited on two common sense knowledge bases to develop a novel intelligent engine for open-domain opinion mining and sentiment analysis. The proposed approach, termed sentic computing, performs a clause-level semantic analysis of text, which allows the inference of both the conceptual and emotional information associated with natural language opinions and, hence, a more efficient passage from (unstructured) textual information to (structured) machine-processable data.",https://books.google.com/books?hl=en&lr=&id=8DPLZ8klJrkC&oi=fnd&pg=PR4&dq=info:EDEx3aa_sewJ:scholar.google.com&ots=lBiJquhfyY&sig=CRRdadHHdgG0DQMeMbdDTVNJvMI
Erik Cambria,Recent Trends in Deep Learning Based Personality Detection,2020,Artificial Intelligence Review,389,"Yash Mehta, Navonil Majumder, Alexander Gelbukh, Erik Cambria",Yash Mehta,Erik Cambria,4,"Recently, the automatic prediction of personality traits has received a lot of attention. Specifically, personality trait prediction from multimodal data has emerged as a hot topic within the field of affective computing. In this paper, we review significant machine learning models which have been employed for personality detection, with an emphasis on deep learning-based methods. This review paper provides an overview of the most popular approaches to automated personality detection, various computational datasets, its industrial applications, and state-of-the-art machine learning models for personality detection with specific focus on multimodal approaches. Personality detection is a very broad and diverse topic: this survey only focuses on computational approaches and leaves out psychological studies on personality detection.",https://link.springer.com/article/10.1007/s10462-019-09770-z
Erik Cambria,Augmenting End-to-End Dialogue Systems with Commonsense Knowledge,2018,Proceedings of AAAI,385,"Tom Young, Erik Cambria, Iti Chaturvedi, Hao Zhou, Subham Biswas, Minlie Huang",Tom Young,Minlie Huang,6,"Building dialogue systems that can converse naturally with humans is a challenging yet intriguing problem of artificial intelligence. In open-domain human-computer conversation, where the conversational agent is expected to respond to human utterances in an interesting and engaging way, commonsense knowledge has to be integrated into the model effectively. In this paper, we investigate the impact of providing commonsense knowledge about the concepts covered in the dialogue. Our model represents the first attempt to integrating a large commonsense knowledge base into end-to-end conversational models. In the retrieval-based scenario, we propose a model to jointly take into account message content and related commonsense for selecting an appropriate response. Our experiments suggest that the knowledge-augmented models are superior to their knowledge-free counterparts.",https://ojs.aaai.org/index.php/AAAI/article/view/11923
Erik Cambria,A Rule-Based Approach to Aspect Extraction from Product Reviews,2014,Proceedings of COLING Workshops,384,"Soujanya Poria, Erik Cambria, Lun-Wei Ku, Chen Gui, Alexander Gelbukh",Soujanya Poria,Alexander Gelbukh,5,"Sentiment analysis is a rapidly growing research field that has attracted both academia and industry because of the challenging research problems it poses and the potential benefits it can provide in many real life applications. Aspect-based opinion mining, in particular, is one of the fundamental challenges within this research field. In this work, we aim to solve the problem of aspect extraction from product reviews by proposing a novel rule-based approach that exploits common-sense knowledge and sentence dependency trees to detect both explicit and implicit aspects. Two popular review datasets were used for evaluating the system against state-of-the-art aspect extraction techniques, obtaining higher detection accuracy for both datasets.",https://aclanthology.org/W14-5905.pdf
Erik Cambria,Multimodal Sentiment Analysis using Hierarchical Fusion with Context Modeling,2018,Knowledge-Based Systems,382,"Navonil Majumder, Devamanyu Hazarika, A Gelbukh, Erik Cambria, Soujanya Poria",Navonil Majumder,Soujanya Poria,5,"Multimodal sentiment analysis is a very actively growing field of research. A promising area of opportunity in this field is to improve the multimodal fusion mechanism. We present a novel feature fusion strategy that proceeds in a hierarchical fashion, first fusing the modalities two in two and only then fusing all three modalities. On multimodal sentiment analysis of individual utterances, our strategy outperforms conventional concatenation of features by 1%, which amounts to 5% reduction in error rate. On utterance-level multimodal sentiment analysis of multi-utterance video clips, for which current state-of-the-art techniques incorporate contextual information from other utterances of the same clip, our hierarchical fusion gives up to 2.4% (almost 10% error rate reduction) over currently used concatenation. The implementation of our method is publicly available in the form of open-source code.",https://www.sciencedirect.com/science/article/pii/S0950705118303897
Erik Cambria,"Multimodal Sentiment Analysis: A Systematic Review of History, Datasets, Multimodal Fusion Methods, Applications, Challenges and Future Directions",2023,Information Fusion,379,"Ankita Gandhi, Kinjal Adhvaryu, Soujanya Poria, Erik Cambria, Amir Hussain",Ankita Gandhi,Amir Hussain,5,"Sentiment analysis (SA) has gained much traction In the field of artificial intelligence (AI) and natural language processing (NLP). There is growing demand to automate analysis of user sentiment towards products or services. Opinions are increasingly being shared online in the form of videos rather than text alone. This has led to SA using multiple modalities, termed Multimodal Sentiment Analysis (MSA), becoming an important research area. MSA utilises latest advancements in machine learning and deep learning at various stages including for multimodal feature extraction and fusion and sentiment polarity detection, with aims to minimize error rate and improve performance. This survey paper examines primary taxonomy and newly released multimodal fusion architectures. Recent developments in MSA architectures are divided into ten categories, namely early fusion, late fusion, hybrid fusion, model-level fusion …",https://www.sciencedirect.com/science/article/pii/S1566253522001634
Erik Cambria,A Practical Guide to Sentiment Analysis,2017,,348,"Erik Cambria, Dipankar Das, Sivaji Bandyopadhyay, Antonio Feraco",Erik Cambria,Antonio Feraco,4,"While sentiment analysis research has become very popular in the past ten years, most companies and researchers still approach it simply as a polarity detection problem. In reality, sentiment analysis is a “suitcase problem” that requires tackling many natural language processing (NLP) subtasks, including microtext analysis, sarcasm detection, anaphora resolution, subjectivity detection, and aspect extraction. In this book, we propose an overview of the main issues and challenges associated with current sentiment analysis research and provide some insights on practical tools and techniques that can be exploited to both advance the state of the art in all sentiment analysis subtasks and explore new areas in the same context. In Chap. 1, we discuss the state of the art of affective computing and sentiment analysis research, including recent deep learning techniques and linguistic patterns for emotion and polarity …",https://link.springer.com/content/pdf/10.1007/978-3-319-55394-8.pdf
Erik Cambria,Multilingual Sentiment Analysis: State of the Art and Independent Comparison of Techniques,2016,Cognitive Computation,348,"Kia Dashtipour, Soujanya Poria, Amir Hussain, Erik Cambria, Ahmad YA Hawalah, Alexander Gelbukh, Qiang Zhou",Kia Dashtipour,Qiang Zhou,7,"With the advent of Internet, people actively express their opinions about products, services, events, political parties, etc., in social media, blogs, and website comments. The amount of research work on sentiment analysis is growing explosively. However, the majority of research efforts are devoted to English-language data, while a great share of information is available in other languages. We present a state-of-the-art review on multilingual sentiment analysis. More importantly, we compare our own implementation of existing approaches on common data. Precision observed in our experiments is typically lower than the one reported by the original authors, which we attribute to the lack of detail in the original presentation of those approaches. Thus, we compare the existing works by what they really offer to the reader, including whether they allow for accurate implementation and for reliable reproduction of the …",https://link.springer.com/article/10.1007/s12559-016-9415-7
Erik Cambria,Distinguishing Between Facts and Opinions for Sentiment Analysis: Survey and Challenges,2018,Information Fusion,342,"Iti Chaturvedi, Erik Cambria, Roy Welsch, Francisco Herrera",Iti Chaturvedi,Francisco Herrera,4,"Sentiment analysis requires a lot of information coming from different sources and about different topics to be retrieved and fused. For this reason, one of the most important subtasks of sentiment analysis is subjectivity detection, i.e., the removal of ‘factual’ or ‘neutral’ comments that lack sentiment. It is possibly the most essential subtask of sentiment analysis as sentiment classifiers are often optimized to categorize text as either negative or positive and, hence, forcefully fit unopinionated sentences into one of these two categories. This article reviews hand-crafted and automatic models for subjectivity detection in the literature. It highlights the key assumptions these models make, the results they obtain, and the issues that still need to be explored to further our understanding of subjective sentences. Lastly, the advantages and limitations of each approach are compared. The methods can be broadly categorized as …",https://www.sciencedirect.com/science/article/pii/S1566253517303901
Erik Cambria,SenticNet 2: A Semantic and Affective Resource for Opinion Mining and Sentiment Analysis,2012,Proceedings of FLAIRS,342,"Erik Cambria, Catherine Havasi, Amir Hussain",Erik Cambria,Amir Hussain,3,"Web 2.0 has changed the ways people communicate, collaborate, and express their opinions and sentiments. But despite social data on the Web being perfectly suitable for human consumption, they remain hardly accessible to machines. To bridge the cognitive and affective gap between word-level natural language data and the concept-level sentiments conveyed by them, we developed SenticNet 2, a publicly available semantic and affective resource for opinion mining and sentiment analysis. SenticNet 2 is built by means of sentic computing, a new paradigm that exploits both AI and Semantic Web techniques to better recognize, interpret, and process natural language opinions. By providing the semantics and sentics (that is, the cognitive and affective information) associated with over 14,000 concepts, SenticNet 2 represents one of the most comprehensive semantic resources for the development of affect-sensitive applications in fields such as social data mining, multimodal affective HCI, and social media marketing.",https://cdn.aaai.org/ocs/4411/4411-21497-1-PB.pdf
Erik Cambria,Ensemble Application of Convolutional and Recurrent Neural Networks for Multi-Label Text Categorization,2017,Proceedings of IJCNN,336,"Guibin Chen, Deheng Ye, Erik Cambria, Jieshan Chen, Zhenchang Xing",Guibin Chen,Zhenchang Xing,5,"Text categorization, or text classification, is one of key tasks for representing the semantic information of documents. Multi-label text categorization is finer-grained approach to text categorization which consists of assigning multiple target labels to documents. It is more challenging compared to the task of multi-class text categorization due to the exponential growth of label combinations. Existing approaches to multi-label text categorization fall short to extract local semantic information and to model label correlations. In this paper, we propose an ensemble application of convolutional and recurrent neural networks to capture both the global and the local textual semantics and to model high-order label correlations while having a tractable computational complexity. Extensive experiments show that our approach achieves the state-of-the-art performance when the CNN-RNN model is trained using a large-sized dataset.",https://ieeexplore.ieee.org/abstract/document/7966144/
Erik Cambria,Sentic LSTM: A Hybrid Network for Targeted Aspect-Based Sentiment Analysis,2018,Cognitive Computation,322,"Yukun Ma, Haiyun Peng, Tahir Khan, Erik Cambria, Amir Hussain",Yukun Ma,Amir Hussain,5,"Sentiment analysis has emerged as one of the most popular natural language processing (NLP) tasks in recent years. A classic setting of the task mainly involves classifying the overall sentiment polarity of the inputs. However, it is based on the assumption that the sentiment expressed in a sentence is unified and consistent, which does not hold in the reality. As a fine-grained alternative of the task, analyzing the sentiment towards a specific target and aspect has drawn much attention from the community for its more practical assumption that sentiment is dependent on a particular set of aspects and entities. Recently, deep neural models have achieved great successes on sentiment analysis. As a functional simulation of the behavior of human brains and one of the most successful deep neural models for sequential data, long short-term memory (LSTM) networks are excellent in learning implicit knowledge …",https://link.springer.com/article/10.1007/s12559-018-9549-x
Erik Cambria,Technical Analysis and Sentiment Embeddings for Market Trend Prediction,2019,Expert Systems with Applications,320,"Andrea Picasso, Simone Merello, Yukun Ma, Luca Oneto, Erik Cambria",Andrea Picasso,Erik Cambria,5,"Stock market prediction is one of the most challenging problems which has been distressing both researchers and financial analysts for more than half a century. To tackle this problem, two completely opposite approaches, namely technical and fundamental analysis, emerged. Technical analysis bases its predictions on mathematical indicators constructed on the stocks price, while fundamental analysis exploits the information retrieved from news, profitability, and macroeconomic factors. The competition between these schools of thought has led to many interesting achievements, however, to date, no satisfactory solution has been found. Our work aims to combine both technical and fundamental analysis through the application of data science and machine learning techniques. In this paper, the stock market prediction problem is mapped in a classification task of time series data. Indicators of technical analysis and …",https://www.sciencedirect.com/science/article/pii/S0957417419304142
Erik Cambria,SenticNet 7: A Commonsense-based Neurosymbolic AI Framework for Explainable Sentiment Analysis,2022,Proceedings of LREC,315,"Erik Cambria, Qian Liu, Sergio Decherchi, Frank Xing, Kenneth Kwok",Erik Cambria,Kenneth Kwok,5,,
Erik Cambria,"The Four Dimensions of Social Network Analysis: An Overview of Research Methods, Applications, and Software Tools",2020,Information Fusion,313,"David Camacho, Angel Panizo-LLedot, Gema Bello-Orgaz, Antonio Gonzalez-Pardo, Erik Cambria",David Camacho,Erik Cambria,5,"Social network based applications have experienced exponential growth in recent years. One of the reasons for this rise is that this application domain offers a particularly fertile place to test and develop the most advanced computational techniques to extract valuable information from the Web. The main contribution of this work is three-fold: (1) we provide an up-to-date literature review of the state of the art on social network analysis (SNA); (2) we propose a set of new metrics based on four essential features (or dimensions) in SNA; (3) finally, we provide a quantitative analysis of a set of popular SNA tools and frameworks. We have also performed a scientometric study to detect the most active research areas and application domains in this area. This work proposes the definition of four different dimensions, namely Pattern & Knowledge discovery, Information Fusion & Integration, Scalability, and Visualization, which …",https://www.sciencedirect.com/science/article/pii/S1566253520302906
Erik Cambria,Sentic computing,2015,Cognitive Computation,296,"Erik Cambria, Amir Hussain",Erik Cambria,Amir Hussain,2,"As the Web rapidly evolves, Web users are evolving with it. In an era of social connectedness, people are becoming more and more enthusiastic about interacting, sharing, and collaborating through social networks, online communities, blogs, Wikis, and other online collaborative media. In recent years, this collective intelligence has spread on many different areas, with particular focus on fields related to everyday life such as commerce, tourism, education, and health, causing the size of the Social Web to expand exponentially.The distillation of knowledge from such a large amount of unstructured information, however, is an extremely difficult task, as the contents of today’s Web are perfectly suitable for human consumption, but remain hardly accessible to machines. The opportunity to capture the opinions of the general public about social events, political movements, company strategies, marketing campaigns, and …",https://link.springer.com/article/10.1007/s12559-015-9325-0
Erik Cambria,Recent Advances in Deep Learning based Dialogue Systems: A Systematic Survey,2023,Artificial Intelligence Review,294,"Jinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, Vinay Adiga, Erik Cambria",Jinjie Ni,Erik Cambria,6,"Dialogue systems are a popular natural language processing (NLP) task as it is promising in real-life applications. It is also a complicated task since many NLP tasks deserving study are involved. As a result, a multitude of novel works on this task are carried out, and most of them are deep learning based due to their outstanding performance. In this survey, we mainly focus on the deep learning based dialogue systems. We comprehensively review state-of-the-art research outcomes in dialogue systems and analyze them from two angles: model type and system type. Specifically, from the angle of model type, we discuss the principles, characteristics, and applications of different models that are widely used in dialogue systems. This will help researchers acquaint these models and see how they are applied in state-of-the-art frameworks, which is rather helpful when designing a new dialogue system. From the angle of …",https://link.springer.com/article/10.1007/s10462-022-10248-8
Erik Cambria,MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare,2022,Proceedings of LREC,272,"Shaoxiong Ji, Tianlin Zhang, Luna Ansari, Jie Fu, Prayag Tiwari, Erik Cambria",Shaoxiong Ji,Erik Cambria,6,"Mental health is a critical issue in modern society, and mental disorders could sometimes turn to suicidal ideation without adequate treatment. Early detection of mental disorders and suicidal ideation from social content provides a potential way for effective social intervention. Recent advances in pretrained contextualized language representations have promoted the development of several domain-specific pretrained models and facilitated several downstream applications. However, there are no existing pretrained language models for mental healthcare. This paper trains and release two pretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to benefit machine learning for the mental healthcare research community. Besides, we evaluate our trained domain-specific models and several variants of pretrained language models on several mental disorder detection benchmarks and demonstrate that language representations pretrained in the target domain improve the performance of mental health detection tasks.",https://arxiv.org/abs/2110.15621
Erik Cambria,Towards an Intelligent Framework for Multimodal Affective Data Analysis,2015,Neural Networks,265,"Soujanya Poria, Erik Cambria, Amir Hussain, Guang-Bin Huang",Soujanya Poria,Guang-Bin Huang,4,"An increasingly large amount of multimodal content is posted on social media websites such as YouTube and Facebook everyday. In order to cope with the growth of such so much multimodal data, there is an urgent need to develop an intelligent multi-modal analysis framework that can effectively extract information from multiple modalities. In this paper, we propose a novel multimodal information extraction agent, which infers and aggregates the semantic and affective information associated with user-generated multimodal data in contexts such as e-learning, e-health, automatic video content tagging and human–computer interaction. In particular, the developed intelligent agent adopts an ensemble feature extraction approach by exploiting the joint use of tri-modal (text, audio and video) features to enhance the multimodal information extraction process. In preliminary experiments using the eNTERFACE dataset …",https://www.sciencedirect.com/science/article/pii/S0893608014002342
Erik Cambria,Suicidal Ideation Detection: A Review of Machine Learning Methods and Applications,2021,IEEE Transactions on Computational Social Systems,262,"Shaoxiong Ji, Shirui Pan, Xue Li, Erik Cambria, Guodong Long, Zi Huang",Shaoxiong Ji,Zi Huang,6,"Suicide is a critical issue in modern society. Early detection and prevention of suicide attempts should be addressed to save people's life. Current suicidal ideation detection (SID) methods include clinical methods based on the interaction between social workers or experts and the targeted individuals and machine learning techniques with feature engineering or deep learning for automatic detection based on online social contents. This article is the first survey that comprehensively introduces and discusses the methods from these categories. Domain-specific applications of SID are reviewed according to their data sources, i.e., questionnaires, electronic health records, suicide notes, and online user content. Several specific tasks and data sets are introduced and summarized to facilitate further research. Finally, we summarize the limitations of current work and provide an outlook of further research directions.",https://ieeexplore.ieee.org/abstract/document/9199553/
Erik Cambria,BiERU: Bidirectional Emotional Recurrent Unit for Conversational Sentiment Analysis,2022,Neurocomputing,261,"Wei Li, Wei Shao, Shaoxiong Ji, Erik Cambria",Wei Li,Erik Cambria,4,"Sentiment analysis in conversations has gained increasing attention in recent years for the growing amount of applications it can serve, e.g., sentiment analysis, recommender systems, and human-robot interaction. The main difference between conversational sentiment analysis and single sentence sentiment analysis is the existence of context information that may influence the sentiment of an utterance in a dialogue. How to effectively encode contextual information in dialogues, however, remains a challenge. Existing approaches employ complicated deep learning structures to distinguish different parties in a conversation and then model the context information. In this paper, we propose a fast, compact and parameter-efficient party-ignorant framework named bidirectional emotional recurrent unit for conversational sentiment analysis. In our system, a generalized neural tensor block followed by a two-channel …",https://www.sciencedirect.com/science/article/pii/S0925231221014351
Erik Cambria,Sentiment and Sarcasm Classification with Multitask Learning,2019,IEEE Intelligent Systems,259,"Navonil Majumder, Soujanya Poria, Haiyun Peng, Niyati Chhaya, Erik Cambria, Alexander Gelbukh",Navonil Majumder,Alexander Gelbukh,6,"Sentiment classification and sarcasm detection are both important natural language processing tasks. Sentiment is always coupled with sarcasm where intensive emotion is expressed. Nevertheless, most literature considers them as two separate tasks. We argue that knowledge in sarcasm detection can also be beneficial to sentiment classification and vice versa. We show that these two tasks are correlated, and present a multitask learning-based framework using a deep neural network that models this correlation to improve the performance of both tasks in a multitask learning setting. Our method outperforms the state of the art by 3–4% in the benchmark dataset.",https://ieeexplore.ieee.org/abstract/document/8766192/
Erik Cambria,A Review of Sentiment Analysis Research in Arabic Language,2020,Future Generation Computer Systems,254,"Oumaima Oueslati, Erik Cambria, Moez Ben HajHmida, Habib Ounelli",Oumaima Oueslati,Habib Ounelli,4,"Sentiment analysis is a task of natural language processing that has recently attracted increasing attention. However, sentiment analysis research has mainly been carried out for the English language. Although Arabic is ramping up as one of the most used languages on the Internet, only a few studies have focused on Arabic sentiment analysis so far. In this paper, we carry out an in-depth qualitative study of the most important research works in this context by discussing strengths and limitations of existing approaches. In particular, we survey both approaches that leverage machine translation or transfer learning to adapt English resources to Arabic and approaches that stem directly from the Arabic language.",https://www.sciencedirect.com/science/article/pii/S0167739X19311537
Erik Cambria,How Intense Are You? Predicting Intensities of Emotions and Sentiments using Stacked Ensemble,2020,IEEE Computational Intelligence Magazine,247,"Md Shad Akhtar, Asif Ekbal, Erik Cambria",Md Shad Akhtar,Erik Cambria,3,"Emotions and sentiments are subjective in nature. They differ on a case-to-case basis. However, predicting only the emotion and sentiment does not always convey complete information. The degree or level of emotions and sentiments often plays a crucial role in understanding the exact feeling within a single class (e.g., `good' versus `awesome'). In this paper, we propose a stacked ensemble method for predicting the degree of intensity for emotion and sentiment by combining the outputs obtained from several deep learning and classical feature-based models using a multi-layer perceptron network. We develop three deep learning models based on convolutional neural network, long short-term memory and gated recurrent unit and one classical supervised model based on support vector regression. We evaluate our proposed technique for two problems, i.e., emotion analysis in the generic domain and sentiment …",https://ieeexplore.ieee.org/abstract/document/8956109/
Erik Cambria,A Survey on Empathetic Dialogue Systems,2020,Information Fusion,247,"Yukun Ma, Khanh Linh Nguyen, Frank Xing, Erik Cambria",Yukun Ma,Erik Cambria,4,"Dialogue systems have achieved growing success in many areas thanks to the rapid advances of machine learning techniques. In the quest for generating more human-like conversations, one of the major challenges is to learn to generate responses in a more empathetic manner. In this review article, we focus on the literature of empathetic dialogue systems, whose goal is to enhance the perception and expression of emotional states, personal preference, and knowledge. Accordingly, we identify three key features that underpin such systems: emotion-awareness, personality-awareness, and knowledge-accessibility. The main goal of this review is to serve as a comprehensive guide to research and development on empathetic dialogue systems and to suggest future directions in this domain.",https://www.sciencedirect.com/science/article/pii/S1566253520303092
Erik Cambria,Anaphora and Coreference Resolution: A Review,2020,Information Fusion,239,"Rhea Sukthanker, Soujanya Poria, Erik Cambria, Ramkumar Thirunavukarasu",Rhea Sukthanker,Ramkumar Thirunavukarasu,4,"Coreference resolution aims at resolving repeated references to an object in a document and forms a core component of natural language processing (NLP) research. When used as a component in the processing pipeline of other NLP fields like machine translation, sentiment analysis, paraphrase detection, and summarization, coreference resolution has a potential to highly improve accuracy. A direction of research closely related to coreference resolution is anaphora resolution. Existing literature is often ambiguous in its usage of these terms and often uses them interchangeably. Through this review article, we clarify the scope of these two tasks. We also carry out a detailed analysis of the datasets, evaluation metrics and research methods that have been adopted to tackle these NLP problems. This survey is motivated by the aim of providing readers with a clear understanding of what constitutes these two tasks in …",https://www.sciencedirect.com/science/article/pii/S1566253519303677
Erik Cambria,CASCADE: Contextual Sarcasm Detection in Online Discussion Forums,2018,Proceedings of COLING,239,"Devamanyu Hazarika, Soujanya Poria, Sruthi Gorantla, Erik Cambria, Roger Zimmermann, Rada Mihalcea",Devamanyu Hazarika,Rada Mihalcea,6,"The literature in automated sarcasm detection has mainly focused on lexical, syntactic and semantic-level analysis of text. However, a sarcastic sentence can be expressed with contextual presumptions, background and commonsense knowledge. In this paper, we propose CASCADE (a ContextuAl SarCasm DEtector) that adopts a hybrid approach of both content and context-driven modeling for sarcasm detection in online social media discussions. For the latter, CASCADE aims at extracting contextual information from the discourse of a discussion thread. Also, since the sarcastic nature and form of expression can vary from person to person, CASCADE utilizes user embeddings that encode stylometric and personality features of the users. When used along with content-based feature extractors such as Convolutional Neural Networks (CNNs), we see a significant boost in the classification performance on a large Reddit corpus.",https://arxiv.org/abs/1805.06413
Erik Cambria,Ensemble Application of Convolutional Neural Networks and Multiple Kernel Learning for Multimodal Sentiment Analysis,2017,Neurocomputing,238,"Soujanya Poria, Haiyun Peng, Amir Hussain, Newton Howard, Erik Cambria",Soujanya Poria,Erik Cambria,5,"The advent of the Social Web has enabled anyone with an Internet connection to easily create and share their ideas, opinions and content with millions of other people around the world. In pace with a global deluge of videos from billions of computers, smartphones, tablets, university projectors and security cameras, the amount of multimodal content on the Web has been growing exponentially, and with that comes the need for decoding such information into useful knowledge. In this paper, a multimodal affective data analysis framework is proposed to extract user opinion and emotions from video content. In particular, multiple kernel learning is used to combine visual, audio and textual modalities. The proposed framework outperforms the state-of-the-art model in multimodal sentiment analysis research with a margin of 10–13% and 3–5% accuracy on polarity detection and emotion recognition, respectively. The …",https://www.sciencedirect.com/science/article/pii/S0925231217302023
Erik Cambria,Feature Ensemble Plus Sample Selection: Domain Adaptation for Sentiment Classification,2013,IEEE Intelligent Systems,236,"Rui Xia, Chengqing Zong, Xuelei Hu, Erik Cambria",Rui Xia,Erik Cambria,4,"Domain adaptation problems often arise often in the field of sentiment classification. Here, the feature ensemble plus sample selection (SS-FE) approach is proposed, which takes labeling and instance adaptation into account. A feature ensemble (FE) model is first proposed to learn a new labeling function in a feature reweighting manner. Furthermore, a PCA-based sample selection (PCA-SS) method is proposed as an aid to FE. Experimental results show that the proposed SS-FE approach could gain significant improvements, compared to FE or PCA-SS, because of its comprehensive consideration of both labeling adaptation and instance adaptation.",https://ieeexplore.ieee.org/abstract/document/6461869/
Erik Cambria,Semi-Supervised Learning for Big Social Data Analysis,2018,Neurocomputing,232,"Amir Hussain, Erik Cambria",Amir Hussain,Erik Cambria,2,"In an era of social media and connectivity, web users are becoming increasingly enthusiastic about interacting, sharing, and working together through online collaborative media. More recently, this collective intelligence has spread to many different areas, with a growing impact on everyday life, such as in education, health, commerce and tourism, leading to an exponential growth in the size of the social Web. However, the distillation of knowledge from such unstructured Big data is, an extremely challenging task. Consequently, the semantic and multimodal contents of the Web in this present day are, whilst being well suited for human use, still barely accessible to machines. In this work, we explore the potential of a novel semi-supervised learning model based on the combined use of random projection scaling as part of a vector space model, and support vector machines to perform reasoning on a knowledge base …",https://www.sciencedirect.com/science/article/pii/S0925231217316363
Erik Cambria,Multi-Level Multiple Attentions for Contextual Multimodal Sentiment Analysis,2017,Proceedings of ICDM,229,"Soujanya Poria, Erik Cambria, Devamanyu Hazarika, Navonil Majumder, Amir Zadeh, Louis-Philippe Morency",Soujanya Poria,Louis-Philippe Morency,6,"Multimodal sentiment analysis involves identifying sentiment in videos and is a developing field of research. Unlike current works, which model utterances individually, we propose a recurrent model that is able to capture contextual information among utterances. In this paper, we also introduce attentionbased networks for improving both context learning and dynamic feature fusion. Our model shows 6-8% improvement over the state of the art on a benchmark dataset.",https://ieeexplore.ieee.org/abstract/document/8215597/
Erik Cambria,A Concept-Level Approach to the Analysis of Online Review Helpfulness,2016,Computers in Human Behavior,225,"Aika Qazi, Karim Bux Shah Syed, Ram Gopal Raj, Erik Cambria, Muhammad Tahir, Daniyal Alghazzawi",Aika Qazi,Daniyal Alghazzawi,6,"Helpfulness of online reviews serves multiple needs of different Web users. Several types of factors can drive reviews' helpfulness. This study focuses on uninvestigated factors by looking at not just the quantitative factors (such as the number of concepts), but also qualitative aspects of reviewers (including review types such as the regular, comparative and suggestive reviews and reviewer helpfulness) and builds a conceptual model for helpfulness prediction. The set of 1500 reviews were randomly collected from TripAdvisor.com across multiple hotels for analysis. A set of four hypotheses were used to test the proposed model. Our results suggest that the number of concepts contained in a review, the average number of concepts per sentence, and the review type contribute to the perceived helpfulness of online reviews. The regular reviews were not statistically significant predictors of helpfulness. As a result, review …",https://www.sciencedirect.com/science/article/pii/S0747563215302995
Erik Cambria,Multimodal Sentiment Analysis: Addressing Key Issues and Setting up the Baselines,2018,IEEE Intelligent Systems,224,"Soujanya Poria, Navonil Majumder, Devamanyu Hazarika, Erik Cambria, Amir Hussain, Alexander Gelbukh",Soujanya Poria,Alexander Gelbukh,6,"We compile baselines, along with dataset split, for multimodal sentiment analysis. In this paper, we explore three different deep-learning-based architectures for multimodal sentiment classification, each improving upon the previous. Further, we evaluate these architectures with multiple datasets with fixed train/test partition. We also discuss some major issues, frequently ignored in multimodal sentiment analysis research, e.g., the role of speaker-exclusive models, the importance of different modalities, and generalizability. This framework illustrates the different facets of analysis to be considered while performing multimodal sentiment analysis and, hence, serves as a new benchmark for future research in this emerging field.",https://ieeexplore.ieee.org/abstract/document/8636432/
Erik Cambria,AffectiveSpace 2: Enabling Affective Intuition for Concept-Level Sentiment Analysis,2015,Proceedings of AAAI,222,"Erik Cambria, Jie Fu, Federica Bisio, Soujanya Poria",Erik Cambria,Soujanya Poria,4,"Predicting the affective valence of unknown multi-word expressions is key for concept-level sentiment analysis. AffectiveSpace 2 is a vector space model, built by means of random projection, that allows for reasoning by analogy on natural language con-cepts. By reducing the dimensionality of affec-tive common-sense knowledge, the model allows semantic features associated with concepts to be generalized and, hence, allows concepts to be intu-itively clustered according to their semantic and affective relatedness. Such an affective intuition (so called because it does not rely on explicit fea-tures, but rather on implicit analogies) enables the inference of emotions and polarity conveyed by multi-word expressions, thus achieving efficient concept-level sentiment analysis.",https://ojs.aaai.org/index.php/AAAI/article/view/9230
Erik Cambria,Multilingual Sentiment Analysis: From Formal to Informal and Scarce Resource Languages,2017,Artificial Intelligence Review,218,"Siaw Ling Lo, Erik Cambria, Raymond Chiong, David Cornforth",Siaw Ling Lo,David Cornforth,4,"The ability to analyse online user-generated content related to sentiments (e.g., thoughts and opinions) on products or policies has become a de-facto skillset for many companies and organisations. Besides the challenge of understanding formal textual content, it is also necessary to take into consideration the informal and mixed linguistic nature of online social media languages, which are often coupled with localised slang as a way to express ‘true’ feelings. Due to the multilingual nature of social media data, analysis based on a single official language may carry the risk of not capturing the overall sentiment of online content. While efforts have been made to understand multilingual sentiment analysis based on a range of informal languages, no significant electronic resource has been built for these localised languages. This paper reviews the various current approaches and tools used for multilingual …",https://link.springer.com/article/10.1007/s10462-016-9508-4
Erik Cambria,Modelling Customer Satisfaction from Online Reviews Using Ensemble Neural Network and Effect-based Kano Model,2019,International Journal of Production Research,216,"Jian-Wu Bi, Yang Liu, Zhi-Ping Fan, Erik Cambria",Jian-Wu Bi,Erik Cambria,4,"With the rapid advances in information technology, an increasing number of online reviews are posted daily on the Internet. Such reviews can serve as a promising data source to understand customer satisfaction. To this end, in this paper, we proposed a method for modelling customer satisfaction from online reviews. In the method, customer satisfaction dimensions (CSDs) are first extracted from online reviews based on latent dirichlet allocation (LDA). The sentiment orientations of the extracted CSDs are identified using a support vector machine (SVM). Then, considering the existence of complex relationships among different CSDs and the customer satisfaction, an ensemble neural network based model (ENNM) is proposed to measure the effects of customer sentiments toward different CSDs on customer satisfaction. On this basis, to identify the category of each CSD from the customer’s perspective, an effect …",https://www.tandfonline.com/doi/abs/10.1080/00207543.2019.1574989
Erik Cambria,EmoSenticSpace: A Novel Framework for Affective Common-Sense Reasoning,2014,Knowledge-Based Systems,215,"Soujanya Poria, Alexander Gelbukh, Erik Cambria, Amir Hussain, Guang-Bin Huang",Soujanya Poria,Guang-Bin Huang,5,"Emotions play a key role in natural language understanding and sensemaking. Pure machine learning usually fails to recognize and interpret emotions in text accurately. The need for knowledge bases that give access to semantics and sentics (the conceptual and affective information) associated with natural language is growing exponentially in the context of big social data analysis. To this end, this paper proposes EmoSenticSpace, a new framework for affective common-sense reasoning that extends WordNet-Affect and SenticNet by providing both emotion labels and polarity scores for a large set of natural language concepts. The framework is built by means of fuzzy c-means clustering and support-vector-machine classification, and takes into account a number of similarity measures, including point-wise mutual information and emotional affinity. EmoSenticSpace was tested on three emotion-related natural …",https://www.sciencedirect.com/science/article/pii/S0950705114002329
Erik Cambria,Sentic Computing for Social Media Marketing,2012,Multimedia Tools and Applications,210,"Erik Cambria, Marco Grassi, Amir Hussain, Catherine Havasi",Erik Cambria,Catherine Havasi,4,"In a world in which millions of people express their opinions about commercial products in blogs, wikis, fora, chats and social networks, the distillation of knowledge from this huge amount of unstructured information can be a key factor for marketers who want to create an image or identity in the minds of their customers for their product, brand or organization. Opinion mining for product positioning, in fact, is getting a more and more popular research field but the extraction of useful information from social media is not a simple task. In this work we merge AI and Semantic Web techniques to extract, encode and represent this unstructured information. In particular, we use Sentic Computing, a multi-disciplinary approach to opinion mining and sentiment analysis, to semantically and affectively analyze text and encode results in a semantic aware format according to different web ontologies. Eventually we …",https://link.springer.com/article/10.1007/s11042-011-0815-0
Erik Cambria,A Review of Sentiment Analysis Research in Chinese Language,2017,Cognitive Computation,200,"Haiyun Peng, Erik Cambria, Amir Hussain",Haiyun Peng,Amir Hussain,3,"Research on sentiment analysis in English language has undergone major developments in recent years. Chinese sentiment analysis research, however, has not evolved significantly despite the exponential growth of Chinese e-business and e-markets. This review paper aims to study past, present, and future of Chinese sentiment analysis from both monolingual and multilingual perspectives. The constructions of sentiment corpora and lexica are first introduced and summarized. Following, a survey of monolingual sentiment classification in Chinese via three different classification frameworks is conducted. Finally, sentiment classification based on the multilingual approach is introduced. After an overview of the literature, we propose that a more human-like (cognitive) representation of Chinese concepts and their inter-connections could overcome the scarceness of available resources and, hence, improve …",https://link.springer.com/article/10.1007/s12559-017-9470-8
Erik Cambria,The Biases of Pre-Trained Language Models: An Empirical Study on Prompt-based Sentiment Analysis and Emotion Detection,2023,IEEE Transactions on Affective Computing,191,"Rui Mao, Qian Liu, Kai He, Wei Li, Erik Cambria",Rui Mao,Erik Cambria,5,"Thanks to the breakthrough of large-scale pre-trained language model (PLM) technology, prompt-based classification tasks, e.g., sentiment analysis and emotion detection, have raised increasing attention. Such tasks are formalized as masked language prediction tasks which are in line with the pre-training objects of most language models. Thus, one can use a PLM to infer the masked words in a downstream task, then obtaining label predictions with manually defined label-word mapping templates. Prompt-based affective computing takes the advantages of both neural network modeling and explainable symbolic representations. However, there still remain many unclear issues related to the mechanisms of PLMs and prompt-based classification. We conduct a systematic empirical study on prompt-based sentiment analysis and emotion detection to study the biases of PLMs towards affective computing. We find …",https://ieeexplore.ieee.org/abstract/document/9881877/
Erik Cambria,The Hourglass Model Revisited,2020,IEEE Intelligent Systems,189,"Yosephine Susanto, A Livingstone, Bee Chin Ng, Erik Cambria",Yosephine Susanto,Erik Cambria,4,"Recent developments in the field of AI have fostered multidisciplinary research in various disciplines, including computer science, linguistics, and psychology. Intelligence, in fact, is much more than just IQ: it comprises many other kinds of intelligence, including physical intelligence, cultural intelligence, linguistic intelligence, and emotional intelligence (EQ). While traditional classification tasks and standard phenomena in computer science are easy to define, however, emotions are still a rather mysterious subject of study. That is why so many different emotion classifications have been proposed in the literature and there is still no common agreement on a universal emotion categorization model. In this article, we revisit the Hourglass of Emotions, an emotion categorization model optimized for polarity detection, based on some recent empirical evidence in the context of sentiment analysis. This new model does not …",https://ieeexplore.ieee.org/abstract/document/9237283/
Erik Cambria,Sentic LDA: Improving on LDA with Semantic Similarity for Aspect-Based Sentiment Analysis,2016,,188,"Soujanya Poria, Iti Chaturvedi, Erik Cambria, Federica Bisio",Soujanya Poria,Federica Bisio,4,"The advent of the Social Web has provided netizens with new tools for creating and sharing, in a time- and cost-efficient way, their contents, ideas, and opinions with virtually the millions of people connected to the World Wide Web. This huge amount of information, however, is mainly unstructured as specifically produced for human consumption and, hence, it is not directly machine-processable. In order to enable a more efficient passage from unstructured information to structured data, aspect-based opinion mining models the relations between opinion targets contained in a document and the polarity values associated with these. Because aspects are often implicit, however, spotting them and calculating their respective polarity is an extremely difficult task, which is closer to natural language understanding rather than natural language processing. To this end, Sentic LDA exploits common-sense reasoning to shift …",https://ieeexplore.ieee.org/abstract/document/7727784/
Erik Cambria,Fuzzy Commonsense Reasoning for Multimodal Sentiment Analysis,2019,Pattern Recognition Letters,185,"Iti Chaturvedi, Ranjan Satapathy, Sandro Cavallari, Erik Cambria",Iti Chaturvedi,Erik Cambria,4,"The majority of user-generated content posted online is in the form of text, images and videos but also physiological signals in games. AffectiveSpace is a vector space of affective commonsense available for English text but not for other languages nor other modalities such as electrocardiogram signals. We overcome this limitation by using deep learning to extract features from each modality and then projecting them to a common AffectiveSpace that has been clustered into different emotions. Because, in the real world, individuals tend to have partial or mixed sentiments about an opinion target, we use a fuzzy logic classifier to predict the degree of a particular emotion in AffectiveSpace. The combined model of deep convolutional neural networks and fuzzy logic is termed Convolutional Fuzzy Sentiment Classifier. Lastly, because the computational complexity of a fuzzy classifier is exponential with respect to the …",https://www.sciencedirect.com/science/article/pii/S0167865519301394
Erik Cambria,"Polarity Shift Detection, Elimination and Ensemble: A Three-Stage Model for Document-Level Sentiment Analysis",2016,Information Processing & Management,184,"Rui Xia, Feng Xu, Jianfei Yu, Yong Qi, Erik Cambria",Rui Xia,Erik Cambria,5,"The polarity shift problem is a major factor that affects classification performance of machine-learning-based sentiment analysis systems. In this paper, we propose a three-stage cascade model to address the polarity shift problem in the context of document-level sentiment classification. We first split each document into a set of subsentences and build a hybrid model that employs rules and statistical methods to detect explicit and implicit polarity shifts, respectively. Secondly, we propose a polarity shift elimination method, to remove polarity shift in negations. Finally, we train base classifiers on training subsets divided by different types of polarity shifts, and use a weighted combination of the component classifiers for sentiment classification. The results on a range of experiments illustrate that our approach significantly outperforms several alternative methods for polarity shift detection and elimination.",https://www.sciencedirect.com/science/article/pii/S0306457315000485
Erik Cambria,A Generative Model for Category Text Generation,2018,Information Sciences,180,"Yang Li, Quan Pan, Suhang Wang, Tao Yang, Erik Cambria",Yang Li,Erik Cambria,5,"The neural network model has been the fulcrum of the so-called AI revolution. Although very powerful for pattern-recognition tasks, however, the model has two main drawbacks: it tends to overfit when the training dataset is small, and it is unable to accurately capture category information when the class number is large. In this paper, we combine reinforcement learning, generative adversarial networks, and recurrent neural networks to build a new model, termed category sentence generative adversarial network (CS-GAN). Not only the proposed model is able to generate category sentences that enlarge the original dataset, but also it helps improve its generalization capability during supervised training. We evaluate the performance of CS-GAN for the task of sentiment analysis. Quantitative evaluation exhibits the accuracy improvement in polarity detection on a small dataset with high category information.",https://www.sciencedirect.com/science/article/pii/S0020025518302366
Erik Cambria,Bayesian Network Based Extreme Learning Machine for Subjectivity Detection,2018,Journal of the Franklin Institute,179,"Iti Chaturvedi, Edoardo Ragusa, Paolo Gastaldo, Rodolfo Zunino, Erik Cambria",Iti Chaturvedi,Erik Cambria,5,"Subjectivity detection is a task of natural language processing that aims to remove ‘factual’ or ‘neutral’ content, i.e., objective text that does not contain any opinion, from online product reviews. Such a pre-processing step is crucial to increase the accuracy of sentiment analysis systems, as these are usually optimized for the binary classification task of distinguishing between positive and negative content. In this paper, we extend the extreme learning machine (ELM) paradigm to a novel framework that exploits the features of both Bayesian networks and fuzzy recurrent neural networks to perform subjectivity detection. In particular, Bayesian networks are used to build a network of connections among the hidden neurons of the conventional ELM configuration in order to capture dependencies in high-dimensional data. Next, a fuzzy recurrent neural network inherits the overall structure generated by the Bayesian …",https://www.sciencedirect.com/science/article/pii/S0016003217303009
Erik Cambria,User Reviews: Sentiment Analysis using Lexicon Integrated Two-Channel CNN–LSTM​ Family Models,2020,Applied Soft Computing,176,"Wei Li, Luyao Zhu, Yong Shi, Kun Guo, Erik Cambria",Wei Li,Erik Cambria,5,"Sentiment analysis, which refers to the task of detecting whether a textual item (e.g., a product review and a blog post) expresses a positive or negative opinion in general or about a given entity (e.g., a product, person, or policy), has received increasing attention in recent years. It serves as an important role in natural language processing. User generated content, like tourism reviews, developed dramatically during the past years, generating a large amount of unstructured data from which it is hard to obtain useful information. Due to the changes in textual order, sequence length and complicated logic, it is still a challenging task to predict the exact sentiment polarities of the user reviews, especially for fine-grained sentiment classification. In this paper, we first propose sentiment padding, a novel padding method compared with zero padding, making the input data sample of a consistent size and improving the …",https://www.sciencedirect.com/science/article/pii/S1568494620303756
Erik Cambria,A Tale of Two Epidemics: Contextual Word2Vec for Classifying Twitter Streams during Outbreaks,2019,Information Processing & Management,175,"Aparup Khatua, Apalak Khatua, Erik Cambria",Aparup Khatua,Erik Cambria,3,"Unstructured tweet feeds are becoming the source of real-time information for various events. However, extracting actionable information in real-time from this unstructured text data is a challenging task. Hence, researchers are employing word embedding approach to classify unstructured text data. We set our study in the contexts of the 2014 Ebola and 2016 Zika outbreaks and probed the accuracy of domain-specific word vectors for identifying crisis-related actionable tweets. Our findings suggest that relatively smaller domain-specific input corpora from the Twitter corpus are better in extracting meaningful semantic relationship than generic pre-trained Word2Vec (contrived from Google News) or GloVe (of Stanford NLP group). However, domain-specific quality tweet corpora during the early stages of outbreaks are normally scant, and identifying actionable tweets during early stages is crucial to stemming the …",https://www.sciencedirect.com/science/article/pii/S0306457317307495
Erik Cambria,Towards Scalable and Reliable Capsule Networks for Challenging NLP Applications,2019,Proceedings of ACL,174,"Wei Zhao, Haiyun Peng, Steffen Eger, Erik Cambria, Min Yang",Wei Zhao,Min Yang,5,"Obstacles hindering the development of capsule networks for challenging NLP applications include poor scalability to large output spaces and less reliable routing processes. In this paper, we introduce: 1) an agreement score to evaluate the performance of routing processes at instance level; 2) an adaptive optimizer to enhance the reliability of routing; 3) capsule compression and partial routing to improve the scalability of capsule networks. We validate our approach on two NLP tasks, namely: multi-label text classification and question answering. Experimental results show that our approach considerably improves over strong competitors on both tasks. In addition, we gain the best results in low-resource settings with few training instances.",https://arxiv.org/abs/1906.02829
Erik Cambria,Label Embedding for Zero-Shot Fine-Grained Named Entity Typing,2016,Proceedings of COLING,173,"Yukun Ma, Erik Cambria, Sa Gao",Yukun Ma,Sa Gao,3,"Named entity typing is the task of detecting the types of a named entity in context. For instance, given “Eric is giving a presentation”, our goal is to infer that ‘Eric’is a speaker or a presenter and a person. Existing approaches to named entity typing cannot work with a growing type set and fails to recognize entity mentions of unseen types. In this paper, we present a label embedding method that incorporates prototypical and hierarchical information to learn pre-trained label embeddings. In addition, we adapt a zero-shot learning framework that can predict both seen and previously unseen entity types. We perform evaluation on three benchmark datasets with two settings: 1) few-shots recognition where all types are covered by the training set; and 2) zero-shot recognition where fine-grained types are assumed absent from training set. Results show that prior knowledge encoded using our label embedding methods can significantly boost the performance of classification for both cases.",https://aclanthology.org/C16-1017/
Erik Cambria,Sentiment Data Flow Analysis by Means of Dynamic Linguistic Patterns,2015,IEEE Computational Intelligence Magazine,171,"Soujanya Poria, Erik Cambria, Alexander Gelbukh, Federica Bisio, Amir Hussain",Soujanya Poria,Amir Hussain,5,"Emulating the human brain is one of the core challenges of computational intelligence, which entails many key problems of artificial intelligence, including understanding human language, reasoning, and emotions. In this work, computational intelligence techniques are combined with common-sense computing and linguistics to analyze sentiment data flows, i.e., to automatically decode how humans express emotions and opinions via natural language. The increasing availability of social data is extremely beneficial for tasks such as branding, product positioning, corporate reputation management, and social media marketing. The elicitation of useful information from this huge amount of unstructured data, however, remains an open challenge. Although such data are easily accessible to humans, they are not suitable for automatic processing: machines are still unable to effectively and dynamically interpret the …",https://ieeexplore.ieee.org/abstract/document/7296727/
Erik Cambria,SeNTU: Sentiment Analysis of Tweets by Combining a Rule-Based Classifier with Supervised Learning,2015,,171,"Prerna Chikersal, Soujanya Poria, Erik Cambria",Prerna Chikersal,Erik Cambria,3,"We describe a Twitter sentiment analysis system developed by combining a rule-based classifier with supervised learning. We submitted our results for the message-level subtask in SemEval 2015 Task 10, and achieved a F1-score of 57.06%. The rule-based classifier is based on rules that are dependent on the occurrences of emoticons and opinion words in tweets. Whereas, the Support Vector Machine (SVM) is trained on semantic, dependency, and sentiment lexicon based features. The tweets are classified as positive, negative or unknown by the rule-based classifier, and as positive, negative or neutral by the SVM. The results we obtained show that rules can help refine the SVM’s predictions.",https://aclanthology.org/S15-2108.pdf
Erik Cambria,Knowledge-Based Approaches to Concept-Level Sentiment Analysis,2013,IEEE Intelligent Systems,171,"Erik Cambria, Björn Schuller, Bing Liu, Haixun Wang, Catherine Havasi",Erik Cambria,Catherine Havasi,5,"The guest editors introduce novel approaches to opinion mining and sentiment analysis that go beyond a mere word-level analysis of text and provide concept-level methods. Such approaches allow a more efficient passage from (unstructured) textual information to (structured) machine-processable data, in potentially any domain.",https://ieeexplore.ieee.org/abstract/document/6547971/
Erik Cambria,Learning Word Representations for Sentiment Analysis,2017,Cognitive Computation,170,"Yang Li, Quan Pan, Tao Yang, Suhang Wang, Jiliang Tang, Erik Cambria",Yang Li,Erik Cambria,6,"Word embedding has been proven to be a useful model for various natural language processing tasks. Traditional word embedding methods merely take into account word distributions independently from any specific tasks. Hence, the resulting representations could be sub-optimal for a given task. In the context of sentiment analysis, there are various types of prior knowledge available, e.g., sentiment labels of documents from available datasets or polarity values of words from sentiment lexicons. We incorporate such prior sentiment information at both word level and document level in order to investigate the influence each word has on the sentiment label of both target word and context words. By evaluating the performance of sentiment analysis in each category, we find the best way of incorporating prior sentiment information. Experimental results on real-world datasets demonstrate that the word …",https://link.springer.com/article/10.1007/s12559-017-9492-2
Erik Cambria,Learning Multi-grained Aspect Target Sequence for Chinese Sentiment Analysis,2018,Knowledge-Based Systems,169,"Haiyun Peng, Yukun Ma, Yang Li, Erik Cambria",Haiyun Peng,Erik Cambria,4,"Aspect-based sentiment analysis aims at identifying sentiment polarity towards aspect targets in a sentence. Previously, the task was modeled as a sentence-level sentiment classification problem that treated aspect targets as a hint. Such approaches oversimplify the problem by averaging word embeddings when the aspect target is a multi-word sequence. In this paper, we formalize the problem from a different perspective, i.e., that sentiment at aspect target level should be the main focus. Due to the fact that written Chinese is very rich and complex, Chinese aspect targets can be studied at three different levels of granularity: radical, character and word. Thus, we propose to explicitly model the aspect target and conduct sentiment classification directly at the aspect target level via three granularities. Moreover, we study two fusion methods for such granularities in the task of Chinese aspect-level sentiment analysis …",https://www.sciencedirect.com/science/article/pii/S0950705118300972
Erik Cambria,Will Affective Computing Emerge from Foundation Models and General Artificial Intelligence? A First Evaluation of ChatGPT,2023,IEEE Intelligent Systems,168,"Mostafa M Amin, Erik Cambria, Björn W Schuller",Mostafa M Amin,Björn W Schuller,3,"ChatGPT has shown the potential of emerging general artificial intelligence capabilities, as it has demonstrated competent performance across many natural language processing tasks. In this work, we evaluate the capabilities of ChatGPT to perform text classification on three affective computing problems, namely, big-five personality prediction, sentiment analysis, and suicide tendency detection. We utilize three baselines, a robust language model (RoBERTa-base), a legacy word model with pretrained embeddings (Word2Vec), and a simple bag-of-words (BoW) baseline. Results show that the RoBERTa model trained for a specific downstream task generally has a superior performance. On the other hand, ChatGPT provides decent results and is relatively comparable to the Word2Vec and BoW baselines. ChatGPT further shows robustness against noisy data, where the Word2Vec model achieves worse results …",https://ieeexplore.ieee.org/abstract/document/10111523/
Erik Cambria,Word Polarity Disambiguation Using Bayesian Model and Opinion-Level Features,2015,Cognitive Computation,162,"Yunqing Xia, Erik Cambria, Amir Hussain, Huan Zhao",Yunqing Xia,Huan Zhao,4,"Contextual polarity ambiguity is an important problem in sentiment analysis. Many opinion keywords carry varying polarities in different contexts, posing huge challenges for sentiment analysis research. Previous work on contextual polarity disambiguation makes use of term-level context, such as words and patterns, and resolves the polarity with a range of rule-based, statistics-based or machine learning methods. The major shortcoming of these methods lies in that the term-level features sometimes are ineffective in resolving the polarity. In this work, opinion-level context is explored, in which intra-opinion features and inter-opinion features are finely defined. To enable effective use of opinion-level features, the Bayesian model is adopted to resolve the polarity in a probabilistic manner. Experiments with the Opinmine corpus demonstrate that opinion-level features can make a significant contribution in word …",https://link.springer.com/article/10.1007/s12559-014-9298-4
Erik Cambria,OntoSenticNet: A Commonsense Ontology for Sentiment Analysis,2018,IEEE Intelligent Systems,161,"Mauro Dragoni, Soujanya Poria, Erik Cambria",Mauro Dragoni,Erik Cambria,3,"In this work, we present OntoSenticNet, a commonsense ontology for sentiment analysis based on SenticNet, a semantic network of 100,000 concepts based on conceptual primitives. The key characteristics of OntoSenticNet are: (i) the definition of precise conceptual hierarchy and properties associating concepts and sentiment values; (ii) the support for connecting external information (e.g., word embedding, domain information, and different polarity representations) to each individual defined within the ontology; and (iii) the capability of associating each concept with annotations contained in external resources (e.g., documents and multimodal resources).",https://ieeexplore.ieee.org/abstract/document/8423526/
Erik Cambria,Real-Time Video Emotion Recognition based on Reinforcement Learning and Domain Knowledge,2022,IEEE Transactions on Circuits and Systems for Video Technology,159,"Ke Zhang, Yuanqing Li, Jingyu Wang, Erik Cambria, Xuelong Li",Ke Zhang,Xuelong Li,5,"Multimodal emotion recognition in conversational videos (ERC) develops rapidly in recent years. To fully extract the relative context from video clips, most studies build their models on the entire dialogues which make them lack of real-time ERC ability. Different from related researches, a novel multimodal emotion recognition model for conversational videos based on reinforcement learning and domain knowledge (ERLDK) is proposed in this paper. In ERLDK, the reinforcement learning algorithm is introduced to conduct real-time ERC with the occurrence of conversations. The collection of history utterances is composed as an emotion-pair which represents the multimodal context of the following utterance to be recognized. Dueling deep-Q-network (DDQN) based on gated recurrent unit (GRU) layers is designed to learn the correct action from the alternative emotion categories. Domain knowledge is extracted from …",https://ieeexplore.ieee.org/abstract/document/9400391/
Erik Cambria,A Survey on Personality-Aware Recommendation Systems,2022,Artificial Intelligence Review,153,"Sahraoui Dhelim, Nyothiri Aung, Mohammed Amine Bouras, Huansheng Ning, Erik Cambria",Sahraoui Dhelim,Erik Cambria,5,"With the emergence of personality computing as a new research field related to artificial intelligence and personality psychology, we have witnessed an unprecedented proliferation of personality-aware recommendation systems. Unlike conventional recommendation systems, these new systems solve traditional problems such as the cold start and data sparsity problems. This survey aims to study and systematically classify personality-aware recommendation systems. To the best of our knowledge, this survey is the first that focuses on personality-aware recommendation systems. We explore the different design choices of personality-aware recommendation systems, by comparing their personality modeling methods, as well as their recommendation techniques. Furthermore, we present the commonly used datasets and point out some of the challenges of personality-aware recommendation systems.",https://link.springer.com/article/10.1007/s10462-021-10063-7
Erik Cambria,Semantic Multi-Dimensional Scaling for Open-Domain Sentiment Analysis,2014,IEEE Intelligent Systems,148,"Erik Cambria, Yangqiu Song, Haixun Wang, Newton Howard",Erik Cambria,Newton Howard,4,"The ability to understand natural language text is far from being emulated in machines. One of the main hurdles to overcome is that computers lack both the common and common-sense knowledge that humans normally acquire during the formative years of their lives. To really understand natural language, a machine should be able to comprehend this type of knowledge, rather than merely relying on the valence of keywords and word co-occurrence frequencies. In this article, the largest existing taxonomy of common knowledge is blended with a natural-language-based semantic network of common-sense knowledge. Multidimensional scaling is applied on the resulting knowledge base for open-domain opinion mining and sentiment analysis.",https://ieeexplore.ieee.org/abstract/document/6383145/
Erik Cambria,A Review of Emotion Sensing: Categorization Models and Algorithms,2020,Multimedia Tools and Applications,147,"Zhaoxia Wang, Seng-Beng Ho, Erik Cambria",Zhaoxia Wang,Erik Cambria,3,"Sentiment analysis consists in the identification of the sentiment polarity associated with a target object, such as a book, a movie or a phone. Sentiments reflect feelings and attitudes, while emotions provide a finer characterization of the sentiments involved. With the huge number of comments generated daily on the Internet, besides sentiment analysis, emotion identification has drawn keen interest from different researchers, businessmen and politicians for polling public opinions and attitudes. This paper reviews and discusses existing emotion categorization models for emotion analysis and proposes methods that enhance existing emotion research. We carried out emotion analysis by inviting experts from different research areas to produce comprehensive results. Moreover, a computational emotion sensing model is proposed, and future improvements are discussed in this paper.",https://link.springer.com/article/10.1007/s11042-019-08328-z
Erik Cambria,An ELM-Based Model for Affective Analogical Reasoning,2015,Neurocomputing,145,"Erik Cambria, Paolo Gastaldo, Federica Bisio, Rodolfo Zunino",Erik Cambria,Rodolfo Zunino,4,"Between the dawn of the Internet through year 2003, there were just a few dozens exabytes of information on the Web. Today, that much information is created weekly. The opportunity to capture the opinions of the general public about social events, political movements, company strategies, marketing campaigns, and product preferences has raised increasing interest both in the scientific community, for the exciting open challenges, and in the business world, for the remarkable fallouts in marketing and financial prediction. Keeping up with the ever-growing amount of unstructured information on the Web, however, is a formidable task and requires fast and efficient models for opinion mining. In this paper, we explore how the high generalization performance, low computational complexity, and fast learning speed of extreme learning machines can be exploited to perform analogical reasoning in a vector space model …",https://www.sciencedirect.com/science/article/pii/S0925231214011187
Erik Cambria,Bottom-Up and Top-Down: Predicting Personality with Psycholinguistic and Language Model Features,2020,Proceedings of ICDM,144,"Yash Mehta, Samin Fatehi, Amirmohammad Kazameini, Clemens Stachl, Erik Cambria, Sauleh Eetemadi",Yash Mehta,Sauleh Eetemadi,6,"State-of-the-art personality prediction with text data mostly relies on bottom up, automated feature generation as part of the deep learning process. More traditional models rely on hand-crafted, theory-based text-feature categories. We propose a novel deep learning-based model which integrates traditional psycholinguistic features with language model embeddings to predict personality from the Essays dataset for Big-Five and Kaggle dataset for MBTI. With this approach we achieve state-of-the-art model performance. Additionally, we use interpretable machine learning to visualize and quantify the impact of various language features in the respective personality prediction models. We conclude with a discussion on the potential this work has for computational modeling and psychological science alike.",https://ieeexplore.ieee.org/abstract/document/9338428/
Erik Cambria,Intelligent Asset Allocation via Market Sentiment Views,2018,IEEE Computational Intelligence Magazine,141,"Frank Xing, Erik Cambria, Roy Welsch",Frank Xing,Roy Welsch,3,"The sentiment index of market participants has been extensively used for stock market prediction in recent years. Many financial information vendors also provide it as a service. However, utilizing market sentiment under the asset allocation framework has been rarely discussed. In this article, we investigate the role of market sentiment in an asset allocation problem. We propose to compute sentiment time series from social media with the help of sentiment analysis and text mining techniques. A novel neural network design, built upon an ensemble of evolving clustering and long short-term memory, is used to formalize sentiment information into market views. These views are later integrated into modern portfolio theory through a Bayesian approach. We analyze the performance of this asset allocation model from many aspects, such as stability of portfolios, computing of sentiment time series, and profitability in our …",https://ieeexplore.ieee.org/abstract/document/8492384/
Erik Cambria,Common Sense Knowledge Based Personality Recognition from Text,2013,,140,"Soujanya Poria, Alexandar Gelbukh, Basant Agarwal, Erik Cambria, Newton Howard",Soujanya Poria,Newton Howard,5,"Past works on personality detection has shown that psycho-linguistic features, frequency based analysis at lexical level, emotive words and other lexical clues such as number of first person or second person words carry major role to identify personality associated with the text. In this work, we propose a new architecture for the same task using common sense knowledge with associated sentiment polarity and affective labels. To extract the common sense knowledge with sentiment polarity scores and affective labels we used Senticnet which is one of the most useful resources for opinion mining and sentiment analysis. In particular, we combined common sense knowledge based features with phycho-linguistic features and frequency based features and later the features were employed in supervised classifiers. We designed five SMO based supervised classifiers for five personality traits. We observe that …",https://link.springer.com/chapter/10.1007/978-3-642-45111-9_42
Erik Cambria,Survey on Sentiment Analysis: Evolution of Research Methods and Topics,2023,Artificial Intelligence Review,138,"Jingfeng Cui, Zhaoxia Wang, Seng-Beng Ho, Erik Cambria",Jingfeng Cui,Erik Cambria,4,"Sentiment analysis, one of the research hotspots in the natural language processing field, has attracted the attention of researchers, and research papers on the field are increasingly published. Many literature reviews on sentiment analysis involving techniques, methods, and applications have been produced using different survey methodologies and tools, but there has not been a survey dedicated to the evolution of research methods and topics of sentiment analysis. There have also been few survey works leveraging keyword co-occurrence on sentiment analysis. Therefore, this study presents a survey of sentiment analysis focusing on the evolution of research methods and topics. It incorporates keyword co-occurrence analysis with a community detection algorithm. This survey not only compares and analyzes the connections between research methods and topics over the past two decades but also uncovers …",https://link.springer.com/article/10.1007/s10462-022-10386-z
Erik Cambria,An Introduction to Concept-Level Sentiment Analysis,2013,Proceedings of MICAI,138,Erik Cambria,Erik Cambria,Erik Cambria,1,"The ways people express their opinions and sentiments have radically changed in the past few years thanks to the advent of social networks, web communities, blogs, wikis, and other online collaborative media. The distillation of knowledge from the huge amount of unstructured information on the Web can be a key factor for marketers who want to create an image or identity in the minds of their customers for their product or brand. These online social data, however, remain hardly accessible to computers, as they are specifically meant for human consumption. The automatic analysis of online opinions, in fact, involves a deep understanding of natural language text by machines, from which we are still very far. To this end, concept-level sentiment analysis aims to go beyond a mere word-level analysis of text and provide novel approaches to opinion mining and sentiment analysis that enable a more efficient …",https://link.springer.com/chapter/10.1007/978-3-642-45111-9_41
Erik Cambria,Guest Editorial: Big Social Data Analysis,2014,Knowledge-Based Systems,137,"Erik Cambria, Haixun Wang, Bebo White",Erik Cambria,Bebo White,3,"Guest editorial: big social data analysis: Knowledge-Based Systems: Vol 69, No 1 skip to main 
content ACM Digital Library home ACM home Google, Inc. (search) Advanced Search Browse 
About Sign in Register Advanced Search Journals Magazines Proceedings Books SIGs 
Conferences People More Search ACM Digital Library SearchSearch Advanced Search 
Knowledge-Based Systems Periodical Home Latest Issue Archive Authors Affiliations Award 
Winners More Home Browse by Title Periodicals Knowledge-Based Systems Vol. 69, No. 1 
Guest editorial: big social data analysis article Share on Guest editorial: big social data analysis 
Authors: Erik Cambria Nanyang Technological University, Singapore Nanyang Technological 
University, Singapore View Profile , Haixun Wang Google Research Google Research View 
Profile , Bebo White Stanford University Stanford University View Profile Authors Info & …",https://dl.acm.org/doi/abs/10.1016/j.knosys.2014.07.002
Erik Cambria,Cognitive-Inspired Domain Adaptation of Sentiment Lexicons,2019,Information Processing & Management,134,"Frank Xing, Filippo Pallucchini, Erik Cambria",Frank Xing,Erik Cambria,3,"Sentiment lexicons are essential tools for polarity classification and opinion mining. In contrast to machine learning methods that only leverage text features or raw text for sentiment analysis, methods that use sentiment lexicons embrace higher interpretability. Although a number of domain-specific sentiment lexicons are made available, it is impractical to build an ex ante lexicon that fully reflects the characteristics of the language usage in endless domains. In this article, we propose a novel approach to simultaneously train a vanilla sentiment classifier and adapt word polarities to the target domain. Specifically, we sequentially track the wrongly predicted sentences and use them as the supervision instead of addressing the gold standard as a whole to emulate the life-long cognitive process of lexicon learning. An exploration-exploitation mechanism is designed to trade off between searching for new sentiment words …",https://www.sciencedirect.com/science/article/pii/S0306457318306228
Erik Cambria,Sentic Computing: Exploitation of Common Sense for the Development of Emotion-Sensitive Systems,2010,,134,"Erik Cambria, Amir Hussain, Catherine Havasi, Chris Eckl",Erik Cambria,Chris Eckl,4,"Emotions are a fundamental component in human experience, cognition, perception, learning and communication. In this paper we explore how the use of Common Sense Computing can significantly enhance computers’ emotional intelligence i.e. their capability of perceiving and expressing emotions, to allow machines to make more human-like decisions and improve the human-computer interaction.",https://link.springer.com/chapter/10.1007/978-3-642-12397-9_12
Erik Cambria,Consensus Vote Models for Detecting and Filtering Neutrality in Sentiment Analysis,2018,Information Fusion,131,"Ana Valdivia, M Victoria Luzón, Erik Cambria, Francisco Herrera",Ana Valdivia,Francisco Herrera,4,"Recently, interest in sentiment analysis has grown exponentially. Many studies have developed a wide variety of algorithms capable of classifying texts according to the sentiment conveyed in them. Such sentiment is usually expressed as positive, neutral or negative. However, neutral reviews are often ignored in many sentiment analysis problems because of their ambiguity and lack of information. In this paper, we propose to empower neutrality by characterizing the boundary between positive and negative reviews, with the goal of improving the model’s performance. We apply different sentiment analysis methods to different corpora extracting their sentiment and, hence, detecting neutral reviews by consensus to filter them, i.e., taking into account different models based on weighted aggregation. We finally compare classification performance on single and aggregated models. The results clearly show that …",https://www.sciencedirect.com/science/article/pii/S1566253517306590
Erik Cambria,A Deep Learning Approach for Multimodal Deception Detection,2018,Proceedings of CICLing,131,"Gangeshwar Krishnamurthy, Navonil Majumder, Soujanya Poria, Erik Cambria",Gangeshwar Krishnamurthy,Erik Cambria,4,"Automatic deception detection is an important task that has gained momentum in computational linguistics due to its potential applications. In this paper, we propose a simple yet tough to beat multimodal neural model for deception detection. By combining features from different modalities such as video, audio, and text along with Micro-Expression features, we show that detecting deception in real life videos can be more accurate. Experimental results on a dataset of real-life deception videos show that our model outperforms existing techniques for deception detection with an accuracy of 96.14% and ROC-AUC of 0.9799.",https://link.springer.com/chapter/10.1007/978-3-031-23793-5_8
Erik Cambria,Sentic PROMs: Application of Sentic Computing to the Development of a Novel Unified Framework for Measuring Health-Care Quality,2012,Expert Systems with Applications,130,"Erik Cambria, Tim Benson, Chris Eckl, Amir Hussain",Erik Cambria,Amir Hussain,4,"Barriers to use health related quality of life measuring systems include the time needed to complete the forms and the need for staff to be trained to understand the results. An ideal system of health assessment needs to be clinically useful, timely, sensitive to change, culturally sensitive, low burden, low cost, involving for the patient and built into standard procedures. A new generation of short and easy-to-use tools to monitor patient outcomes on a regular basis has been recently proposed. These tools are quick, effective and easy to understand, as they are very structured and rigid. Such structuredness, however, leaves no space to those patients who would like to say something more. Patients, in fact, are usually willing to express their opinions and feelings in free text, rather than simply filling in a questionnaire, for either speaking out their satisfaction or for cathartic complaining. Sentic PROMs allow patients to …",https://www.sciencedirect.com/science/article/pii/S0957417412003831
Erik Cambria,Learning Short-Text Semantic Similarity with Word Embeddings and External Knowledge Sources,2019,Knowledge-Based Systems,129,"Hien T Nguyen, Phuc H Duong, Erik Cambria",Hien T Nguyen,Erik Cambria,3,"We present a novel method based on interdependent representations of short texts for determining their degree of semantic similarity. The method represents each short text as two dense vectors: the former is built using the word-to-word similarity based on pre-trained word vectors, the latter is built using the word-to-word similarity based on external sources of knowledge. We also developed a preprocessing algorithm that chains coreferential named entities together and performs word segmentation to preserve the meaning of phrasal verbs and idioms. We evaluated the proposed method on three popular datasets, namely Microsoft Research Paraphrase Corpus, STS2015 and P4PIN, and obtained state-of-the-art results on all three without using prior knowledge of natural language, e.g., part-of-speech tags or parse tree, which indicates the interdependent representations of short text pairs are effective and …",https://www.sciencedirect.com/science/article/pii/S095070511930317X
Erik Cambria,Merging SenticNet and WordNet-Affect Emotion Lists for Sentiment Analysis,2012,Proceedings of ICSP,129,"Soujanya Poria, Alexander Gelbukh, Erik Cambria, Peipei Yang, Amir Hussain, Tariq Durrani",Soujanya Poria,Tariq Durrani,6,"SenticNet is currently one of the most comprehensive freely available semantic resources for opinion mining. However, it only provides numerical polarity scores, while more detailed sentiment-related information for its concepts is often desirable. Another important resource for opinion mining and sentiment analysis is WordNet-Affect, which in turn lacks quantitative information. We report a work on automatically merging these two resources by assigning emotion labels to more than 2700 concepts.",https://ieeexplore.ieee.org/abstract/document/6491803/
Erik Cambria,Sentic Computing for Patient Centered Applications,2010,Proceedings of ICSP,129,"Erik Cambria, Amir Hussain, Tariq Durrani, Catherine Havasi, Chris Eckl, James Munro",Erik Cambria,James Munro,6,"Next-generation patients are far from being peripheral to health-care. They are central to understanding the effectiveness and efficiency of services and how they can be improved. Today a lot of patients are used to reviewing local health services on-line but this social information is just stored in natural language text and it is not machine-accessible and machine-processable. To distil knowledge from this extremely unstructured information we use Sentic Computing, a new opinion mining and sentiment analysis paradigm which exploits AI and Semantic Web techniques to better recognize, interpret and process opinions and sentiments in natural language text. In particular, we use a language visualization and analysis system, a novel emotion categorization model, a resource for opinion mining based on a web ontology and novel techniques for finding and defining topic dependent concepts, namely spectral …",https://ieeexplore.ieee.org/abstract/document/5657072/
Erik Cambria,Common Sense Computing: From the Society of Mind to Digital Intuition and Beyond,2009,,129,"Erik Cambria, Amir Hussain, Catherine Havasi, Chris Eckl",Erik Cambria,Chris Eckl,4,"What is Common Sense Computing? And why is it so important for the technological evolution of humankind? This paper presents an overview of past, present and future efforts of the AI community to give computers the capacity for Common Sense reasoning, from Minsky’s Society of Mind to Media Laboratory’s Digital Intuition theory, and beyond. Is it actually possible to build a machine with Common Sense or is it just an utopia? This is the question this paper is trying to answer.",https://link.springer.com/chapter/10.1007/978-3-642-04391-8_33
Erik Cambria,"A Survey of Large Language Models for Healthcare: From Data, Technology, and Applications to Accountability and Ethics",2025,arXiv preprint arXiv:2310.05694,127,"Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, Erik Cambria",Kai He,Erik Cambria,7,"The utilization of large language models (LLMs) in the Healthcare domain has generated both excitement and concern due to their ability to effectively respond to freetext queries with certain professional knowledge. This survey outlines the capabilities of the currently developed LLMs for Healthcare and explicates their development process, with the aim of providing an overview of the development roadmap from traditional Pretrained Language Models (PLMs) to LLMs. Specifically, we first explore the potential of LLMs to enhance the efficiency and effectiveness of various Healthcare applications highlighting both the strengths and limitations. Secondly, we conduct a comparison between the previous PLMs and the latest LLMs, as well as comparing various LLMs with each other. Then we summarize related Healthcare training data, training methods, optimization strategies, and usage. Finally, the unique concerns associated with deploying LLMs in Healthcare settings are investigated, particularly regarding fairness, accountability, transparency and ethics. Our survey provide a comprehensive investigation from perspectives of both computer science and Healthcare specialty. Besides the discussion about Healthcare concerns, we supports the computer science community by compiling a collection of open source resources, such as accessible datasets, the latest methodologies, code implementations, and evaluation benchmarks in the Github. Summarily, we contend that a significant paradigm shift is underway, transitioning from PLMs to LLMs. This shift encompasses a move from discriminative AI approaches to generative AI approaches, as well …",https://arxiv.org/abs/2310.05694
Erik Cambria,Intention Awareness: Improving upon Situation Awareness in Human-Centric Environments,2013,Human-centric Computing and Information Sciences,127,"Newton Howard, Erik Cambria",Newton Howard,Erik Cambria,2,"As the gap between human and machine shrinks, it becomes increasingly important to develop computer systems that incorporate or enhance existing Situation Awareness. However, these tend to focus on raw quantitative parameters, such as position and speed of objects. When these situations are governed by human actors, such parameters leave significant margins of uncertainty. In this paper, we discuss the potential of applying the characteristics intrinsic to the human actors that comprise a given situation to Situation Awareness, and the capacity that these concepts have to improve situation-aware systems. We argue that intention-aware based systems offer an advantage over situation-aware based systems in that they reduce the informational burden on humans without limiting effectiveness. We argue that computational analysis and tracking of semantic and affective information associated with …",https://link.springer.com/article/10.1186/2192-1962-3-9
Erik Cambria,Modelling Public Sentiment in Twitter: Using Linguistic Patterns to Enhance Supervised Learning,2015,Proceedings of CICLing,126,"Prerna Chikersal, Soujanya Poria, Erik Cambria, Alexander Gelbukh, Eng Siong Chng",Prerna Chikersal,Eng Siong Chng,5,"This paper describes a Twitter sentiment analysis system that classifies a tweet as positive or negative based on its overall tweet-level polarity. Supervised learning classifiers often misclassify tweets containing conjunctions such as “but” and conditionals such as “if”, due to their special linguistic characteristics. These classifiers also assign a decision score very close to the decision boundary for a large number tweets, which suggests that they are simply unsure instead of being completely wrong about these tweets. To counter these two challenges, this paper proposes a system that enhances supervised learning for polarity classification by leveraging on linguistic rules and sentic computing resources. The proposed method is evaluated on two publicly available Twitter corpora to illustrate its effectiveness.",https://link.springer.com/chapter/10.1007/978-3-319-18117-2_4
Erik Cambria,Learning Word Dependencies in Text by Means of a Deep Recurrent Belief Network,2016,Knowledge-Based Systems,125,"Iti Chaturvedi, Yew-Soon Ong, Ivor W Tsang, Roy Welsch, Erik Cambria",Iti Chaturvedi,Erik Cambria,5,"We propose a deep recurrent belief network with distributed time delays for learning multivariate Gaussians. Learning long time delays in deep belief networks is difficult due to the problem of vanishing or exploding gradients with increase in delay. To mitigate this problem and improve the transparency of learning time-delays, we introduce the use of Gaussian networks with time-delays to initialize the weights of each hidden neuron. From our knowledge of time delays, it is possible to learn the long delays from short delays in a hierarchical manner. In contrast to previous works, here dynamic Gaussian Bayesian networks over training samples are evolved using Markov Chain Monte Carlo to determine the initial weights of each hidden layer of neurons. In this way, the time-delayed network motifs of increasing Markov order across layers can be modeled hierarchically using a deep model. To validate the proposed …",https://www.sciencedirect.com/science/article/pii/S0950705116302349
Erik Cambria,Sentic Web: A New Paradigm for Managing Social Media Affective Information,2011,Cognitive Computation,125,"Marco Grassi, Erik Cambria, Amir Hussain, Francesco Piazza",Marco Grassi,Francesco Piazza,4,"The recent success of media-sharing services caused an exponential growth of community-contributed multimedia data on the Web and hence a consistent shift of the flow of information from traditional communication channels to social media ones. Retrieving relevant information from this kind of data is getting more and more difficult, not only for their volume, but also for the different nature and formats of their contents. In this work, we introduce Sentic Web, a new paradigm for the management of social media affective information, which exploits AI and Semantic Web techniques to extract, encode, and represent opinions and sentiments over the Web. In particular, the computational layer consists in an intelligent engine for the inference of emotions from text, the representation layer is developed on the base of specific domain ontologies, and the application layer is based on the faceted browsing paradigm …",https://link.springer.com/article/10.1007/s12559-011-9101-8
Erik Cambria,Statistical Learning Theory and ELM for Big Social Data Analysis,2016,IEEE Computational Intelligence Magazine,124,"Luca Oneto, Federica Bisio, Erik Cambria, Davide Anguita",Luca Oneto,Davide Anguita,4,"The science of opinion analysis based on data from social networks and other forms of mass media has garnered the interest of the scientific community and the business world. Dealing with the increasing amount of information present on the Web is a critical task and requires efficient models developed by the emerging field of sentiment analysis. To this end, current research proposes an efficient approach to support emotion recognition and polarity detection in natural language text. In this paper, we show how to exploit the most recent technological tools and advances in Statistical Learning Theory (SLT) in order to efficiently build an Extreme Learning Machine (ELM) and assess the resultant model's performance when applied to big social data analysis. ELM represents a powerful learning tool, developed to overcome some issues in back-propagation networks. The main problem with ELM is in training them to …",https://ieeexplore.ieee.org/abstract/document/7515290/
Erik Cambria,Big Social Data Analysis,2013,,122,"E Cambria, D Rajagopal, D Olsher, D Das",E Cambria,D Das,4,"As the Web rapidly evolves, Web users too are evolving with it. In an era of social connectedness, people are becoming increasingly enthusiastic about interacting, sharing, and collaborating through social networks, online communities, blogs, Wikis, and other online collaborative media. In recent years, this collective intelligence has spread to many different areas, with particular focus on fields related to everyday life such as commerce, tourism, education, and health, causing the size of the social Web to expand exponentially. The distillation of knowledge from such a large amount of unstructured information, however, is an extremely difficult task, as the contents of today’s Web are perfectly suitable for human consumption, but remain hardly accessible to machines. Big social data analysis grows out of this need and it includes disciplines such as social network analysis, multimedia management, social media …",https://api.taylorfrancis.com/content/chapters/edit/download?identifierName=doi&identifierValue=10.1201/b16014-24&type=chapterpdf
Erik Cambria,Sentiment Analysis and Topic Recognition in Video Transcriptions,2021,IEEE Intelligent Systems,121,"Lukas Stappen, Alice Baird, Erik Cambria, Björn W Schuller",Lukas Stappen,Björn W Schuller,4,"Nowadays, videos are an integral modality for information sharing on the World Wide Web. However, systems able to automatically understand the content and sentiment of a video are still in their infancy. Linguistic information transported in spoken parts of a video is known to convey valuable properties in regards to context and emotions. In this article, we explore a lexical knowledge-based extraction approach to obtain such understanding from the video transcriptions of a large-scale multimodal dataset (MuSe-CAR). To this end, we use SenticNet to extract natural language concepts and fine-tune several feature types on a subset of MuSe-CAR. With these features, we explore the content of a video as well as learning to predict emotional valence, arousal, and speaker topic classes. Our best model improves the linguistic baseline from the MuSe-Topic 2020 subchallenge by almost 3% (absolute) for the prediction …",https://ieeexplore.ieee.org/abstract/document/9434455/
Erik Cambria,A Graph-Based Approach to Commonsense Concept Extraction and Semantic Similarity Detection,2013,Proceedings of WWW Workshops,121,"Dheeraj Rajagopal, Erik Cambria, Daniel Olsher, Kenneth Kwok",Dheeraj Rajagopal,Kenneth Kwok,4,"Commonsense knowledge representation and reasoning support a wide variety of potential applications in fields such as document auto-categorization, Web search enhancement, topic gisting, social process modeling, and concept-level opinion and sentiment analysis. Solutions to these problems, however, demand robust knowledge bases capable of supporting flexible, nuanced reasoning. Populating such knowledge bases is highly time-consuming, making it necessary to develop techniques for deconstructing natural language texts into commonsense concepts. In this work, we propose an approach for effective multi-word commonsense expression extraction from unrestricted English text, in addition to a semantic similarity detection technique allowing additional matches to be found for specific concepts not already present in knowledge bases.",https://dl.acm.org/doi/abs/10.1145/2487788.2487995
Erik Cambria,Sentic Blending: Scalable Multimodal Fusion for the Continuous Interpretation of Semantics and Sentics,2013,Proceedings of IEEE SSCI,118,"Erik Cambria, Newton Howard, Jane Hsu, Amir Hussain",Erik Cambria,Amir Hussain,4,"The capability of interpreting the conceptual and affective information associated with natural language through different modalities is a key issue for the enhancement of human-agent interaction. The proposed methodology, termed sentic blending, enables the continuous interpretation of semantics and sentics (i.e., the conceptual and affective information associated with natural language) based on the integration of an affective common-sense knowledge base with any multimodal signal-processing module. In this work, in particular, sentic blending is interfaced with a facial emotional classifier and an opinion mining engine. One of the main distinguishing features of the proposed technique is that it does not simply perform cognitive and affective classification in terms of discrete labels, but it operates in a multidimensional space that enables the generation of a continuous stream characterising user's semantic and …",https://ieeexplore.ieee.org/abstract/document/6613272/
Erik Cambria,IARM: Inter-Aspect Relation Modeling with Memory Networks in Aspect-Based Sentiment Analysis,2018,Proceedings of EMNLP,117,"Navonil Majumder, Soujanya Poria, Alexander Gelbukh, Md Shad Akhtar, Erik Cambria, Asif Ekbal",Navonil Majumder,Asif Ekbal,6,"Sentiment analysis has immense implications in e-commerce through user feedback mining. Aspect-based sentiment analysis takes this one step further by enabling businesses to extract aspect specific sentimental information. In this paper, we present a novel approach of incorporating the neighboring aspects related information into the sentiment classification of the target aspect using memory networks. We show that our method outperforms the state of the art by 1.6% on average in two distinct domains: restaurant and laptop.",https://aclanthology.org/D18-1377/
Erik Cambria,Do Not Feel the Trolls,2010,Proceedings of ISWC Workshops,114,"Erik Cambria, Praphul Chandra, Avinash Sharma, Amir Hussain",Erik Cambria,Amir Hussain,4,"The passage from a read-only to a read-write Web gave people the possibility to freely interact, share and collaborate through social networks, online communities, blogs, wikis and other online collaborative media. The democracy of the Web is what made it so popular in the past decades but such a high degree of freedom of expression also gave birth to negative side effects–the so called ‘dark side’of the Web. An example of this is trolling, ie, the exploitation of the anonymity of the Web to post inflammatory and outrageous messages directed to one specific person or community to provoke them into a desired emotional response. Online community masters usually warn users against trolls with messages such as DNFTT (Do Not Feed The Trolls) but so far this has not been enough to stop trolls trolling. The aim of this work is to use sentic computing, a new paradigm for the affective analysis of natural language text, to detect trolls and hence prevent web-users from being emotionally hurt by malicious posts.",https://www.sentic.net/do-not-feel-the-trolls.pdf
Erik Cambria,Suicidal Ideation and Mental Disorder Detection with Attentive Relation Networks,2022,Neural Computing and Applications,113,"Shaoxiong Ji, Xue Li, Zi Huang, Erik Cambria",Shaoxiong Ji,Erik Cambria,4,"Mental health is a critical issue in modern society, and mental disorders could sometimes turn to suicidal ideation without effective treatment. Early detection of mental disorders and suicidal ideation from social content provides a potential way for effective social intervention. However, classifying suicidal ideation and other mental disorders is challenging as they share similar patterns in language usage and sentimental polarity. This paper enhances text representation with lexicon-based sentiment scores and latent topics and proposes using relation networks to detect suicidal ideation and mental disorders with related risk indicators. The relation module is further equipped with the attention mechanism to prioritize more critical relational features. Through experiments on three real-world datasets, our model outperforms most of its counterparts.",https://link.springer.com/article/10.1007/s00521-021-06208-y
Erik Cambria,The CLSA Model: A Novel Framework for Concept-Level Sentiment Analysis,2015,Proceedings of CICLing,113,"Erik Cambria, Soujanya Poria, Federica Bisio, Rajiv Bajpai, Iti Chaturvedi",Erik Cambria,Iti Chaturvedi,5,"Hitherto, sentiment analysis has been mainly based on algorithms relying on the textual representation of online reviews and microblogging posts. Such algorithms are very good at retrieving texts, splitting them into parts, checking the spelling, and counting their words. But when it comes to interpreting sentences and extracting opinionated information, their capabilities are known to be very limited. Current approaches to sentiment analysis are mainly based on supervised techniques relying on manually labeled samples, such as movie or product reviews, where the overall positive or negative attitude was explicitly indicated. However, opinions do not occur only at document-level, nor they are limited to a single valence or target. Contrary or complementary attitudes toward the same topic or multiple topics can be present across the span of a review. In order to overcome this and many other issues related to …",https://link.springer.com/chapter/10.1007/978-3-319-18117-2_1
Erik Cambria,A Survey on XAI and Natural Language Explanations,2023,Information Processing & Management,112,"Erik Cambria, Lorenzo Malandri, Fabio Mercorio, Mario Mezzanzanica, Navid Nobani",Erik Cambria,Navid Nobani,5,"The field of explainable artificial intelligence (XAI) is gaining increasing importance in recent years. As a consequence, several surveys have been published to explore the current state of the art on this topic. One aspect that seems to be overlooked by these works is the applied presentation methods and, specifically, the role of natural language in generating the final explanations. This survey reviews 70 XAI papers published between 2006 and 2021 and evaluates their readiness with respect to natural language explanations. Thus, together with a set of hierarchical criteria, we define a multi-criteria decision-making model. Finally, we conclude that only a handful of recent XAI works either considered natural language explanations to approach final users (see, e.g.,(Bennetot et al., 2021)) or implemented a method capable of generating such explanations.",https://www.sciencedirect.com/science/article/pii/S0306457322002126
Erik Cambria,Statistical Approaches to Concept-Level Sentiment Analysis,2013,IEEE Intelligent Systems,112,"Erik Cambria, Bjorn Schuller, Bing Liu, Haixun Wang, Catherine Havasi",Erik Cambria,Catherine Havasi,5,"The guest editors introduce novel statistical approaches to concept-level sentiment analysis that go beyond a mere syntactic-driven analysis of text and provide semantic-based methods. Such approaches allow a more efficient passage from (unstructured) textual information to (structured) machine-processable data, in potentially any domain.",https://ieeexplore.ieee.org/abstract/document/6588860/
Erik Cambria,Disentangled Variational Auto-Encoder for Semi-Supervised Learning,2019,Information Sciences,109,"Yang Li, Quan Pan, Suhang Wang, Haiyun Peng, Tao Yang, Erik Cambria",Yang Li,Erik Cambria,6,"Semi-supervised learning is attracting increasing attention due to the fact that datasets of many domains lack enough labeled data. Variational Auto-Encoder (VAE), in particular, has demonstrated the benefits of semi-supervised learning. The majority of existing semi-supervised VAEs utilize a classifier to exploit label information, where the parameters of the classifier are introduced to the VAE. Given the limited labeled data, learning the parameters for the classifiers may not be an optimal solution for exploiting label information. Therefore, in this paper, we develop a novel approach for semi-supervised VAE without classifier. Specifically, we propose a new model called Semi-supervised Disentangled VAE (SDVAE), which encodes the input data into disentangled representation and non-interpretable representation, then the category information is directly utilized to regularize the disentangled representation via the …",https://www.sciencedirect.com/science/article/pii/S0020025518310077
Erik Cambria,Public Mood–Driven Asset Allocation: The Importance of Financial Sentiment in Portfolio Management,2018,Cognitive Computation,102,"Lorenzo Malandri, Frank Xing, Carlotta Orsenigo, Carlo Vercellis, Erik Cambria",Lorenzo Malandri,Erik Cambria,5,"The study of the impact of investor sentiment on stock returns has gained increasing momentum in the past few years. It has been widely accepted that public mood is correlated with financial markets. However, only a few studies discussed how the public mood would affect one of the fundamental problems of computational finance: portfolio management. In this study, we use public financial sentiment and historical prices collected from the New York Stock Exchange (NYSE) to train multiple machine learning models for automatic wealth allocation across a set of assets. Unlike previous studies which set as target variable the asset prices in the portfolio, the variable to predict here is represented by the best asset allocation strategy ex post. Experiments performed on five portfolios show that long short-term memory networks are superior to multi-layer perceptron and random forests producing, in the period …",https://link.springer.com/article/10.1007/s12559-018-9609-2
Erik Cambria,Benchmarking Multimodal Sentiment Analysis,2017,Proceedings of CICLing,102,"Erik Cambria, Devamanyu Hazarika, Soujanya Poria, Amir Hussain, RBV Subramaanyam",Erik Cambria,RBV Subramaanyam,5,"We propose a deep-learning-based framework for multimodal sentiment analysis and emotion recognition. In particular, we leverage on the power of convolutional neural networks to obtain a performance improvement of 10% over the state of the art by combining visual, text and audio features. We also discuss some major issues frequently ignored in multimodal sentiment analysis research, e.g., role of speaker-independent models, importance of different modalities, and generalizability. The framework illustrates the different facets of analysis to be considered while performing multimodal sentiment analysis and, hence, serves as a new benchmark for future research in this emerging field.",https://link.springer.com/chapter/10.1007/978-3-319-77116-8_13
Erik Cambria,Sentic Medoids: Organizing Affective Common Sense Knowledge in a Multi-Dimensional Vector Space,2011,,100,"Erik Cambria, Thomas Mazzocco, Amir Hussain, Chris Eckl",Erik Cambria,Chris Eckl,4,"Existing approaches to opinion mining and sentiment analysis mainly rely on parts of text in which opinions and sentiments are explicitly expressed such as polarity terms and affect words. However, opinions and sentiments are often conveyed implicitly through context and domain dependent concepts, which make purely syntactical approaches ineffective. To overcome this problem, we have recently proposed Sentic Computing, a multi-disciplinary approach to opinion mining and sentiment analysis that exploits both computer and social sciences to better recognize and process opinions and sentiments over the Web. Among other tools, Sentic Computing includes AffectiveSpace, a language visualization system that transforms natural language from a linguistic form into a multi-dimensional space. In this work, we present a new technique to better cluster this vector space and, hence, better organize and …",https://link.springer.com/chapter/10.1007/978-3-642-21111-9_68
Erik Cambria,"The MuSe 2021 Multimodal Sentiment Analysis Challenge: Sentiment, Emotion, Physiological-Emotion, and Stress",2021,Proceedings of ACM Multimedia,99,"Lukas Stappen, Alice Baird, Lukas Christ, Lea Schumann, Benjamin Sertolli, Eva-Maria Messner, Erik Cambria, Guoying Zhao, Björn W Schuller",Lukas Stappen,Björn W Schuller,9,"Multimodal Sentiment Analysis (MuSe) 2021 is a challenge focusing on the tasks of sentiment and emotion, as well as physiological-emotion and emotion-based stress recognition through more comprehensively integrating the audio-visual, language, and biological signal modalities. The purpose of MuSe 2021 is to bring together communities from different disciplines; mainly, the audio-visual emotion recognition community (signal-based), the sentiment analysis community (symbol-based), and the health informatics community. We present four distinct sub-challenges: MuSe-Wilder and MuSe-Stress which focus on continuous emotion (valence and arousal) prediction; MuSe-Sent, in which participants recognise five classes each for valence and arousal; and MuSe-Physio, in which the novel aspect of 'physiological-emotion' is to be predicted. For this year's challenge, we utilise the MuSe-CaR dataset focusing on …",https://dl.acm.org/doi/abs/10.1145/3475957.3484450
Erik Cambria,Learning Binary Codes with Neural Collaborative Filtering for Efficient Recommendation Systems,2019,Knowledge-Based Systems,97,"Yang Li, Suhang Wang, Quan Pan, Haiyun Peng, Tao Yang, Erik Cambria",Yang Li,Erik Cambria,6,"The fast-growing e-commerce scenario brings new challenges to traditional collaborative filtering because the huge amount of users and items requires large storage and efficient recommendation systems. Hence, hashing for collaborative filtering has attracted increasing attention as binary codes can significantly reduce the storage requirement and make similarity calculations efficient. In this paper, we investigate the novel problem of deep collaborative hashing codes on user–item ratings. We propose a new deep learning framework for it, which adopts neural networks to better learn both user and item representations and make these close to binary codes such that the quantization loss is minimized. In addition, we extend the proposed framework for out-of-sample cases, i.e., dealing with new users, new items, and new ratings. Extensive experiments on real-world datasets demonstrate the effectiveness of the …",https://www.sciencedirect.com/science/article/pii/S0950705119300735
Erik Cambria,Multi-source Aggregated Classification for Stock Price Movement Prediction,2023,Information Fusion,95,"Yu Ma, Rui Mao, Qika Lin, Peng Wu, Erik Cambria",Yu Ma,Erik Cambria,5,"Predicting stock price movements is a challenging task. Previous studies mostly used numerical features and news sentiments of target stocks to predict stock price movements. However, their semantics-based sentiment analysis is sub-optimal to represent real market sentiments. Moreover, only considering the information of target companies is insufficient because the stock prices of target companies can be affected by their related companies. Thus, we propose a novel Multi-source Aggregated Classification (MAC) method for stock price movement prediction. MAC incorporates the numerical features and market-driven news sentiments of target stocks, as well as the news sentiments of their related stocks. To better represent real market sentiments from the news, we pre-train an embedding feature generator by fitting the news to real stock price movements. Embeddings given by the pre-trained sentiment classifier …",https://www.sciencedirect.com/science/article/pii/S1566253522002019
Erik Cambria,MELM: Data Augmentation with Masked Entity Language Modeling for Low-Resource NER,2022,Proceedings of ACL,95,"Ran Zhou, Xin Li, Ruidan He, Lidong Bing, Erik Cambria, Luo Si, Chunyan Miao",Ran Zhou,Chunyan Miao,7,"Data augmentation is an effective solution to data scarcity in low-resource scenarios. However, when applied to token-level tasks such as NER, data augmentation methods often suffer from token-label misalignment, which leads to unsatsifactory performance. In this work, we propose Masked Entity Language Modeling (MELM) as a novel data augmentation framework for low-resource NER. To alleviate the token-label misalignment issue, we explicitly inject NER labels into sentence context, and thus the fine-tuned MELM is able to predict masked entity tokens by explicitly conditioning on their labels. Thereby, MELM generates high-quality augmented data with novel entities, which provides rich entity regularity knowledge and boosts NER performance. When training data from multiple languages are available, we also integrate MELM with code-mixing for further improvement. We demonstrate the effectiveness of MELM on monolingual, cross-lingual and multilingual NER across various low-resource levels. Experimental results show that our MELM presents substantial improvement over the baseline methods.",https://arxiv.org/abs/2108.13655
Erik Cambria,BabelSenticNet: A Commonsense Reasoning Framework for Multilingual Sentiment Analysis,2018,Proceedings of IEEE SSCI,94,"David Vilares, Haiyun Peng, Ranjan Satapathy, Erik Cambria",David Vilares,Erik Cambria,4,"SenticNet is a concept-level knowledge base used to develop commonsense reasoning algorithms for sentiment analysis tasks. One of the challenges that this resource must overcome is its lack of availability for languages aside from English. Prototype algorithms have been recently proposed to create non-English language concept-level knowledge databases, but they rely on a number of heterogeneous resources that complicate comparison, reproducibility and maintenance. This paper proposes an easy and replicable method to automatically generate SenticNet for a variety of languages, obtaining as a result BabelSenticNet. We use statistical machine translation tools to create a high coverage SenticNet version for the target language. We then introduce an algorithm to increase the robustness of the translated resources, relying on a mapping technique, based on WordNet and its multilingual versions …",https://ieeexplore.ieee.org/abstract/document/8628718/
Erik Cambria,Circular-ELM for the Reduced-Reference Assessment of Perceived Image Quality,2013,Neurocomputing,94,"Sergio Decherchi, Paolo Gastaldo, Rodolfo Zunino, Erik Cambria, Judith Redi",Sergio Decherchi,Judith Redi,5,"Providing a satisfactory visual experience is one of the main goals for present-day electronic multimedia devices. All the enabling technologies for storage, transmission, compression, rendering should preserve, and possibly enhance, the quality of the video signal; to do so, quality control mechanisms are required. These mechanisms rely on systems that can assess the visual quality of the incoming signal consistently with human perception. Computational Intelligence (CI) paradigms represent a suitable technology to tackle this challenging problem. The present research introduces an augmented version of the basic Extreme Learning Machine (ELM), the Circular-ELM (C-ELM), which proves effective in addressing the visual quality assessment problem. The C-ELM model derives from the original Circular BackPropagation (CBP) architecture, in which the input vector of a conventional MultiLayer Perceptron (MLP …",https://www.sciencedirect.com/science/article/pii/S0925231212004249
Erik Cambria,Pattern Recognition Techniques: A Review,2012,International Journal of Computer Science and Telecommunications,94,"Seema Asht, Rajeshwar Dass, A Fallis, TY Dn, T Yyepg, E Cambria, GB Huang, LLC Kasun, H Zhou, CM Vong, J Lin, J Yin, Z Cai, Q Liu, K Li, VCM Leung, L Feng, YS Ong, MH Lim, J Liu",Seema Asht,J Liu,20,,https://scholar.google.com/scholar?cluster=13307713257128104834&hl=en&oi=scholarr
Erik Cambria,"Sentic Album: Content-, Concept-, and Context-Based Online Personal Photo Management System",2012,Cognitive Computation,93,"Erik Cambria, Amir Hussain",Erik Cambria,Amir Hussain,2,"The world of online personal photo management has come a long way in the past few years, but today, there are still huge gaps in annotating, organizing, and retrieving online pictures in such a way that they can be easily queried and visualized. Existing content-based image retrieval systems apply statistics, pattern recognition, signal processing, and computer vision techniques but these are still too weak to ‘bridge the semantic gap’ between the low-level data representation and the high-level concepts the user associates with images. Image meta search engines, on the other hand, rely on tags associated with online pictures but results are often too inaccurate since they mainly depend on keyword-based rather than concept-based algorithms. Sentic Album is a novel content-, concept-, and context-based online personal photo management system that exploits both data and metadata of online personal …",https://link.springer.com/article/10.1007/s12559-012-9145-4
Erik Cambria,Modeling Inter-Aspect Dependencies for Aspect-Based Sentiment Analysis,2018,Proceedings of NAACL,92,"Devamanyu Hazarika, Soujanya Poria, Prateek Vij, Gangeshwar Krishnamurthy, Erik Cambria, Roger Zimmermann",Devamanyu Hazarika,Roger Zimmermann,6,"Aspect-based Sentiment Analysis is a fine-grained task of sentiment classification for multiple aspects in a sentence. Present neural-based models exploit aspect and its contextual information in the sentence but largely ignore the inter-aspect dependencies. In this paper, we incorporate this pattern by simultaneous classification of all aspects in a sentence along with temporal dependency processing of their corresponding sentence representations using recurrent networks. Results on the benchmark SemEval 2014 dataset suggest the effectiveness of our proposed approach.",https://aclanthology.org/N18-2043/
Erik Cambria,Inconsistencies on TripAdvisor Reviews: A Unified Index between Users and Sentiment Analysis Methods,2019,Neurocomputing,91,"Ana Valdivia, Emiliya Hrabova, Iti Chaturvedi, M Victoria Luzón, Luigi Troiano, Erik Cambria, Francisco Herrera",Ana Valdivia,Francisco Herrera,7,"TripAdvisor is an opinion source frequently used in Sentiment Analysis. On this social network, users explain their experiences in hotels, restaurants or touristic attractions. They write texts of 200 character minimum and score the overall of their review with a numeric scale that ranks from 1 (Terrible) to 5 (Excellent). In this work, we aim that this score, which we define as the User Polarity, may not be representative of the sentiment of all the sentences that make up the opinion. We analyze opinions from six Italian and Spanish monument reviews and detect that there exist inconsistencies between the User Polarity and Sentiment Analysis Methods that automatically extract polarities. The fact is that users tend to rate their visit positively, but in some cases negative sentences and aspects appear, which are detected by these methods. To address these problems, we propose a Polarity Aggregation Model that takes into …",https://www.sciencedirect.com/science/article/pii/S0925231219303285
Erik Cambria,Phonetic-Based Microtext Normalization for Twitter Sentiment Analysis,2017,Proceedings of ICDM Workshops,91,"Ranjan Satapathy, Claudia Guerreiro, Iti Chaturvedi, Erik Cambria",Ranjan Satapathy,Erik Cambria,4,"The proliferation of Web 2.0 technologies and the increasing use of computer-mediated communication resulted in a new form of written text, termed microtext. This poses new challenges to natural language processing tools which are usually designed for well-written text. This paper proposes a phonetic-based framework for normalizing microtext to plain English and, hence, improve the classification accuracy of sentiment analysis. Results demonstrated that there is a high (>0.8) similarity index between tweets normalized by our model and tweets normalized by human annotators in 85.31% of cases, and that there is an accuracy increase of >4% in terms of polarity detection after normalization.",https://ieeexplore.ieee.org/abstract/document/8215691/
Erik Cambria,GPTEval: A Survey on Assessments of ChatGPT and GPT-4,2024,Proceedings of LREC-COLING,90,"Rui Mao, Guanyi Chen, Xulang Zhang, Frank Guerin, Erik Cambria",Rui Mao,Erik Cambria,5,"The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.",https://arxiv.org/abs/2308.12488
Erik Cambria,A Survey on Deep Reinforcement Learning for Audio-Based Applications,2023,Artificial Intelligence Review,90,"Siddique Latif, Heriberto Cuayáhuitl, Farrukh Pervez, Fahad Shamshad, Hafiz Shehbaz Ali, Erik Cambria",Siddique Latif,Erik Cambria,6,"Deep reinforcement learning (DRL) is poised to revolutionise the field of artificial intelligence (AI) by endowing autonomous systems with high levels of understanding of the real world. Currently, deep learning (DL) is enabling DRL to effectively solve various intractable problems in various fields including computer vision, natural language processing, healthcare, robotics, to name a few. Most importantly, DRL algorithms are also being employed in audio signal processing to learn directly from speech, music and other sound signals in order to create audio-based autonomous systems that have many promising applications in the real world. In this article, we conduct a comprehensive survey on the progress of DRL in the audio domain by bringing together research studies across different but related areas in speech and music. We begin with an introduction to the general field of DL and reinforcement learning (RL …",https://link.springer.com/article/10.1007/s10462-022-10224-2
Erik Cambria,A Novel Context-Aware Multimodal Framework for Persian Sentiment Analysis,2021,Neurocomputing,89,"Kia Dashtipour, Mandar Gogate, Erik Cambria, Amir Hussain",Kia Dashtipour,Amir Hussain,4,"Most recent works on sentiment analysis have exploited the text modality. However, millions of hours of video recordings posted on social media platforms everyday hold vital unstructured information that can be exploited to more effectively gauge public perception. Multimodal sentiment analysis offers an innovative solution to computationally understand and harvest sentiments from videos by contextually exploiting audio, visual and textual cues. In this paper, we, firstly, present a first of its kind Persian multimodal dataset comprising more than 800 utterances, as a benchmark resource for researchers to evaluate multimodal sentiment analysis approaches in Persian language. Secondly, we present a novel context-aware multimodal sentiment analysis framework, that simultaneously exploits acoustic, visual and textual cues to more accurately determine the expressed sentiment. We employ both decision-level (late …",https://www.sciencedirect.com/science/article/pii/S0925231221002666
Erik Cambria,Personality Trait Detection Using Bagged SVM over BERT Word Embedding Ensembles,2020,Proceedings of WiNLP,89,"Amirmohammad Kazameini, Samin Fatehi, Yash Mehta, Sauleh Eetemadi, Erik Cambria",Amirmohammad Kazameini,Erik Cambria,5,"Recently, the automatic prediction of personality traits has received increasing attention and has emerged as a hot topic within the field of affective computing. In this work, we present a novel deep learning-based approach for automated personality detection from text. We leverage state of the art advances in natural language understanding, namely the BERT language model to extract contextualized word embeddings from textual data for automated author personality detection. Our primary goal is to develop a computationally efficient, high-performance personality prediction model which can be easily used by a large number of people without access to huge computation resources. Our extensive experiments with this ideology in mind, led us to develop a novel model which feeds contextualized embeddings along with psycholinguistic features toa Bagged-SVM classifier for personality trait prediction. Our model outperforms the previous state of the art by 1.04% and, at the same time is significantly more computationally efficient to train. We report our results on the famous gold standard Essays dataset for personality detection.",https://arxiv.org/abs/2010.01309
Erik Cambria,Sentic Activation: A Two-Level Affective Common Sense Reasoning Framework,2012,Proceedings of AAAI,89,"Erik Cambria, Daniel Olsher, Kenneth Kwok",Erik Cambria,Kenneth Kwok,3,"An important difference between traditional AI systems and human intelligence is our ability to harness common sense knowledge gleaned from a lifetime of learning and experiences to inform our decision making and behavior. This allows humans to adapt easily to novel situations where AI fails catastrophically for lack of situation-specific rules and generalization capabilities. Common sense knowledge also provides the background knowledge for humans to successfully operate in social situations where such knowledge is typically assumed. In order for machines to exploit common sense knowledge in reasoning as humans do, moreover, we need to endow them with human-like reasoning strategies. In this work, we propose a two-level affective reasoning framework that concurrently employs multi-dimensionality reduction and graph mining techniques to mimic the integration of conscious and unconscious reasoning, and exploit it for sentiment analysis.",https://ojs.aaai.org/index.php/AAAI/article/view/8154
Erik Cambria,Multi-Level Fine-Scaled Sentiment Sensing with Ambivalence Handling,2020,"International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems",88,"Zhaoxia Wang, Seng Beng Ho, Erik Cambria",Zhaoxia Wang,Erik Cambria,3,"Social media represent a rich source of information, such as critiques, feedback, and other opinions posted online by Internet users. Such information is typically a good reflection of users’ sentiments and attitudes towards various services, topics, or products. Sentiment analysis has become an increasingly important natural language processing (NLP) task to help users make sense of what is happening in the Internet blogosphere and it can be useful for companies as well as public organizations. However, most existing sentiment analysis techniques are only able to analyze data at the aggregate level, merely providing a binary classification (positive vs. negative), and are not able to generate finer characterizations of sentiments as well as emotions involved. This paper describes a new opinion analysis scheme, i.e., a multi-level fine-scaled sentiment sensing with ambivalence handling. The ambivalence handler is …",https://www.worldscientific.com/doi/abs/10.1142/S0218488520500294
Erik Cambria,SenticSpace: Visualizing Opinions and Sentiments in a Multi-dimensional Vector Space,2010,Knowledge-Based and Intelligent Information and Engineering Systems,88,"Erik Cambria, Amir Hussain, Catherine Havasi, Chris Eckl",Erik Cambria,Chris Eckl,4,"In a world in which millions of people express their feelings and opinions about any issue in blogs, wikis, fora, chats and social networks, the distillation of knowledge from this huge amount of unstructured information is a challenging task. In this work we build a knowledge base which merges common sense and affective knowledge and visualize it in a multi-dimensional vector space, which we call SenticSpace. In particular we blend ConceptNet and WordNet-Affect and use dimensionality reduction on the resulting knowledge base to build a 24-dimensional vector space in which different vectors represent different ways of making binary distinctions among concepts and sentiments.",https://link.springer.com/chapter/10.1007/978-3-642-15384-6_41
Erik Cambria,AffectiveSpace: Blending Common Sense and Affective Knowledge to Perform Emotive Reasoning,2009,Proceedings of CAEPIA Workshops,87,"Erik Cambria, Amir Hussain, Catherine Havasi, Chris Eckl",Erik Cambria,Chris Eckl,4,"The detection of emotions in text is a key issue for the development of intelligent systems. As demonstrated by the Turing test, a machine cannot be considered really intelligent unless it is also capable of perceiving and expressing emotions. In this work we focus on building a knowledge base which merges Common Sense and affective knowledge and use dimensionality reduction to perform emotive reasoning on it.",http://dig.csail.mit.edu/2010/DIG_Seminar/erik_talk/AffectiveSpace.pdf
Erik Cambria,Embedding Both Finite and Infinite Communities on Graphs,2019,IEEE Computational Intelligence Magazine,84,"Sandro Cavallari, Erik Cambria, Hongyun Cai, Kevin Chen-Chuan Chang, Vincent W Zheng",Sandro Cavallari,Vincent W Zheng,5,"In this paper, we introduce a new setting for graph embedding, which considers embedding communities instead of individual nodes. We find that community embedding is not only useful for community-level applications such as graph visualization but also provide an exciting opportunity to improve community detection and node classification. Specifically, we consider the interaction between community embedding and detection as a closed loop, through node embedding. On the one hand, node embedding can improve community detection since the detected communities are used to fit a community embedding. On the other hand, community embedding can be used to optimize node embedding by introducing a community-aware high-order proximity. However, in practice, the number of communities can be unknown beforehand; thus we extend our previous Community Embedding (ComE) model. We propose …",https://ieeexplore.ieee.org/abstract/document/8764640/
Erik Cambria,Application of Multi-Dimensional Scaling and Artificial Neural Networks for Biologically Inspired Opinion Mining,2013,Biologically Inspired Cognitive Architectures,83,"Erik Cambria, Thomas Mazzocco, Amir Hussain",Erik Cambria,Amir Hussain,3,"The way people express their opinions has radically changed in the past few years thanks to the advent of online collaborative media. The distillation of knowledge from this huge amount of unstructured information can be a key factor for marketers who want to create an identity for their product or brand in the minds of their customers. These online social data, however, remain hardly accessible to computers, as they are specifically meant for human consumption. Existing approaches to opinion mining, in fact, are still far from being able to infer the cognitive and affective information associated with natural language as they mainly rely on knowledge bases that are too limited to efficiently process text at concept-level. In this context, standard clustering techniques have been previously employed on an affective common-sense knowledge base in attempt to discover how different natural language concepts are …",https://www.sciencedirect.com/science/article/pii/S2212683X13000212
Erik Cambria,Enriching SenticNet Polarity Scores through Semi-Supervised Fuzzy Clustering,2012,Proceedings of ICDM Workshops,83,"Soujanya Poria, Alexander Gelbukh, Erik Cambria, Dipankar Das, Sivaji Bandyopadhyay",Soujanya Poria,Sivaji Bandyopadhyay,5,"SenticNet 1.0 is one of the most widely used freely-available resources for concept-level opinion mining, containing about 5,700 common sense concepts and their corresponding polarity scores. Specific affective information associated to such concepts, however, is often desirable for tasks such as emotion recognition. In this work, we propose a method for assigning emotion labels to SenticNet concepts based on a semi-supervised classifier trained on WordNet-Affect emotion lists with features extracted from various lexical resources.",https://ieeexplore.ieee.org/abstract/document/6406509/
Erik Cambria,Meta-based Self-training and Re-weighting for Aspect-based Sentiment Analysis,2023,IEEE Transactions on Affective Computing,82,"Kai He, Rui Mao, Tieliang Gong, Chen Li, Erik Cambria",Kai He,Erik Cambria,5,"Aspect-based sentiment analysis (ABSA) means to identify fine-grained aspects, opinions, and sentiment polarities. Recent ABSA research focuses on utilizing multi-task learning (MTL) to achieve less computational costs and better performance. However, there are certain limits in MTL-based ABSA. For example, unbalanced labels and sub-task learning difficulties may result in the biases that some labels and sub-tasks are overfitting, while the others are underfitting. To address these issues, inspired by neuro-symbolic learning systems, we propose a meta-based self-training method with a meta-weighter (MSM). We believe that a generalizable model can be achieved by appropriate symbolic representation selection (in-domain knowledge) and effective learning control (regulation) in a neural system. Thus, MSM trains a teacher model to generate in-domain knowledge (e.g., unlabeled data selection and pseudo …",https://ieeexplore.ieee.org/abstract/document/9870538/
Erik Cambria,Context- and Sentiment-Aware Networks for Emotion Recognition in Conversation,2022,IEEE Transactions on Artificial Intelligence,82,"Geng Tu, Jintao Wen, Cheng Liu, Dazhi Jiang, Erik Cambria",Geng Tu,Erik Cambria,5,"Emotion recognition in conversation (ERC) has promising potential in many fields, such as recommendation systems, man–machine interaction, and medical care. In contrast to other emotion identification tasks, conversation is essentially a process of dynamic interaction in which people often convey emotional messages relying on context and common-sense knowledge. In this article, we propose a context- and sentiment-aware framework, termed Sentic GAT, to solve this challenge. In Sentic GAT, common-sense knowledge is dynamically represented by the context- and sentiment-aware graph attention mechanism based on sentimental consistency, and context information is captured by the dialogue transformer (DT) with hierarchical multihead attention (HMAT), where HMAT is used to obtain the dependency of historical utterances on themselves and other utterances for better context representation …",https://ieeexplore.ieee.org/abstract/document/9706271/
Erik Cambria,Sentiment-Aware Volatility Forecasting,2019,Knowledge-Based Systems,82,"Frank Xing, Erik Cambria, Yue Zhang",Frank Xing,Yue Zhang,3,"Recent advances in the integration of deep recurrent neural networks and statistical inferences have paved new avenues for joint modeling of moments of random variables, which is highly useful for signal processing, time series analysis, and financial forecasting. However, introducing explicit knowledge as exogenous variables has received little attention. In this paper, we propose a novel model termed sentiment-aware volatility forecasting (SAVING), which incorporates market sentiment for stock return fluctuation prediction. Our framework provides an ensemble of symbolic and sub-symbolic AI approaches, that is, including grounded knowledge into a connectionist neural network. The model aims at producing a more accurate estimation of temporal variances of asset returns by better capturing the bi-directional interaction between movements of asset price and market sentiment. The interaction is modeled …",https://www.sciencedirect.com/science/article/pii/S0950705119301546
Erik Cambria,Financial Sentiment Analysis: An Investigation into Common Mistakes and Silver Bullets,2020,Proceedings of COLING,80,"Frank Xing, Lorenzo Malandri, Yue Zhang, Erik Cambria",Frank Xing,Erik Cambria,4,"The recent dominance of machine learning-based natural language processing methods has fostered the culture of overemphasizing model accuracies rather than studying the reasons behind their errors. Interpretability, however, is a critical requirement for many downstream AI and NLP applications, eg, in finance, healthcare, and autonomous driving. This study, instead of proposing any “new model”, investigates the error patterns of some widely acknowledged sentiment analysis methods in the finance domain. We discover that (1) those methods belonging to the same clusters are prone to similar error patterns, and (2) there are six types of linguistic features that are pervasive in the common errors. These findings provide important clues and practical considerations for improving sentiment analysis models for financial applications.",https://aclanthology.org/2020.coling-main.85/
Erik Cambria,Time Expression Analysis and Recognition Using Syntactic Token Types and General Heuristic Rules,2017,Proceedings of ACL,80,"Xiaoshi Zhong, Aixin Sun, Erik Cambria",Xiaoshi Zhong,Erik Cambria,3,"Extracting time expressions from free text is a fundamental task for many applications. We analyze the time expressions from four datasets and find that only a small group of words are used to express time information, and the words in time expressions demonstrate similar syntactic behaviour. Based on the findings, we propose a type-based approach, named SynTime, to recognize time expressions. Specifically, we define three main syntactic token types, namely time token, modifier, and numeral, to group time-related regular expressions over tokens. On the types we design general heuristic rules to recognize time expressions. In recognition, SynTime first identifies the time tokens from raw text, then searches their surroundings for modifiers and numerals to form time segments, and finally merges the time segments to time expressions. As a light-weight rule-based tagger, SynTime runs in real time, and can be easily expanded by simply adding keywords for the text of different types and of different domains. Experiment on benchmark datasets and tweets data shows that SynTime outperforms state-of-the-art methods.",https://aclanthology.org/P17-1039/
Erik Cambria,Common Sense Knowledge for Handwritten Chinese Text Recognition,2012,Cognitive Computation,80,"Qiu-Feng Wang, Erik Cambria, Cheng-Lin Liu, Amir Hussain",Qiu-Feng Wang,Amir Hussain,4,"Compared to human intelligence, computers are far short of common sense knowledge which people normally acquire during the formative years of their lives. This paper investigates the effects of employing common sense knowledge as a new linguistic context in handwritten Chinese text recognition. Three methods are introduced to supplement the standard n-gram language model: embedding model, direct model, and an ensemble of these two. The embedding model uses semantic similarities from common sense knowledge to make the n-gram probabilities estimation more reliable, especially for the unseen n-grams in the training text corpus. The direct model, in turn, considers the linguistic context of the whole document to make up for the short context limit of the n-gram model. The three models are evaluated on a large unconstrained handwriting database, CASIA-HWDB, and the results show that …",https://link.springer.com/article/10.1007/s12559-012-9183-y
Erik Cambria,MetaPro: A Computational Metaphor Processing Model for Text Pre-Processing,2022,Information Fusion,79,"Rui Mao, Xiao Li, Mengshi Ge, Erik Cambria",Rui Mao,Erik Cambria,4,"Metaphor is a special linguistic phenomenon, challenging diverse natural language processing tasks. Previous works focused on either metaphor identification or domain-specific metaphor interpretation, e.g., interpreting metaphors with a specific part-of-speech, metaphors in a specific application scenario or metaphors with specific concepts. These methods cannot be used directly in everyday texts. In this paper, we propose a metaphor processing model, termed MetaPro, which integrates metaphor identification and interpretation modules for text pre-processing. To the best of our knowledge, this is the first end-to-end metaphor processing approach in the present field. MetaPro can identify metaphors in a sentence on token-level, paraphrasing the identified metaphors into their literal counterparts, and explaining metaphoric multi-word expressions. It achieves state-of-the-art performance in the evaluation of sub …",https://www.sciencedirect.com/science/article/pii/S1566253522000550
Erik Cambria,Sounds of Silence Breakers: Exploring Sexual Violence on Twitter,2018,Proceedings of ASONAM,79,"Aparup Khatua, Erik Cambria, Apalak Khatua",Aparup Khatua,Apalak Khatua,3,"Gender-based-violence is a serious concern in recent times. Due to the social stigma attached to these assaults, victims rarely come forward. Implementing policy measures to prevent sexual violence get constrained due to lack of crime statistics. However, the recent outcry on the Twitter platform allows us to address this concern. Sexual assaults occur at workplaces, public places, educational institutes and also at home. Policy level approaches and awareness campaign for these assaults would not be similar. So, we want to identify the risk factor associated with these sexual assaults. We extracted 0.7 million tweets during the #MeToo social media movement. Next, we employ deep learning techniques to classify these sexual violences. We observe that sexual assaults by a family member at own home is a more serious concern than harassment by a stranger at public places. This study reveals assaults by a known …",https://ieeexplore.ieee.org/abstract/document/8508576/
Erik Cambria,Explainable Metaphor Identification Inspired by Conceptual Metaphor Theory,2022,Proceedings of AAAI,76,"Mengshi Ge, Rui Mao, Erik Cambria",Mengshi Ge,Erik Cambria,3,"Metaphor is not only a linguistic phenomenon but also reflects the concept projection between source and target domains in human cognition. Previous sequence tagging-based metaphor identification methods could not model the concept projection, resulting in a limitation that the outputs of these models are unexplainable in the predictions of the metaphoricity labels. In this work, we propose the first explainable metaphor identification model, inspired by Conceptual Metaphor Theory. The model is based on statistic learning, a lexical resource, and a novel reward mechanism. Our model can identify the metaphoricity on the word-pair level, and explain the predicted metaphoricity labels via learned concept mappings. The use of the reward mechanism allows the model to learn the optimal concept mappings without knowing their true labels. Our method is also applicable for the concepts that are out of training domains by using the lexical resource. The automatically generated concept mappings demonstrate the implicit human thoughts in metaphoric expressions. Our experiments show the effectiveness of the proposed model in metaphor identification, and concept mapping tasks, respectively.",https://ojs.aaai.org/index.php/AAAI/article/view/21313
Erik Cambria,Seven Pillars for the Future of Artificial Intelligence,2023,IEEE Intelligent Systems,73,"Erik Cambria, Rui Mao, Melvin Chen, Zhaoxia Wang, Seng-Beng Ho",Erik Cambria,Seng-Beng Ho,5,"In recent years, artificial intelligence (AI) research has showcased tremendous potential to positively impact humanity and society. Although AI frequently outperforms humans in tasks related to classification and pattern recognition, it continues to face challenges when dealing with complex tasks such as intuitive decision making, sense disambiguation, sarcasm detection, and narrative understanding as these require advanced kinds of reasoning, e.g., common-sense reasoning and causal reasoning, which have not been emulated satisfactorily yet. To address these shortcomings, we propose seven pillars that we believe represent the key hallmark features for the future of AI, namely, multidisciplinarity, task decomposition, parallel analogy, symbol grounding, similarity measure, intention awareness, and trustworthiness.",https://ieeexplore.ieee.org/abstract/document/10352155/
Erik Cambria,Multitask Learning for Emotion and Personality Traits Detection,2022,Neurocomputing,72,"Yang Li, Amirmohammad Kazemeini, Yash Mehta, Erik Cambria",Yang Li,Erik Cambria,4,"In recent years, deep learning-based automated personality traits detection has received a lot of attention, especially now, due to the massive digital footprints of an individual. Moreover, many researchers have demonstrated that there is a strong link between personality traits and emotions. In this paper, we build on the known correlation between personality traits and emotional behaviors and propose a novel transferring based multitask learning framework that simultaneously predicts both of them. We also empirically evaluate and discuss different information-sharing mechanisms between the two tasks. To ensure the high quality of the learning process, we adopt a model-agnostic meta-learning-like framework for model optimization. Our computationally efficient multitask learning model achieves the state-of-the-art performance across multiple famous personality and emotion datasets, even outperforming …",https://www.sciencedirect.com/science/article/pii/S0925231222004180
Erik Cambria,Ensemble Hybrid Learning Methods for Automated Depression Detection,2023,IEEE Transactions on Computational Social Systems,70,"Luna Ansari, Shaoxiong Ji, Qian Chen, Erik Cambria",Luna Ansari,Erik Cambria,4,"Changes in human lifestyle have led to an increase in the number of people suffering from depression over the past century. Although in recent years, rates of diagnosing mental illness have improved, many cases remain undetected. Automated detection methods can help identify depressed or individuals at risk. An understanding of depression detection requires effective feature representation and analysis of language use. In this article, text classifiers are trained for depression detection. The key objective is to improve depression detection performance by examining and comparing two sets of methods: hybrid and ensemble. The results show that ensemble models outperform the hybrid model classification results. The strength and effectiveness of the combined features demonstrate that better performance can be achieved by multiple feature combinations and proper feature selection.",https://ieeexplore.ieee.org/abstract/document/9733425/
Erik Cambria,KnowleNet: Knowledge Fusion Network for Multimodal Sarcasm Detection,2023,Information Fusion,69,"Tan Yue, Rui Mao, Heng Wang, Zonghai Hua, Erik Cambria",Tan Yue,Erik Cambria,5,"Sarcasm is a form of communication often used to express contempt or ridicule, where the speaker conveys a message opposite to their true meaning, typically intending to mock or belittle a specific target. Sarcasm detection has gained great attention in the field of natural language processing due to the fact that sarcasm is widespread on social media and difficult to detect for machines. While early efforts in sarcasm detection solely relied on textual data, the abundance of multimodal data on social media is also non-negligible. Recent research has focused on multimodal sarcasm detection, where attention mechanisms and graph neural networks were commonly used to identify relevant information in both image and text data. However, these methods may overlook the importance of prior knowledge and cross-modal semantic contrast, which are crucial factors for human sarcasm detection. In this paper, we …",https://www.sciencedirect.com/science/article/pii/S1566253523002373
Erik Cambria,Intelligent Fake Reviews Detection based on Aspect Extraction and Analysis using Deep Learning,2022,Neural Computing and Applications,69,"Gourav Bathla, Pardeep Singh, Rahul Kumar Singh, Erik Cambria, Rajeev Tiwari",Gourav Bathla,Rajeev Tiwari,5,"In the era of social networking and e-commerce sites, users provide their feedback and comments in the form of reviews for any product, topic, or organization. Due to high influence of reviews on users, spammers use fake reviews to promote their product/organization and to demote the competitors. It is estimated that approximately 14% of reviews on any platform are fake reviews. Several researchers have proposed various approaches to detect fake reviews. The limitation of existing approaches is that complete review text is analysed which increases computation time and degrades accuracy. In our proposed approach, aspects are extracted from reviews and only these aspects and respective sentiments are employed for fake reviews detection. Extracted aspects are fed into CNN for aspect replication learning. The replicated aspects are fed into LSTM for fake reviews detection. As per our knowledge, aspects …",https://link.springer.com/article/10.1007/s00521-022-07531-8
Erik Cambria,Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation and Beyond,2025,arXiv preprint arXiv:2306.09841,67,"Fangzhi Xu, Qika Lin, Jiawei Han, Tianzhe Zhao, Jun Liu, Erik Cambria",Fangzhi Xu,Erik Cambria,6,"Large Language Models (LLMs) have achieved great success in various natural language tasks. It has aroused much interest in evaluating the specific reasoning capability of LLMs, such as multilingual reasoning and mathematical reasoning. However, as one of the key reasoning perspectives, logical reasoning capability has not yet been thoroughly evaluated. In this work, we aim to bridge those gaps and provide comprehensive evaluations. Firstly, to offer systematic evaluations, this paper selects fifteen typical logical reasoning datasets and organizes them into deductive, inductive, abductive and mixed-form reasoning settings. Considering the comprehensiveness of evaluations, we include three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD) and evaluate them on all selected datasets under zero-shot, one-shot and three-shot settings. Secondly, different from previous evaluations relying only on simple metrics (e.g., accuracy), we propose fine-level evaluations from objective and subjective manners, covering both answers and explanations. Also, to uncover the logical flaws of LLMs, bad cases will be attributed to five error types from two dimensions. Thirdly, to avoid the influences of knowledge bias and purely focus on benchmarking the logical reasoning capability of LLMs, we propose a new dataset with neutral content. It contains 3K samples and covers deductive, inductive and abductive reasoning settings. Based on the in-depth evaluations, this paper finally concludes the ability maps of logical reasoning capability from six dimensions (i.e., correct, rigorous, self-aware, active, oriented and no hallucination). It reflects the …",https://arxiv.org/abs/2306.09841
Erik Cambria,Dynamic Interactive Multiview Memory Network for Emotion Recognition in Conversation,2023,Information Fusion,67,"Jintao Wen, Dazhi Jiang, Geng Tu, Cheng Liu, Erik Cambria",Jintao Wen,Erik Cambria,5,"When available, multimodal data is key for enhanced emotion recognition in conversation. Text, audio, and video in dialogues can facilitate and complement each other in analyzing speakers’ emotions. However, it is very challenging to effectively fuse multimodal features to understand the detailed contextual information in conversations. In this work, we focus on dynamic interactions during the information fusion process and propose a Dynamic Interactive Multiview Memory Network (DIMMN) model to integrate interaction information for recognizing emotions. Specifically, the information fusion within DIMMN is through multiple perspectives (combining different modalities). We designed multiview layers in attention networks to enable the model to mine the crossmodal dynamic dependencies between different groups in the process of dynamic modal interaction. In order to learn the long-term dependency information …",https://www.sciencedirect.com/science/article/pii/S1566253522001786
Erik Cambria,Hierarchical Attention Network for Explainable Depression Detection on Twitter Aided by Metaphor Concept Mappings,2022,Proceedings of COLING,67,"Sooji Han, Rui Mao, Erik Cambria",Sooji Han,Erik Cambria,3,"Automatic depression detection on Twitter can help individuals privately and conveniently understand their mental health status in the early stages before seeing mental health professionals. Most existing black-box-like deep learning methods for depression detection largely focused on improving classification performance. However, explaining model decisions is imperative in health research because decision-making can often be high-stakes and life-and-death. Reliable automatic diagnosis of mental health problems including depression should be supported by credible explanations justifying models' predictions. In this work, we propose a novel explainable model for depression detection on Twitter. It comprises a novel encoder combining hierarchical attention mechanisms and feed-forward neural networks. To support psycholinguistic studies, our model leverages metaphorical concept mappings as input. Thus, it not only detects depressed individuals, but also identifies features of such users' tweets and associated metaphor concept mappings.",https://arxiv.org/abs/2209.07494
Erik Cambria,Predicting Political Sentiments of Voters from Twitter in Multi-party Contexts,2020,Applied Soft Computing,67,"Aparup Khatua, Apalak Khatua, Erik Cambria",Aparup Khatua,Erik Cambria,3,"Prior Twitter-based electoral research has mostly ignored multi-party contexts and ‘mix tweets’ that jointly mention more than one party. Hence, we investigate the complex nature of these mix tweets in a multi-party context, and we argue mix tweeting patterns of users implicitly capture their political opinions. We predict the political leaning of users based on their mix tweeting patterns in the context of the 2014 Indian General Election. We have agglomerated 2.4 million tweets from 0.15 million unique users. Next, we employ a multinomial logit regression model to test the hypothesized causal relation between mix tweeting patterns and the political leaning of users. Additionally, we also employ neural network-based algorithms to predict political leaning. Our study demonstrates that user-level mix-tweeting patterns can reveal the political opinions of Twitter users.",https://www.sciencedirect.com/science/article/pii/S1568494620306815
Erik Cambria,Role of Muscle Synergies in Real-Time Classification of Upper Limb Motions using Extreme Learning Machines,2016,Journal of NeuroEngineering and Rehabilitation,67,"Chris Wilson Antuvan, Federica Bisio, Francesca Marini, Shih-Cheng Yen, Erik Cambria, Lorenzo Masia",Chris Wilson Antuvan,Lorenzo Masia,6,"Myoelectric signals offer significant insights in interpreting the motion intention and extent of effort involved in performing a movement, with application in prostheses, orthosis and exoskeletons. Feature extraction plays a vital role, and follows two approaches: EMG and synergy features. More recently, muscle synergy based features are being increasingly explored, since it simplifies dimensionality of control, and are considered to be more robust to signal variations. Another important aspect in a myoelectrically controlled devices is the learning capability and speed of performance for online decoding. Extreme learning machine (ELM) is a relatively new neural-network based learning algorithm: its performance hasn’t been explored in the context of online control, which is a more reliable measure compared to offline analysis. To this purpose we aim at focusing our investigation …",https://link.springer.com/article/10.1186/s12984-016-0183-0
Erik Cambria,Fusing Task-Oriented and Open-Domain Dialogues in Conversational Agents,2022,Proceedings of AAAI,66,"Tom Young, Frank Xing, Vlad Pandelea, Jinjie Ni, Erik Cambria",Tom Young,Erik Cambria,5,"The goal of building intelligent dialogue systems has largely been separately pursued under two paradigms: task-oriented dialogue (TOD) systems, which perform task-specific functions, and open-domain dialogue (ODD) systems, which focus on non-goal-oriented chitchat. The two dialogue modes can potentially be intertwined together seamlessly in the same conversation, as easily done by a friendly human assistant. Such ability is desirable in conversational agents, as the integration makes them more accessible and useful. Our paper addresses this problem of fusing TODs and ODDs in multi-turn dialogues. Based on the popular TOD dataset MultiWOZ, we build a new dataset FusedChat, by rewriting the existing TOD turns and adding new ODD turns. This procedure constructs conversation sessions containing exchanges from both dialogue modes. It features inter-mode contextual dependency, ie, the dialogue turns from the two modes depend on each other. Rich dependency patterns such as co-reference and ellipsis are included. The new dataset, with 60k new human-written ODD turns and 5k re-written TOD turns, offers a benchmark to test a dialogue model's ability to perform inter-mode conversations. This is a more challenging task since the model has to determine the appropriate dialogue mode and generate the response based on the inter-mode context. However, such models would better mimic human-level conversation capabilities. We evaluate two baseline models on this task, including the classification-based two-stage models and the two-in-one fused models. We publicly release FusedChat and the baselines to propel future …",https://ojs.aaai.org/index.php/AAAI/article/view/21416
Erik Cambria,Towards Crowd Validation of the UK National Health Service,2010,Proceedings of WebSci,66,"Erik Cambria, Amir Hussain, Catherine Havasi",Erik Cambria,Catherine Havasi,3,"Online patient opinions are a very important instrument for the effective evaluation of local hospitals, hospices, and mental health services. The distillation of knowledge from this unstructured information, however, remains a difficult and complex task. In this paper, we aim to effectively mine and analyze this social information to make a comprehensive and dynamic evaluation of the UK National Health Service. To this end we use SenticNet, a new opinion mining and sentiment analysis resource which exploits AI and Semantic Web techniques to better recognize, interpret, and process opinions and sentiments in natural language text.",https://sentic.net/crowd-validation.pdf
Erik Cambria,SKIER: A Symbolic Knowledge Integrated Model for Conversational Emotion Recognition,2023,Proceedings of AAAI,65,"Wei Li, Luyao Zhu, Rui Mao, Erik Cambria",Wei Li,Erik Cambria,4,"Emotion recognition in conversation (ERC) has received increasing attention from the research community. However, the ERC task is challenging, largely due to the complex and unstructured properties of multi-party conversations. Besides, the majority of daily dialogues take place in a specific context or circumstance, which requires rich external knowledge to understand the background of a certain dialogue. In this paper, we address these challenges by explicitly modeling the discourse relations between utterances and incorporating symbolic knowledge into multi-party conversations. We first introduce a dialogue parsing algorithm into ERC and further improve the algorithm through a transfer learning method. Moreover, we leverage different symbolic knowledge graph relations to learn knowledge-enhanced features for the ERC task. Extensive experiments on three benchmarks demonstrate that both dialogue structure graphs and symbolic knowledge are beneficial to the model performance on the task. Additionally, experimental results indicate that the proposed model surpasses baseline models on several indices.",https://ojs.aaai.org/index.php/AAAI/article/view/26541
Erik Cambria,Arabic Question Answering System: A Survey,2022,Artificial Intelligence Review,63,"Tahani H Alwaneen, Aqil M Azmi, Hatim A Aboalsamh, Erik Cambria, Amir Hussain",Tahani H Alwaneen,Amir Hussain,5,"Question answering is a subfield of information retrieval. It is a task of answering a question posted in a natural language. A question answering system (QAS) may be considered a good alternative to search engines that return a set of related documents. The QAS system is composed of three main modules; question analysis, passage retrieval, and answer extraction. Over the years, numerous QASs have been presented for use in different languages. However, the the development of Arabic QASs has been slowed by linguistic challenges and the lack of resources and tools available to researchers. In this survey, we start with the challenges due to the language and how these challenges make the development of new Arabic QAS more difficult. Next, we do a detailed review of several Arabic QASs. This is followed by an in-depth analysis of the techniques and approaches in the three modules of a QAS. We …",https://link.springer.com/article/10.1007/S10462-021-10031-1
Erik Cambria,Computational Intelligence for Affective Computing and Sentiment Analysis [Guest Editorial],2019,IEEE Computational Intelligence Magazine,63,"Erik Cambria, Soujanya Poria, Amir Hussain, Bing Liu",Erik Cambria,Bing Liu,4,"Emotions are intrinsically part of our mental activity and play a key role in communication and decision-making processes. Emotion is a chain of events made up of feedback loops. Feelings and behavior can affect cognition, just as cognition can influence feeling. Emotion, cognition, and action interact in feedback loops and emotion can be viewed in a structural model tied to adaptation. Besides being important for the advancement of AI, detecting and interpreting emotional information are key in multiple areas of computer science, e.g., human-computer interaction, e-learning, e-health, domotics, automotive, security, user profiling and personalization.",https://ieeexplore.ieee.org/abstract/document/8686323/
Erik Cambria,"The MuSe 2022 Multimodal Sentiment Analysis Challenge: Humor, Emotional Reactions, and Stress",2022,Proceedings of ACM Multimedia,61,"Lukas Christ, Shahin Amiriparian, Alice Baird, Panagiotis Tzirakis, Alexander Kathan, Niklas Müller, Lukas Stappen, Eva-Maria Meßner, Andreas König, Alan Cowen, Erik Cambria, Björn W Schuller",Lukas Christ,Björn W Schuller,12,"The Multimodal Sentiment Analysis Challenge (MuSe) 2022 is dedicated to multimodal sentiment and emotion recognition. For this year's challenge, we feature three datasets: (i) the Passau Spontaneous Football Coach Humor (Passau-SFCH) dataset that contains audio-visual recordings of German football coaches, labelled for the presence of humour; (ii) the Hume-Reaction dataset in which reactions of individuals to emotional stimuli have been annotated with respect to seven emotional expression intensities, and (iii) the Ulm-Trier Social Stress Test (Ulm-TSST) dataset comprising of audio-visual data labelled with continuous emotion values (arousal and valence) of people in stressful dispositions. Using the introduced datasets, MuSe 2022 addresses three contemporary affective computing problems: in the Humor Detection Sub-Challenge (MuSe-Humor), spontaneous humour has to be recognised; in the …",https://dl.acm.org/doi/abs/10.1145/3551876.3554817
Erik Cambria,New Trends of Learning in Computational Intelligence [Guest Editorial],2015,IEEE Computational Intelligence Magazine,59,"Guang-Bin Huang, Erik Cambria, Kar-Ann Toh, Bernard Widrow, Zongben Xu",Guang-Bin Huang,Zongben Xu,5,"The articles in this special issue are dedicated to new trends of Learning in the field of computational intelligence. Over the past few decades, conventional computational intelligence techniques faced severe bottlenecks in terms of algorithmic learning. Particularly, in the areas of big data computation, brain science, cognition and reasoning, it is almost inevitable that intensive human intervention and time consuming trial and error efforts are to be employed before any meaningful observations can be obtained. Recent development of emerging computational intelligence techniques such as extreme learning machines (ELM) and fast solutions shed some light upon how to effectively deal with these computational bottlenecks.",https://ieeexplore.ieee.org/abstract/document/7083692/
Erik Cambria,Phonetic-Enriched Text Representation for Chinese Sentiment Analysis with Reinforcement Learning,2021,Information Fusion,58,"Haiyun Peng, Yukun Ma, Soujanya Poria, Yang Li, Erik Cambria",Haiyun Peng,Erik Cambria,5,"The Chinese pronunciation system offers two characteristics that distinguish it from other languages: deep phonemic orthography and intonation variations. In this paper, we hypothesize that these two important properties can play a major role in Chinese sentiment analysis. In particular, we propose two effective features to encode phonetic information and, hence, fuse it with textual information. With this hypothesis, we propose Disambiguate Intonation for Sentiment Analysis (DISA), a network that we develop based on the principles of reinforcement learning. DISA disambiguates intonations for each Chinese character (pinyin) and, hence, learns precise phonetic representations. We also fuse phonetic features with textual and visual features to further improve performance. Experimental results on five different Chinese sentiment analysis datasets show that the inclusion of phonetic features significantly and …",https://www.sciencedirect.com/science/article/pii/S1566253521000117
Erik Cambria,Virtual Prompt Pre-Training for Prototype-based Few-Shot Relation Extraction,2023,Expert Systems with Applications,57,"Kai He, Yucheng Huang, Rui Mao, Tieliang Gong, Chen Li, Erik Cambria",Kai He,Erik Cambria,6,"Prompt tuning with pre-trained language models (PLM) has exhibited outstanding performance by reducing the gap between pre-training tasks and various downstream applications, which requires additional labor efforts in label word mappings and prompt template engineering. However, in a label intensive research domain, e.g., few-shot relation extraction (RE), manually defining label word mappings is particularly challenging, because the number of utilized relation label classes with complex relation names can be extremely large. Besides, the manual prompt development in natural language is subjective to individuals. To tackle these issues, we propose a virtual prompt pre-training method, projecting the virtual prompt to latent space, then fusing with PLM parameters. The pre-training is entity-relation-aware for RE, including the tasks of mask entity prediction, entity typing, distant supervised RE, and …",https://www.sciencedirect.com/science/article/pii/S0957417422019455
Erik Cambria,"MER 2023: Multi-label Learning, Modality Robustness, and Semi-Supervised Learning",2023,Proceedings of ACM Multimedia,56,"Zheng Lian, Haiyang Sun, Licai Sun, Jinming Zhao, Ye Liu, Bin Liu, Jiangyan Yi, Meng Wang, Erik Cambria, Guoying Zhao, Björn W Schuller, Jianhua Tao",Zheng Lian,Jianhua Tao,12,"The first Multimodal Emotion Recognition Challenge (MER 2023)1 was successfully held at ACM Multimedia. The challenge focuses on system robustness and consists of three distinct tracks: (1) MER-MULTI, where participants are required to recognize both discrete and dimensional emotions; (2) MER-NOISE, in which noise is added to test videos for modality robustness evaluation; (3) MER-SEMI, which provides a large amount of unlabeled samples for semi-supervised learning. In this paper, we introduce the motivation behind this challenge, describe the benchmark dataset, and provide some statistics about participants. To continue using this dataset after MER 2023, please sign a new End User License Agreement2 and send it to our official email address3. We believe this high-quality dataset can become a new benchmark in multimodal emotion recognition, especially for the Chinese research community.",https://dl.acm.org/doi/abs/10.1145/3581783.3612836
Erik Cambria,Fusing Topology Contexts and Logical Rules in Language Models for Knowledge Graph Completion,2023,Information Fusion,55,"Qika Lin, Rui Mao, Jun Liu, Fangzhi Xu, Erik Cambria",Qika Lin,Erik Cambria,5,"Knowledge graph completion (KGC) aims to infer missing facts based on the observed ones, which is significant for many downstream applications. Given the success of deep learning and pre-trained language models (LMs), some LM-based methods are proposed for the KGC task. However, most of them focus on modeling the text of fact triples and ignore the deeper semantic information (e.g., topology contexts and logical rules) that is significant for KG modeling. For such a reason, we propose a unified framework FTL-LM to Fuse Topology contexts and Logical rules in Language Models for KGC, which mainly contains a novel path-based method for topology contexts learning and a variational expectation–maximization (EM) algorithm for soft logical rule distilling. The former utilizes a heterogeneous random-walk to generate topology paths and further reasoning paths that can represent topology contexts …",https://www.sciencedirect.com/science/article/pii/S1566253522001592
Erik Cambria,Comment Toxicity Detection via a Multichannel Convolutional Bidirectional Gated Recurrent Unit,2021,Neurocomputing,54,"Ashok J Kumar, S Abirami, Tina Esther Trueman, Erik Cambria",Ashok J Kumar,Erik Cambria,4,"Recently, toxicity identification has become the most serious problem in online communities and social networking sites. Therefore, an automatic toxic identification system needs to be developed for preventing and limiting users from these online environments. In this paper, we present a multichannel convolutional bidirectional gated recurrent unit (MCBiGRU) for detecting toxic comments in a multilabel environment. The proposed model generates word vectors using pre-trained word embeddings. Moreover, this hybrid model extracts local features with many filters and different kernel sizes to model input words with long term dependency. We then integrate multiple channels with a fully connected layer, normalization layer, and an output layer with a sigmoid activation function for predicting multilabel categories. The experimental results indicate that the proposed MCBiGRU model outperforms in terms of multilabel …",https://www.sciencedirect.com/science/article/pii/S0925231221002691
Erik Cambria,A Multilingual Semi-Supervised Approach in Deriving Singlish Sentic Patterns for Polarity Detection,2016,Knowledge-Based Systems,54,"Siaw Ling Lo, Erik Cambria, Raymond Chiong, David Cornforth",Siaw Ling Lo,David Cornforth,4,"Due to the huge volume and linguistic variation of data shared online, accurate detection of the sentiment of a message (polarity detection) can no longer rely on human assessors or through simple lexicon keyword matching. This paper presents a semi-supervised approach in constructing essential toolkits for analysing the polarity of a localised scarce-resource language, Singlish (Singaporean English). Corpus-based bootstrapping using a multilingual, multifaceted lexicon was applied to construct an annotated testing dataset, while unsupervised methods such as lexicon polarity detection, frequent item extraction through association rules and latent semantic analysis were used to identify the polarity of Singlish n-grams before human assessment was done to isolate misleading terms and remove concept ambiguity. The findings suggest that this multilingual approach outshines polarity analysis using only the …",https://www.sciencedirect.com/science/article/pii/S0950705116300764
Erik Cambria,New Avenues in Knowledge Bases for Natural Language Processing,2016,Knowledge-Based Systems,53,"Erik Cambria, Björn Schuller, Yunqing Xia, Bebo White",Erik Cambria,Bebo White,4,"New avenues in knowledge bases for natural language processing | Knowledge-Based 
Systems ACM Digital Library home ACM home Google, Inc. (search) Advanced Search 
Browse About Sign in Register Advanced Search Journals Magazines Proceedings Books 
SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced 
Search Knowledge-Based Systems Periodical Home Latest Issue Archive Authors 
Affiliations Award Winners More Home Browse by Title Periodicals Knowledge-Based 
Systems Vol. 108, No. C New avenues in knowledge bases for natural language processing 
research-article Share on New avenues in knowledge bases for natural language 
processing Authors: Erik Cambria School of Computer Science and Engineering, Nanyang 
Technological University, Singapore School of Computer Science and Engineering, 
Nanyang Technological University, Singapore View …",https://dl.acm.org/doi/abs/10.1016/j.knosys.2016.07.025
Erik Cambria,Computational Intelligence for Big Social Data Analysis [Guest Editorial],2016,IEEE Computational Intelligence Magazine,53,"Erik Cambria, Newton Howard, Yunqing Xia, Tat-Seng Chua",Erik Cambria,Tat-Seng Chua,4,"The articles in this special section focus on computational intelligence for big social data analytics. In the eras of social connectedness and social colonization, people are becoming increasingly enthusiastic about interacting, sharing, and collaborating through online collaborative media. In recent years, this collective intelligence has spread to many different areas, with particular focus on fields related to everyday life such as commerce, tourism, education, and health, causing the size of the Social Web to expand exponentially. The distillation of knowledge from such a large amount of unstructured information, however, is an extremely difficult task, as the contents of today's Web are perfectly suitable for human consumption, but remain hardly understandable to machines. Big social data analysis grows out of this need and combines multiple disciplines such as social network analysis, multimedia management, social …",https://ieeexplore.ieee.org/abstract/document/7515242/
Erik Cambria,OntoSenticNet 2: Enhancing Reasoning within Sentiment Analysis,2022,IEEE Intelligent Systems,52,"Mauro Dragoni, Ivan Donadello, Erik Cambria",Mauro Dragoni,Erik Cambria,3,"Sentiment analysis is a trending topic that has not yet exhausted its attractiveness, despite the huge research effort carried out in the last 15 years. One of the most promising directions to investigate is the integration of knowledge-based representations within sentiment analysis systems in order to enhance their expressiveness and, at the same time, to enable reasoning over the relevant information detected within opinion-based sources. In this article, we present an improved version of OntoSenticNet providing: i) an updated definition of concepts, properties, and individuals together with an improved hierarchical organization of such entities; ii) the modeling of the sentic algebra elements for supporting the execution of semantic sentiment operations at reasoning time; and iii) the conceptual model of sentiment dependencies and discovery paths. The process of building OntoSenticNet 2 is discussed and some …",https://ieeexplore.ieee.org/abstract/document/9779602/
Erik Cambria,A Convolutional Stacked Bidirectional LSTM with a Multiplicative Attention Mechanism for Aspect Category and Sentiment Detection,2021,Cognitive Computation,52,"Ashok J Kumar, Tina Esther Trueman, Erik Cambria",Ashok J Kumar,Erik Cambria,3,"Traditionally, sentiment analysis is a binary classification task that aims to categorize a piece of text as positive or negative. This approach, however, can be too simplistic when the text under scrutiny contains more than one opinion target. Hence, aspect-based sentiment analysis provides fine-grained sentiment understanding of the product, service, or policy. Machine learning and deep learning algorithms play an important role in this kind of task. Also, attention mechanism has shown breakthrough in the field of natural language processing. Therefore, we propose a convolutional stacked bidirectional long short-term memory with a multiplicative attention mechanism for aspect category and sentiment polarity detection. More specifically, we treat the proposed model as a multiclass classification problem. The proposed model is evaluated using SemEval-2015 and SemEval-2016 dataset. Our proposed model …",https://link.springer.com/article/10.1007/s12559-021-09948-0
Erik Cambria,Gated Recurrent Unit with Multilingual Universal Sentence Encoder for Arabic Aspect-Based Sentiment Analysis,2023,Knowledge-Based Systems,51,"AL-Smadi Mohammad, Mahmoud M Hammad, A Sa’ad, AL-Tawalbeh Saja, Erik Cambria",AL-Smadi Mohammad,Erik Cambria,5,"The increasing interactive content in the Internet motivated researchers and data scientists to conduct Aspect-Based Sentiment Analysis (ABSA) research to understand the various sentiments and the different aspects of a product in a single user’s comment. Determining the various aspects along with their polarities (positive, negative, or neutral) from a single comment is a challenging problem. To this end, we have designed and developed a deep learning model based on Gated Recurrent Units (GRU) and features extracted using the Multilingual Universal Sentence Encoder (MUSE). The proposed Pooled-GRU model trained on a Hotels’ Arabic reviews to address two ABSA tasks: (1) aspect extraction, and (2) aspect polarity classification. The proposed model achieved high results with 93.0% F1 score in the former task and 90.86% F1 score in the latter task. Our experimental results show that our proposed model …",https://www.sciencedirect.com/science/article/pii/S0950705121008029
Erik Cambria,MuSe-Toolbox: The Multimodal Sentiment Analysis Continuous Annotation Fusion and Discrete Class Transformation Toolbox,2021,,50,"Lukas Stappen, Lea Schumann, Benjamin Sertolli, Alice Baird, Benjamin Weigell, Erik Cambria, Björn W Schuller",Lukas Stappen,Björn W Schuller,7,"We introduce the MuSe-Toolbox - a Python-based open-source toolkit for creating a variety of continuous and discrete emotion gold standards. In a single framework, we unify a wide range of fusion methods and propose the novel Rater Aligned Annotation Weighting (RAAW), which aligns the annotations in a translation-invariant way before weighting and fusing them based on the inter-rater agreements between the annotations. Furthermore, discrete categories tend to be easier for humans to interpret than continuous signals. With this in mind, the MuSe-Toolbox provides the functionality to run exhaustive searches for meaningful class clusters in the continuous gold standards. To our knowledge, this is the first toolkit that provides a wide selection of state-of-the-art emotional gold standard methods and their transformation to discrete classes. Experimental results indicate that MuSe-Toolbox can provide promising …",https://dl.acm.org/doi/abs/10.1145/3475957.3484451
Erik Cambria,PerSent: A Freely Available Persian Sentiment Lexicon,2016,Proceedings of BICS,50,"Kia Dashtipour, Amir Hussain, Qiang Zhou, Alexander Gelbukh, Ahmad YA Hawalah, Erik Cambria",Kia Dashtipour,Erik Cambria,6," People need to know other people’s opinions to make well-informed decisions to buy products or services. Companies and organizations need to understand people’s attitude towards their products and services and use feedback from the customers to improve their products. Sentiment analysis techniques address these needs. While the majority of Internet users are not English speakers, most research papers in the sentiment-analysis field focus on English; resources for other languages are scarce. In this paper, we introduce a Persian sentiment lexicon, which consists of 1500 words along with their part-of-speech tags and polarity scores. We have used two machine-learning algorithms to evaluate the performance of this resource on a sentiment analysis task. The lexicon is freely available and can be downloaded from our website. ",https://link.springer.com/chapter/10.1007/978-3-319-49685-6_28
Erik Cambria,Unsupervised Commonsense Knowledge Enrichment for Domain-Specific Sentiment Analysis,2016,Cognitive Computation,48,"Nir Ofek, Soujanya Poria, Lior Rokach, Erik Cambria, Amir Hussain, Asaf Shabtai",Nir Ofek,Asaf Shabtai,6,"Sentiment analysis in natural language text is a challenging task involving a deep understanding of both syntax and semantics. Leveraging the polarity of multiword expressions—or concepts—rather than single words can mitigate the difficulty of such a task as these expressions carry more contextual information than isolated words. Such contextual information is the key to understanding both the syntactic and semantic structure of natural language text and hence is useful in tasks such as sentiment analysis. In this work, we propose a new method to enrich SenticNet (a publicly available knowledge base for concept-level sentiment analysis) with domain-level concepts composed of aspects and sentiment word pairs, along with a measure of their polarity. We process a set of unlabeled texts and, by considering the statistical co-occurrence information, generate a direct acyclic graph (DAG) of concepts. The …",https://link.springer.com/article/10.1007/s12559-015-9375-3
Erik Cambria,Bridging Cognitive Models and Recommender Systems,2020,Cognitive Computation,47,"Cecilio Angulo, Zoe Falomir, Davide Anguita, Núria Agell, Erik Cambria",Cecilio Angulo,Erik Cambria,5,"Intelligent systems must be designed to interact with human beings. Hence, ideal systems for interacting with people would be those capable of interpreting their environment cognitively, that is, similarly to how people do it. This special issue proposed a space for researchers to discuss the issues and advantages of bridging different fields for the study of cognitive approaches for recommendation [1–4], and for the development of recommender systems shaping cognitive architectures [5, 6]. In recent conferences and meetings [7, 8], we realized that the link between these fields has not received sufficient attention. In our opinion, recommendations should also be designed and evaluated considering cognitive factors. The level of cognitive reasoning in a system or the number of creative solutions that a system can provide can be considered as a measure to evaluate the intelligence of that system [9, 10]. This issue is …",https://link.springer.com/article/10.1007/s12559-020-09719-3
Erik Cambria,Ensemble Application of ELM and GPU for Real-Time Multimodal Sentiment Analysis,2018,Memetic Computing,47,"Ha-Nguyen Tran, Erik Cambria",Ha-Nguyen Tran,Erik Cambria,2,"The enormous number of videos posted everyday on multimedia websites such as Facebook and YouTube makes the Internet an infinite source of information. Collecting and processing such information, however, is a very challenging task as it involves dealing with a huge amount of information that is changing at a very high speed. To this end, we leverage on the processing speed of extreme learning machine and graphics processing unit to overcome the limitations of standard learning algorithms and central processing unit (CPU) and, hence, perform real-time multimodal sentiment analysis, i.e., harvesting sentiments from web videos by taking into account audio, visual and textual modalities as sources of the information. For the sentiment classification, we leveraged on sentic memes, i.e., basic units of sentiment whose combination can potentially describe the full range of emotional experiences that …",https://link.springer.com/article/10.1007/s12293-017-0228-3
Erik Cambria,Multimodal Sentiment Analysis,2018,,46,"Soujanya Poria, Amir Hussain, Erik Cambria",Soujanya Poria,Erik Cambria,3,,
Erik Cambria,Sentic API: A Common-Sense based API for Concept-level Sentiment Analysis,2014,Proceedings of WWW Workshops,46,"Erik Cambria, Soujanya Poria, Alexander Gelbukh, Kenneth Kwok",Erik Cambria,Kenneth Kwok,4,"The bag-of-concepts model can represent semantics associated with natural language text much better than bags-of-words. In the bagof-words model, in fact, a concept such as cloud_computing would be split into two separate words, disrupting the semantics of the input sentence. Working at concept-level is important for tasks such as opinion mining, especially in the case of microblogging analysis. In this work, we present Sentic API, a common-sense based application programming interface for concept-level sentiment analysis, which provides semantics and sentics (that is, denotative and connotative information) associated with 15,000 natural language concepts.",https://dr.ntu.edu.sg/handle/10220/41976
Erik Cambria,Sequential Fusion of Facial Appearance and Dynamics for Depression Recognition,2021,Pattern Recognition Letters,45,"Qian Chen, Iti Chaturvedi, Shaoxiong Ji, Erik Cambria",Qian Chen,Erik Cambria,4,"In mental health assessment, it is validated that nonverbal cues like facial expressions can be indicative of depressive disorders. Recently, the multimodal fusion of facial appearance and dynamics based on convolutional neural networks has demonstrated encouraging performance in depression analysis. However, correlation and complementarity between different visual modalities have not been well studied in prior methods. In this paper, we propose a sequential fusion method for facial depression recognition. For mining the correlated and complementary depression patterns in multimodal learning, a chained-fusion mechanism is introduced to jointly learn facial appearance and dynamics in a unified framework. We show that such sequential fusion can provide a probabilistic perspective of the model correlation and complementarity between two different data modalities for improved depression recognition …",https://www.sciencedirect.com/science/article/pii/S0167865521002397
Erik Cambria,Radical-Based Hierarchical Embeddings for Chinese Sentiment Analysis at Sentence Level,2017,Proceedings of FLAIRS,45,"Haiyun Peng, Erik Cambria, Xiaomei Zou",Haiyun Peng,Xiaomei Zou,3,"Text representation in Chinese sentiment analysis is usually working at word or character level. In this paper, we prove that radical-level processing could greatly improve sentiment classification performance. In particular, we propose two types of Chinese radical-based hierarchical embeddings. The embeddings incorporate not only semantics at radical and character level, but also sentiment information. In the evaluation of our embeddings, we conduct Chinese sentiment analysis at sentence level on four different datasets. Experimental results validate our assumption that radical-level semantics and sentiments can contribute to sentence-level sentiment classification and demonstrate the superiority of our embeddings over classic textual features and popular word and character embeddings.",https://cdn.aaai.org/ocs/15460/15460-68671-1-PB.pdf
Erik Cambria,Discriminative Bi-Term Topic Model for Headline-Based Social News Clustering,2015,Proceedings of FLAIRS,45,"Yunqing Xia, Nan Tang, Amir Hussain, Erik Cambria",Yunqing Xia,Erik Cambria,4,"Social news are becoming increasingly popular. News organizations and popular journalists are starting to use social media more and more heavily for broadcasting news. The major challenge in social news clustering lies in the fact that textual content is only a headline, which is much shorter than the fulltext. Previous works showed that the bi-term topic model (BTM) is effective in modeling short text such as tweets. However, the drawback is that all non-stop terms are considered equally in forming the bi-terms. In this paper, a discriminative bi-term topic model (d-BTM) is presented, which tries to exclude less indicative bi-terms by discriminating topical terms from general and documentspecific ones. Experiments on TDT4 and Reuter-21578 show that using merely headlines, the d-BTM model is able to induce latent topics that are nearly as good as that are generated by LDA using news fulltext as evidence. The major contribution of this work lies in the empirical study on the reliability of topic modeling using merely news headlines.",https://cdn.aaai.org/ocs/10428/10428-46121-1-PB.pdf
Erik Cambria,Enhancing Business Intelligence by Means of Suggestive Reviews,2014,The Scientific World Journal,45,"Atika Qazi, Ram Gopal Raj, Muhammad Tahir, Erik Cambria, Karim Bux Shah Syed",Atika Qazi,Karim Bux Shah Syed,5,"Appropriate identification and classification of online reviews to satisfy the needs of current and potential users pose a critical challenge for the business environment. This paper focuses on a specific kind of reviews: the suggestive type. Suggestions have a significant influence on both consumers’ choices and designers’ understanding and, hence, they are key for tasks such as brand positioning and social media marketing. The proposed approach consists of three main steps: (1) classify comparative and suggestive sentences; (2) categorize suggestive sentences into different types, either explicit or implicit locutions; (3) perform sentiment analysis on the classified reviews. A range of supervised machine learning approaches and feature sets are evaluated to tackle the problem of suggestive opinion mining. Experimental results for all three tasks are obtained on a dataset of mobile phone reviews and demonstrate …",https://onlinelibrary.wiley.com/doi/abs/10.1155/2014/879323
Erik Cambria,"SenticNet 8: Fusing Emotion AI and Commonsense AI for Interpretable, Trustworthy, and Explainable Affective Computing",2024,Proceedings of HCII,44,"Erik Cambria, Xulang Zhang, Rui Mao, Melvin Chen, Kenneth Kwok",Erik Cambria,Kenneth Kwok,5,"ChatGPT has stunned the world with its ability to generate detailed, original, and accurate responses to prompts. While it unlocked solutions to problems that were previously considered unsolvable, however, it also introduced new ones. One of such problems is the phenomenon known as hallucination, the generation of content that is nonsensical or unfaithful to the provided source content. In this work, we propose SenticNet 8, a neurosymbolic AI framework leveraging an ensemble of commonsense knowledge representation and hierarchical attention networks, which aims to mitigate some of these issues in the context of affective computing. In particular, we focus on the tasks of sentiment analysis, personality prediction, and suicidal ideation detection. Results show that SenticNet 8 presents superior accuracy with respect to all four baselines, namely: bag-of-words, word2vec, RoBERTa, and ChatGPT. Unlike …",https://link.springer.com/chapter/10.1007/978-3-031-76827-9_11
Erik Cambria,Dialogue Systems with Audio Context,2020,Neurocomputing,44,"Tom Young, Vlad Pandelea, Soujanya Poria, Erik Cambria",Tom Young,Erik Cambria,4,"Research on building dialogue systems that converse with humans naturally has recently attracted a lot of attention. Most work on this area assumes text-based conversation, where the user message is modeled as a sequence of words in a vocabulary. Real-world human conversation, in contrast, involves other modalities, such as voice, facial expression and body language, which can influence the conversation significantly in certain scenarios. In this work, we explore the impact of incorporating the audio features of the user message into generative dialogue systems. Specifically, we first design an auxiliary response retrieval task for audio representation learning. Then, we use word-level modality fusion to incorporate the audio features as additional context to our main generative model. Experiments show that our audio-augmented model outperforms the audio-free counterpart on perplexity, response diversity …",https://www.sciencedirect.com/science/article/pii/S0925231220300758
Erik Cambria,A Survey of Graph Processing on Graphics Processing Units,2018,The Journal of Supercomputing,44,"Ha-Nguyen Tran, Erik Cambria",Ha-Nguyen Tran,Erik Cambria,2,"Graphics processing units (GPUs) have become popular high-performance computing platforms for a wide range of applications. The trend of processing graph structures on modern GPUs has also attracted an increasing interest in recent years. This article aims to review research works on adapting the massively parallel architecture of GPUs to accelerate the performance of fundamental graph operations. Despite their merits, some factors such as the unique architecture of GPUs, limited programming models, and irregular structures of graphs prevent GPU implementations from achieving high performance. Thus, this survey also discusses challenges and optimization techniques used by recent studies to fully utilize the GPU capability. A categorization of the existing research works is also presented based on the specific issues these attempted to solve.",https://link.springer.com/article/10.1007/s11227-017-2225-1
Erik Cambria,Stock Trading Rule Discovery with Double Deep Q-Network,2021,Applied Soft Computing,43,"Yong Shi, Wei Li, Luyao Zhu, Kun Guo, Erik Cambria",Yong Shi,Erik Cambria,5,"Stock market serves as an important indicator of today’s economy. Predicting the price fluctuation of stocks and acquiring the maximum gains has been the main concern of investors. In recent years, deep learning models are widely applied to stock market prediction and have achieved good performances. However, the majority of these deep learning based models belong to supervised learning methods and are not capable of dealing with long-term targets. Therefore, in this paper we proposed a deep reinforcement learning based stock market trading model, which is suitable for predicting stock price fluctuation and stock transactions. We carefully devise the reward function and deep learning based policy network, which enables the model to capture the hidden dependencies and latent dynamics in the stock data. In order to evaluate the superiority of the proposed model, stock price trend forecasting and …",https://www.sciencedirect.com/science/article/pii/S156849462100243X
Erik Cambria,New Research Methods & Algorithms in Social Network Analysis,2021,Future Generation Computer Systems,43,"David Camacho, Ma Victoria Luzón, Erik Cambria",David Camacho,Erik Cambria,3,"The exponential growth of social media and online social networks (e.g., Facebook, Twitter, Instagram, and TikTok) has changed the daily lives of millions of people. The ease to accessing, gathering and processing available data and the high societal and industrial interest in such data have attracted the interest of a large of research disciplines. This special issue has been focused mainly on Data Science and Artificial Intelligence techniques, and their application to social network analysis. The issue provides a total of 12 selected papers (out of 65) that represent latest advances and developments in these areas.",https://www.sciencedirect.com/science/article/pii/S0167739X20324912
Erik Cambria,End-to-End Latent-Variable Task-Oriented Dialogue System with Exact Log-Likelihood Optimization,2020,World Wide Web,42,"Haotian Xu, Haiyun Peng, Haoran Xie, Erik Cambria, Liuyang Zhou, Weiguo Zheng",Haotian Xu,Weiguo Zheng,6,"We propose an end-to-end dialogue model based on a hierarchical encoder-decoder, which employed a discrete latent variable to learn underlying dialogue intentions. The system is able to model the structure of utterances dominated by statistics of the language and the dependencies among utterances in dialogues without manual dialogue state design. We argue that the latent discrete variable interprets the intentions that guide machine responses generation. We also propose a model which can be refined autonomously with reinforcement learning, due to that intention selection at each dialogue turn can be formulated as a sequential decision-making process. Our experiments show that exact MLE optimized model is much more robust than neural variational inference on dialogue success rate with limited BLEU sacrifice.",https://link.springer.com/article/10.1007/s11280-019-00688-8
Erik Cambria,Ensemble of Technical Analysis and Machine Learning for Market Trend Prediction,2018,Proceedings of IEEE SSCI,42,"Andrea Picasso, Simone Merello, Luca Oneto, Yukun Ma, Lorenzo Malandri, Erik Cambria",Andrea Picasso,Erik Cambria,6,,
Erik Cambria,MetaPro Online: A Computational Metaphor Processing Online System,2023,Proceedings of ACL,41,"Rui Mao, Xiao Li, Kai He, Mengshi Ge, Erik Cambria",Rui Mao,Erik Cambria,5,"M etaphoric expressions are a special linguistic phenomenon, frequently appearing in everyday language. Metaphors do not take their literal meanings in contexts, which may cause obstacles for language learners to understand them. Metaphoric expressions also reflect the cognition of humans via concept mappings, attracting great attention from cognitive science and psychology communities. Thus, we aim to develop a computational metaphor processing online system, termed MetaPro Online 1, that allows users without a coding background, eg, language learners and linguists, to easily query metaphoricity labels, metaphor paraphrases, and concept mappings for non-domainspecific text. The outputs of MetaPro can be directly used by language learners and natural language processing downstream tasks because MetaPro is an end-to-end system.",https://aura.abdn.ac.uk/bitstream/handle/2164/22918/Mao_etal_ACL_Metapro_Online_a_VOR.pdf?sequence=1
Erik Cambria,Combining ELMs with Random Projections,2013,IEEE Intelligent Systems,41,"Paolo Gastaldo, Rodolfo Zunino, Erik Cambria, Sergio Decherchi",Paolo Gastaldo,Sergio Decherchi,4,"RP is a simple and powerful dimension reduction technique that uses a suitably scaled random matrix with independent, normally distributed entries to project data into low-dimensional spaces. The procedure to get a random projection is straightforward and arises from the Johnson-Lindenstrauss (JL) lemma [2]. The lemma states that any N point set lying in d-dimensional Euclidean space can be embedded into a r-dimensional space, with r≥ O (ε− 2ln (N)), without distorting the distances between any pair of points by more than a factor 1±ε, where ε∈(0, 1). Over the years, the use of probabilistic methods greatly simplified the original proof of Johnson and Lindenstrauss, and at the same time lead to straightforward randomized algorithms for implementing the transformation. In matrix notation, the embedding operation is expressed as",https://w.sentic.net/rp-elm.pdf
Erik Cambria,ECPEC: Emotion-Cause Pair Extraction in Conversations,2023,IEEE Transactions on Affective Computing,40,"Wei Li, Yang Li, Vlad Pandelea, Mengshi Ge, Luyao Zhu, Erik Cambria",Wei Li,Erik Cambria,6,"Conversational sentiment analysis (CSA) and emotion-cause pair extraction (ECPE) tasks have attracted increasing attention in recent years. The former aims to predict the sentiment states of speakers in a conversation, and the latter is about extracting emotion-cause clauses in a document. However, one drawback of CSA is that it cannot model the causal reasoning among emotion and neutral utterances from different speakers. In this work, we propose a new task: emotion-cause pair extraction in conversations (ECPEC), which aims to extract pairs of emotional utterances and corresponding cause utterances in conversations. The utterance-level ECPEC task is more challenging since the distance between emotion and cause utterances is larger than that of the clause-level ECPE task. To this end, we build a novel dataset ConvECPE and propose a specifically designed two-step framework for the new ECPEC …",https://ieeexplore.ieee.org/abstract/document/9926166/
Erik Cambria,Extracting Time Expressions and Named Entities with Constituent-Based Tagging Schemes,2020,Cognitive Computation,40,"Xiaoshi Zhong, Erik Cambria, Amir Hussain",Xiaoshi Zhong,Amir Hussain,3,"Time expressions and named entities play important roles in data mining, information retrieval, and natural language processing. However, the conventional position-based tagging schemes (e.g., the BIO and BILOU schemes) that previous research used to model time expressions and named entities suffer from the problem of inconsistent tag assignment. To overcome the problem of inconsistent tag assignment, we designed a new type of tagging schemes to model time expressions and named entities based on their constituents. Specifically, to model time expressions, we defined a constituent-based tagging scheme termed TOMN scheme with four tags, namely T, O, M, and N, indicating the defined constituents of time expressions, namely time token, modifier, numeral, and the words outside time expressions. To model named entities, we defined a constituent-based tagging scheme termed UGTO scheme with …",https://link.springer.com/article/10.1007/s12559-020-09714-8
Erik Cambria,Time Expression Recognition Using a Constituent-Based Tagging Scheme,2018,Proceedings of WWW,40,"Xiaoshi Zhong, Erik Cambria",Xiaoshi Zhong,Erik Cambria,2,"We find from four datasets that time expressions are formed by loose structure and the words used to express time information can differentiate time expressions from common text. The findings drive us to design a learning method named TOMN to model time expressions. TOMN defines a time-related tagging scheme named TOMN scheme with four tags, namely \tomnT,\tomnO, \tomnM,and \tomnN, indicating the constituents of time expression, namely \tomnT ime token, \tomnM odifier, \tomnN umeral, and the words \tomnO utside time expression. In modeling, TOMN assigns a word with a TOMN tag under conditional random fields with minimal features. Essentially, our constituent-based TOMN scheme overcomes the problem of inconsistent tag assignment that is caused by the conventional position-based tagging schemes (\eg BIO scheme and BILOU scheme). Experiments show that TOMN is equally or more …",https://dl.acm.org/doi/abs/10.1145/3178876.3185997
Erik Cambria,Ten Years of Sentic Computing,2022,Cognitive Computation,39,"Yosephine Susanto, Erik Cambria, Bee Chin Ng, Amir Hussain",Yosephine Susanto,Amir Hussain,4,"Sentic computing is a multi-disciplinary approach to sentiment analysis at the crossroads between affective computing and commonsense computing, which exploits both computer and social sciences to better recognize, interpret, and process opinions and sentiments over the Web. In the last ten years, many different models (such as the Hourglass of Emotions and Sentic Patterns), resources (such as AffectiveSpace and SenticNet), algorithms (such as Sentic LDA and Sentic LSTM), and applications (such as Sentic PROMs and Sentic Album) have been developed under the umbrella of sentic computing. In this paper, we review all such models, resources, algorithms, and applications together with the key shifts and tasks introduced by sentic computing in the context of affective computing and sentiment analysis. We also discuss future directions in these fields.",https://link.springer.com/article/10.1007/s12559-021-09824-x
Erik Cambria,Discovering Bayesian Market Views for Intelligent Asset Allocation,2018,Proceedings of ECML,39,"Frank Xing, Erik Cambria, Lorenzo Malandri, Carlo Vercellis",Frank Xing,Carlo Vercellis,4,"Along with the advance of opinion mining techniques, public mood has been found to be a key element for stock market prediction. However, how market participants’ behavior is affected by public mood has been rarely discussed. Consequently, there has been little progress in leveraging public mood for the asset allocation problem, which is preferred in a trusted and interpretable way. In order to address the issue of incorporating public mood analyzed from social media, we propose to formalize public mood into market views, because market views can be integrated into the modern portfolio theory. In our framework, the optimal market views will maximize returns in each period with a Bayesian asset allocation model. We train two neural models to generate the market views, and benchmark the model performance on other popular asset allocation strategies. Our experimental results suggest that the …",https://link.springer.com/chapter/10.1007/978-3-030-10997-4_8
Erik Cambria,Isanette: A Common and Common Sense Knowledge Base for Opinion Mining,2011,Proceedings of ICDM Workshops,38,"Erik Cambria, Yangqiu Song, Haixun Wang, Amir Hussain",Erik Cambria,Amir Hussain,4,"The ability to understand natural language text is far from being emulated in machines. One of the main hurdles to overcome is that computers lack both the common and the common sense knowledge humans normally acquire during the formative years of their lives. If we want machines to really understand natural language, we need to provide them with this kind of knowledge rather than relying on the valence of keywords and word co-occurrence frequencies. In this work, we blend the largest existing taxonomy of common knowledge with a natural-language-based semantic network of common sense knowledge, and use multi-dimensionality reduction techniques on the resulting knowledge base for opinion mining and sentiment analysis.",https://ieeexplore.ieee.org/abstract/document/6137396/
Erik Cambria,A Survey on Semantic Processing Techniques,2024,Information Fusion,37,"Rui Mao, Kai He, Xulang Zhang, Guanyi Chen, Jinjie Ni, Zonglin Yang, Erik Cambria",Rui Mao,Erik Cambria,7,"Semantic processing is a fundamental research domain in computational linguistics. In the era of powerful pre-trained language models and large language models, the advancement of research in this domain appears to be decelerating. However, the study of semantics is multi-dimensional in linguistics. The research depth and breadth of computational semantic processing can be largely improved with new technologies. In this survey, we analyzed five semantic processing tasks, e.g., word sense disambiguation, anaphora resolution, named entity recognition, concept extraction, and subjectivity detection. We study relevant theoretical research in these fields, advanced methods, and downstream applications. We connect the surveyed tasks with downstream applications because this may inspire future scholars to fuse these low-level semantic processing tasks with high-level natural language processing tasks …",https://www.sciencedirect.com/science/article/pii/S1566253523003044
Erik Cambria,Tweeting in Support of LGBT? A Deep Learning Approach,2019,Proceedings of CODS-COMAD,37,"Aparup Khatua, Erik Cambria, Kuntal Ghosh, Nabendu Chaki, Apalak Khatua",Aparup Khatua,Apalak Khatua,5,"This paper explores the Twitter deliberation as a response to the Supreme Court of India's verdict regarding the decriminalization of homosexuality. We have collected 0.58 million tweets to gauge the societal perception about the LGBT community whether social media users are supportive or skeptic about sexual minorities. Our deep learning algorithms (accuracy in the range of 85%) have outperformed machine learning algorithms (accuracy in the range of 60%). Furthermore, we note that dominant aspects of supporting tweets are revolving around equality, justice, human rights of the LGBT community. On the contrary, opposing tweets are perceiving this verdict as a threat to the Indian culture, tradition and the family system.",https://dl.acm.org/doi/abs/10.1145/3297001.3297057
Erik Cambria,From Node Embedding to Community Embedding,2016,Proceedings of KDD Workshops,37,"Vincent W Zheng, Sandro Cavallari, Hongyun Cai, Kevin Chen-Chuan Chang, Erik Cambria",Vincent W Zheng,Erik Cambria,5,"Most of the existing graph embedding methods focus on nodes, which aim to output a vector representation for each node in the graph such that two nodes being ""close"" on the graph are close too in the low-dimensional space. Despite the success of embedding individual nodes for graph analytics, we notice that an important concept of embedding communities (i.e., groups of nodes) is missing. Embedding communities is useful, not only for supporting various community-level applications, but also to help preserve community structure in graph embedding. In fact, we see community embedding as providing a higher-order proximity to define the node closeness, whereas most of the popular graph embedding methods focus on first-order and/or second-order proximities. To learn the community embedding, we hinge upon the insight that community embedding and node embedding reinforce with each other. As a result, we propose ComEmbed, the first community embedding method, which jointly optimizes the community embedding and node embedding together. We evaluate ComEmbed on real-world data sets. We show it outperforms the state-of-the-art baselines in both tasks of node classification and community prediction.",https://arxiv.org/abs/1610.09950
Erik Cambria,"What Do People Think about this Monument? Understanding Negative Reviews via Deep Learning, Clustering and Descriptive Rules",2020,Journal of Ambient Intelligence and Humanized Computing,36,"Ana Valdivia, Eugenio Martínez-Cámara, Iti Chaturvedi, M Victoria Luzón, Erik Cambria, Yew-Soon Ong, Francisco Herrera",Ana Valdivia,Francisco Herrera,7,"Aspect-based sentiment analysis enables the extraction of fine-grained information, as it connects specific aspects that appear in reviews with a polarity. Although we detect that the information from these algorithms is very accurate at local level, it does not contribute to obtain an overall understanding of reviews. To fill this gap, we propose a methodology to portray opinions through the most relevant associations between aspects and polarities. Our methodology combines three off-the-shelf algorithms: (1) deep learning for extracting aspects, (2) clustering for joining together similar aspects, and (3) subgroup discovery for obtaining descriptive rules that summarize the polarity information of set of reviews. Concretely, we aim at depicting negative opinions from three cultural monuments in order to detect those features that need to be improved. Experimental results show that our approach clearly gives an overview of …",https://link.springer.com/article/10.1007/s12652-018-1150-3
Erik Cambria,Lyapunov Filtering of Objectivity for Spanish Sentiment Model,2016,Proceedings of IJCNN,36,"Iti Chaturvedi, Erik Cambria, David Vilares",Iti Chaturvedi,David Vilares,3,"Objective sentences lack sentiments and, hence, can reduce the accuracy of a sentiment classifier. Traditional methods prior to 2001 used hand-crafted templates to identify subjectivity and did not generalize well for resource-deficient languages such as Spanish. Later works published between 2002 and 2009 proposed the use of deep neural networks to automatically learn a dictionary of features (in the form of convolution kernels) that is portable to new languages. Recently, recurrent neural networks are being used to model alternating subjective and objective sentences within a single review. Such networks are difficult to train for a large vocabulary of words due to the problem of vanishing gradients. Hence, in this paper we consider use of a Lyapunov linear matrix inequality to classify Spanish text as subjective or objective by combining Spanish features and features obtained from the corresponding translated …",https://ieeexplore.ieee.org/abstract/document/7727785/
Erik Cambria,"The MuSe 2023 Multimodal Sentiment Analysis Challenge: Mimicked Emotions, Cross-Cultural Humour, and Personalisation",2023,Proceedings of ACM Multimedia,35,"Lukas Christ, Shahin Amiriparian, Alice Baird, Alexander Kathan, Niklas Müller, Steffen Klug, Chris Gagne, Panagiotis Tzirakis, Eva-Maria Meßner, Andreas König, Alan Cowen, Erik Cambria, Björn W Schuller",Lukas Christ,Björn W Schuller,13,"The Multimodal Sentiment Analysis Challenge (MuSe) 2023 is a set of shared tasks addressing three different contemporary multimodal affect and sentiment analysis problems: In the Mimicked Emotions Sub-Challenge (MuSe-Mimic), participants predict three continuous emotion targets. This sub-challenge utilises the Hume-Vidmimic dataset comprising of user-generated videos. For the Cross-Cultural Humour Detection Sub-Challenge (MuSe-Humour), an extension of the Passau Spontaneous Football Coach Humour (Passau-SFCH) dataset is provided. Participants predict the presence of spontaneous humour in a cross-cultural setting. The Personalisation Sub-Challenge (MuSe-Personalisation) challenge is based on the Ulm-Trier Social Stress Test (Ulm-TSST) dataset, featuring recordings of subjects in a stressed situation. Here, arousal and valence signals are to be predicted, whereas parts of the test labels …",https://dl.acm.org/doi/abs/10.1145/3606039.3613114
Erik Cambria,HiTKG: Towards Goal-Oriented Conversations via Multi-Hierarchy Learning,2022,Proceedings of AAAI,35,"Jinjie Ni, Vlad Pandelea, Tom Young, Haicang Zhou, Erik Cambria",Jinjie Ni,Erik Cambria,5,"Human conversations are guided by short-term and long-term goals. We study how to plan short-term goal sequences as coherently as humans do and naturally direct them to an assigned long-term goal in open-domain conversations. Goal sequences are a series of knowledge graph (KG) entity-relation connections generated by KG walkers that traverse through the KG. The existing recurrent and graph attention based KG walkers either insufficiently utilize the conversation states or lack global guidance. In our work, a hierarchical model learns goal planning in a hierarchical learning framework. We present HiTKG, a hierarchical transformer-based graph walker that leverages multiscale inputs to make precise and flexible predictions on KG paths. Furthermore, we propose a two-hierarchy learning framework that employs two stages to learn both turn-level (short-term) and global-level (long-term) conversation goals. Specifically, at the first stage, HiTKG is trained in a supervised fashion to learn how to plan turn-level goal sequences; at the second stage, HiTKG tries to naturally approach the assigned global goal via reinforcement learning. In addition, we propose MetaPath as the backbone method for KG path representation to exploit the entity and relation information concurrently. We further propose Multi-source Decoding Inputs and Output-level Length Head to improve the decoding controllability. Our experiments show that HiTKG achieves a significant improvement in the performance of turn-level goal learning compared with state-of-the-art baselines. Additionally, both automatic and human evaluation prove the effectiveness of the two …",https://ojs.aaai.org/index.php/AAAI/article/view/21360
Erik Cambria,A Review of Shorthand Systems: From Brachygraphy to Microtext and Beyond,2020,Cognitive Computation,35,"Ranjan Satapathy, Erik Cambria, Andrea Nanetti, Amir Hussain",Ranjan Satapathy,Amir Hussain,4,"Human civilizations have performed the art of writing across continents and over different time periods. In order to speed up the writing process, the art of shorthand (brachygraphy) came into existence. Today, the performance of writing does not make an exception in social media platforms. Brachygraphy started to re-emerge in the early 2000s in the form of microtext in order to facilitate faster typing without compromising semantic clarity. This paper focuses on microtext approaches predominantly found in social media and explains the relevance of microtext normalization for natural language processing tasks in English. The review introduces brachygraphy and how it has evolved into microtext in today’s social media–dominant society. The study provides a comprehensive classification of microtext normalization based on different approaches. We propose to classify microtext based on different normalization …",https://link.springer.com/article/10.1007/s12559-020-09723-7
Erik Cambria,TECHS: Temporal Logical Graph Networks for Explainable Extrapolation Reasoning,2023,Proceedings of ACL,34,"Qika Lin, Jun Liu, Rui Mao, Fangzhi Xu, Erik Cambria",Qika Lin,Erik Cambria,5,"Extrapolation reasoning on temporal knowledge graphs (TKGs) aims to forecast future facts based on past counterparts. There are two main challenges:(1) incorporating the complex information, including structural dependencies, temporal dynamics, and hidden logical rules;(2) implementing differentiable logical rule learning and reasoning for explainability. To this end, we propose an explainable extrapolation reasoning framework TEemporal logiCal grapH networkS (TECHS), which mainly contains a temporal graph encoder and a logical decoder. The former employs a graph convolutional network with temporal encoding and heterogeneous attention to embed topological structures and temporal dynamics. The latter integrates propositional reasoning and first-order reasoning by introducing a reasoning graph that iteratively expands to find the answer. A forward message-passing mechanism is also proposed to update node representations, and their propositional and first-order attention scores. Experimental results demonstrate that it outperforms state-of-the-art baselines.",https://aclanthology.org/2023.acl-long.71/
Erik Cambria,A Brief Survey on Recent Advances in Coreference Resolution,2023,Artificial Intelligence Review,34,"Ruicheng Liu, Rui Mao, Anh Tuan Luu, Erik Cambria",Ruicheng Liu,Erik Cambria,4,"The task of resolving repeated objects in natural languages is known as coreference resolution, and it is an important part of modern natural language processing. It is classified into two categories depending on the resolved objects, namely entity coreference resolution and event coreference resolution. Predicting coreference connections and identifying mentions/triggers are the major challenges in coreference resolution, because these implicit relationships are particularly difficult in natural language understanding in downstream tasks. Coreference resolution techniques have experienced considerable advances in recent years, encouraging us to review this task in the following aspects: current employed evaluation metrics, datasets, and methods. We investigate 10 widely used metrics, 18 datasets and 4 main technical trends in this survey. We believe that this work is a comprehensive roadmap for …",https://link.springer.com/article/10.1007/s10462-023-10506-3
Erik Cambria,ESWC’14 challenge on concept-level sentiment analysis,2014,Semantic Web Evaluation Challenge,34,"Diego Reforgiato Recupero, Erik Cambria",Diego Reforgiato Recupero,Erik Cambria,2,"With the introduction of social networks, blogs, wikis, etc., the users’ behavior and their interaction in the Web have changed. As a consequence, people express their opinions and sentiments in a totally different way with respect to the past. All this information hinders potential business opportunities, especially within the advertising world, and key stakeholders need to catch up with the latest technology if they want to be at the forefront in the market. In practical terms, the automatic analysis of online opinions involves a deep understanding of natural language text, and it has been proved that the use of semantics improves the accuracy of existing sentiment analysis systems based on classical machine learning or statistical approaches. To this end, the Concept Level Sentiment Analysis challenge aims to provide a push in this direction offering the researchers an event where they can learn new approaches …",https://link.springer.com/chapter/10.1007/978-3-319-12024-9_1
Erik Cambria,Affective Common Sense Knowledge Acquisition for Sentiment Analysis,2012,Proceedings of LREC,34,"Erik Cambria, Yunqing Xia, Amir Hussain",Erik Cambria,Amir Hussain,3,"Thanks to the advent of Web 2.0, the potential for opinion sharing today is unmatched in history. Making meaning out of the huge amount of unstructured information available online, however, is extremely difficult as web-contents, despite being perfectly suitable for human consumption, still remain hardly accessible to machines. To bridge the cognitive and affective gap between word-level natural language data and the concept-level sentiments conveyed by them, affective common sense knowledge is needed. In sentic computing, the general common sense knowledge contained in ConceptNet is usually exploited to spread affective information from selected affect seeds to other concepts. In this work, besides exploiting the emotional content of the Open Mind corpus, we also collect new affective common sense knowledge through label sequential rules, crowd sourcing, and games-with-a-purpose techniques. In particular, we develop Open Mind Common Sentics, an emotion-sensitive IUI that serves both as a platform for affective common sense acquisition and as a publicly available NLP tool for extracting the cognitive and affective information associated with short texts.",http://lrec.elra.info/proceedings/lrec2012/pdf/159_Paper.pdf
Erik Cambria,Dilated Convolutional Attention Network for Medical Code Assignment from Clinical Text,2020,Proceedings of EMNLP Workshops,33,"Shaoxiong Ji, Erik Cambria, Pekka Marttinen",Shaoxiong Ji,Pekka Marttinen,3,"Medical code assignment, which predicts medical codes from clinical texts, is a fundamental task of intelligent medical information systems. The emergence of deep models in natural language processing has boosted the development of automatic assignment methods. However, recent advanced neural architectures with flat convolutions or multi-channel feature concatenation ignore the sequential causal constraint within a text sequence and may not learn meaningful clinical text representations, especially for lengthy clinical notes with long-term sequential dependency. This paper proposes a Dilated Convolutional Attention Network (DCAN), integrating dilated convolutions, residual connections, and label attention, for medical code assignment. It adopts dilated convolutions to capture complex medical patterns with a receptive field which increases exponentially with dilation size. Experiments on a real-world clinical dataset empirically show that our model improves the state of the art.",https://arxiv.org/abs/2009.14578
Erik Cambria,A Survey on Deep Learning in Image Polarity Detection: Balancing Generalization Performances and Computational Costs,2019,,33,"Edoardo Ragusa, Erik Cambria, Rodolfo Zunino, Paolo Gastaldo",Edoardo Ragusa,Paolo Gastaldo,4,"Deep convolutional neural networks (CNNs) provide an effective tool to extract complex information from images. In the area of image polarity detection, CNNs are customarily utilized in combination with transfer learning techniques to tackle a major problem: the unavailability of large sets of labeled data. Thus, polarity predictors in general exploit a pre-trained CNN as the feature extractor that in turn feeds a classification unit. While the latter unit is trained from scratch, the pre-trained CNN is subject to fine-tuning. As a result, the specific CNN architecture employed as the feature extractor strongly affects the overall performance of the model. This paper analyses state-of-the-art literature on image polarity detection and identifies the most reliable CNN architectures. Moreover, the paper provides an experimental protocol that should allow assessing the role played by the baseline architecture in the polarity detection task. Performance is evaluated in terms of both generalization abilities and computational complexity. The latter attribute becomes critical as polarity predictors, in the era of social networks, might need to be updated within hours or even minutes. In this regard, the paper gives practical hints on the advantages and disadvantages of the examined architectures both in terms of generalization and computational cost.",https://www.mdpi.com/2079-9292/8/7/783
Erik Cambria,PAED: Zero-Shot Persona Attribute Extraction in Dialogues,2023,Proceedings of ACL,32,"Luyao Zhu, Wei Li, Rui Mao, Vlad Pandelea, Erik Cambria",Luyao Zhu,Erik Cambria,5,"Persona attribute extraction is critical for personalized human-computer interaction. Dialogue is an important medium that communicates and delivers persona information. Although there is a public dataset for triplet-based persona attribute extraction from conversations, its automatically generated labels present many issues, including unspecific relations and inconsistent annotations. We fix such issues by leveraging more reliable text-label matching criteria to generate high-quality data for persona attribute extraction. We also propose a contrastive learning-and generation-based model with a novel hard negative sampling strategy for generalized zero-shot persona attribute extraction. We benchmark our model with state-of-the-art baselines on our dataset and a public dataset, showing outstanding accuracy gains. Our sampling strategy also exceeds others by a large margin in persona attribute extraction.",https://aclanthology.org/2023.acl-long.544/
Erik Cambria,"MuSe 2020 Challenge and Workshop: Multimodal Sentiment Analysis, Emotion-target Engagement and Trustworthiness Detection in Real-life Media",2020,Proceedings of ACM Multimedia,32,"Lukas Stappen, Alice Baird, Georgios Rizos, Panagiotis Tzirakis, Xinchen Du, Felix Hafner, Lea Schumann, Adria Mallol-Ragolta, Björn Schuller, Iulia Lefter, Erik Cambria, Ioannis Kompatsiaris",Lukas Stappen,Ioannis Kompatsiaris,12,"Multimodal Sentiment Analysis in Real-life Media (MuSe) 2020 is a Challenge-based Workshop focusing on the tasks of sentiment recognition, as well as emotion-target engagement and trustworthiness detection by means of more comprehensively integrating the audio-visual and language modalities. The purpose of MuSe 2020 is to bring together communities from different disciplines; mainly, the audio-visual emotion recognition community (signal-based), and the sentiment analysis community (symbol-based). We present three distinct sub-challenges: MuSe-Wild, which focuses on continuous emotion (arousal and valence) prediction; MuSe-Topic, in which participants recognise 10 domain-specific topics as the target of 3-class (low, medium, high) emotions; and MuSe-Trust, in which the novel aspect of trustworthiness is to be predicted. In this paper, we provide detailed information on MuSe-CAR, the first of its …",https://dl.acm.org/doi/abs/10.1145/3423327.3423673
Erik Cambria,Recent Developments in Recommender Systems: A Survey,2024,IEEE Computational Intelligence Magazine,31,"Yang Li, Kangbo Liu, Ranjan Satapathy, Suhang Wang, Erik Cambria",Yang Li,Erik Cambria,5,"In this technical survey, the latest advancements in the field of recommender systems are comprehensively summarized. The objective of this study is to provide an overview of the current state-of-the-art in the field and highlight the latest trends in the development of recommender systems. It starts with a comprehensive summary of the main taxonomy of recommender systems, including personalized and group recommender systems. In addition, the survey analyzes the robustness, data bias, and fairness issues in recommender systems, summarizing the evaluation metrics used to assess the performance of these systems. Finally, it provides insights into the latest trends in the development of recommender systems and highlights the new directions for future research in the field.",https://ieeexplore.ieee.org/abstract/document/10494051/
Erik Cambria,Improving Zero Shot Learning Baselines with Commonsense Knowledge,2022,Cognitive Computation,31,"Abhinaba Roy, Deepanway Ghosal, Erik Cambria, Navonil Majumder, Rada Mihalcea, Soujanya Poria",Abhinaba Roy,Soujanya Poria,6,"Zero-shot learning — the problem of training and testing on a completely disjoint set of classes — relies greatly on its ability to transfer knowledge from train classes to test classes. Traditionally semantic embeddings consisting of human-defined attributes or distributed word embeddings are used to facilitate this transfer by improving the association between visual and semantic embeddings. In this paper, we take advantage of explicit relations between nodes defined in ConceptNet, a commonsense knowledge graph, to generate commonsense embeddings of the class labels by using a graph convolution network-based autoencoder. Our experiments performed on three standard benchmark datasets surpass the strong baselines when we fuse our commonsense embeddings with existing semantic embeddings, i.e., human-defined attributes and distributed word embeddings. This work paves the path to more brain …",https://link.springer.com/article/10.1007/s12559-022-10044-0
Erik Cambria,Sentiment Analysis in the Bio-Medical Domain,2017,,31,"Ranjan Satapathy, Erik Cambria, Amir Hussain",Ranjan Satapathy,Amir Hussain,3,"The opportunity to capture the opinions of the general public has raised growing interest both within the scientific community, leading to many exciting open challenges, and in the business world due to the remarkable range of benefits envisaged, including from marketing, business intelligence and financial prediction. Mining opinions and sentiments from natural language, however, is an extremely difficult task as it involves a deep understanding of most of the explicit and implicit, regular and irregular and syntactical and semantic rules appropriate of a language. Existing approaches to sentiment analysis mainly rely on parts of text in which opinions are explicitly expressed such as polarity terms, affect words and their co-occurrence frequencies. However, opinions and sentiments are often conveyed implicitly through latent semantics, which make purely syntactical approaches ineffective.Natural language …",https://link.springer.com/content/pdf/10.1007/978-3-319-68468-0.pdf
Erik Cambria,Acoustic Template-Matching for Automatic Emergency State Detection: An ELM Based Algorithm,2015,Neurocomputing,31,"Emanuele Principi, Stefano Squartini, Erik Cambria, Francesco Piazza",Emanuele Principi,Francesco Piazza,4,"Extreme Learning Machine (ELM) represents a popular paradigm for training feedforward neural networks due to its fast learning time. This paper applies the technique for the automatic classification of speech utterances. Power Normalized Cepstral Coefficients (PNCC) are employed as feature vectors and ELM performs the final classification. Both the baseline ELM algorithm and ELM with kernel have been employed and tested. Due to the fixed number of input neurons in the ELM, a length normalization algorithm is employed to transform the PNCC sequence into a vector of fixed length. Length normalization has been performed using two techniques: the first is based on Dynamic Time Warping (DTW) distances, the second on the vectorized outerproduct of trajectory matrix. Experiments have been conducted on the TIDIGITS corpus, to assess the performance on an isolated speech recognition task, and on ITAAL …",https://www.sciencedirect.com/science/article/pii/S0925231214011394
Erik Cambria,Commonsense-Based Topic Modeling,2013,Proceedings of KDD Workshops,31,"Dheeraj Rajagopal, Daniel Olsher, Erik Cambria, Kenneth Kwok",Dheeraj Rajagopal,Kenneth Kwok,4,"Topic modeling is a technique used for discovering the abstract 'topics' that occur in a collection of documents, which is useful for tasks such as text auto-categorization and opinion mining. In this paper, a commonsense knowledge based algorithm for document topic modeling is presented. In contrast to probabilistic models, the proposed approach does not involve training of any kind and does not depend on word co-occurrence or particular word distributions, making the algorithm effective on texts of any length and composition. 'Semantic atoms' are used to generate feature vectors for document concepts. These features are then clustered using group average agglomerative clustering, providing much improved performance over existing algorithms.",https://dl.acm.org/doi/abs/10.1145/2502069.2502075
Erik Cambria,Sparks of Large Audio Models: A Survey and Outlook,2025,,30,"Siddique Latif, Moazzam Shoukat, Fahad Shamshad, Muhammad Usama, Yi Ren, Heriberto Cuayáhuitl, Wenwu Wang, Xulong Zhang, Roberto Togneri, Erik Cambria, Björn W Schuller",Siddique Latif,Björn W Schuller,11,"This survey paper provides a comprehensive overview of the recent advancements and challenges in applying large language models to the field of audio signal processing. Audio processing, with its diverse signal representations and a wide range of sources--from human voices to musical instruments and environmental sounds--poses challenges distinct from those found in traditional Natural Language Processing scenarios. Nevertheless, \textit{Large Audio Models}, epitomized by transformer-based architectures, have shown marked efficacy in this sphere. By leveraging massive amount of data, these models have demonstrated prowess in a variety of audio tasks, spanning from Automatic Speech Recognition and Text-To-Speech to Music Generation, among others. Notably, recently these Foundational Audio Models, like SeamlessM4T, have started showing abilities to act as universal translators, supporting multiple speech tasks for up to 100 languages without any reliance on separate task-specific systems. This paper presents an in-depth analysis of state-of-the-art methodologies regarding \textit{Foundational Large Audio Models}, their performance benchmarks, and their applicability to real-world scenarios. We also highlight current limitations and provide insights into potential future research directions in the realm of \textit{Large Audio Models} with the intent to spark further discussion, thereby fostering innovation in the next generation of audio-processing systems. Furthermore, to cope with the rapid development in this area, we will consistently update the relevant repository with relevant recent articles and their open-source …",https://arxiv.org/abs/2308.12792
Erik Cambria,Domain-specific Continued Pretraining of Language Models for Capturing Long Context in Mental Health,2025,arXiv preprint arXiv:2304.10447,30,"Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria, Jörg Tiedemann",Shaoxiong Ji,Jörg Tiedemann,6,"Pretrained language models have been used in various natural language processing applications. In the mental health domain, domain-specific language models are pretrained and released, which facilitates the early detection of mental health conditions. Social posts, e.g., on Reddit, are usually long documents. However, there are no domain-specific pretrained models for long-sequence modeling in the mental health domain. This paper conducts domain-specific continued pretraining to capture the long context for mental health. Specifically, we train and release MentalXLNet and MentalLongformer based on XLNet and Longformer. We evaluate the mental health classification performance and the long-range ability of these two domain-specific pretrained models. Our models are released in HuggingFace.",https://arxiv.org/abs/2304.10447
Erik Cambria,Financial Sentiment Analysis: Techniques and Applications,2024,ACM Computing Surveys,30,"Kelvin Du, Frank Xing, Rui Mao, Erik Cambria",Kelvin Du,Erik Cambria,4,"Financial Sentiment Analysis (FSA) is an important domain application of sentiment analysis that has gained increasing attention in the past decade. FSA research falls into two main streams. The first stream focuses on defining tasks and developing techniques for FSA, and its main objective is to improve the performances of various FSA tasks by advancing methods and using/curating human-annotated datasets. The second stream of research focuses on using financial sentiment, implicitly or explicitly, for downstream applications on financial markets, which has received more research efforts. The main objective is to discover appropriate market applications for existing techniques. More specifically, the application of FSA mainly includes hypothesis testing and predictive modeling in financial markets. This survey conducts a comprehensive review of FSA research in both the technique and application areas and …",https://dl.acm.org/doi/abs/10.1145/3649451
Erik Cambria,Quantitative Stock Portfolio Optimization by Multi-task Learning Risk and Return,2024,Information Fusion,30,"Yu Ma, Rui Mao, Qika Lin, Peng Wu, Erik Cambria",Yu Ma,Erik Cambria,5,"Selecting profitable stocks for investments is a challenging task. Recent research has made significant progress on stock ranking prediction to select top-ranked stocks for portfolio optimization. However, the stocks are only ranked by predicted stock return, ignoring the stock price volatility risk—a critical aspect for stock selection and investments. Moreover, they preliminarily attempted to capture the effects of related stocks from a singular relation, disregarding the rich information regarding multiple spillover effects from related stocks and the distinctions in effects among various relations. Thus, we propose a risk and return multi-task learning model with a heterogeneous graph attention network (HGA-MT) to predict stock ranking for portfolio optimization. First, to aggregate the multiple spillover effects of related stocks, we introduce graph convolutional networks to fuse the effects of related stocks in each relation and …",https://www.sciencedirect.com/science/article/pii/S1566253523004815
Erik Cambria,A Wide Evaluation of ChatGPT on Affective Computing Tasks,2024,IEEE Transactions on Affective Computing,30,"Mostafa M Amin, Rui Mao, Erik Cambria, Björn W Schuller",Mostafa M Amin,Björn W Schuller,4,"With the rise of foundation models, a new artificial intelligence paradigm has emerged, by simply using general purpose foundation models with prompting to solve problems instead of training a separate machine learning model for each problem. Such models have been shown to have emergent properties of solving problems that they were not initially trained on. The studies for the effectiveness of such models are still quite limited. In this work, we widely study the capabilities of the ChatGPT models, namely GPT-4 and GPT-3.5, on 13 affective computing problems, namely aspect extraction, aspect polarity classification, opinion extraction, sentiment analysis, sentiment intensity ranking, emotions intensity ranking, suicide tendency detection, toxicity detection, well-being assessment, engagement measurement, personality assessment, sarcasm detection, and subjectivity detection. We introduce a framework to …",https://ieeexplore.ieee.org/abstract/document/10572294/
Erik Cambria,Sentic Parser: A Graph-Based Approach to Concept Extraction for Sentiment Analysis,2022,Proceedings of ICDM Workshops,30,"Erik Cambria, Rui Mao, Sooji Han, Qian Liu",Erik Cambria,Qian Liu,4,"Concept-level sentiment analysis improves on standard word-level opinion mining by leveraging the power of multiword expressions, linguistic objects formed by two or more words that behave like ‘semantic atoms’ by displaying formal or functional idiosyncratic properties with respect to free word combinations. The extraction of meaningful multiword expressions from text, however, is not an easy task, as it goes beyond simple n-gram modeling. In the context of sentiment analysis, such meaningful concepts are represented by those multiword expressions with high connotative, rather than denotative, information, i.e., combination of words that convey a certain degree of subjectivity (positive or negative polarity) rather than objectivity (neutral polarity). In this work, we propose a morphology-aware concept parser for the efficient extraction and generalization of affective multiword expressions from English text. The …",https://ieeexplore.ieee.org/abstract/document/10031225/
Erik Cambria,Learning-Based Stock Trending Prediction by Incorporating Technical Indicators and Social Media Sentiment,2023,Cognitive Computation,29,"Zhaoxia Wang, Zhenda Hu, Fang Li, Seng-Beng Ho, Erik Cambria",Zhaoxia Wang,Erik Cambria,5,"Stock trending prediction is a challenging task due to its dynamic and nonlinear characteristics. With the development of social platform and artificial intelligence (AI), incorporating timely news and social media information into stock trending models becomes possible. However, most of the existing works focus on classification or regression problems when predicting stock market trending without fully considering the effects of different influence factors in different phases. To address this gap, this research solves stock trending prediction problem utilizing both technical indicators and sentiments of the social media text as influence factors in different situations. A 3-phase hybrid model is proposed where daily sentiment values and technical indicators are considered when predicting the trends of the stocks. The proposed method leverages both traditional learning and deep learning methods as the core predictors in …",https://link.springer.com/article/10.1007/s12559-023-10125-8
Erik Cambria,Multitask Learning for Multilingual Intent Detection and Slot Filling in Dialogue Systems,2023,Information Fusion,29,"Mauajama Firdaus, Asif Ekbal, Erik Cambria",Mauajama Firdaus,Erik Cambria,3,"Dialogue systems are becoming an ubiquitous presence in our everyday lives having a huge impact on business and society. Spoken language understanding (SLU) is the critical component of every goal-oriented dialogue system or any conversational system. The understanding of the user utterance is crucial for assisting the user in achieving their desired objectives. Future-generation systems need to be able to handle the multilinguality issue. Hence, the development of conversational agents becomes challenging as it needs to understand the different languages along with the semantic meaning of the given utterance. In this work, we propose a multilingual multitask approach to fuse the two primary SLU tasks, namely, intent detection and slot filling for three different languages. While intent detection deals with identifying user’s goal or purpose, slot filling captures the appropriate user utterance information in …",https://www.sciencedirect.com/science/article/pii/S1566253522001671
Erik Cambria,"MuSe 2022 Challenge: Multimodal Humour, Emotional Reactions, and Stress",2022,,29,"Shahin Amiriparian, Lukas Christ, Andreas König, Eva-Maria Meßner, Alan Cowen, Erik Cambria, Björn W Schuller",Shahin Amiriparian,Björn W Schuller,7,"The 3rd Multimodal Sentiment Analysis Challenge (MuSe) focuses on multimodal affective computing. The workshop is held in conjunction with ACM Multimedia'22. Three datasets are provided as part of the challenge: (i) the Passau Spontaneous Football Coach Humor (Passau-SFCH) dataset which contains humour-tagged audio-visual data of German football coaches, (ii) the Hume-Reaction dataset, which contains annotations on how people respond to emotional stimuli in terms of seven different emotional expression intensities, and (iii) the Ulm-Trier Social Stress Test (Ulm-TSST) dataset, which consists of audio-visual recordings labelled with continuous emotion values of individuals in stressful circumstances. Based on these datasets three affective computing challenges are defined: 1) Humor Detection Sub-Challenge (MuSe-Humor), for spontaneous humour recognition, 2) Emotional Reactions Sub …",https://dl.acm.org/doi/abs/10.1145/3503161.3551792
Erik Cambria,Ensemble Application of Transfer Learning and Sample Weighting for Stock Market Prediction,2019,Proceedings of IJCNN,29,"Simone Merello, Andrea Picasso, Luca Oneto, Erik Cambria",Simone Merello,Erik Cambria,4,"Forecasting stock market behavior is an interesting and challenging problem. Regression of prices and classification of daily returns have been widely studied with the main goal of supplying forecasts useful in real trading scenarios. Unfortunately, the outcomes are not directly related with the maximization of the financial gain. Firstly, the optimal strategy requires to invest on the most performing asset every period and trading accordingly is not trivial given the predictions. Secondly, price fluctuations of different magnitude are often treated as equals even if during market trading losses or gains of different intensities are derived. In this paper, the problem of stock market forecasting is formulated as regression of market returns. This approach is able to estimate the amount of price change and thus the most performing assets. Price fluctuations of different magnitude are treated differently through the application of …",https://ieeexplore.ieee.org/abstract/document/8851938/
Erik Cambria,Relation Extraction of Medical Concepts Using Categorization and Sentiment Analysis,2018,Cognitive Computation,29,"Anupam Mondal, Erik Cambria, Dipankar Das, Amir Hussain, Sivaji Bandyopadhyay",Anupam Mondal,Sivaji Bandyopadhyay,5,"In healthcare services, information extraction is the key to understand any corpus-based knowledge. The process becomes laborious when the annotation is done manually for the availability of a large number of text corpora. Hence, future automated extraction systems will be essential for groups of experts such as doctors and medical practitioners as well as non-experts such as patients, to ensure enhanced clinical decision-making for improving healthcare systems. Such extraction systems can be developed using medical concepts and concept-related features as the part of a structured corpus. The latter can assist in assigning the category and sentiment to each of the medical concepts and their lexical contexts. These categories and sentiment assignments constitute semantic relations of medical concepts, with their context, represented by sentences of the corpus. This paper presents a new domain …",https://link.springer.com/article/10.1007/s12559-018-9567-8
Erik Cambria,Discovering the Cognition behind Language: Financial Metaphor Analysis with MetaPro,2023,Proceedings of ICDM,28,"Rui Mao, Kelvin Du, Yu Ma, Luyao Zhu, Erik Cambria",Rui Mao,Erik Cambria,5,"Metaphors frequently appear in financial news headlines due to their ability to effectively convey complex financial concepts and market trends in a concise and memorable manner. Cognitive scientists have found that metaphors serve as the reflections of human cognition by means of concept mappings. In this work, we aim to analyze the metaphorical expressions and associated cognitive patterns employed by financial analysts in the headlines of financial analysis reports. Such an examination would enhance our comprehension of the cognitive state of financial analysts regarding various financial trends. We employ the latest computational metaphor processing tool, MetaPro to achieve this target by mining metaphors and cognitive patterns from 1,407,328 financial analyst report headlines, spanning the period from 14 February 2009 to 11 June 2020. We analyze the mined concept mappings by different time …",https://ieeexplore.ieee.org/abstract/document/10415727/
Erik Cambria,MEGACare: Knowledge-guided Multi-view Hypergraph Predictive Framework for Healthcare,2023,Information Fusion,28,"Jialun Wu, Kai He, Rui Mao, Chen Li, Erik Cambria",Jialun Wu,Erik Cambria,5,"Predicting a patient’s future health condition by analyzing their Electronic Health Records (EHRs) is a trending subject in the intelligent medical field, which can help clinicians prescribe safely and effectively, and also make more accurate diagnoses. Benefiting from powerful feature extraction capabilities, graph representation learning can capture complex relationships and achieve promising performance in many clinical prediction tasks. However, existing works either exclusively consider single domain knowledge with an independent task or do not fully capitalize on domain knowledge that can provide more predictive signals in the code encoding stage. Moreover, the heterogeneous and high-dimensional nature of EHR data leads to a deficiency of hardly encoding implicit high-order correlations. To address these limitations, we proposed a knowledge-guided Multi-viEw hyperGrAph predictive framework …",https://www.sciencedirect.com/science/article/pii/S1566253523002555
Erik Cambria,Seq2Seq Deep Learning Models for Microtext Normalization,2019,Proceedings of IJCNN,28,"Ranjan Satapathy, Yang Li, Sandro Cavallari, Erik Cambria",Ranjan Satapathy,Erik Cambria,4,"Microtext analysis is a crucial task for gauging social media opinion. In this paper, we compare four different deep learning encoder-decoder frameworks to handle microtext normalization problem. The frameworks have been evaluated on four different datasets in three different domains. To understand the impact of microtext normalization, we further integrate the framework into a sentiment classification task. This paper is the first of its kind to incorporate deep learning into a microtext normalization module and improve the sentiment analysis task. We show our models as a sequence to sequence character to word encoder-decoder model. We compare four deep learning models for microtext normalization task which further improve the accuracy of the sentiment analysis. Results show that the attentive LSTM and GRU cell both increase the sentiment analysis accuracy in the range of 4%–7% whereas LSTM and …",https://ieeexplore.ieee.org/abstract/document/8851895/
Erik Cambria,Adaptive Two-Stage Feature Selection for Sentiment Classification,2017,Proceedings of SMC,28,"Xu Chi, Erik Cambria, Tan Puay Siew",Xu Chi,Tan Puay Siew,3,"Sentiment analysis is able to automatically extract valuable customer information from large amount of unstructured text data to support decision making in manufacturing applications such as product design and demand planning. One of the key issues of sentiment analysis is the high dimensionality of data, which can be effectively solved by feature selection. Existing feature selection techniques compute feature scores solely based on training data statistics or by modifying a specific feature metric formula to include test data information which can not be generalized to other types of feature metrics. In this paper, we propose an adaptive two-stage feature selection approach, which generates base feature scores from a training dataset and then weights them based on individual test sample so that the feature importance evaluation is adapted to the characteristic of test data as well. The proposed method is applicable …",https://ieeexplore.ieee.org/abstract/document/8122782/
Erik Cambria,Enhancing Sentiment Classification Performance Using Bi-Tagged Phrases,2013,Proceedings of ICDM Workshops,28,"Basant Agarwal, Namita Mittal, Erik Cambria",Basant Agarwal,Erik Cambria,3,"Sentiment analysis research mainly aims to determine the orientation of an opinionated stretch of text into positive or negative polarity. The key motivation of sentiment analysis is getting to know what consumers think about products and services by analyzing their opinions on online portals, blogs, discussion boards, reviews etc. The main objective of this paper is to incorporate the information of POS-based sentiment-rich phrases in a machine-learning algorithm that determines the semantic orientation of a given text. In this paper, bi-tagged phrases are used as features in combination with unigram features for sentiment classification. Joint feature vectors of unigrams and bi-tagged phrases have high dimensions consisting of noisy and irrelevant features. Therefore, a feature selection method is used to select only relevant features from the feature vector. Experimental results show that the combination of prominent …",https://ieeexplore.ieee.org/abstract/document/6754016/
Erik Cambria,Incorporating Multiple Knowledge Sources for Targeted Aspect-based Financial Sentiment Analysis,2023,ACM Transactions on Management Information Systems,27,"Kelvin Du, Frank Xing, Erik Cambria",Kelvin Du,Erik Cambria,3,"Combining symbolic and subsymbolic methods has become a promising strategy as research tasks in AI grow increasingly complicated and require higher levels of understanding. Targeted Aspect-based Financial Sentiment Analysis (TABFSA) is an example of such complicated tasks, as it involves processes like information extraction, information specification, and domain adaptation. However, little is known about the design principles of such hybrid models leveraging external lexical knowledge. To fill this gap, we define anterior, parallel, and posterior knowledge integration and propose incorporating multiple lexical knowledge sources strategically into the fine-tuning process of pre-trained transformer models for TABFSA. Experiments on the Financial Opinion mining and Question Answering challenge (FiQA) Task 1 and SemEval 2017 Task 5 datasets show that the knowledge-enabled models systematically …",https://dl.acm.org/doi/abs/10.1145/3580480
Erik Cambria,Semantic Matching in Machine Reading Comprehension: An Empirical Study,2023,Information Processing & Management,27,"Qian Liu, Rui Mao, Xiubo Geng, Erik Cambria",Qian Liu,Erik Cambria,4,"Machine reading comprehension (MRC) is a challenging task in the field of artificial intelligence. Most existing MRC works contain a semantic matching module, either explicitly or intrinsically, to determine whether a piece of context answers a question. However, there is scant work which systematically evaluates different paradigms using semantic matching in MRC. In this paper, we conduct a systematic empirical study on semantic matching. We formulate a two-stage framework which consists of a semantic matching model and a reading model, based on pre-trained language models. We compare and analyze the effectiveness and efficiency of using semantic matching modules with different setups on four types of MRC datasets. We verify that using semantic matching before a reading model improves both the effectiveness and efficiency of MRC. Compared with answering questions by extracting information from …",https://www.sciencedirect.com/science/article/pii/S0306457322002461
Erik Cambria,GECKA: Game Engine for Commonsense Knowledge Acquisition,2015,Proceedings of FLAIRS,27,"Erik Cambria, Dheeraj Rajagopal, Kenneth Kwok, Jose Sepulveda",Erik Cambria,Jose Sepulveda,4,"Commonsense knowledge representation and reasoning is key for tasks such as natural language understanding. Since common-sense consists of information that humans take for granted, however, gathering it is an extremely difficult task. The game engine for commonsense knowledge acquisition (GECKA) aims to collect common-sense from game designers through the development of serious games. GECKA merges, as never before, the potential of serious games and games with a purpose. This not only provides a platform for the acquisition of re-usable and multi-purpose knowledge, but also enables the development of games that can, apart from providing entertainment value, also teach gamers something meaningful about the world they live in.",https://cdn.aaai.org/ocs/10425/10425-46116-1-PB.pdf
Erik Cambria,Data Intensive Review Mining for Sentiment Classification across Heterogeneous Domains,2013,Proceedings of FOSINT-SI,27,"Federica Bisio, Paolo Gastaldo, Chiara Peretti, Rodolfo Zunino, Erik Cambria",Federica Bisio,Erik Cambria,5,"The automatic detection of orientation and emotions in texts is becoming increasingly important in the Web 2.0 scenario. There is a considerable need for innovative techniques and tools capable of identifying and detecting the attitude of unstructured text. The paper tackles two crucial aspects of the sentiment classification problem: first, the computational complexity of the deployed framework; second, the ability of the framework itself to operate effectively in heterogeneous commercial domains. The proposed approach adopts empirical learning to implement the sentiment-classification technology, and uses a distance-based predictive model to combine computational efficiency and modularity. A suitably designed semantic-based metric is the cognitive core that measures the distance between two user reviews, according to the sentiment they communicate. The framework ultimately nullifies the training process; at …",https://dl.acm.org/doi/abs/10.1145/2492517.2500280
Erik Cambria,Sentic Demo: A Hybrid Concept-Level Aspect-Based Sentiment Analysis Toolkit,2014,Proceedings of ESWC,26,"Soujanya Poria, Alexander Gelbukh, B Agarwal, E Cambria, N Howard",Soujanya Poria,N Howard,5,"The ways people express their opinions and sentiments have radically changed in the past few years thanks to the advent of social networks, web communities, blogs, wikis, and other online collaborative media. Ideally, automatic analysis of online opinions should involve deep understanding of natural language text by machines, from which we are still very far. In this work, we introduce a novel paradigm for concept-level sentiment analysis that merges linguistics, common-sense computing, and machine learning for improving the accuracy of tasks such as polarity detection. By allowing sentiments to flow from concept to concept based on the dependency relation of the input sentence, in particular, we achieve a better understanding of the contextual role of each concept within the sentence. With this, our polarity detection engine outperforms the state-ofthe-art statistical methods.",https://2014.eswc-conferences.org/sites/default/files/eswc2014-challenges_cl_submission_31.pdf
Erik Cambria,Sentic Avatar: Multimodal Affective Conversational Agent with Common Sense,2011,,26,"Erik Cambria, Isabelle Hupont, Amir Hussain, Eva Cerezo, Sandra Baldassarri",Erik Cambria,Sandra Baldassarri,5,"The capability of perceiving and expressing emotions through different modalities is a key issue for the enhancement of human-computer interaction. In this paper we present a novel architecture for the development of intelligent multimodal affective interfaces. It is based on the integration of Sentic Computing, a new opinion mining and sentiment analysis paradigm based on AI and Semantic Web techniques, with a facial emotional classifier and Maxine, a powerful multimodal animation engine for managing virtual agents and 3D scenarios. One of the main distinguishing features of the system is that it does not simply perform emotional classification in terms of a set of discrete emotional labels but it operates in a continuous 2D emotional space, enabling the integration of the different affective extraction modules in a simple and scalable way.",https://link.springer.com/chapter/10.1007/978-3-642-18184-9_8
Erik Cambria,Sentiment Analysis Meets Explainable Artificial Intelligence: A Survey on Explainable Sentiment Analysis,2024,IEEE Transactions on Affective Computing,25,"Arwa Diwali, Kawther Saeedi, Kia Dashtipour, Mandar Gogate, Erik Cambria, Amir Hussain",Arwa Diwali,Amir Hussain,6,"Sentiment analysis can be used to derive knowledge that is connected to emotions and opinions from textual data generated by people. As computer power has grown, and the availability of benchmark datasets has increased, deep learning models based on deep neural networks have emerged as the dominant approach for sentiment analysis. While these models offer significant advantages, their lack of interpretability poses a major challenge in comprehending the rationale behind their reasoning and prediction processes, leading to complications in the models' explainability. Further, only limited research has been carried out into developing deep learning models that describe their internal functionality and behaviors. In this timely study, we carry out a first of its kind overview of key sentiment analysis techniques and eXplainable artificial intelligence (XAI) methodologies that are currently in use. Furthermore, we …",https://ieeexplore.ieee.org/abstract/document/10185138/
Erik Cambria,Information Fusion for Affective Computing and Sentiment Analysis,2021,Information Fusion,25,"Amir Hussain, Erik Cambria, Soujanya Poria, Ahmad Hawalah, Francisco Herrera",Amir Hussain,Francisco Herrera,5,"Emotions are intrinsically part of our mental activity and play a key role in communication and decision-making processes [1],[2]. Emotion, cognition, and action interact in feedback loops and emotion can be viewed in a structural model tied to adaptation. Besides being important for the advancement of AI, detecting and interpreting emotional information is key in multiple areas of computer science, eg, human-agent,-computer, and-robot interaction, but also e-learning, e-health, domotics, automotive, security, user profiling and personalization.In recent years, emotion and sentiment analysis has become increasingly popular also for processing social media data on social networks, online communities, blogs, Wikis, microblogging platforms, and other online collaborative media [3],[4]. The distillation of knowledge from such a big amount of unstructured information, however, is an extremely difficult task, as the contents …",https://www.sciencedirect.com/science/article/pii/S1566253521000269
Erik Cambria,Deciphering Public Opinion of Nuclear Energy on Twitter,2020,Proceedings of IJCNN,25,"Aparup Khatua, Erik Cambria, Shirley S Ho, Jin Cheon Na",Aparup Khatua,Jin Cheon Na,4,"This paper explores nuclear energy-related Twitter discussions as a response to the 2011 Fukushima Nuclear Disaster and the 2017 Nobel Peace Prize won by the International Campaign to Abolish Nuclear Weapons. We have considered a total of 2 million tweets for these two events. In particular, we employed CNN, LSTM, and Bi-LSTM to investigate whether social media users are supportive or cynical about nuclear energy. Our AI algorithms have performed better for polarity detection (accuracy in the range of 90%) with respect to subjectivity detection (accuracy in the range of 75%). We also note that dominant aspects of supporting tweets revolve around concepts like clean energy, lower CO2 emission, and sustainable future. On the contrary, cynical users see nuclear energy as a threat to the environment, human life, and safety.",https://ieeexplore.ieee.org/abstract/document/9206903/
Erik Cambria,Bayesian Deep Convolution Belief Networks for Subjectivity Detection,2016,Proceedings of ICDM Workshops,25,"Iti Chaturvedi, Erik Cambria, Soujanya Poria, Rajiv Bajpai",Iti Chaturvedi,Rajiv Bajpai,4,"Subjectivity detection aims to distinguish natural language as either opinionated (positive or negative) or neutral. In word vector based convolutional neural network models, a word meaning is simply a signal that helps to classify larger entities such as a document. Previous works do not usually consider prior distribution when using sliding windows to learn word embedding's and, hence, they are unable to capture higher-order and long-range features in text. In this paper, we employ dynamic Gaussian Bayesian networks to learn significant network motifs of words and concepts. These motifs are used to pre-train the convolutional neural network and capture the dynamics of discourse across several sentences.",https://ieeexplore.ieee.org/abstract/document/7836765/
Erik Cambria,"A Survey on Computational Metaphor Processing Techniques: From Identification, Interpretation, Generation to Application",2023,Artificial Intelligence Review,24,"Mengshi Ge, Rui Mao, Erik Cambria",Mengshi Ge,Erik Cambria,3,"Metaphors are figurative expressions frequently appearing daily. Given its significance in downstream natural language processing tasks such as machine translation and sentiment analysis, computational metaphor processing has led to an upsurge in the community. The progress of Artificial Intelligence has incentivized several technological tools and frameworks in this domain. This article aims to comprehensively summarize and categorize previous computational metaphor processing approaches regarding metaphor identification, interpretation, generation, and application. Though studies on metaphor identification have made significant progress, metaphor understanding, conceptual metaphor processing, and metaphor generation still need in-depth analysis. We hope to identify future directions for prospective researchers based on comparing the strengths and weaknesses of the previous works.",https://link.springer.com/article/10.1007/s10462-023-10564-7
Erik Cambria,Predicting Evolving Chaotic Time Series with Fuzzy Neural Networks,2017,Proceedings of IJCNN,24,"Frank Xing, Erik Cambria, Xiaomei Zou",Frank Xing,Xiaomei Zou,3,"This work tackles the seldom discussed task of predicting chaotic time series generated by dynamic systems with evolving parameters. Representative chaotic time series produced by different system dimensions are introduced with a critical parameter linearly depending on time. The evolving character of systems are qualitatively studied by phase portraits. We assess the predictability of different fuzzy neural network (FNN) architectures on several evolving chaotic time series. Experiments illustrate that FNN models can generally better approximate evolving chaotic systems comparing to the autoregression method as a benchmark. The main contribution of our work is that we found out certain FNN types, e.g., NEFCON and DENFIS, are more robust to changing system parameters. In spite of the performance, some FNN models are more vulnerable and incline to be destabilized by high order chaotic systems. This …",https://ieeexplore.ieee.org/abstract/document/7966252/
Erik Cambria,SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations,2024,Proceedings of SemEval,23,"Fanfan Wang, Heqing Ma, Jianfei Yu, Rui Xia, Erik Cambria",Fanfan Wang,Erik Cambria,5,"The ability to understand emotions is an essential component of human-like artificial intelligence, as emotions greatly influence human cognition, decision making, and social interactions. In addition to emotion recognition in conversations, the task of identifying the potential causes behind an individual's emotional state in conversations, is of great importance in many application scenarios. We organize SemEval-2024 Task 3, named Multimodal Emotion Cause Analysis in Conversations, which aims at extracting all pairs of emotions and their corresponding causes from conversations. Under different modality settings, it consists of two subtasks: Textual Emotion-Cause Pair Extraction in Conversations (TECPE) and Multimodal Emotion-Cause Pair Extraction in Conversations (MECPE). The shared task has attracted 143 registrations and 216 successful submissions. In this paper, we introduce the task, dataset and evaluation settings, summarize the systems of the top teams, and discuss the findings of the participants.",https://arxiv.org/abs/2405.13049
Erik Cambria,SemEval 2024 – Task 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF),2024,Proceedings of SemEval,23,"Shivani Kumar, Md Shad Akhtar, Erik Cambria, Tanmoy Chakraborty",Shivani Kumar,Tanmoy Chakraborty,4,"We present SemEval-2024 Task 10, a shared task centred on identifying emotions and finding the rationale behind their flips within monolingual English and Hindi-English code-mixed dialogues. This task comprises three distinct subtasks - emotion recognition in conversation for code-mixed dialogues, emotion flip reasoning for code-mixed dialogues, and emotion flip reasoning for English dialogues. Participating systems were tasked to automatically execute one or more of these subtasks. The datasets for these tasks comprise manually annotated conversations focusing on emotions and triggers for emotion shifts (The task data is available at https://github.com/LCS2-IIITD/EDiReF-SemEval2024.git). A total of 84 participants engaged in this task, with the most adept systems attaining F1-scores of 0.70, 0.79, and 0.76 for the respective subtasks. This paper summarises the results and findings from 24 teams alongside their system descriptions.",https://arxiv.org/abs/2402.18944
Erik Cambria,Stress Detection from Social Media Articles: New Dataset Benchmark and Analytical Study,2022,Proceedings of IJCNN,23,"Aryan Rastogi, Qian Liu, Erik Cambria",Aryan Rastogi,Erik Cambria,3,"Stress detection is a basic and essential task for examining the mental health of a given population. With the rapid digitalization leading to text-based forms of communication gaining dominance over spoken ones, there is now the chance to develop analytical studies for stress detection directly from textual inputs in social media. However, only a limited number of benchmarks are publicly available. To this end, we create four high quality datasets based on Twitter and Reddit, which are designed particularly for the task of stress detection from social media texts. The main contributions are three-folds: 1) for each dataset, we provide a detailed description on our dataset construction process, including data collection, data preprocessing and annotation; 2) we perform a comparative study on the performance of different rule-based and machine learning-based approaches on the proposed datasets as the new …",https://ieeexplore.ieee.org/abstract/document/9892889/
Erik Cambria,Taylor’s Theorem: A New Perspective for Neural Tensor Networks,2021,Knowledge-Based Systems,23,"Wei Li, Luyao Zhu, Erik Cambria",Wei Li,Erik Cambria,3,"Neural tensor networks have been widely used in a large number of natural language processing tasks such as conversational sentiment analysis, named entity recognition and knowledge base completion. However, the mathematical explanation of neural tensor networks remains a challenging problem, due to the bilinear term. According to Taylor’s theorem, a k th order differentiable function can be approximated by a k th order Taylor polynomial around a given point. Therefore, we provide a mathematical explanation of neural tensor networks and also reveal the inner link between them and feedforward neural networks from the perspective of Taylor’s theorem. In addition, we unify two forms of neural tensor networks into a single framework and present factorization methods to make the neural tensor networks parameter-efficient. Experimental results bring some valuable insights into neural tensor networks.",https://www.sciencedirect.com/science/article/pii/S0950705121005207
Erik Cambria,A Multitask Learning Framework for Multimodal Sentiment Analysis,2021,Proceedings of ICDM Workshops,23,"Dazhi Jiang, Runguo Wei, Hao Liu, Jintao Wen, Geng Tu, Lin Zheng, Erik Cambria",Dazhi Jiang,Erik Cambria,7,"Mapping continuous dimensional emotion to discrete classes is an extremely difficult task. In this paper, we predict the intensity classes of emotions based on valence and arousal in segments of audio-visual recordings about car reviews. Consequently, for unimodal features, we first employ baseline methods and principal component analysis to search for the best unimodal features in different modalities, which can simplify the relationship between feature attributes. For multimodal features, we perform multimodal fusion on the best and other unimodal features through an early fusion strategy. For sentiment analysis, we propose six hybrid temporal models for modeling complex time dependencies. To avoid overfitting the validation set and providing complementary information between different modalities, we propose a multitask learning framework, which can adaptively change the weight of loss per subtask.",https://ieeexplore.ieee.org/abstract/document/9679905/
Erik Cambria,Towards GPU-Based Common-Sense Reasoning: Using Fast Subgraph Matching,2016,Cognitive Computation,23,"Ha-Nguyen Tran, Erik Cambria, Amir Hussain",Ha-Nguyen Tran,Amir Hussain,3,"Common-sense reasoning is concerned with simulating cognitive human ability to make presumptions about the type and essence of ordinary situations encountered every day. The most popular way to represent common-sense knowledge is in the form of a semantic graph. Such type of knowledge, however, is known to be rather extensive: the more concepts added in the graph, the harder and slower it becomes to apply standard graph mining techniques.In this work, we propose a new fast subgraph matching approach to overcome these issues. Subgraph matching is the task of finding all matches of a query graph in a large data graph, which is known to be a non-deterministic polynomial time-complete problem. Many algorithms have been previously proposed to solve this problem using central processing units. Here …",https://link.springer.com/article/10.1007/s12559-016-9418-4
Erik Cambria,Weakly Supervised Semantic Segmentation with Superpixel Embedding,2016,Proceedings of ICIP,23,"Frank Xing, Erik Cambria, Win-Bin Huang, Yang Xu",Frank Xing,Yang Xu,4,"In this paper, we propose to use contexts of superpixels as a prior to improve semantic segmentation by the CRF framework. A graphical model is constructed on over-segmented images. Our main contribution is to take the concept of “superpixel embedding” into consideration, which is formalized as a potential item for optimizing the energy of the whole graph. We also introduce two ways of calculating this embedding potential. Experiments on several popular datasets, e.g., MRSC-21 and PASCAL VOC, illustrate that our approach enhances the performance of a previously proposed segmentation model without embedding. The accuracy results are comparable to some fully supervised methods.",https://ieeexplore.ieee.org/abstract/document/7532562/
Erik Cambria,MiMuSA - Mimicking Human Language Understanding for Fine-grained Multi-class Sentiment Analysis,2023,Neural Computing and Applications,22,"Zhaoxia Wang, Zhenda Hu, Seng-Beng Ho, Erik Cambria, Ah-Hwee Tan",Zhaoxia Wang,Ah-Hwee Tan,5,"Sentiment analysis is an important natural language processing (NLP) task due to a wide range of applications. Most existing sentiment analysis techniques are limited to the analysis carried out at the aggregate level, merely providing negative, neutral and positive sentiments. The latest deep learning-based methods have been leveraged to provide more than three sentiment classes. However, such learning-based methods are still black-box-based methods rather than explainable language processing methods. To address this gap, this paper proposes a new explainable fine-grained multi-class sentiment analysis method, namely MiMuSA, which mimics the human language understanding processes. The proposed method involves a multi-level modular structure designed to mimic human’s language understanding processes, e.g., ambivalence handling process, sentiment strength handling process, etc …",https://link.springer.com/article/10.1007/s00521-023-08576-z
Erik Cambria,A Mixed Approach for Aggressive Political Discourse Analysis on Twitter,2023,Cognitive Computation,22,"Javier Torregrosa, Sergio D’Antonio-Maceiras, Guillermo Villar-Rodríguez, Amir Hussain, Erik Cambria, David Camacho",Javier Torregrosa,David Camacho,6,"Political tensions have grown throughout Europe since the beginning of the new century. The consecutive crises led to the rise of different social movements in several countries, in which the political status quo changed. These changes included an increment of the different tensions underlying politics, as has been reported after many other political and economical crises during the twentieth century. This article proposes the study of the political discourse, and its underlying tension, during Madrid’s elections (Spain) in May 2021 by using a mixed approach. To demonstrate if an aggressive tone is used during the campaign, a mixed methodology approach is applied: quantitative computational techniques, related to natural language processing, are used to conduct a first general analysis of the information screened; then, these methods are used for detecting specific trends that can be later filtered and analyzed …",https://link.springer.com/article/10.1007/s12559-022-10048-w
Erik Cambria,Arabic Sentiment Analysis using Dependency-based Rules and Deep Neural Networks,2022,Applied Soft Computing,22,"Arwa Diwali, Kia Dashtipour, Kawther Saeedi, Mandar Gogate, Erik Cambria, Amir Hussain",Arwa Diwali,Amir Hussain,6,"With the growth of social platforms in recent years and the rapid increase in the means of communication through these platforms, a significant amount of textual data is available that contains an abundance of individuals’ opinions. Sentiment analysis is a task that supports companies and organizations to evaluate this textual data with the intention of understanding people’s thoughts concerning services or products. Most previous research in Arabic sentiment analysis relies on word frequencies, lexicons, or black box methods to determine the sentiment of a sentence. It should be noted that these approaches do not take into account the semantic relations and dependencies between words. In this work, we propose a framework that incorporates Arabic dependency-based rules and deep learning models. Dependency-based rules are created by using linguistic patterns to map the meaning of words to concepts in …",https://www.sciencedirect.com/science/article/pii/S1568494622005269
Erik Cambria,"The ICML 2022 Expressive Vocalizations Workshop and Competition: Recognizing, Generating, and Personalizing Vocal Bursts",2022,Proceedings of ICML,22,"Alice Baird, Panagiotis Tzirakis, Gauthier Gidel, Marco Jiralerspong, Eilif B Muller, Kory Mathewson, Björn Schuller, Erik Cambria, Dacher Keltner, Alan Cowen",Alice Baird,Alan Cowen,10,"The ICML Expressive Vocalization (ExVo) Competition is focused on understanding and generating vocal bursts: laughs, gasps, cries, and other non-verbal vocalizations that are central to emotional expression and communication. ExVo 2022, includes three competition tracks using a large-scale dataset of 59,201 vocalizations from 1,702 speakers. The first, ExVo-MultiTask, requires participants to train a multi-task model to recognize expressed emotions and demographic traits from vocal bursts. The second, ExVo-Generate, requires participants to train a generative model that produces vocal bursts conveying ten different emotions. The third, ExVo-FewShot, requires participants to leverage few-shot learning incorporating speaker identity to train a model for the recognition of 10 emotions conveyed by vocal bursts. This paper describes the three tracks and provides performance measures for baseline models using state-of-the-art machine learning strategies. The baseline for each track is as follows, for ExVo-MultiTask, a combined score, computing the harmonic mean of Concordance Correlation Coefficient (CCC), Unweighted Average Recall (UAR), and inverted Mean Absolute Error (MAE) () is at best, 0.335 ; for ExVo-Generate, we report Fr\'echet inception distance (FID) scores ranging from 4.81 to 8.27 (depending on the emotion) between the training set and generated samples. We then combine the inverted FID with perceptual ratings of the generated samples () and obtain 0.174 ; and for ExVo-FewShot, a mean CCC of 0.444 is obtained.",https://arxiv.org/abs/2205.01780
Erik Cambria,Guest Editorial: Industrial Internet of Things: Where Are We and What Is Next?,2021,IEEE Transactions on Industrial Informatics,22,"Francesco Piccialli, Nik Bessis, Erik Cambria",Francesco Piccialli,Erik Cambria,3,"When IoT meets Industry 4.0, we talk about Industrial Internet of Things (IIoT) or the use of typical Internet of Things (IoT) solutions in the industrial sector, integrating different technologies such as machine learning, big data and analytics, sensor data, Machine to Machine communication (M2M) and automation. Its application within the fourth industrial revolution has initiated a profound change within companies making them increasingly connected and exploiting data to optimize their production processes. IIoT is revolutionizing sectors such as manufacturing, automotive and healthcare. Collecting and analyzing all the data coming from the production sensors and drawing the information for your business through business analytics tools is the new key to competitiveness.",https://ieeexplore.ieee.org/abstract/document/9447225/
Erik Cambria,"Artificial Intelligence, Social Media and Supply Chain Management: The Way Forward",2021,,22,"Apalak Khatua, Aparup Khatua, Xu Chi, Erik Cambria",Apalak Khatua,Erik Cambria,4,"Supply chain management (SCM) is a complex network of multiple entities ranging from business partners to end consumers. These stakeholders frequently use social media platforms, such as Twitter and Facebook, to voice their opinions and concerns. AI-based applications, such as sentiment analysis, allow us to extract relevant information from these deliberations. We argue that the context-specific application of AI, compared to generic approaches, is more efficient in retrieving meaningful insights from social media data for SCM. We present a conceptual overview of prevalent techniques and available resources for information extraction. Subsequently, we have identified specific areas of SCM where context-aware sentiment analysis can enhance the overall efficiency.",https://www.mdpi.com/2079-9292/10/19/2348
Erik Cambria,Semi-Supervised Learning for Affective Common-Sense Reasoning,2017,Cognitive Computation,22,"Luca Oneto, Federica Bisio, Erik Cambria, Davide Anguita",Luca Oneto,Davide Anguita,4,"Big social data analysis is the area of research focusing on collecting, examining, and processing large multi-modal and multi-source datasets in order to discover patterns/correlations and extract information from the Social Web. This is usually accomplished through the use of supervised and unsupervised machine learning algorithms that learn from the available data. However, these are usually highly computationally expensive, either in the training or in the prediction phase, as they are often not able to handle current data volumes. Parallel approaches have been proposed in order to boost processing speeds, but this clearly requires technologies that support distributed computations.Extreme learning machines (ELMs) are an emerging learning paradigm, presenting an efficient unified solution to generalized feed-forward neural …",https://link.springer.com/article/10.1007/s12559-016-9433-5
Erik Cambria,Affective Neural Networks and Cognitive Learning Systems for Big Data Analysis,2014,Neural Networks,22,"Amir Hussain, Erik Cambria, Björn Schuller, Newton Howard",Amir Hussain,Newton Howard,4,"Web users continue to evolve with the rapidly evolving Web. In an era of social connectedness, people are becoming increasingly enthusiastic about interacting, sharing, and collaborating through social networks, online communities, blogs, Wikis, as well as a range of other online collaborative media. In recent years, this collective intelligence has spread to many different areas, with a particular focus in fields related to everyday life such as commerce, tourism, education, and health, causing the size of the Web to expand exponentially. The distillation of knowledge from such a large amount of unstructured information, however, remains an extremely difficult task, since the contents of today’s Web are perfectly suitable for human consumption, yet hardly accessible to machines.The opportunity to capture the opinions of the general public on social events, political movements, company strategies, marketing campaigns, and product preferences, has raised growing interest both within the scientific community, leading to many exciting open challenges, as well as in the business world, due to the remarkable benefits expected from marketing and financial market prediction. Existing approaches to opinion mining mainly rely on parts of text in which sentiment is explicitly expressed, eg, through polarity terms or affect words (and their cooccurrence frequencies). However, opinions and sentiments are often conveyed implicitly through latent semantics, which make purely syntactical approaches ineffective.",http://w.sentic.net/anncls.pdf
Erik Cambria,A Comprehensive Review on Financial Explainable AI,2025,Artificial Intelligence Review,21,"Wei Jie Yeo, Wihan van der Heever, Rui Mao, Erik Cambria, Ranjan Satapathy, Gianmarco Mengaldo",Wei Jie Yeo,Gianmarco Mengaldo,6,"The success of artificial intelligence (AI), and deep learning models in particular, has led to their widespread adoption across various industries due to their ability to process huge amounts of data and learn complex patterns. However, due to their lack of explainability, there are significant concerns regarding their use in critical sectors, such as finance and healthcare, where decision-making transparency is of paramount importance. In this paper, we provide a comparative survey of methods that aim to improve the explainability of deep learning models within the context of finance. We categorize the collection of explainable AI methods according to their corresponding characteristics, and we review the concerns and challenges of adopting explainable AI methods, together with future directions we deemed appropriate and important.",https://arxiv.org/abs/2309.11960
Erik Cambria,A Review of Deep Learning for Video Captioning,2025,Transactions on Pattern Analysis and Machine Intelligence,21,"Moloud Abdar, Meenakshi Kollati, Swaraja Kuraparthi, Farhad Pourpanah, Daniel McDuff, Mohammad Ghavamzadeh, Shuicheng Yan, Abduallah Mohamed, Abbas Khosravi, Erik Cambria, Fatih Porikli",Moloud Abdar,Fatih Porikli,11,"Video captioning (VC) is a fast-moving, cross-disciplinary area of research that comprises contributions from domains such as computer vision, natural language processing, linguistics, and human-computer interaction. VC aims to understand a video and describe it through natural language descriptors. It plays a crucial role in various applications, from improving accessibility features such as low-vision navigation to advancing video question answering, video retrieval, and content generation. In this survey paper, we present a comprehensive review of deep learning-based VC methods. First, we provide an overview of VC, including the problem formulation, evaluation metrics, training losses, and attention-based architectures. Then, we categorize VC methods into several categories, including attention-based architectures graph networks, reinforcement learning, adversarial networks, and dense video captioning …",https://ieeexplore.ieee.org/abstract/document/10815993/
Erik Cambria,Fusing Pairwise Modalities for Emotion Recognition in Conversations,2024,Information Fusion,21,"Chunxiao Fan, Jie Lin, Rui Mao, Erik Cambria",Chunxiao Fan,Erik Cambria,4,"Multimodal fusion has the potential to significantly enhance model performance in the domain of Emotion Recognition in Conversations (ERC) by efficiently integrating information from diverse modalities. However, existing methods face challenges as they directly integrate information from different modalities, making it difficult to assess the individual impact of each modality during training and to capture nuanced fusion. To deal with it, we propose a novel framework named Fusing Pairwise Modalities for ERC. In this proposed method, the pairwise fusion technique is incorporated into multimodal fusion to enhance model performance, which enables each modality to contribute unique information, thereby facilitating a more comprehensive understanding of the emotional context. Additionally, a designed density loss is applied to characterise fused feature density, with a specific focus on mitigating redundancy in …",https://www.sciencedirect.com/science/article/pii/S1566253524000848
Erik Cambria,Improving Self-training for Cross-lingual Named Entity Recognition with Contrastive and Prototype Learning,2023,Proceedings of ACL,21,"Ran Zhou, Xin Li, Lidong Bing, Erik Cambria, Chunyan Miao",Ran Zhou,Chunyan Miao,5,"In cross-lingual named entity recognition (NER), self-training is commonly used to bridge the linguistic gap by training on pseudo-labeled target-language data. However, due to sub-optimal performance on target languages, the pseudo labels are often noisy and limit the overall performance. In this work, we aim to improve self-training for cross-lingual NER by combining representation learning and pseudo label refinement in one coherent framework. Our proposed method, namely ContProto mainly comprises two components: (1) contrastive self-training and (2) prototype-based pseudo-labeling. Our contrastive self-training facilitates span classification by separating clusters of different classes, and enhances cross-lingual transferability by producing closely-aligned representations between the source and target language. Meanwhile, prototype-based pseudo-labeling effectively improves the accuracy of pseudo labels during training. We evaluate ContProto on multiple transfer pairs, and experimental results show our method brings in substantial improvements over current state-of-the-art methods.",https://arxiv.org/abs/2305.13628
Erik Cambria,Gender-Based Multi-Aspect Sentiment Detection using Multilabel Learning,2022,Information Sciences,21,"Ashok J Kumar, Tina Esther Trueman, Erik Cambria",Ashok J Kumar,Erik Cambria,3,"Sentiment analysis is an important task in the field of natural language processing that aims to gauge and predict people’s opinions from large amounts of data. In particular, gender-based sentiment analysis can influence stakeholders and drug developers in real-world markets. In this work, we present a gender-based multi-aspect sentiment detection model using multilabel learning algorithms. We divide Abilify and Celebrex datasets into three groups based on gender information, namely: male, female, and mixed. We then represent bag-of-words (BoW), term frequency-inverse document frequency (TF-IDF), and global vectors for word representation (GloVe) based features for each group. Next, we apply problem transformation approaches and multichannel recurrent neural networks with attention mechanism. Results show that traditional multilabel transformation methods achieve better performance for small …",https://www.sciencedirect.com/science/article/pii/S002002552200490X
Erik Cambria,Taking Refuge in Your Personal Sentic Corner,2011,Proceedings of IJCNLP Workshops,21,"Erik Cambria, Amir Hussain, Chris Eckl",Erik Cambria,Chris Eckl,3,"In a world in which web users are continuously blasted by ads and often compelled to deal with user-unfriendly interfaces, we sometimes feel like we want to evade from the sensory overload of standard web pages and take refuge in a safe web corner, in which contents and design are in harmony with our current frame of mind. Sentic Corner is an intelligent user interface that dynamically collects audio, video, images and text related to the user’s current feelings and activities as an interconnected knowledge base, which is browsable through a multi-faceted classification website.",https://aclanthology.org/W11-3706.pdf
Erik Cambria,Can ChatGPT's Responses Boost Traditional Natural Language Processing?,2023,IEEE Intelligent Systems,20,"Mostafa M Amin, Erik Cambria, Björn W Schuller",Mostafa M Amin,Björn W Schuller,3,"The employment of foundation models is steadily expanding, especially with the launch of ChatGPT and the release of other foundation models. These models have shown the potential of emerging capabilities to solve problems without being particularly trained to solve them. A previous work demonstrated these emerging capabilities in affective computing tasks; the performance quality was similar to that of traditional natural language processing (NLP) techniques but fell short of specialized trained models, like fine-tuning of the RoBERTa language model. In this work, we extend this by exploring whether ChatGPT has novel knowledge that would enhance existing specialized models when they are fused together. We achieve this by investigating the utility of verbose responses from ChatGPT for solving a downstream task in addition to studying the utility of fusing that with existing NLP methods. The study is …",https://ieeexplore.ieee.org/abstract/document/10269775/
Erik Cambria,Predicting Video Engagement using Heterogeneous DeepWalk,2021,Neurocomputing,20,"Iti Chaturvedi, Kishor Thapa, Sandro Cavallari, Erik Cambria, Roy Welsch",Iti Chaturvedi,Roy Welsch,5,"Video engagement is important in online advertisements where there is no physical interaction with the consumer. Engagement can be directly measured as the number of seconds after which a consumer skips an advertisement. In this paper, we propose a model to predict video engagement of an advertisement using only a few samples. This allows for early identification of poor quality videos. This can also help identify advertisement frauds where a robot runs fake videos behind the name of well-known brands. We leverage on the fact that videos with high engagement have similar viewing patterns over time. Hence, we can create a similarity network of videos and use a graph-embedding model called DeepWalk to cluster videos into significant communities. The learned embedding is able to identify viewing patterns of fraud and popular videos. In order to assess the impact of a video, we also consider how the …",https://www.sciencedirect.com/science/article/pii/S0925231221013382
Erik Cambria,PerSent 2.0: Persian Sentiment Lexicon Enriched with Domain-Specific Words,2019,Proceedings of BICS,20,"Kia Dashtipour, Ali Raza, Alexander Gelbukh, Rui Zhang, Erik Cambria, Amir Hussain",Kia Dashtipour,Amir Hussain,6,"Sentiment analysis is probably the most actively growing area of natural language processing nowadays, which leverages huge amount of user-contributed data on Internet to improve income of businesses and quality of life of consumer. The majority of existent sentiment-analysis systems is focused on English, due to lack of resources and tools for other languages. To fill this gap for Persian language, in our previous work we have compiled the first version of PerSent Persian sentiment lexicon, which was small and included only words and phrases from general domain. In this paper, we present its extension with words from three different domains and evaluate its performance on polarity classification task using various machine learning-based classifiers. We use a multi-domain dataset to evaluate the performance of our new lexicon on various domains. Our results demonstrate usefulness of the new …",https://link.springer.com/chapter/10.1007/978-3-030-39431-8_48
Erik Cambria,"WME: Sense, Polarity and Affinity based Concept Resource for Medical Events",2016,Proceedings of the 8th Global WordNet Conference (GWC),20,"Anupam Mondal, Dipankar Das, Erik Cambria, Sivaji Bandyopadhyay",Anupam Mondal,Sivaji Bandyopadhyay,4,"In order to overcome the lack of medical corpora, we have developed a WordNet for Medical Events (WME) for identifying medical terms and their sense related information using a seed list. The initial WME resource contains 1654 medical terms or concepts. In the present research, we have reported the enhancement of WME with 6415 number of medical concepts along with their conceptual features viz. Parts-of-Speech (POS), gloss, semantics, polarity, sense and affinity. Several polarity lexicons viz. SentiWordNet, SenticNet, Bing Liu’s subjectivity list and Taboda’s adjective list were introduced with WordNet synonyms and hyponyms for expansion. The semantics feature guided us to build a semantic co-reference relation based network between the related medical concepts. These features help to prepare a medical concept network for better sense relation based visualization. Finally, we evaluated with respect to Adaptive Lesk Algorithm and conducted an agreement analysis for validating the expanded WME resource.",https://aclanthology.org/2016.gwc-1.35/
Erik Cambria,"MER 2024: Semi-Supervised Learning, Noise Robustness, and Open-Vocabulary Multimodal Emotion Recognition",2024,Proceedings of IJCAI,19,"Zheng Lian, Haiyang Sun, Licai Sun, Zhuofan Wen, Siyuan Zhang, Shun Chen, Hao Gu, Jinming Zhao, Ziyang Ma, Xie Chen, Jiangyan Yi, Rui Liu, Kele Xu, Bin Liu, Erik Cambria, Guoying Zhao, Björn W Schuller, Jianhua Tao",Zheng Lian,Jianhua Tao,18,"Multimodal emotion recognition is an important research topic in artificial intelligence. Over the past few decades, researchers have made remarkable progress by increasing dataset size and building more effective architectures. However, due to various reasons (such as complex environments and inaccurate labels), current systems still cannot meet the demands of practical applications. Therefore, we plan to organize a series of challenges around emotion recognition to further promote the development of this field. Last year, we launched MER2023, focusing on three topics: multi-label learning, noise robustness, and semi-supervised learning. This year, we continue to organize MER2024. In addition to expanding the dataset size, we introduce a new track around open-vocabulary emotion recognition. The main consideration for this track is that existing datasets often fix the label space and use majority voting to enhance annotator consistency, but this process may limit the model's ability to describe subtle emotions. In this track, we encourage participants to generate any number of labels in any category, aiming to describe the character's emotional state as accurately as possible. Our baseline is based on MERTools and the code is available at: https://github.com/zeroQiaoba/MERTools/tree/master/MER2024.",https://arxiv.org/abs/2404.17113
Erik Cambria,Large Language Models for Automated Open-domain Scientific Hypotheses Discovery,2024,Proceedings of ACL,19,"Zonglin Yang, Xinya Du, Junxian Li, Jie Zheng, Soujanya Poria, Erik Cambria",Zonglin Yang,Erik Cambria,6,"Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction is under a constrained setting: (1) the observation annotations in the dataset are carefully manually handpicked sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses are mostly commonsense knowledge, making the task less challenging. In this work, we tackle these problems by proposing the first NLP dataset for social science academic hypotheses discovery, consisting of 50 recent top social science publications; and a raw web corpus that contains enough information to make it possible to develop all the research hypotheses in the 50 papers. The final goal is to create systems that automatically generate valid, novel, and helpful scientific hypotheses, given only a pile of raw web corpus. Different from the previous settings, the new dataset requires (1) using open-domain data (raw web corpus) as observations; and (2) proposing hypotheses even new to humanity. A multi-module framework is developed for the task, as well as three different feedback mechanisms that empirically show performance gain over the base framework. Finally, our framework exhibits superior performance in terms of both GPT-4 based evaluation and expert-based evaluation.To the best of our knowledge, this is the first work showing that LLMs are able to generate novel (""not existing in the literature"") and valid (""reflecting reality"") scientific hypotheses.",https://arxiv.org/abs/2309.02726
Erik Cambria,Polarity and Subjectivity Detection with Multitask Learning and BERT Embedding,2022,Future Internet,19,"Ranjan Satapathy, Shweta Rajesh Pardeshi, Erik Cambria",Ranjan Satapathy,Erik Cambria,3,"In recent years, deep learning-based sentiment analysis has received attention mainly because of the rise of social media and e-commerce. In this paper, we showcase the fact that the polarity detection and subjectivity detection subtasks of sentiment analysis are inter-related. To this end, we propose a knowledge-sharing-based multitask learning framework. To ensure high-quality knowledge sharing between the tasks, we use the Neural Tensor Network, which consists of a bilinear tensor layer that links the two entity vectors. We show that BERT-based embedding with our MTL framework outperforms the baselines and achieves a new state-of-the-art status in multitask learning. Our framework shows that the information across datasets for related tasks can be helpful for understanding task-specific features.",https://www.mdpi.com/1999-5903/14/7/191
Erik Cambria,PhonSenticNet: A Cognitive Approach to Microtext Normalization for Concept-Level Sentiment Analysis,2019,Proceedings of CSoNet,19,"Ranjan Satapathy, Aalind Singh, Erik Cambria",Ranjan Satapathy,Erik Cambria,3," With the current upsurge in the usage of social media platforms, the trend of using short text (microtext) in place of text with standard words has seen a significant rise. The usage of microtext poses a considerable performance issue to sentiment analysis, since models are trained on standard words. This paper discusses the impact of coupling sub-symbolic (phonetics) with symbolic (machine learning) Artificial Intelligence to transform the out-of-vocabulary (OOV) concepts into their standard in-vocabulary (IV) form. We develop binary classifier to detect OOV sentences and then they are transformed to phoneme subspace using grapheme to phoneme converter. We compare the phonetic and string distance using the Sorensen similarity algorithm. The phonetically similar IV concepts thus obtained are then used to compute the correct polarity value, which was previously being miscalculated because of the presence …",https://link.springer.com/chapter/10.1007/978-3-030-34980-6_20
Erik Cambria,Semantic Sentiment Analysis Challenge at ESWC2017,2017,Semantic Web Evaluation Challenge,19,"Diego Reforgiato Recupero, Erik Cambria, Emanuele Di Rosa",Diego Reforgiato Recupero,Emanuele Di Rosa,3,,
Erik Cambria,Bridging the Gap between Structured and Unstructured Healthcare Data through Semantics and Sentics,2011,Proceedings of WebSci,19,"Erik Cambria, Amir Hussain, Chris Eckl",Erik Cambria,Chris Eckl,3,"As Web 2.0 dramatically reduced the cost of reaching others, forming groups, obtaining and republishing information, today it is easy and rewarding for patients and carers to share their personal experiences with the health-care system. This social information, however, is often stored in natural language text and hence intrinsically unstructured, which makes comparison with the structured information supplied by health-care providers very difficult. To bridge the gap between these data, which though different at structure-level are similar at concept-level, we exploit the semantics and sentics, ie the cognitive and affective information, associated with on-line patient opinions and, hence, provide the end-users of the health system with a common framework to compare, validate and select their health-care providers.",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=2c1c3ca9a05e1d2e649a65bcb0c79c8b06822b0f
Erik Cambria,"MuSe 2023 Challenge: Multimodal Prediction of Mimicked Emotions, Cross-Cultural Humour, and Personalised Recognition of Affects",2023,,18,"Shahin Amiriparian, Lukas Christ, Andreas König, Alan Cowen, Eva-Maria Meßner, Erik Cambria, Björn W Schuller",Shahin Amiriparian,Björn W Schuller,7,"The 4th Multimodal Sentiment Analysis Challenge (MuSe) focuses on Multimodal Prediction of Mimicked Emotions, Cross-Cultural Humour, and Personalised Recognition of Affects. The workshop takes place in conjunction with ACM Multimedia'23. We provide three datasets as part of the challenge: (i) The Hume-Vidmimic dataset which offers 30+ hours of expressive behaviour data from 557 participants. It involves mimicking and rating emotions: Approval, Disappointment, and Uncertainty. This multimodal resource is valuable for studying human emotional expressions. (ii) The 2023 edition of the Passau Spontaneous Football Coach Humor (Passau-SFCH) dataset comprises German football press conference recordings within the training set, while videos of English football press conferences are included in the unseen test set. This unique configuration offers a cross-cultural evaluation environment for humour …",https://dl.acm.org/doi/abs/10.1145/3581783.3610943
Erik Cambria,A Survey on Syntactic Processing Techniques,2023,Artificial Intelligence Review,18,"Xulang Zhang, Rui Mao, Erik Cambria",Xulang Zhang,Erik Cambria,3,"Computational syntactic processing is a fundamental technique in natural language processing. It normally serves as a pre-processing method to transform natural language into structured and normalized texts, yielding syntactic features for downstream task learning. In this work, we propose a systematic survey of low-level syntactic processing techniques, namely: microtext normalization, sentence boundary disambiguation, part-of-speech tagging, text chunking, and lemmatization. We summarize and categorize widely used methods in the aforementioned syntactic analysis tasks, investigate the challenges, and yield possible research directions to overcome the challenges in future work.",https://link.springer.com/article/10.1007/s10462-022-10300-7
Erik Cambria,ConNER: Consistency Training for Cross-lingual Named Entity Recognition,2022,Proceedings of EMNLP,18,"Ran Zhou, Xin Li, Lidong Bing, Erik Cambria, Luo Si, Chunyan Miao",Ran Zhou,Chunyan Miao,6,"Cross-lingual named entity recognition (NER) suffers from data scarcity in the target languages, especially under zero-shot settings. Existing translate-train or knowledge distillation methods attempt to bridge the language gap, but often introduce a high level of noise. To solve this problem, consistency training methods regularize the model to be robust towards perturbations on data or hidden states. However, such methods are likely to violate the consistency hypothesis, or mainly focus on coarse-grain consistency. We propose ConNER as a novel consistency training framework for cross-lingual NER, which comprises of: (1) translation-based consistency training on unlabeled target-language data, and (2) dropoutbased consistency training on labeled source-language data. ConNER effectively leverages unlabeled target-language data and alleviates overfitting on the source language to enhance the cross-lingual adaptability. Experimental results show our ConNER achieves consistent improvement over various baseline methods.",https://arxiv.org/abs/2211.09394
Erik Cambria,"MuSe 2021 Challenge: Multimodal Emotion, Sentiment, Physiological-Emotion, and Stress Detection",2021,,18,"Lukas Stappen, Eva-Maria Meßner, Erik Cambria, Guoying Zhao, Björn W Schuller",Lukas Stappen,Björn W Schuller,5,"The 2nd Multimodal Sentiment Analysis (MuSe) 2021 Challenge-based Workshop is held in conjunction with ACM Multimedia'21. Two datasets are provided as part of the challenge. Firstly, the MuSe-CaR dataset, which focuses on user-generated, emotional vehicle reviews from YouTube, and secondly, the novel Ulm-Trier Social Stress (Ulm-TSST) dataset, which shows people in stressful circumstances. Participants are faced with four sub-challenges: predicting arousal and valence in a time- and value-continuous manner on a) MuSe-CaR (MuSe-Wilder) and b) Ulm-TSST (MuSe-Stress); c) predicting unsupervised created emotion classes on MuSe-CaR (MuSe-Sent); d) predicting a fusion of human-annotated arousal and measured galvanic skin response also as a continuous target on Ulm-TSST (MuSe-Physio). In this summary, we describe the motivation, the sub-challenges, the challenge conditions, the …",https://dl.acm.org/doi/abs/10.1145/3474085.3478582
Erik Cambria,Popularity Prediction on Vacation Rental Websites,2020,Neurocomputing,18,"Yang Li, Suhang Wang, Yukun Ma, Quan Pan, Erik Cambria",Yang Li,Erik Cambria,5,"In the personal house renting scenario, customers usually make quick assessments based on previous customers' reviews, which makes such reviews essential for the business. If the house is assessed as popular, a Matthew effect will be observed as more people will be willing to book it. Due to the lack of definition and quantity assessment measures, however, it is difficult to make a popularity evaluation and prediction. To solve this problem, the concept of house popularity is well defined in this paper. Specifically, the house popularity is decided by inter-event timeand rating score at the same time. To make a more effective prediction over these two correlated variables, a dual-gated recurrent unit (DGRU) is employed. Furthermore, an encoder-decoder framework with DGRU is proposed to perform popularity prediction. Empirical results show the effectiveness of the proposed DGRU and the encoder-decoder …",https://www.sciencedirect.com/science/article/pii/S0925231220309498
Erik Cambria,Can a Humanoid Robot be part of the Organizational Workforce? A User Study Leveraging Sentiment Analysis,2019,Proceedings of Ro-Man,18,"Nidhi Mishra, Manoj Ramanathan, Ranjan Satapathy, Erik Cambria, Nadia Magnenat-Thalmann",Nidhi Mishra,Nadia Magnenat-Thalmann,5,"Hiring robots for the workplaces is a challenging task as robots have to cater to customer demands, follow organizational protocols and behave with social etiquette. In this study, we propose to have a humanoid social robot, Nadine, as a customer service agent in an open social work environment. The objective of this study is to analyze the effects of humanoid robots on customers in a work environment, and see if it can handle social scenarios. We propose to evaluate these objectives through two modes, namely: survey questionnaire and customer feedback. The survey questionnaires are analyzed based on the datapoints provided in the questionnaire. We propose a novel approach to analyze customer feedback data using sentic computing. Specifically, we employ aspect extraction and sentiment analysis to analyze the data. From our framework, we detect sentiment associated to the aspects that mainly …",https://ieeexplore.ieee.org/abstract/document/8956349/
Erik Cambria,Subjectivity Detection in Nuclear Energy Tweets,2017,Computación y Sistemas,18,"Ranjan Satapathy, Iti Chaturvedi, Erik Cambria, Shirley Ho, Jin Cheon Na",Ranjan Satapathy,Jin Cheon Na,5,"The subjectivity detection is an important binary classification task that aims at distinguishing natural language texts as opinionated (positive or negative) and non-opinionated (neutral). In this paper, we develop and apply recent subjectivity detection techniques to determine subjective and objective tweets towards the hot topic of nuclear energy. This will further help us to detect the presence or absence of social media bias towards Nuclear Energy. In particular, significant network motifs of words and concepts were learned in dynamic Gaussian Bayesian networks, while using Twitter as a source of information. We use reinforcement learning to update each weight based on a probabilistic reward function over all the weights and, hence, to regularize the sentence model. The proposed framework opens new avenues in helping government agencies manage online public opinion to decide and act according to the need of the hour.",https://www.scielo.org.mx/scielo.php?pid=S1405-55462017000400657&script=sci_arttext&tlng=en
Erik Cambria,Multilingual Subjectivity Detection Using Deep Multiple Kernel Learning,2015,Proceedings of KDD Workshops,18,"Iti Chaturvedi, Erik Cambria, Feida Zhu, Lin Qiu, Wee Keong Ng",Iti Chaturvedi,Wee Keong Ng,5,"Subjectivity detection can prevent a sentiment classifier from considering irrelevant or potentially misleading text. Since, different attributes may correspond to different opinions in the lexicon of different languages, we resort to multiple kernel learning (MKL) to simultaneously optimize the different modalities. Previous approaches to MKL for sentence classifiers are computationally slow and lack any hierarchy when grouping features into different kernels. In this paper, we consider deep recurrent convolution neural networks to reduce the dimensionality of the problem. Further, the lower layers in a deep model are abstract and the higher layers become more detailed connecting attributes to opinions. Hence, the features learned automatically in the multiple intermediate layers can be used to train MKL classifiers depending on the application. The proposed deep recurrent MKL outperforms the accuracy of baselines by over 5-30% and is several times faster on two benchmark datasets for subjectivity detection. It can also be used to develop subjectivity lexicons in other languages using English.",http://www.sentic.net/multilingual-subjectivity-detection.pdf
Erik Cambria,How Interpretable are Reasoning Explanations from Prompting Large Language Models?,2024,Proceedings of NAACL,17,"Wei Jie Yeo, Ranjan Satapathy, Goh Siow Mong, Erik Cambria",Wei Jie Yeo,Erik Cambria,4,"Prompt Engineering has garnered significant attention for enhancing the performance of large language models across a multitude of tasks. Techniques such as the Chain-of-Thought not only bolster task performance but also delineate a clear trajectory of reasoning steps, offering a tangible form of explanation for the audience. Prior works on interpretability assess the reasoning chains yielded by Chain-of-Thought solely along a singular axis, namely faithfulness. We present a comprehensive and multifaceted evaluation of interpretability, examining not only faithfulness but also robustness and utility across multiple commonsense reasoning benchmarks. Likewise, our investigation is not confined to a single prompting technique; it expansively covers a multitude of prevalent prompting techniques employed in large language models, thereby ensuring a wide-ranging and exhaustive evaluation. In addition, we introduce a simple interpretability alignment technique, termed Self-Entailment-Alignment Chain-of-thought, that yields more than 70\% improvements across multiple dimensions of interpretability. Code is available at https://github.com/SenticNet/CoT_interpretability",https://arxiv.org/abs/2402.11863
Erik Cambria,Guest Editorial: Explainable Artificial Intelligence for Sentiment Analysis,2022,Knowledge-Based Systems,17,"Erik Cambria, Akshi J Kumar, Mahmoud Al-Ayyoub, Newton Howard",Erik Cambria,Newton Howard,4,"Social media analytics have proven valuable in numerous research areas as a pragmatic tool for public opinion mining and analysis [1]. Sentiment analysis addresses the dynamics of complex socio-affective applications that permeate intelligence and decision making in the sentient and solution-savvy Social Web [2]. Having started as simple polarity detection, contemporary sentiment analysis has advanced to a more nuanced analysis of affect and emotion sensing [3]. Detecting fine-grained sentiment in natural language, however, is tricky even for humans, making its automated detection very complicated. Moreover, online opinions can be put forth in the form of text reviews or ratings, for a product as a whole, or each of its individual aspects [4]. Multiple and lengthy reviews, usage of casual dialect with microtext (wordplay, neologism and slang), use of figurative language (sarcasm, irony), multilingual content (code-mixed and code-switched) and opinion spamming add challenges to the task of extracting opinions.Recently memes, GIFs, typo-graphic (artistic way of text representation), info-graphic (text embedded along with an image) visual content and edited videos also dominate social feeds. Consequently, the intra-modal modeling and inter-modal interactions between the textual, visual and acoustic components add to the linguistic challenges [5]. Therefore, conceptualization and development of multi-faceted sentiment analysis models to adequately capture",https://www.academia.edu/download/112614984/xaisa.pdf
Erik Cambria,Multitask Balanced and Recalibrated Network for Medical Code Prediction,2022,ACM Transactions on Intelligent Systems and Technology,17,"Wei Sun, Shaoxiong Ji, Erik Cambria, Pekka Marttinen",Wei Sun,Pekka Marttinen,4,"Human coders assign standardized medical codes to clinical documents generated during patients’ hospitalization, which is error prone and labor intensive. Automated medical coding approaches have been developed using machine learning methods, such as deep neural networks. Nevertheless, automated medical coding is still challenging because of complex code association, noise in lengthy documents, and the imbalanced class problem. We propose a novel neural network, called the Multitask Balanced and Recalibrated Neural Network, to solve these issues. Significantly, the multitask learning scheme shares the relationship knowledge between different coding branches to capture code association. A recalibrated aggregation module is developed by cascading convolutional blocks to extract high-level semantic features that mitigate the impact of noise in documents. Also, the cascaded structure of the …",https://dl.acm.org/doi/abs/10.1145/3563041
Erik Cambria,Investigating Timing and Impact of News on the Stock Market,2018,Proceedings of ICDM Workshops,17,"Simone Merello, Andrea Picasso, Yukun Ma, Luca Oneto, Erik Cambria",Simone Merello,Erik Cambria,5,"Predicting stock market movements is an interesting and challenging problem: researchers and traders have approached this task with different techniques, from time series prediction to technical and fundamental analysis. Nowadays, a huge amount of textual data can be used to lead a new source of information on this task, well known to be highly stochastic and temporal dependent. In this paper, we investigate the problem of analyzing the timing and the impact that news have on the stock market. We focus on two different important aspects: the possible contribution that new information can have on the stock price and its possible relation with the aggregate news recently published. Our approach involves using the information available now to predict different prices movements, from the recent past to the far future. Results on US market show that the information contained in news can be used as an accurate …",https://ieeexplore.ieee.org/abstract/document/8637369/
Erik Cambria,Rethinking Large Language Models in Mental Health Applications,2025,arXiv preprint arXiv:2311.11267,16,"Shaoxiong Ji, Tianlin Zhang, Kailai Yang, Sophia Ananiadou, Erik Cambria",Shaoxiong Ji,Erik Cambria,5,"Large Language Models (LLMs) have become valuable assets in mental health, showing promise in both classification tasks and counseling applications. This paper offers a perspective on using LLMs in mental health applications. It discusses the instability of generative models for prediction and the potential for generating hallucinatory outputs, underscoring the need for ongoing audits and evaluations to maintain their reliability and dependability. The paper also distinguishes between the often interchangeable terms ``explainability'' and ``interpretability'', advocating for developing inherently interpretable methods instead of relying on potentially hallucinated self-explanations generated by LLMs. Despite the advancements in LLMs, human counselors' empathetic understanding, nuanced interpretation, and contextual awareness remain irreplaceable in the sensitive and complex realm of mental health counseling. The use of LLMs should be approached with a judicious and considerate mindset, viewing them as tools that complement human expertise rather than seeking to replace it.",https://arxiv.org/abs/2311.11267
Erik Cambria,Hate Speech Detection: A Comprehensive Review of Recent Works,2024,Expert Systems,16,"Ankita Gandhi, Param Ahir, Pooja Adhvaryu, Kinjal, Shah, Ritika Lohiya, Erik Cambria, Soujanya Poria, Amir Hussain",Ankita Gandhi,Amir Hussain,9,"There has been surge in the usage of Internet as well as social media platforms which has led to rise in online hate speech targeted on individual or group. In the recent years, hate speech has resulted in one of the challenging problems that can unfurl at a fast pace on digital platforms leading to various issues such as prejudice, violence and even genocide. Considering the acceptance of Artificial Intelligence (AI) and Natural Language Processing (NLP) techniques in varied application domains, it would be intriguing to consider these techniques for automated hate speech detection. In literature, there have been efforts to recognize and categorize hate speech using varied Machine Learning (ML) and Deep Learning (DL) techniques. Hence, considering the need and provocations for hate speech detection we aim to present a comprehensive review that discusses fundamental taxonomy as well as recent advances …",https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13562
Erik Cambria,Saving Earth One Tweet at a Time through the Lens of Artificial Intelligence,2022,Proceedings of IJCNN,16,"Cuc Duong, Qian Liu, Rui Mao, Erik Cambria",Cuc Duong,Erik Cambria,4,"The impacts of climate change and global warming have become more visible globally because of the increasing frequency of extreme weather events, abnormal heatwaves, and other climate crises. Besides the traditional survey method, it is beneficial to automatically distillate climate change opinions from social platforms to measure public reactions quickly. We investigate how to organize climate change opinions on Twitter into meaningful categories to support perspective summarizing tasks. We find that merely using the available taxonomy for this task is ineffective; hence we must consider the entire text content. We recommend five high-level categories (Root cause, Impact, Mitigation, Politics or Policy, Others) and assemble ClimateTweets, a dataset with category and polarity labels. In addition, we construct category classification and polarity detection tasks with a range of opinion mining baselines. The …",https://ieeexplore.ieee.org/abstract/document/9892271/
Erik Cambria,New Trends and Applications in Social Media Analytics,2021,Future Generation Computer Systems,16,"David Camacho, Ma Victoria Luzón, Erik Cambria",David Camacho,Erik Cambria,3,"The fast growth of social media platforms and their related applications have dramatically changed the way billions of people relate to each other on the Web. This evolution of social media has blossomed in a plethora of end-user, or user-centered, applications that required innovative and efficient techniques for data processing. This was made possible recently thanks to advances in data science and artificial intelligence in fields like pattern recognition, information fusion, knowledge discovery and data visualization. This special issue provides a set of 12 selected papers (out of 65 submissions) that represent latest advances and developments in these areas.",https://www.sciencedirect.com/science/article/pii/S0167739X20324924
Erik Cambria,Balancing Computational Complexity and Generalization Ability: A Novel Design for ELM,2020,Neurocomputing,16,"Edoardo Ragusa, Paolo Gastaldo, Rodolfo Zunino, Erik Cambria",Edoardo Ragusa,Erik Cambria,4,"Learning paradigms that use random basis functions provide effective tools to deal with large datasets, as they combine efficient training algorithms with remarkable generalization performances. The paper first considers the affinity between the paradigm of learning with similarity functions and the Extreme Learning Machine (ELM) model, and reformulates the mapping scheme of ELMs. A mapping scheme that better balances generalization ability and network size is a novelty point of the proposed approach, and represent a major advantage when targeting implementation on resource-constrained devices. A computationally efficient heuristic supports the training procedure, and suitably applies the theory of learning with similarity functions to the availability of consistent amounts of data. Experimental results on standard datasets confirm the effectiveness of the proposed approach.",https://www.sciencedirect.com/science/article/pii/S0925231220304197
Erik Cambria,"One Belt, One Road, One Sentiment? A Hybrid Approach to Gauging Public Opinions on the New Silk Road Initiative",2020,Proceedings of ICDM Workshops,16,"Jonathan Kevin Chandra, Erik Cambria, Andrea Nanetti",Jonathan Kevin Chandra,Andrea Nanetti,3,"With the rapid adoption of the Internet, fast-moving social media platforms have been able to extract and encapsulate real-time public sentiments on different entities. Real-time sentiment analysis on current dynamic events such as elections, global affairs and sports are essential in the understanding the public's reaction to the states and trajectories of these events. In this paper, we aim to extract the sentiments of the Belt and Road Initiative from Twitter. Using aspect-based sentiment analysis, we were able to obtain the tweet's sentiment polarity on the related aspect category to better understand the topics that were discussed. We have developed an end-to-end sentiment analysis system that collects relevant data from Twitter, processes it and visualizes it on an intuitive display. We employed a hybrid approach of symbolic and sub-symbolic techniques using gated convolutional networks, aspect embeddings and …",https://ieeexplore.ieee.org/abstract/document/9346455/
Erik Cambria,JUSTers at SemEval-2020 Task 4: Evaluating Transformer Models Against Commonsense Validation and Explanation,2020,Proceedings of SemEval,16,"Ali Fadel, Mahmoud Al-Ayyoub, Erik Cambria",Ali Fadel,Erik Cambria,3,"In this paper, we describe our team’s (JUSTers) effort in the Commonsense Validation and Explanation (ComVE) task, which is part of SemEval2020. We evaluate five pre-trained Transformer-based language models with various sizes against the three proposed subtasks. For the first two subtasks, the best accuracy levels achieved by our models are 92.90% and 92.30%, respectively, placing our team in the 12th and 9th places, respectively. As for the last subtask, our models reach 16.10 BLEU score and 1.94 human evaluation score placing our team in the 5th and 3rd places according to these two metrics, respectively. The latter is only 0.16 away from the 1st place human evaluation score.",https://aclanthology.org/2020.semeval-1.66/
Erik Cambria,Understanding the Role of Social Media in Backpacker Tourism,2019,Proceedings of ICDM Workshops,16,"Claudia Guerreiro, Erik Cambria, Hien T Nguyen",Claudia Guerreiro,Hien T Nguyen,3,"The Web 2.0 revolution has affected many areas of society and tourism is not exception to that. Travel 2.0 replaced the first, booking-oriented wave with a crowdsourced, fully interactive one that aids travel planners in making decisions via user-generated content (UGC). In this work, we study how social media are shaping backpackers' experiences by employing sentiment analysis on their blogs. Into the bargain, there are two main research objectives which consist on providing insights into the contemporary backpackers' attitudes and examining the potential implications of their UGC to assist travel-related marketing strategies along with product and service improvement. Such information is found in word-based blog entries and is extracted and analyzed through a combination of methods, specifically sentiment analysis and digital ethnography.",https://ieeexplore.ieee.org/abstract/document/8955645/
Erik Cambria,Towards a Chinese Common and Common Sense Knowledge Base for Sentiment Analysis,2012,,16,"Erik Cambria, Amir Hussain, Tariq Durrani, Jiajun Zhang",Erik Cambria,Jiajun Zhang,4,"To date, the majority of sentiment analysis research has focused on English language. Recent studies, however, show that non-native English speakers heavily support the growing use of Internet. Chinese, specifically, is poised to outpace English as the dominant language online in a few years’ time. So far, just a few isolated research endeavors have been undertaken to meet the demands of real-life Chinese web environments. Natural language processing research endeavor, in fact, primarily depends on the availability of resources like lexicons and corpora, which are still very limited for sentiment analysis research in Chinese language. To this end, we are developing a Chinese common and common sense knowledge base for sentiment analysis by blending the largest existing taxonomy of English common knowledge with a semantic network of English common sense knowledge, and by using …",https://link.springer.com/chapter/10.1007/978-3-642-31087-4_46
Erik Cambria,Understanding Natural Language Understanding,2024,,15,Erik Cambria,Erik Cambria,Erik Cambria,1,"About half a century ago, AI pioneers like Marvin Minsky embarked on the ambitious project of emulating how the human mind encodes and decodes meaning. While today we have a better understanding of the brain thanks to neuroscience, we are still far from unlocking the secrets of the mind, especially when it comes to language, the prime example of human intelligence.“Understanding natural language understanding”, ie, understanding how the mind encodes and decodes meaning through language, is a significant milestone in our journey towards creating machines that genuinely comprehend human language. Large language models (LLMs) such as GPT-4 have astounded us with their ability to generate coherent, contextually relevant text, seemingly bridging the gap between human and machine communication. Yet, despite their impressive capabilities, these models operate on statistical patterns rather …",https://link.springer.com/book/10.1007/978-3-031-73974-3?source=shoppingads&locale=en-gb
Erik Cambria,Template-Free Prompting for Few-Shot Named Entity Recognition via Semantic-Enhanced Contrastive Learning,2024,IEEE Transactions on Neural Networks and Learning Systems,15,"Kai He, Rui Mao, Yucheng Huang, Tieliang Gong, Chen Li, Erik Cambria",Kai He,Erik Cambria,6,"Prompt tuning has achieved great success in various sentence-level classification tasks by using elaborated label word mappings and prompt templates. However, for solving token-level classification tasks, e.g., named entity recognition (NER), previous research, which utilizes N-gram traversal for prompting all spans with all possible entity types, is time-consuming. To this end, we propose a novel prompt-based contrastive learning method for few-shot NER without template construction and label word mappings. First, we leverage external knowledge to initialize semantic anchors for each entity type. These anchors are simply appended with input sentence embeddings as template-free prompts (TFPs). Then, the prompts and sentence embeddings are in-context optimized with our proposed semantic-enhanced contrastive loss. Our proposed loss function enables contrastive learning in few-shot scenarios without …",https://ieeexplore.ieee.org/abstract/document/10264144/
Erik Cambria,End-to-end Case-Based Reasoning for Commonsense Knowledge Base Completion,2023,Proceedings of EACL,15,"Zonglin Yang, Xinya Du, Erik Cambria, Claire Cardie",Zonglin Yang,Claire Cardie,4,"Pretrained language models have been shown to store knowledge in their parameters and have achieved reasonable performance in commonsense knowledge base completion (CKBC) tasks. However, CKBC is knowledge-intensive and it is reported that pretrained language models’ performance in knowledge-intensive tasks are limited because of their incapability of accessing and manipulating knowledge. As a result, we hypothesize that providing retrieved passages that contain relevant knowledge as additional input to the CKBC task will improve performance. In particular, we draw insights from Case-Based Reasoning (CBR)–which aims to solve a new problem by reasoning with retrieved relevant cases, and investigate the direct application of it to CKBC. On two benchmark datasets, we demonstrate through automatic and human evaluations that our End-to-end Case-Based Reasoning Framework (ECBRF) generates more valid, informative, and novel knowledge than the state-of-the-art COMET model for CKBC in both the fully supervised and few-shot settings. We provide insights on why previous retrieval-based methods only achieve merely the same performance with COMET. From the perspective of CBR, our framework addresses a fundamental question on whether CBR methodology can be utilized to improve deep learning models.",https://aclanthology.org/2023.eacl-main.255/
Erik Cambria,AutoML-Emo: Automatic Knowledge Selection using Congruent Effect for Emotion Identification in Conversations,2023,IEEE Transactions on Affective Computing,15,"Dazhi Jiang, Runguo Wei, Jintao Wen, Geng Tu, Erik Cambria",Dazhi Jiang,Erik Cambria,5,"Emotion recognition in conversations (ERC) has wide applications in medical care, human-computer interaction, and other fields. Unlike the general task of emotion analysis, humans usually rely on context and commonsense knowledge to convey emotions in conversations. Only when the model can connect and fully utilize a large-scale commonsense knowledge base, it can better understand latent contents in conversations. Unfortunately, there is no available knowledge selection mechanism to address such knowledge needs and to make sure the system is not flooded with irrelevant commonsense knowledge. Therefore, we propose an AutoML strategy based on emotion congruent effect to select suitable knowledge and models, called AutoML-Emo. Global exploration and local exploitation-based selection mechanisms (G&LESM) are used for automatic knowledge selection. The transformer-based architecture …",https://ieeexplore.ieee.org/abstract/document/9999285/
Erik Cambria,Does Semantics Aid Syntax? An Empirical Study on Named Entity Recognition and Classification,2022,Neural Computing and Applications,15,"Xiaoshi Zhong, Erik Cambria, Amir Hussain",Xiaoshi Zhong,Amir Hussain,3,"Many researchers jointly model multiple linguistic tasks (e.g., joint modeling of named entity recognition and named entity classification and joint modeling of syntactic parsing and semantic parsing) with an implicit assumption that these individual tasks can enhance each other via the joint modeling. Before conducting research on jointly modeling multiple tasks, however, such researchers hardly examine whether such assumption is true or not. In this paper, we empirically examine whether named entity classification improves the performance of named entity recognition as an empirical case of examining whether semantics improves the performance of a syntactic task. To this end, we firstly specify the way to determine whether a linguistic task is a syntactic task or a semantic task according to both syntactic theory and semantic theory. After that, we design and conduct extensive experiments on two well …",https://link.springer.com/article/10.1007/s00521-021-05949-0
Erik Cambria,Genetic Programming for Domain Adaptation in Product Reviews,2020,Proceedings of the IEEE Congress on Evolutionary Computation,15,"Iti Chaturvedi, Sandro Cavallari, Erik Cambria, Roy Welsch",Iti Chaturvedi,Roy Welsch,4,"There is a large variety of products sold online and the websites are in several languages. Hence, it is desirable to train a model that can predict sentiments in different domains simultaneously. Previous authors have used deep learning to extract features from multiple domains. Here, each word is represented by a vector that is determined using co-occurrence data. Such a model requires that all sentences have the same length resulting in low accuracy. To overcome this challenge, we model the features in each sentence using a variable length tree called a Genetic Program. The polarity of clauses can be represented using mathematical operators such as '+' or '-' at internal nodes in the tree. The proposed model is evaluated on Amazon product reviews for different products and in different languages. We are able to outperform the accuracy of baseline multi-domain models in the range of 5-20%.",https://ieeexplore.ieee.org/abstract/document/9185713/
Erik Cambria,Aspect-Sentiment Embeddings for Company Profiling and Employee Opinion Mining,2018,Proceedings of CICLing,15,"Rajiv Bajpai, Devamanyu Hazarika, Kunal Singh, Sruthi Gorantla, Erik Cambria, Roger Zimmerman",Rajiv Bajpai,Roger Zimmerman,6,"With the multitude of companies and organizations abound today, ranking them and choosing one out of the many is a difficult and cumbersome task. Although there are many available metrics that rank companies, there is an inherent need for a generalized metric that takes into account the different aspects that constitute employee opinions of the companies. In this work, we aim to overcome the aforementioned problem by generating aspect-sentiment based embedding for the companies by looking into reliable employee reviews of them. We created a comprehensive dataset of company reviews from the famous website Glassdoor.com and employed a novel ensemble approach to perform aspect-level sentiment analysis. Although a relevant amount of work has been done on reviews centered on subjects like movies, music, etc., this work is the first of its kind. We also provide several insights from the collated …",https://link.springer.com/chapter/10.1007/978-3-031-23804-8_12
Erik Cambria,CSenticNet: A Concept-Level Resource for Sentiment Analysis in Chinese Language,2017,Proceedings of CICLing,15,"Haiyun Peng, Erik Cambria",Haiyun Peng,Erik Cambria,2,"In recent years, sentiment analysis has become a hot topic in natural language processing. Although sentiment analysis research in English is rather mature, Chinese sentiment analysis has just set sail, as the limited amount of sentiment resources in Chinese severely limits its development. In this paper, we present a method for the construction of a Chinese sentiment resource. We utilize both English sentiment resources and the Chinese knowledge base NTU Multi-lingual Corpus. In particular, we first propose a resource based on SentiWordNet and a second version based on SenticNet.",https://link.springer.com/chapter/10.1007/978-3-319-77116-8_7
Erik Cambria,Sentiment-Oriented Information Retrieval: Affective Analysis of Documents Based on the SenticNet Framework,2016,,15,"Federica Bisio, Claudia Meda, Paolo Gastaldo, Rodolfo Zunino, Erik Cambria",Federica Bisio,Erik Cambria,5,"     Sentiment      analysis research has acquired a growing importance due to its applications in several different fields. A large number of companies have included the analysis of opinions and sentiments of costumers as a part of their mission. Therefore, the analysis and automatic classification of large corpora of documents in natural language, based on the conveyed feelings and emotions, has become a crucial issue for text mining purposes. This chapter aims to relate the sentiment-based characterization inferred from books with the distribution of emotions within the same texts. The main result consists in a method to compare and classify texts based on the feelings expressed within the narrative trend.",https://link.springer.com/chapter/10.1007/978-3-319-30319-2_8
Erik Cambria,Neurosymbolic Sentiment Analysis with Dynamic Word Sense Disambiguation,2023,Proceedings of EMNLP,14,"Xulang Zhang, Rui Mao, Kai He, Erik Cambria",Xulang Zhang,Erik Cambria,4,"Sentiment analysis is a task that highly depends on the understanding of word senses. Traditional neural network models are black boxes that represent word senses as vectors that are uninterpretable for humans. On the other hand, the application of Word Sense Disambiguation (WSD) systems in downstream tasks poses challenges regarding i) which words need to be disambiguated, and ii) how to model explicit word senses into easily understandable terms for a downstream model. This work proposes a neurosymbolic framework that incorporates WSD by identifying and paraphrasing ambiguous words to improve the accuracy of sentiment predictions. The framework allows us to understand which words are paraphrased into which semantically unequivocal words, thus enabling a downstream task model to gain both accuracy and interpretability. To better fine-tune a lexical substitution model for WSD on a downstream task without ground-truth word sense labels, we leverage dynamic rewarding to jointly train sentiment analysis and lexical substitution models. Our framework proves to effectively improve the performance of sentiment analysis on corpora from different domains.",https://aclanthology.org/2023.findings-emnlp.587/
Erik Cambria,Fake News Detection Using XLNet Fine-Tuning Model,2021,Proceedings of ICCICA,14,"Ashok J Kumar, Tina Esther Trueman, Erik Cambria",Ashok J Kumar,Erik Cambria,3,"In recent years, the traditional way of getting news from a Television, news paper, or national newscast is gone. Today, online social media provides the fastest news content for people. This, however, brings about the problem of fake news. In fact, fake news detection is one of the challenging tasks in natural language processing to differentiate between real (or true) and fake (or false) news content. In this paper, we propose an XLNet fine-tuning model to predict fake news in a multi-class and binary class problem. Our results show that the proposed XLNet model comparatively achieves a better result than the existing state-of-the-art models.",https://ieeexplore.ieee.org/abstract/document/9697269/
Erik Cambria,Graph Routing between Capsules,2021,Neural Networks,14,"Yang Li, Wei Zhao, Erik Cambria, Suhang Wang, Steffen Eger",Yang Li,Steffen Eger,5,"Routing methods in capsule networks often learn a hierarchical relationship for capsules in successive layers, but the intra-relation between capsules in the same layer is less studied, while this intra-relation is a key factor for the semantic understanding in text data. Therefore, in this paper, we introduce a new capsule network with graph routing to learn both relationships, where capsules in each layer are treated as the nodes of a graph. We investigate strategies to yield adjacency and degree matrix with three different distances from a layer of capsules, and propose the graph routing mechanism between those capsules. We validate our approach on five text classification datasets, and our findings suggest that the approach combining bottom-up routing and top-down attention performs the best. Such an approach demonstrates generalization capability across datasets. Compared to the state-of-the-art routing …",https://www.sciencedirect.com/science/article/pii/S0893608021002501
Erik Cambria,Multitask Recalibrated Aggregation Network for Medical Code Prediction,2021,Proceedings of ECML PKDD,14,"Wei Sun, Shaoxiong Ji, Erik Cambria, Pekka Marttinen",Wei Sun,Pekka Marttinen,4,"Medical coding translates professionally written medical reports into standardized codes, which is an essential part of medical information systems and health insurance reimbursement. Manual coding by trained human coders is time-consuming and error-prone. Thus, automated coding algorithms have been developed, building especially on the recent advances in machine learning and deep neural networks. To solve the challenges of encoding lengthy and noisy clinical documents and capturing code associations, we propose a multitask recalibrated aggregation network. In particular, multitask learning shares information across different coding schemes and captures the dependencies between different medical codes. Feature recalibration and aggregation in shared modules enhance representation learning for lengthy notes. Experiments with a real-world MIMIC-III dataset show significantly improved …",https://link.springer.com/chapter/10.1007/978-3-030-86514-6_23
Erik Cambria,Business Taxonomy Construction Using Concept-Level Hierarchical Clustering,2019,Proceedings of IJCAI Workshops,14,"Haodong Bai, Frank Xing, Erik Cambria, Win-Bin Huang",Haodong Bai,Win-Bin Huang,4,"Business taxonomies are indispensable tools for investors to do equity research and make professional decisions. However, to identify the structure of industry sectors in an emerging market is challenging for two reasons. First, existing taxonomies are designed for mature markets, which may not be the appropriate classification for small companies with innovative business models. Second, emerging markets are fast-developing, thus the static business taxonomies cannot promptly reflect the new features. In this article, we propose a new method to construct business taxonomies automatically from the content of corporate annual reports. Extracted concepts are hierarchically clustered using greedy affinity propagation. Our method requires less supervision and is able to discover new terms. Experiments and evaluation on the Chinese National Equities Exchange and Quotations (NEEQ) market show several advantages of the business taxonomy we build. Our results provide an effective tool for understanding and investing in the new growth companies.",https://arxiv.org/abs/1906.09694
Erik Cambria,Document Representation with Statistical Word Senses in Cross-Lingual Document Clustering,2015,International Journal of Pattern Recognition and Artificial Intelligence,14,"Guoyu Tang, Yunqing Xia, Erik Cambria, Peng Jin, Thomas Fang Zheng",Guoyu Tang,Thomas Fang Zheng,5,"Cross-lingual document clustering is the task of automatically organizing a large collection of multi-lingual documents into a few clusters, depending on their content or topic. It is well known that language barrier and translation ambiguity are two challenging issues for cross-lingual document representation. To this end, we propose to represent cross-lingual documents through statistical word senses, which are automatically discovered from a parallel corpus through a novel cross-lingual word sense induction model and a sense clustering method. In particular, the former consists in a sense-based vector space model and the latter leverages on a sense-based latent Dirichlet allocation. Evaluation on the benchmarking datasets shows that the proposed models outperform two state-of-the-art methods for cross-lingual document clustering.",https://www.worldscientific.com/doi/abs/10.1142/S021800141559003X
Erik Cambria,Sentic Panalogy: Swapping Affective Common Sense Reasoning Strategies and Foci,2012,Proceedings of CogSci,14,"E Cambria, D Olsher, K Kwok",E Cambria,K Kwok,3,"An important difference between traditional AI systems and human intelligence is our ability to harness common sense knowledge gleaned from a lifetime of learning and experiences to inform our decision-making and behavior. This allows humans to adapt easily to novel situations where AI fails catastrophically for lack of situation-specific rules and generalization capabilities. In order for machines to exploit common sense knowledge in reasoning as humans do, moreover, we need to endow them with human-like reasoning strategies. In problem-solving situations, in particular, several analogous representations of the same problem should be maintained in parallel while trying to solve it so that, when problem-solving begins to fail while using one representation, the system can switch to one of the others. Sentic panalogy is a technique that aims to emulate such process by exploiting graph-mining and dimensionality-reduction techniques to dynamically interchange both different reasoning strategies and the foci around which such strategies are developed.",https://escholarship.org/content/qt5zm3x3kb/qt5zm3x3kb.pdf
Erik Cambria,Neurosymbolic AI for Personalized Sentiment Analysis,2024,Proceedings of HCII,13,"Luyao Zhu, Rui Mao, Erik Cambria, Bernard Jim Jansen",Luyao Zhu,Bernard Jim Jansen,4,"Sentiment analysis is crucial in extracting valuable insights from vast amounts of textual data generated across various platforms, such as social media, customer reviews, news articles, etc. Over the years, researchers and business professionals have worked hard to refine sentiment analysis algorithms, but there is a limit to how accurate any algorithm can be without considering personalization. In this work, we propose a framework for personalized sentiment analysis that performs automatic user profiling by modeling users based on different levels of personalization, before performing sentiment analysis. In particular, such framework leverages seven levels of personalization (from bottom to top), namely: Entity, to distinguish between humans and other intelligent agents; Culture, to take into account how different cultures perceive the same concept as positive or negative; Religion, to consider how specific religious …",https://link.springer.com/chapter/10.1007/978-3-031-76827-9_16
Erik Cambria,Can Generative AI Models Extract Deeper Sentiments as Compared to Traditional Deep Learning Algorithms?,2024,IEEE Intelligent Systems,13,"Mohammad Anas, Anam Saiyeda, Shahab Saquib Sohail, Erik Cambria, Amir Hussain",Mohammad Anas,Amir Hussain,5,"Recent advances in the context of deep learning have led to the development of generative artificial intelligence (AI) models which have shown remarkable performance in complex language understanding tasks. This study proposes an evaluation of traditional deep learning algorithms and generative AI models for sentiment analysis. Experimental results show that RoBERTa outperforms all models, including ChatGPT and Bard, suggesting that generative AI models are not yet able to capture the nuances and subtleties of sentiment in text. We provide valuable insights into the strengths and weaknesses of different models for sentiment analysis and offer guidance for researchers and practitioners in selecting suitable models for their tasks.",https://ieeexplore.ieee.org/abstract/document/10510596/
Erik Cambria,Deep-Attack over the Deep Reinforcement Learning,2022,Knowledge-Based Systems,13,"Yang Li, Quan Pan, Erik Cambria",Yang Li,Erik Cambria,3,"Recent adversarial attack developments have made reinforcement learning more vulnerable, and different approaches exist to deploy attacks against it, where the key is how to choose the right timing of the attack. Some work tries to design an attack evaluation function to select critical points that will be attacked if the value is greater than a certain threshold. This approach makes it difficult to find the right place to deploy an attack without considering the long-term impact. In addition, there is a lack of appropriate indicators of assessment during attacks. To make the attacks more intelligent as well as to remedy the existing problems, we propose the reinforcement learning-based attacking framework by considering the effectiveness and stealthy spontaneously, while we also propose a new metric to evaluate the performance of the attack model in these two aspects. Experimental results show the effectiveness of our …",https://www.sciencedirect.com/science/article/pii/S0950705122004671
Erik Cambria,Transformer-Based Bidirectional Encoder Representations for Emotion Detection from Text,2021,Proceedings of IEEE SSCI,13,"Ashok J Kumar, Erik Cambria, Tina Esther Trueman",Ashok J Kumar,Tina Esther Trueman,3,"Social media influences internet users to share their sentiments, feelings, or emotions about entities. In particular, sentiment analysis classifies a text into positive, negative, or neutral. It does not capture the state of mind of an individual like happiness, anger, and fear. Therefore, emotion detection plays an important role in user-generated content for capturing the state of mind. Moreover, researchers adopted traditional machine learning and deep learning models to capture emotions from the text. Recently, transformers-based architectures achieve better results in various natural language processing tasks. Therefore, we propose a transformer-based emotion detection system, which uses context-dependent features and a one-cycle learning rate policy for a better understanding of emotions from the text. We evaluate the proposed emotion detection model using error matrix, learning curve, precision, recall, F1-score …",https://ieeexplore.ieee.org/abstract/document/9660152/
Erik Cambria,Interpretable Representation Learning for Personality Detection,2021,Proceedings of ICDM Workshops,13,"Amirmohammad Kazemeini, Sudipta Singha Roy, Robert E Mercer, Erik Cambria",Amirmohammad Kazemeini,Erik Cambria,4,"Automatic personality detection has gained increasing interest recently. Several models have been introduced to perform this task. The weakness of these models is their inability to interpret their results. Even if the model shows excellent performance over test data, it can sometimes fail in real-life tasks since it may incorrectly interpret a statement. To investigate this issue, we evaluate two approaches. In the first approach, we generate sentence embeddings by training a siamese BiLSTM with max-pooling on the psychological statement pairs to compute the semantic similarities between them. In the second approach, we evaluate state-of-the-art pretrained language models to see whether their output representations can distinguish personality types. Both of these approaches outperform state-of-the-art models for this task with less computational overhead. We conclude by discussing the implications of this work for …",https://ieeexplore.ieee.org/abstract/document/9679950/
Erik Cambria,Intelligent Asset Management,2019,,13,"Frank Xing, Erik Cambria, Roy Welsch",Frank Xing,Roy Welsch,3,"The scenario when investors need to manage a large number of financial assets has an essential difference from what most of the people do for stock movement prediction today. Unlike the situation of considering a single stock, investors need to consider co-movement of related stocks and control risk within a certain level. In traditional asset allocation models, expected returns and correlations of financial assets are difficult to estimate from historical price series, which are nonstationary and volatile. Therefore, we resort to textual knowledge hidden behind the huge amount of unstructured market information produced by human beings. In fact, one of the central research topics of this book include incorporating natural language processing techniques into several asset allocation models and finding the proper variables in financial models that naturally link to the contents of financial reports and the market sentiment …",https://link.springer.com/content/pdf/10.1007/978-3-030-30263-4.pdf
Erik Cambria,Growing Semantic Vines for Robust Asset Allocation,2019,Knowledge-Based Systems,13,"Frank Xing, Erik Cambria, Roy Welsch",Frank Xing,Roy Welsch,3,"The vine structure has been widely studied as a graphical representation for high-dimensional dependence modeling, depicting complicated probability density functions, and robust correlation estimation. However, specification of the best vine structure is challenging as the number of candidate vine structures grows combinatorially when the number of elements increases. In this article, we propose to leverage semantic prior knowledge of assets extracted from their descriptive documents to find a suitable vine structure for financial portfolio optimization. A vine growing algorithm is provided and the robust covariance matrix estimation process is performed on this vine structure. Our construction of a semantic vine improves the state-of-the-art arbitrary vine-growing method in the context of robust correlation estimation and multi-period asset allocation. The effectiveness of our methods on a large scale is also …",https://www.sciencedirect.com/science/article/pii/S0950705118305872
Erik Cambria,SLT-Based ELM for Big Social Data Analysis,2017,Cognitive Computation,13,"Luca Oneto, Federica Bisio, Erik Cambria, Davide Anguita",Luca Oneto,Davide Anguita,4,"Recently, social networks and other forms of media communication have been gathering the interest of both the scientific and the business world, leading to the increasing development of the science of opinion and sentiment analysis. Facing the huge amount of information present on the Web represents a crucial task and leads to the study and creation of efficient models able to tackle the task. To this end, current research proposes an efficient approach to support emotion recognition and polarity detection in natural language text. In this paper, we show how the most recent advances in statistical learning theory (SLT) can support the development of an efficient extreme learning machine (ELM) and the assessment of the resultant model’s performance when applied to big social data analysis. ELM, developed to overcome some issues in back-propagation networks, represents a powerful learning tool …",https://link.springer.com/article/10.1007/s12559-016-9440-6
Erik Cambria,A Learning Scheme Based on Similarity Functions for Affective Common-Sense Reasoning,2015,Proceedings of IJCNN,13,"Federica Bisio, Paolo Gastaldo, Rodolfo Zunino, Erik Cambria",Federica Bisio,Erik Cambria,4,"This paper explores the theory of learning with similarity functions in the context of common-sense reasoning and natural language processing. Based on this theory, the proposed approach (called Sim-Predictor) is characterized by the process of remapping the input space into a new space which is able to convey the similarity between the input pattern and a number of landmarks, i.e., a subset of patterns randomly extracted from the training set. The new learning scheme exhibits the interesting property of relating the dimensionality of the remapped space to the learning abilities of the eventual predictor in a formal fashion. The evaluation phase shows that Sim-Predictor compares positively with ELM and SVM, when addressing the problem of polarity detection in the sentic computing framework, a novel approach to big social data analysis based on the interpretation of the cognitive and affective information …",https://ieeexplore.ieee.org/abstract/document/7280633/
Erik Cambria,MetaPro 2.0: Computational Metaphor Processing on the Effectiveness of Anomalous Language Modeling,2024,Proceedings of ACL,12,"Rui Mao, Kai He, Claudia Beth Ong, Qian Liu, Erik Cambria",Rui Mao,Erik Cambria,5,"Metaphor interpretation is a difficult task in natural language understanding. The development of relevant techniques in this domain is slow, mostly because of the lack of large annotated datasets and effective pre-trained language models (PLMs) for metaphor learning. Thus, we propose a large annotated dataset and a PLM for the metaphor interpretation task. Our foundation model is based on a novel anomalous language modeling (ALM) method, which we benchmark with comparable PLM baselines on the new dataset, finding that it largely improves model performance on metaphor identification and interpretation.",https://aclanthology.org/2024.findings-acl.590/
Erik Cambria,FinXABSA: Explainable Finance through Aspect-Based Sentiment Analysis,2023,Proceedings of ICDM Workshops,12,"Keane Ong, Wihan van der Heever, Ranjan Satapathy, Gianmarco Mengaldo, Erik Cambria",Keane Ong,Erik Cambria,5,"This paper presents a novel approach for explain-ability in financial analysis by deriving financially-explainable statistical relationships through aspect-based sentiment analysis, Pearson correlation, Granger causality & uncertainty coefficient. The proposed methodology involves constructing an aspect list from financial literature and applying aspect-based sentiment analysis on social media text to compute sentiment scores for each aspect. Pearson correlation is then applied to uncover financially explainable relationships between aspect sentiment scores and stock prices. Findings for derived relationships are made robust by applying Granger causality to determine the forecasting ability of each aspect sentiment score for stock prices. Finally, an added layer of interpretability is added by evaluating uncertainty coefficient scores between aspect sentiment scores and stock prices. This allows us to determine the …",https://ieeexplore.ieee.org/abstract/document/10411537/
Erik Cambria,Emotion recognition on edge devices: Training and deployment,2021,Sensors,12,"Vlad Pandelea, Edoardo Ragusa, Tommaso Apicella, Paolo Gastaldo, Erik Cambria",Vlad Pandelea,Erik Cambria,5,"Emotion recognition, among other natural language processing tasks, has greatly benefited from the use of large transformer models. Deploying these models on resource-constrained devices, however, is a major challenge due to their computational cost. In this paper, we show that the combination of large transformers, as high-quality feature extractors, and simple hardware-friendly classifiers based on linear separators can achieve competitive performance while allowing real-time inference and fast training. Various solutions including batch and Online Sequential Learning are analyzed. Additionally, our experiments show that latency and performance can be further improved via dimensionality reduction and pre-training, respectively. The resulting system is implemented on two types of edge device, namely an edge accelerator and two smartphones.",https://www.mdpi.com/1424-8220/21/13/4496
Erik Cambria,Learning with Similarity Functions: A Tensor-Based Framework,2019,Cognitive Computation,12,"Edoardo Ragusa, Paolo Gastaldo, Rodolfo Zunino, Erik Cambria",Edoardo Ragusa,Erik Cambria,4,"Machine learning algorithms are typically designed to deal with data represented as vectors. Several major applications, however, involve multi-way data, such as video sequences and multi-sensory arrays. In those cases, tensors endow a more consistent way to capture multi-modal relations, which may be lost by a conventional remapping of original data into a vector representation. This paper presents a tensor-oriented machine learning framework, and shows that the theory of learning with similarity functions provides an effective paradigm to support this framework. The proposed approach adopts a specific similarity function, which defines a measure of similarity between a pair of tensors. The performance of the tensor-based framework is evaluated on a set of complex, real-world, pattern-recognition problems. Experimental results confirm the effectiveness of the framework, which compares favorably …",https://link.springer.com/article/10.1007/s12559-018-9590-9
Erik Cambria,Singlish SenticNet: A Concept-Based Sentiment Resource for Singapore English,2018,Proceedings of IEEE SSCI,12,"Danyuan Ho, Diyana Hamzah, Soujanya Poria, Erik Cambria",Danyuan Ho,Erik Cambria,4,"Singlish (or Singapore Colloquial English) is markedly distinct from Standard English due to extensive influence from other languages in Singapore. There is thus a need to construct Singlish-specific resources and tools to improve the sentiment analysis performance of online texts in Singlish. This paper leverages sentic computing techniques to develop Singlish SenticNet, a concept-level resource for sentiment analysis that provides the semantics and sentics associated with 10,000 words and multi-word expressions in Singlish. It is semi-automatically constructed by applying graph-mining and multi-dimensional scaling techniques on the affective commonsense knowledge collected from different sources. The knowledge is represented redundantly at three levels (semantic network, matrix, and vector space), each useful for a certain reasoning. A preliminary evaluation revealed a higher accuracy for Singlish …",https://ieeexplore.ieee.org/abstract/document/8628796/
Erik Cambria,Text-Image Sentiment Analysis,2018,Proceedings of CICLing,12,"Qian Chen, Edoardo Ragusa, Iti Chaturvedi, Erik Cambria, Rodolfo Zunino",Qian Chen,Rodolfo Zunino,5,"Expressiveness varies from one person to another. Most images posted on Twitter lack good labels and the accompanying tweets have a lot of noise. Hence, in this paper we identify the contents and sentiments in images through the fusion of both image and text features. We leverage on the fact that AlexNet is a pre-trained model with great performance in image classification and the corresponding set of images are extracted from the web. In particular, we present a novel method to extract features from Twitter images and the corresponding labels or tweets using deep convolutional neural networks trained on Twitter data. We consider fine tuning AlexNet pre-trained CNNs to initialize the model and AffectiveSpace of English concepts as text features. Lastly, to combine the image and text predictions we propose a novel sentiment score. Our model is evaluated on Twitter dataset of images and corresponding labels …",https://link.springer.com/chapter/10.1007/978-3-031-23804-8_14
Erik Cambria,Concept-Level Sentiment Analysis with SenticNet,2017,,12,"Federica Bisio, Claudia Meda, Paolo Gastaldo, Rodolfo Zunino, Erik Cambria",Federica Bisio,Erik Cambria,5,"SenticNet is a publicly available resource for opinion mining that exploits AI, linguistics, and psychology to infer the polarity associated with commonsense concepts and encode this in a semantic-aware representation. In particular, SenticNet uses dimensionality reduction to calculate the affective valence of multi-word expressions and, hence, represent it in a machine-accessible and machine-processable format. This chapter presents an overview of the most recent sentic computing tools and techniques, with particular focus on applications in the context of big social data analysis.",https://link.springer.com/chapter/10.1007/978-3-319-55394-8_9
Erik Cambria,Emotion and sentiment in social and expressive media: Introduction to the special issue,2016,Information Processing & Management,12,"Paolo Rosso, Cristina Bosco, Rossana Damiano, Viviana Patti, Erik Cambria",Paolo Rosso,Erik Cambria,5,"Social and expressive media represent a challenge and a push forward for research on emotion and sentiment analysis. The advent of social media has brought about new paradigms of interaction that foster first-person engagement and crowdsourced contents: the subjective dimension moves to the foreground, opening the way to the emergence of an affective component within a dynamic corpus of digitized contents created and enriched by the users. Expressive media, which play a key role in fields related to creativity, such as figurative arts, music or drama, gather multimedia contents into online social environments, by joining the social dimension with the aims of artistic creation and self-expression. Artistic creation and performance seem to be a very interesting testbed for cross-validating and possibly integrating approaches, models and tools for automatically analyzing emotion and sentiment. In fact, in such …",https://www.sciencedirect.com/science/article/pii/S0306457315001260
Erik Cambria,AspNet: Aspect Extraction by Bootstrapping Generalization and Propagation Using an Aspect Network,2015,Cognitive Computation,12,"Yunqing Xia, Erik Cambria, Amir Hussain",Yunqing Xia,Amir Hussain,3,"Aspect-level opinion mining systems suffer from concept coverage problem due to the richness and ambiguity of natural language opinions. Aspects mentioned by review authors can be expressed in various forms, resulting in a potentially large number of missing or incomplete aspects. This work proposes a novel unsupervised method to extract aspects from raw reviews with a broader coverage. Previous research has shown that unsupervised methods based on dependency relations are promising for opinion target extraction (OTE). In this work, we introduce Aspect Network (AspNet), an AspNet that further improves existing OTE methods by providing a new framework for modeling aspects. AspNet represents the general indecomposable atom aspects and their dependency relations in a two-layered, directed, weighted graph, based on which the specific decomposable compound aspects in reviews can …",https://link.springer.com/article/10.1007/s12559-014-9305-9
Erik Cambria,The MuSe 2024 Multimodal Sentiment Analysis Challenge: Social Perception and Humor Recognition,2024,Proceedings of ACM Multimedia,11,"Shahin Amiriparian, Lukas Christ, Alexander Kathan, Maurice Gerczuk, Niklas Müller, Steffen Klug, Lukas Stappen, Andreas König, Erik Cambria, Björn Schuller, Simone Eulitz",Shahin Amiriparian,Simone Eulitz,11,"The Multimodal Sentiment Analysis Challenge (MuSe) 2024 addresses two contemporary multimodal affect and sentiment analysis problems: In the Social Perception Sub-Challenge (MuSe-Perception), participants will predict 16 different social attributes of individuals such as assertiveness, dominance, likability, and sincerity based on the provided audio-visual data. The Cross-Cultural Humor Detection Sub-Challenge (MuSe-Humor) dataset expands upon the Passau Spontaneous Football Coach Humor (Passau-SFCH) dataset, focusing on the detection of spontaneous humor in a cross-lingual and cross-cultural setting. The main objective of MuSe 2024 is to unite a broad audience from various research domains, including multimodal sentiment analysis, audio-visual affective computing, continuous signal processing, and natural language processing. By fostering collaboration and exchange among experts in these fields, the MuSe 2024 endeavors to advance the understanding and application of sentiment analysis and affective computing across multiple modalities. This baseline paper provides details on each sub-challenge and its corresponding dataset, extracted features from each data modality, and discusses challenge baselines. For our baseline system, we make use of a range of Transformers and expert-designed features and train Gated Recurrent Unit (GRU)-Recurrent Neural Network (RNN) models on them, resulting in a competitive baseline system. On the unseen test datasets of the respective sub-challenges, it achieves a mean Pearson's Correlation Coefficient () of 0.3573 for MuSe-Perception and an Area Under the Curve …",https://arxiv.org/abs/2406.07753
Erik Cambria,Emotion-and-Knowledge Grounded Response Generation in an Open-domain Dialogue Setting,2024,Knowledge-Based Systems,11,"Deeksha Varshney, Asif Ekbal, Erik Cambria",Deeksha Varshney,Erik Cambria,3,"The neural-based interactive dialogue system focuses on engaging and retaining humans in long-lasting conversations. This has been explored for a variety of goal-oriented dialogue domains, such as education, health care, entertainment, sports, and politics. To develop an understanding and awareness of social and cultural norms, and to address specific social skills, we need to invent strategies for building interactive systems that take into account the user’s emotions and relevant-facts in a multi-turn conversation. In this paper, we propose a new neural generative model that combines step-wise co-attention with a self-attention-based transformer network along with an emotion classifier to jointly control emotion and knowledge transfer during response generation. Quantitative, qualitative, and human evaluation results on the benchmark Topical Chat and the CMU_DoG dataset show that the proposed models …",https://www.sciencedirect.com/science/article/pii/S0950705123009231
Erik Cambria,Neurosymbolic AI for Mining Public Opinions about Wildfires,2024,Cognitive Computation,11,"Cuc Duong, Vethavikashini Chithrra Raghuram, Amos Lee, Rui Mao, Gianmarco Mengaldo, Erik Cambria",Cuc Duong,Erik Cambria,6,"Wildfires are among the most threatening hazards to life, property, well-being, and the environment. Studying public opinions about wildfires can help monitor the perception of the impacted communities. Nevertheless, wildfire research is relatively limited compared to other climate-related hazards. This article presents our data mining work on public opinions about wildfires in Australia from 2014 to 2021. Three key aspects are analyzed: the topic of concern, sentiment polarization, and perceived emotions. We propose a data filtering approach to acquire golden samples to train a supervised model for emotion quantification to achieve the last target. The results show that the new model produces a more accurate emotion estimation than the existing lexicon approach. Through data analysis, we find that people have seen wildfires as one of the impacts of climate change; trends of tweets can reflect the damage of …",https://link.springer.com/article/10.1007/s12559-023-10195-8
Erik Cambria,WME 3.0: An Enhanced and Validated Lexicon of Medical Concepts,2018,Proceedings of GWC,11,"Anupam Mondal, Dipankar Das, Erik Cambria, Sivaji Bandyopadhyay",Anupam Mondal,Sivaji Bandyopadhyay,4,"Information extraction in the medical domain is laborious and time-consuming due to the insufficient number of domain-specific lexicons and lack of involvement of domain experts such as doctors and medical practitioners. Thus, in the present work, we are motivated to design a new lexicon, WME 3.0 (WordNet of Medical Events), which contains over 10,000 medical concepts along with their part of speech, gloss (descriptive explanations), polarity score, sentiment, similar sentiment words, category, affinity score and gravity score features. In addition, the manual annotators help to validate the overall as well as individual category level of medical concepts of WME 3.0 using Cohen’s Kappa agreement metric. The agreement score indicates almost correct identification of medical concepts and their assigned features in WME 3.0.",https://aclanthology.org/2018.gwc-1.2/
Erik Cambria,MediConceptNet: An Affinity Score Based Medical Concept Network,2017,Proceedings of FLAIRS,11,"Anupam Mondal, Erik Cambria, Dipankar Das, Sivaji Bandyopadhyay",Anupam Mondal,Sivaji Bandyopadhyay,4,"In healthcare, information extraction is essential in building automatic domain-specific applications. Medical concepts and their semantic identification take an important role to develop a network for visualizing medical concepts and their relations. The challenge appears while available medical corpora are only in either unstructured or semi-structured forms. In the present paper, to overcome the challenge and consequently to construct a structured corpus, we apply a domain-specific lexicon, namely WordNet of Medical Event. Medical concepts assigned by this lexicon and their affinity score, polarity score, sense, and semantic features assist in identifying conceptual and sentiment relations from the corpus. The lexicon and all these features provide an essential support to analyze an unstructured corpus and represent it in a structured corpus which we term MediConceptNet: the medical concepts are connected with each other through the concerned features. A previously suggested network for the same purpose, eg, SemNet, is only based on the semantic and affinity features. The semantic relations of the concepts can be successfully determined in three distinct ranges, eg, 0 for no relation, 0-1 for partial relations, and 1 corresponding a full relation. To evaluate the data of MediConceptNet, we apply an agreement analysis provided by the Cohen’s kappa coefficient and achieve 0.66 agreement score, evaluating the comparative statistics of two medical practitioners working as manual annotators.",https://cdn.aaai.org/ocs/15474/15474-68673-1-PB.pdf
Erik Cambria,A Localization Toolkit for SenticNet,2014,Proceedings of ICDM Workshops,11,"Yunqing Xia, Xiaoyu Li, Erik Cambria, Amir Hussain",Yunqing Xia,Amir Hussain,4,"Sentic Net is a popular resource for concept-level sentiment analysis. Because Sentic Net was created specifically for opinion mining in English language, however, its localization can be very laborious. In this work, a toolkit for creating non-English versions of Sentic Net in a time- and cost-effective way is proposed. This is achieved by exploiting online facilities such as Web dictionaries and translation engines. The challenging issues are three: firstly, when a Web lexicon is used, one sentiment concept in English can usually be mapped to multiple concepts in the local language. In this work, we develop a concept disambiguation algorithm to discover context within texts in the target language. Secondly, the polarity of some concepts in the local language may be different from the counterpart in English, which is referred to as language-dependent sentiment concepts. An algorithm is developed to detect sentiment …",https://ieeexplore.ieee.org/abstract/document/7022624/
Erik Cambria,Understanding Public Perception Towards Weather Disasters Through the Lens of Metaphor,2024,Proceedings of IJCAI,10,"Rui Mao, Qika Lin, Qiawen Liu, Gianmarco Mengaldo, Erik Cambria",Rui Mao,Erik Cambria,5,"Extreme weather can lead to weather-induced disasters. These have a profound impact on communities worldwide, causing loss of life, damage to properties and infrastructure, and disruption of daily activities. In alignment with the United Nations Sustainable Development Goals, addressing the increasing frequency and severity of these events, exacerbated by climate change, is imperative. Exploring public perception and responses to weather disasters becomes crucial for policymakers to formulate effective strategies that not only mitigate the impacts but also contribute to the goal of ensuring sustainable and resilient communities. Social media, as a pervasive and real-time communication platform, has gathered a large amount of public opinion. In this work, we analyze public perception towards weather disasters based on tweets and metaphors. Metaphor, as a linguistic device, plays a pivotal role in unraveling cognitive processes and understanding how individuals perceive and make sense of concepts. We focus on tweets related to four distinct types of weather disasters ie, floods, hurricanes, tornadoes, and wildfires, aiming to extract nuanced insights regarding public perceptions, concerns, and attitudes towards these specific events. We also deliver constructive recommendations, based on the insights.",https://sentic.net/public-perception-towards-weather-disasters.pdf
Erik Cambria,Unveiling Diplomatic Narratives: Analyzing United Nations Security Council Debates Through Metaphorical Cognition,2024,Proceedings of CogSci,10,"Rui Mao, Tianwei Zhang, Qian Liu, Amir Hussain, Erik Cambria",Rui Mao,Erik Cambria,5,"The United Nations Security Council (UNSC) is entrusted with the responsibility of safeguarding global peace and security. Prominent global security concerns will be deliberated upon, and viewpoints will be presented within the UNSC. Analyzing the cognitive patterns from UNSC debates helps scholars gain insights into the intricacies of international relations and diplomatic discourse. In this study, our focus lies in the cognitive analysis of debates held within the UNSC. We employ metaphors and their associated concept mappings as a methodological tool to dissect the cognitive nuances present in the debates, spanning from January 1995 to December 2020. To undertake this extensive analysis from a large volume of documents, we leverage MetaPro, a state-of-the-art computational metaphor processing system to obtain the concept mappings of metaphors. We analyze cognitive variations by temporal and geographical variables. We also demonstrate the correlation between metaphor-reflected cognition and diplomatic behavior, and their recursive influence, based on large sample research. Our major finding highlights the mutual impacts of metaphorical cognition and voting behavior at the UN.",https://escholarship.org/uc/item/5360b3js
Erik Cambria,PrimeNet: A Framework for Commonsense Knowledge Representation and Reasoning Based on Conceptual Primitives,2024,Cognitive Computation,10,"Qian Liu, Sooji Han, Erik Cambria, Yang Li, Kenneth Kwok",Qian Liu,Kenneth Kwok,5,"Commonsense knowledge acquisition and representation is a core topic in artificial intelligence (AI), which is crucial for building more sophisticated and human-like AI systems. However, existing commonsense knowledge bases organize facts in an isolated manner like bag of facts, lacking the cognitive-level connections that humans commonly possess. People have the ability to efficiently organize vast amounts of knowledge by linking or generalizing concepts using a limited set of conceptual primitives that serve as the fundamental building blocks of reasoning. These conceptual primitives are basic, foundational elements of thought that humans use to make sense of the world. By combining and recombining these primitives, people can construct complex ideas, solve problems, and understand new concepts. To emulate this cognitive mechanism, we design a new commonsense knowledge base, termed …",https://link.springer.com/article/10.1007/s12559-024-10345-6
Erik Cambria,Language Models as Inductive Reasoners,2024,Proceedings of EACL,10,"Zonglin Yang, Li Dong, Xinya Du, Hao Cheng, Erik Cambria, Xiaodong Liu, Jianfeng Gao, Furu Wei",Zonglin Yang,Furu Wei,8,"Inductive reasoning is a core component of human intelligence. In the past research of inductive reasoning within computer science, logic language is used as representations of knowledge (facts and rules, more specifically). However, logic language can cause systematic problems for inductive reasoning such as disability of handling raw input such as natural language, sensitiveness to mislabeled data, and incapacity to handle ambiguous input. To this end, we propose a new task, which is to induce natural language rules from natural language facts, and create a dataset termed DEER containing 1.2k rule-fact pairs for the task, where rules and facts are written in natural language. New automatic metrics are also proposed and analysed for the evaluation of this task. With DEER, we investigate a modern approach for inductive reasoning where we use natural language as representation for knowledge instead of logic language and use pretrained language models as ''reasoners''. Moreover, we provide the first and comprehensive analysis of how well pretrained language models can induce natural language rules from natural language facts. We also propose a new framework drawing insights from philosophy literature for this task, which we show in the experiment section that surpasses baselines in both automatic and human evaluations.",https://arxiv.org/abs/2212.10923
Erik Cambria,Time Expression Recognition and Normalization: A Survey,2023,Artificial Intelligence Review,10,"Xiaoshi Zhong, Erik Cambria",Xiaoshi Zhong,Erik Cambria,2,"Time information plays an important role in the areas of data mining, information retrieval, and natural language processing. Among the linguistic tasks related to time expressions, time expression recognition and normalization (TERN) is fundamental for other downstream tasks. Researchers from these areas have devoted considerable effort in the last two decades to define the problem of time expression analysis, design the standards for time expression annotation, build annotated corpora for time expressions, and develop methods to identify time expressions from free text. While there are some surveys concerned with the development of time information extraction, retrieval, and reasoning, to the best of our knowledge, there is no survey focusing on the TERN development. We fill in this blank. In this survey, we review previous researches, aiming to draw an overview of the development of time expression …",https://link.springer.com/article/10.1007/s10462-023-10400-y
Erik Cambria,Soft Computing for Recommender Systems and Sentiment Analysis,2022,,10,"Lorenzo Malandri, Carlos Porcel, Frank Xing, Jesus Serrano-Guerrero, Erik Cambria",Lorenzo Malandri,Erik Cambria,5,"The World Wide Web is becoming a bottomless source of unstructured data, with quintillions of bytes of data generated daily and publicly accessible [1]. Social media, customer reviews, and online news articles, as well as the comments associated with them, are just some examples of what the Internet is producing in terms of text data. Text data is usually not standalone like digitalized books, but associated with a lot of information about user behaviors and preferences. This has led to a growing interest in the research of social media analysis and many applications, including sentiment analysis and recommender systems. Closely related to the two mentioned are other tasks, such as opinion retrieval, opinion summarization, subjectivity classification, sarcasm/irony detection and more.We only see a strengthening trend of the online presence of text data bounded with our daily activities as we migrate to the …",https://www.sciencedirect.com/science/article/pii/S1568494621010735
Erik Cambria,JCBIE: A Joint Continual Learning Neural Network for Biomedical Information Extraction,2022,BMC Bioinformatics,10,"Kai He, Rui Mao, Tieliang Gong, Erik Cambria, Chen Li",Kai He,Chen Li,5,"Extracting knowledge from heterogeneous data sources is fundamental for the construction of structured biomedical knowledge graphs (BKGs), where entities and relations are represented as nodes and edges in the graphs, respectively. Previous biomedical knowledge extraction methods simply considered limited entity types and relations by using a task-specific training set, which is insufficient for large-scale BKGs development and downstream task applications in different scenarios. To alleviate this issue, we propose a joint continual learning biomedical information extraction (JCBIE) network to extract entities and relations from different biomedical information datasets. By empirically studying different joint learning and continual learning strategies, the proposed JCBIE can learn and expand different types of entities and relations from different datasets. JCBIE uses two separated encoders in joint-feature …",https://link.springer.com/article/10.1186/s12859-022-05096-w
Erik Cambria,Guest Editorial: Knowledge Graph Representation and Reasoning,2021,Neurocomputing,10,"Erik Cambria, Shaoxiong Ji, Shirui Pan, S Yu Philip",Erik Cambria,S Yu Philip,4,"Recent years have witnessed the release of many open-source and enterprise-driven knowledge graphs with a dramatic increase of applications of knowledge representation and reasoning in fields such as natural language processing, computer vision, and bioinformatics. With those large-scale knowledge graphs, recent research tends to incorporate human knowledge and imitate human’s ability of relational reasoning [1]. Factual knowledge stored in knowledge bases or knowledge graphs can be utilized as a source for logical reasoning and, hence, be integrated to improve real-world applications [2],[3],[4],[5],[6].Emerging embedding-based methods for knowledge graph representation have shown their ability to capture relational facts and model different scenarios with heterogenous information [7]. By combining symbolic reasoning methods or Bayesian models, deep representation learning techniques on …",https://www.sciencedirect.com/science/article/pii/S092523122100953X
Erik Cambria,Social Media Marketing and Financial Forecasting,2020,Information Processing & Management,10,"Frank Xing, Soujanya Poria, Erik Cambria, Roy Welsch",Frank Xing,Roy Welsch,4,"The last decade has witnessed a huge development in social media interactions. Today, social media is becoming ubiquitous in two senses:(1) it crosses boundaries and expands to more nations, and (2) it deeply intervenes in our personal life and economic activities. This outburst of social media data has led to an extensive amount of research for analyzing and extracting useful knowledge and workable patterns from social media data (Hussain & Cambria, 2018). Among those, however, the academic interest in social media marketing and financial forecasting has only increased in recent years (Xing, Cambria, & Welsch, 2018b). For example, only one special issue (Hajli & Laroche, 2019) and two workshops (Chen, Huang, Takamura, Chen, Hahn, Hoste, & Tsai (2018).) have been organized on these two topics, respectively.Social media marketing aims to communicate with potential customers to build brand …",https://www.sciencedirect.com/science/article/pii/S0306457320308098
Erik Cambria,Developing a Concept-Level Knowledge Base for Sentiment Analysis in Singlish,2016,Proceedings of CICLing,10,"Rajiv Bajpai, Soujanya Poria, Danyun Ho, Erik Cambria",Rajiv Bajpai,Erik Cambria,4,"In this paper, we present Singlish SenticNet, a concept-level knowledge base for sentiment analysis that associates multiword expressions to a set of emotion labels and a polarity value. Unlike many other sentiment analysis resources, SenticNet is not built by manually labeling pieces of knowledge coming from general NLP resources such as WordNet or DBPedia. Instead, it is automatically constructed by applying graph-mining and multi-dimensional scaling techniques on the affective common-sense knowledge collected from three different sources. This knowledge is represented redundantly at three levels: semantic network, matrix, and vector space. Subsequently, the concepts are labeled by emotions and polarity through the ensemble application of spreading activation, neural networks and an emotion categorization model.",https://link.springer.com/chapter/10.1007/978-3-319-75487-1_27
Erik Cambria,FinSenticNet: A Concept-Level Lexicon for Financial Sentiment Analysis,2023,Proceedings of IEEE SSCI,9,"Kelvin Du, Frank Xing, Rui Mao, Erik Cambria",Kelvin Du,Erik Cambria,4,"Sentiment lexicons are important tools for research involving opinion mining and sentiment analysis. They are highly inter-operable, and address critical limitations of learning-based or large language model-based sentiment analysis, providing better reproducibility and explainability. Existing financial sentiment lexicons, manually crafted or automatically constructed, primarily comprise single-word entries despite the fact that jargon, terminologies, and collocations in finance are often multi-word expressions. To address this gap, we present FinSenticNet, a concept-level domain-specific lexicon specifically designed for financial sentiment analysis, where over 65% entries are multi-word expressions. Our construction approach is semi-supervised: the framework consists of a concept parser, a sentiment seeds generation module, and a semantic graph construction module. Each concept (graph node) is subsequently …",https://ieeexplore.ieee.org/abstract/document/10371970/
Erik Cambria,Finding the Pillars of Strength for Multi-Head Attention,2023,Proceedings of ACL,9,"Jinjie Ni, Rui Mao, Zonglin Yang, Han Lei, Erik Cambria",Jinjie Ni,Erik Cambria,5,"Recent studies have revealed some issues of Multi-Head Attention (MHA), e.g., redundancy and over-parameterization. Specifically, the heads of MHA were originally designed to attend to information from different representation subspaces, whereas prior studies found that some attention heads likely learn similar features and can be pruned without harming performance. Inspired by the minimum-redundancy feature selection, we assume that focusing on the most representative and distinctive features with minimum resources can mitigate the above issues and lead to more effective and efficient MHAs. In particular, we propose Grouped Head Attention, trained with a self-supervised group constraint that group attention heads, where each group focuses on an essential but distinctive feature subset. We additionally propose a Voting-to-Stay procedure to remove redundant heads, thus achieving a transformer with lighter weights. Moreover, our method achieves significant performance gains on three well-established tasks while considerably compressing parameters.",https://arxiv.org/abs/2305.14380
Erik Cambria,Teaching Simulations Supported by Artificial Intelligence in the Real World,2023,Education Sciences,9,"Iti Chaturvedi, Roy Welsch, Erik Cambria",Iti Chaturvedi,Erik Cambria,3,"Video conferencing has enabled synchronous communication in a classroom and created multi-sensory content to stimulate learners. Artificial intelligence involves complex equations that are better taught using a constructive pedagogy where students experiment with alternative ways of solving the same problem. Multiple-choice questions have high reliability and can easily reveal student skill levels in a quick way. The Australian Computer Society accreditation exercise ensures that the content for each subject serves as a flexible template for teaching. The geographical extent of the country requires the presence of multiple subordinate campuses affiliated to a main campus. Following the concept of strands, it was also necessary to show continuity in learning and assessments between the first- and second-year subjects. Student feedback for subjects with artificial intelligence-based simulations showed that several students found it difficult to understand lectures and assignments. Hence, to measure student learning, we introduced a Kahoot quiz during the recess of each lecture that students could join through their mobile phones from different campuses. Software project management is challenging for students with vision or attention-related disorders. We taught them how to use charts to visually observe variables and narrow down possible relationships before performing in-depth analysis. One of the main purposes of education is employability. Hence, greater context to real world industry examples was introduced into lectures.",https://www.mdpi.com/2227-7102/13/2/187
Erik Cambria,Mood of the Planet: Challenging Visions of Big Data in the Arts,2022,Cognitive Computation,9,"Vibeke Sorensen, John Stephen Lansing, Nagaraju Thummanapalli, Erik Cambria",Vibeke Sorensen,Erik Cambria,4,"Mood of the Planet is an interactive physical-digital sculpture that has as its center-piece a large “arch” or “doorway” that emits colored light and sound as a form of visualization and sonification of the changing, live emotions expressed by people all around the Earth. It is the product of several disciplines, including the arts, computer science, linguistics and psychology. In particular, we use artificial intelligence to collect and analyze social media data and extract emotions from these using a brain-inspired and psychologically motivated emotion categorization model. Such emotions are then translated into colors and sounds that the audience can experience while passing through the arch. Feedback from the audience proved the Mood of the Planet to provide a more accurate, personal and tangible experience about the data-emotions dichotomy.",https://link.springer.com/article/10.1007/s12559-020-09766-w
Erik Cambria,Time Expression and Named Entity Recognition,2021,,9,"Xiaoshi Zhong, Erik Cambria",Xiaoshi Zhong,Erik Cambria,2,"This exciting series publishes state-of-the-art research on socially intelligent, affective, and multimodal human-machine interaction and systems. It emphasizes the role of affect in social interactions and the humanistic side of affective computing by promoting publications at the crossroads between computer science, engineering and the human sciences (including biological, social, and cultural aspects of human life).Three broad domains of social and affective computing will be covered by the book series: social computing; affective computing; and the interplay of these domains (for example, augmenting social interaction through affective computing). Examples of the first domain include all types of social interactions that contribute to meaning, interest, and richness in our daily life, eg, information produced by a group of people used to provide or enhance the functioning of a system. Examples of the second domain …",https://link.springer.com/content/pdf/10.1007/978-3-030-78961-9.pdf
Erik Cambria,Sentic computing for social network analysis,2017,,9,"F Bisio, L Oneto, E Cambria",F Bisio,E Cambria,3,"Sentiment analysis and opinion mining have been acquiring a crucial role in both commercial and research applications because of their possible applicability to several different fields. Therefore a large number of companies have included the analysis of opinions and sentiments of customers as part of their mission. One of the most interesting applications of these approaches involves the automatic analysis of social network messages, on the basis of the feelings and emotions conveyed. This chapter aims to relate the most recent state-of-the-art sentiment-based techniques and tools to the affective characterization that may be inferred from social networks. The main result consists of a review of the most interesting methods employed to compare and classify messages on social media platforms and a description of advanced tools in this area.",https://www.sciencedirect.com/science/article/pii/B978012804412400005X
Erik Cambria,Beyond Text Based Sentiment Analysis: Towards Multi-Modal Systems,2013,"University of Stirling, Stirling FK9 4LA, UK, Tech. Rep",9,"Soujanya Poria, Amir Hussain, Erik Cambria",Soujanya Poria,Erik Cambria,3,"A huge number of videos are posted each day on social media platforms such as YouTube, Facebook etc. It makes the Internet an almost unlimited source of information. In the coming decades it will become increasingly challenging for researchers to cope with this information and mine useful knowledge from it. In this paper, we address the problem of multimodal sentiment analysis ie harvesting sentiment from Web videos by demonstrating a novel model which uses audio, visual and textual modalities as sources of information. Here, we first extract information from three modalities and then fuse these at both feature and decision level. We employ a kernel based fusion method to fuse the information extracted from multiple modalities. A thorough comparison with existing state-of-the-art works in this area is carried out. In preliminary experiments using the YouTube dataset, our proposed multimodal system is shown to achieve an accuracy of 78.20%, outperforming the best state-of-the-art systems by more than 22.90%.",https://scholar.google.com/scholar?cluster=989819881690361063&hl=en&oi=scholarr
Erik Cambria,Clustering Social Networks Using Interaction Semantics and Sentics,2012,,9,"Praphul Chandra, Erik Cambria, Amir Hussain",Praphul Chandra,Amir Hussain,3,"The passage from a static read-only Web to a dynamic read-write Web gave birth to a huge amount of online social networks with the ultimate goal of making communication easier between people with common interests. Unlike real world social networks, however, online social groups tend to form for extremely varied and multi-faceted reasons. This makes very difficult to group members of the same social network in subsets in a way that certain types of contents are shared with just certain types of friends. Moreover, such a task is usually too tedious to be performed manually and too complex to be performed automatically. In this work, we propose a new approach for automatically clustering social networks, which exploits interaction semantics and sentics, that is, the conceptual and affective information associated with the interactive behavior of online social network members.",https://link.springer.com/chapter/10.1007/978-3-642-31346-2_43
Erik Cambria,Enriching Social Communication through Semantics and Sentics,2011,Proceedings of IJCNLP Workshops,9,"Praphul Chandra, Erik Cambria, Alvin Pradeep",Praphul Chandra,Alvin Pradeep,3,"Online communication is one of the key value propositions of mobile devices. While a variety of instant messaging clients offer users the ability to communicate with other users in real-time, the user experience remains dominated by a basic exchange of textual content. When compared to face-to-face communication, this experience is significantly poorer. In our proposed solution, we seek to enhance the chat experience by using an intelligent adaptive user interface that exploits semantics and sentics, that is the cognitive and affective information, associated with the ongoing communication. In particular, our approach leverages sentiment analysis techniques to process communication content and context and, hence, enable the interface to be adaptive in order to offer users a richer and more immersive chat experience.",https://aclanthology.org/W11-3710.pdf
Erik Cambria,Semantic Models for Style-Based Text Clustering,2011,Proceedings of ICSC,9,"Alessio Leoncini, Fabio Sangiacomo, Chiara Peretti, Sonia Argentesi, Rodolfo Zunino, Erik Cambria",Alessio Leoncini,Erik Cambria,6,"The paper addresses some roles of concept-based representations in document clustering to support knowledge discovery. Computational Intelligence algorithms can benefit from semantic networks in the definition of similarity between pairs of documents. After analyzing the tuning of semantic networks in a systematic fashion, the research defines and evaluates a novel semantic-based metrics, which integrates both classical and style-related features of texts. Experimental results confirm the effectiveness of the approach, showing that applying a refined semantic representation into a clustering engine yields consistent structures for information retrieval and knowledge acquisition.",https://ieeexplore.ieee.org/abstract/document/6061439/
Erik Cambria,Logical Reasoning over Natural Language as Knowledge Representation: A Survey,2025,arXiv preprint arXiv:2303.12023,8,"Zonglin Yang, Xinya Du, Rui Mao, Jinjie Ni, Erik Cambria",Zonglin Yang,Erik Cambria,5,"Logical reasoning is central to human cognition and intelligence. It includes deductive, inductive, and abductive reasoning. Past research of logical reasoning within AI uses formal language as knowledge representation and symbolic reasoners. However, reasoning with formal language has proved challenging (e.g., brittleness and knowledge-acquisition bottleneck). This paper provides a comprehensive overview on a new paradigm of logical reasoning, which uses natural language as knowledge representation and pretrained language models as reasoners, including philosophical definition and categorization of logical reasoning, advantages of the new paradigm, benchmarks and methods, challenges of the new paradigm, possible future directions, and relation to related NLP fields. This new paradigm is promising since it not only alleviates many challenges of formal representation but also has advantages over end-to-end neural methods. This survey focus on transformer-based LLMs explicitly working on deductive, inductive, and abductive reasoning over English representation.",https://arxiv.org/abs/2303.12023
Erik Cambria,An Evaluation of Reasoning Capabilities of Large Language Models in Financial Sentiment Analysis,2024,Proceedings of IEEE CAI,8,"Kelvin Du, Frank Xing, Rui Mao, Erik Cambria",Kelvin Du,Erik Cambria,4,"Large Language Models (LLMs) have garnered significant attention within the academic community due to their advanced capabilities in natural language understanding and generation. While empirical studies have shed light on LLMs’ proficiency in complex task reasoning, a lingering question persists in the field of Financial Sentiment Analysis (FSA): the extent to which LLMs can effectively reason about various financial attributes for FSA. This study employs a prompting framework to investigate this topic, assessing multiple financial attribute reasoning capabilities of LLMs in the context of FSA. By studying relevant literature, we first identified six key financial attributes related to semantic, numerical, temporal, comparative, causal, and risk factors. Our experimental results uncover a deficiency in the financial attribute reasoning capabilities of LLMs for FSA. For example, the examined LLMs such as PaLM-2 and GPT-3.5 display weaknesses in reasoning numerical and comparative attributes within financial texts. On the other hand, explicit prompts related to other financial attributes showcase varied utilities, contributing to LLMs’ proficiency in discerning financial sentiment.",https://sentic.net/llm-reasoning-capabilities-in-financial-sentiment-analysis.pdf
Erik Cambria,TbExplain: A Text-Based Explanation Method for Scene Classification Models with the Statistical Prediction Correction,2024,Proceedings of GUIDE-AI,8,"Amirhossein Aminimehr, Pouya Khani, Amirali Molaei, Amirmohammad Kazemeini, Erik Cambria",Amirhossein Aminimehr,Erik Cambria,5," Heatmaps are common tools in Explainable Artificial Intelligence (XAI) field, but they are not without imperfections; E.g., non-expert users may not grasp the underlying rationale of heatmaps, wherein pixels relevant to the model’s prediction are highlighted through distinct intensities or colors. Moreover, objects and regions of the input image that are relevant to the model prediction are frequently not entirely differentiated by heatmaps. In this paper, we propose a framework called TbExplain that employs XAI techniques and a pre-trained object detector to present text-based explanations of scene classification models. Moreover, TbExplain incorporates a novel method to correct predictions and textually explain them based on the statistics of objects in the input image when the initial prediction is unreliable. To assess the trustworthiness and validity of the text-based explanations, we conducted a qualitative …",https://dl.acm.org/doi/abs/10.1145/3665601.3669841
Erik Cambria,Guest Editorial: Sentiment Analysis as a Multidisciplinary Research Area,2022,IEEE Transactions on Artificial Intelligence,8,"Erik Cambria, Frank Xing, Mike Thelwall, Roy Welsch",Erik Cambria,Roy Welsch,4,"The papers in this special section focus on bringing multidisciplinary knowledge into sentiment analysis. The last two decades have witnessed an enormous amount of research works on sentiment analysis and significant progress has been made. In terms of depth, finer-grained semantic schemas are defined, such as aspect, target, and category. In terms of broadness, multimodal sentiment analysis touches audio and video channels. Conversational sentiment analysis considers contextual and time-dependent relations and domain-specific sentiment analysis settings tackles real-life challenges, including but not limited to user profiling, financial prediction, abusive language detection, and mental health.",https://ieeexplore.ieee.org/abstract/document/9924247/
Erik Cambria,Speaker-Independent Multimodal Sentiment Analysis for Big Data,2019,,8,"Erik Cambria, Soujanya Poria, Amir Hussain",Erik Cambria,Amir Hussain,3,"In this chapter, we propose a contextual multimodal sentiment analysis framework which outperforms the state of the art. This framework has been evaluated against speaker-dependent and speaker-independent problems. We also address the generalizability issue of the proposed method. This chapter also contains a discussion for an important component to be considered for a multimodal information processing system, which is the type of information fusion technique to be applied to combine the multimodal data.",https://link.springer.com/chapter/10.1007/978-3-319-97598-6_2
Erik Cambria,Semantically Enhanced Models for Commonsense Knowledge Acquisition,2018,Proceedings of ICDM Workshops,8,"Ikhlas Alhussien, Erik Cambria, Zhang NengSheng",Ikhlas Alhussien,Zhang NengSheng,3,"Commonsense knowledge is paramount to enable intelligent systems. Typically, it is characterized as being implicit and ambiguous, hindering thereby the automation of its acquisition. To address these challenges, this paper presents semantically enhanced models to enable reasoning through resolving part of commonsense ambiguity. The proposed models enhance in a knowledge graph embedding framework for knowledge base completion. Experimental results show the effectiveness of the new semantic models in commonsense reasoning.",https://ieeexplore.ieee.org/abstract/document/8637489/
Erik Cambria,Affective Reasoning for Big Social Data Analysis,2017,IEEE Transactions on Affective Computing,8,"Erik Cambria, Amir Hussain, Alessandro Vinciarelli",Erik Cambria,Alessandro Vinciarelli,3,"This special section focuses on the introduction, presentation, and discussion of novel techniques that further develop and apply affective reasoning tools and techniques for big social data analysis. A key motivation for this special section, in particular, is to explore the adoption of novel affective reasoning frameworks and cognitive learning systems to go beyond a mere word-level analysis of natural language text and provide novel concept-level tools and techniques that allow a more efficient passage from (unstructured) natural language to (structured) machine-processable affective data, in potentially any domain. The selected papers aim to address the wide spectrum of issues related to affective computing research and, hence, better grasp the current limitations and opportunities related to this fast-evolving branch of artificial intelligence. Out of the 29 submissions received, 5 were accepted to appear in the …",https://ieeexplore.ieee.org/abstract/document/8120260/
Erik Cambria,Let’s Chat about Brexit! A Politically-Sensitive Dialog System Based on Twitter Data,2017,Proceedings of ICDM Workshops,8,"Aparup Khatua, Erik Cambria, Apalak Khatua, Iti Chaturvedi",Aparup Khatua,Iti Chaturvedi,4,"Data scientists are exploring various semi-supervised learning methods to build conversational agents - commonly known as chatterbot. This paper investigates various issues related to a political chatterbot where human agents are politically opinionated. Here, understanding the latent intent of human agent is crucial for developing an efficient political chatterbot. We set our study in the context of 2016 Brexit referendum. We argue that employing a subjectivity detector and an emotion analyzer, in addition to the keyword based topic detector, enhances the intent detection process. Next, we discuss the importance of maintaining political neutrality. To maintain its neutrality, a chatterbot needs to disassociate itself from a politically opinionated response. This can be achieved by associating a response with a user or a set of users. Nowadays, the Twitter platform provides an enormous amount of user-generated contents …",https://ieeexplore.ieee.org/abstract/document/8215689/
Erik Cambria,Semantic Outlier Detection for Affective Common-Sense Reasoning and Concept-Level Sentiment Analysis,2015,Proceedings of FLAIRS,8,"Erik Cambria, Giuseppe Melfi",Erik Cambria,Giuseppe Melfi,2,"Between the dawn of the Internet through year 2003, there were just a few dozens exabytes of information on the Web. Today, that much information is created weekly. The opportunity to capture the opinions of the general public about social events, political movements, company strategies, marketing campaigns, and product preferences has raised increasing interest both in the scientific community, for the exciting open challenges, and in the business world, for the remarkable fallouts in social media marketing and financial forecast. Keeping up with the ever-growing amount of unstructured information on the Web, however, is a formidable task. Unlike standard statistical approaches, sentic computing relies on a vector space model of affective common-sense knowledge to work with natural language at conceptlevel. The well-known noisiness of common-sense data sources, however, is a major factor in jeopardizing the efficiency of analogical reasoning in the vector space. In this work, it is explored how least absolute deviations can aid semantic outlier detection and, hence, enhance concept-level opinion mining.",https://cdn.aaai.org/ocs/10422/10422-46115-1-PB.pdf
Erik Cambria,Muscle Synergies for Reliable Classification of Arm Motions using Myoelectric Interface,2014,Proceedings of EMBC,8,"Chris Wilson Antuvan, Federica Bisio, Erik Cambria, Lorenzo Masia",Chris Wilson Antuvan,Lorenzo Masia,4,"Synergistic activation of muscles are considered to be the phenomenon by which the central nervous system simplifies its control strategy. Muscle synergies are neurally encoded and considered robust to be able to adapt for various external dynamics. This paper presents a myoelectric-based interface to identify and classify motions of the upper arm involving the shoulder and elbow. We contrast performance of the decoder while using time domain and synergy features. The decoder is trained using extreme learning machine algorithm, and online testing is performed in a virtual environment. Better classification accuracy for online control is obtained while using muscle synergy features. The results indicate better online performance compared to offline performance while using synergy features to classify movements, indicating generalization to dynamic situations and robustness of control.",https://ieeexplore.ieee.org/abstract/document/7318566/
Erik Cambria,Computational Intelligence for Natural Language Processing,2014,IEEE Computational Intelligence Magazine,8,"Erik Cambria, Bebo White, T Durrani, Newton Howard",Erik Cambria,Newton Howard,4,"[1] G. Stegmayer, M. Gerard, and DH Milone,“Data mining over biological datasets: An integrated approach based on computational intelligence,” IEEE Comput. Intell. Mag., vol. 7, no. 4, pp. 22–34, Nov. 2012.[2] OG Martinsen, S. Clausen, JB Nysaether, and S. Grimnes,“Utilizing characteristic electrical properties of the epidermal skin layers to detect fake fingers in biometric fingerprint systems—A pilot study,” IEEE Trans. Biomed. Eng., vol. 54, no. 5, pp. 891–894, May 2007.[3] F. Scotti and V. Piuri,“Adaptive reflection detection and location in iris biometric images by using computational intelligence techniques,” IEEE Trans. Instrum.Meas., vol. 59, no. 7, pp. 1825–1833, July 2010.[4] Q. Tao and R. Veldhuis,“Biometric authentication system on mobile personal device,” IEEE Trans. Instrum. Meas., vol. 59, no. 4, pp. 763–773, Apr. 2010.[5] MG Tsipouras, DI Fotiadis, and D. Sideris,“Arrhythmia classification using the RR-interval duration signal,” Comput. Cardiol., vol. 29, pp. 485–488, Sept. 2002.[6] P. de Chazal, BG Celler, and RB Reilly,“Using wavelet coefficients for classification of the electrocardio-",https://www.researchgate.net/profile/Newton-Howard/publication/260711511_Computational_Intelligence_for_Natural_Language_Processing_Guest_Editorial/links/5491f1ff0cf2ac83c53dbc5d/Computational-Intelligence-for-Natural-Language-Processing-Guest-Editorial.pdf
Erik Cambria,EmpathyEar: An Open-source Avatar Multimodal Empathetic Chatbot,2024,Proceedings of ACL,7,"Hao Fei, Han Zhang, Bin Wang, Lizi Liao, Qian Liu, Erik Cambria",Hao Fei,Erik Cambria,6,"This paper introduces EmpathyEar, a pioneering open-source, avatar-based multimodal empathetic chatbot, to fill the gap in traditional text-only empathetic response generation (ERG) systems. Leveraging the advancements of a large language model, combined with multimodal encoders and generators, EmpathyEar supports user inputs in any combination of text, sound, and vision, and produces multimodal empathetic responses, offering users, not just textual responses but also digital avatars with talking faces and synchronized speeches. A series of emotion-aware instruction-tuning is performed for comprehensive emotional understanding and generation capabilities. In this way, EmpathyEar provides users with responses that achieve a deeper emotional resonance, closely emulating human-like empathy. The system paves the way for the next emotional intelligence, for which we open-source the code for public access.",https://arxiv.org/abs/2406.15177
Erik Cambria,Disentangled Retrieval and Reasoning for Implicit Question Answering,2024,IEEE Transactions on Neural Networks and Learning Systems,7,"Qian Liu, Xiubo Geng, Yu Wang, Erik Cambria, Daxin Jiang",Qian Liu,Daxin Jiang,5,"To date, most of the existing open-domain question answering (QA) methods focus on explicit questions where the reasoning steps are mentioned explicitly in the question. In this article, we study implicit QA where the reasoning steps are not evident in the question. Implicit QA is challenging in two aspects. First, evidence retrieval is difficult since there is little overlap between a question and its required evidence. Second, answer inference is difficult since the reasoning strategy is latent in the question. To tackle implicit QA, we propose a systematic solution denoted as DisentangledQA, which disentangles topic, attribute, and reasoning strategy from the implicit question to guide the retrieval and reasoning. Specifically, we disentangle the topic and attribute information from the implicit question to guide evidence retrieval. For answer reasoning, we propose a disentangled reasoning model for answer prediction based …",https://ieeexplore.ieee.org/abstract/document/9951599/
Erik Cambria,Soft Labeling Constraint for Generalizing from Sentiments in Single Domain,2022,Knowledge-Based Systems,7,"Abhinaba Roy, Erik Cambria",Abhinaba Roy,Erik Cambria,2,"In this work, we deal with domain generalization in sentiment analysis. In traditional domain generalization systems, multiple source domains are used to generalize to a single target domain. However, we tackle the scenario where examples of sentiments from only one domain are available. Recent works have proposed to generate target domain examples from a single source domain by means of an adversarial training, ensuring that generated examples performs well on classifier trained on source domain. However, the inherent assumption is that domain shift is only due to covariate shift. In our work, we argue that, in realistic scenarios such as sentiment analysis, there is significant change in label distribution across domains as well. Subsequently, we propose a soft labeling formulation that provides better generalization and more robust classifiers across unseen sentiment domains. Experimental results on the …",https://www.sciencedirect.com/science/article/pii/S0950705122001277
Erik Cambria,Toward Hardware-Aware Deep-Learning-Based Dialogue Systems,2022,Neural Computing and Applications,7,"Vlad Pandelea, Edoardo Ragusa, Tom Young, Paolo Gastaldo, Erik Cambria",Vlad Pandelea,Erik Cambria,5,"In the past few years, the use of transformer-based models has experienced increasing popularity as new state-of-the-art performance was achieved in several natural language processing tasks. As these models are often extremely large, however, their use for applications within embedded devices may not be feasible. In this work, we look at one such specific application, retrieval-based dialogue systems, that poses additional difficulties when deployed in environments characterized by limited resources. Research on building dialogue systems able to engage in natural sounding conversation with humans has attracted increasing attention in recent years. This has led to the rise of commercial conversational agents, such as Google Home, Alexa and Siri situated on embedded devices, that enable users to interface with a wide range of underlying functionalities in a natural and seamless manner. In part due …",https://link.springer.com/article/10.1007/s00521-020-05530-1
Erik Cambria,Predicting Future Market Trends: Which Is the Optimal Window?,2019,Proceedings of INNS,7,"Simone Merello, Andrea Picasso, Luca Oneto, Erik Cambria",Simone Merello,Erik Cambria,4,"The problem of predicting future market trends has been attracting the interest of researches, mathematicians, and financial analysts for more then fifty years. Many different approaches have been proposed to solve the task. However only few of them have focused on the selection of the optimal trend window to be forecasted and most of the research focuses on the daily prediction without a proper explanation. In this work, we exploit finance-related numerical and textual data to predict different trend windows through several learning algorithms. We demonstrate the non optimality of the daily trend prediction with the aim to establish a new guideline for future research.",https://link.springer.com/chapter/10.1007/978-3-030-16841-4_19
Erik Cambria,Auto-Categorization of Medical Concepts and Contexts,2017,Proceedings of IEEE SSCI,7,"Anupam Mondal, Erik Cambria, Antonio Feraco, Dipankar Das, Sivaji Bandyopadhyay",Anupam Mondal,Sivaji Bandyopadhyay,5,"In healthcare, information extraction is important in order to identify conceptual knowledge as a category of medical concepts from a large number of unstructured and semi-structured corpora. Category describes how medical concepts are fundamentally separated from each other to represent their conceptual knowledge in the corpus. In this paper, we focus on identifying the category of medical concepts and contexts which describe the subjective and the conceptual information of the medical corpus. To recognize the medical concept and assign their category, we employ our previously developed WordNet of Medical Event (WME 2.0) domain-specific lexicon. The lexicon provides medical concepts and their affinity, gravity, polarity scores, similar sentiment words, and sentiment features, help to develop the category assignment system. The identified categories for the concepts are diseases, drugs, symptoms …",https://ieeexplore.ieee.org/abstract/document/8285253/
Erik Cambria,Employing Sentiment-Based Affinity and Gravity Scores to Identify Relations of Medical Concepts,2017,Proceedings of IEEE SSCI,7,"Anupam Mondal, Erik Cambria, Dipankar Das, Sivaji Bandyopadhyay",Anupam Mondal,Sivaji Bandyopadhyay,4,"Sentiment based relations are considered as important clues in order to identify the hidden links between medical concepts as well as to link various concepts with their source of glosses represented as descriptive explanations. Affinity score describes what extend two concepts are linked with each other by measuring the number of common sentiment words whereas gravity score identifies the sentimentoriented relevance between medical concepts and their various glosses. To uncover salient connections between the concepts, we employ the existing WordNet of Medical Events (WME 2.0) lexicon and enrich it with the affinity and gravity scores. We have employed the supervised classifiers, Naïve Bayes and Sequential Minimal Optimization as well as unsupervised K-Means classifier to evaluate the identified sentiments of medical concepts present in WME 2.0 lexicon. The comparative results provide Cohen's …",https://ieeexplore.ieee.org/abstract/document/8285275/
Erik Cambria,Open Secrets and Wrong Rights: Automatic Satire Detection in English Text,2017,Proceedings of CSCW,7,"Aishwarya Reganti, Tushar Maheshwari, Amitava Das, Erik Cambria",Aishwarya Reganti,Erik Cambria,4,"Satire is an element of figurative language which often conveys feelings contrary to what is literally stated. It refers to a trenchant wit, irony, or sarcasm used to expose discredit vice or folly. The presence of a satirical utterance in text can entirely change the sentiment of the statement, hence it is necessary to distinguish between true positive statements and satirical ones.In this paper, we identify key value components and features for automatic satire detection. Our experiments have been carried out on three data sets, namely, tweets, product reviews and newswire articles. We examine the impact of a number of state of the art features as well as new generalised textual features.",https://dl.acm.org/doi/abs/10.1145/3022198.3026344
Erik Cambria,Storages Are Not Forever,2017,Cognitive Computation,7,"Erik Cambria, Anupam Chattopadhyay, Eike Linn, Bappaditya Mandal, Bebo White",Erik Cambria,Bebo White,5,"Not unlike the concern over diminishing fossil fuel, information technology is bringing its own share of future worries. We chose to look closely into one concern in this paper, namely the limited amount of data storage. By a simple extrapolatory analysis, it is shown that we are on the way to exhaust our storage capacity in less than two centuries with current technology and no recycling. This can be taken as a note of caution to expand research initiative in several directions: firstly, bringing forth innovative data analysis techniques to represent, learn, and aggregate useful knowledge while filtering out noise from data; secondly, tap onto the interplay between storage and computing to minimize storage allocation; thirdly, explore ingenious solutions to expand storage capacity. Throughout this paper, we delve deeper into the state-of-the-art research and also put forth novel propositions in all of the …",https://link.springer.com/article/10.1007/s12559-017-9482-4
Erik Cambria,"Semantic Web Evaluation Challenge: SemWebEval 2014 at ESWC 2014, Anissaras, Crete, Greece, May 25-29, 2014, Revised Selected Papers",2014,,7,"Valentina Presutti, Milan Stankovic, Erik Cambria, Iván Cantador, Angelo Di Iorio, Tommaso Di Noia, Christoph Lange, Diego Reforgiato Recupero, Anna Tordai",Valentina Presutti,Anna Tordai,9,"This book constitutes the thoroughly refereed post conference proceedings of the first edition of the Semantic Web Evaluation Challenge, SemWebEval 2014, co-located with the 11th Extended Semantic Web conference, held in Anissaras, Crete, Greece, in May 2014. This book includes the descriptions of all methods and tools that competed at SemWebEval 2014, together with a detailed description of the tasks, evaluation procedures and datasets. The contributions are grouped in three areas: semantic publishing (sempub), concept-level sentiment analysis (ssa), and linked-data enabled recommender systems (recsys).",https://books.google.com/books?hl=en&lr=&id=7jKvBAAAQBAJ&oi=fnd&pg=PR5&dq=info:pzYQ3wC4EPAJ:scholar.google.com&ots=xQ6_J9pYdz&sig=j7S3FUug2RZICUjMparr4Nt6soU
Erik Cambria,XAI Meets LLMs: A Survey of the Relation between Explainable AI and Large Language Models,2025,arXiv preprint arXiv:2407.15248,6,"Erik Cambria, Lorenzo Malandri, Fabio Mercorio, Navid Nobani, Andrea Seveso",Erik Cambria,Andrea Seveso,5,"In this survey, we address the key challenges in Large Language Models (LLM) research, focusing on the importance of interpretability. Driven by increasing interest from AI and business sectors, we highlight the need for transparency in LLMs. We examine the dual paths in current LLM research and eXplainable Artificial Intelligence (XAI): enhancing performance through XAI and the emerging focus on model interpretability. Our paper advocates for a balanced approach that values interpretability equally with functional advancements. Recognizing the rapid development in LLM research, our survey includes both peer-reviewed and preprint (arXiv) papers, offering a comprehensive overview of XAI's role in LLM research. We conclude by urging the research community to advance both LLM and XAI fields together.",https://arxiv.org/abs/2407.15248
Erik Cambria,PanoSent: A Panoptic Sextuple Extraction Benchmark for Multimodal Conversational Aspect-based Sentiment Analysis,2024,Proceedings of ACM Multimedia,6,"Meng Luo, Hao Fei, Bobo Li, Shengqiong Wu, Qian Liu, Soujanya Poria, Erik Cambria, Mong-Li Lee, Wynne Hsu",Meng Luo,Wynne Hsu,9,"While existing Aspect-based Sentiment Analysis (ABSA) has received extensive effort and advancement, there are still gaps in defining a more holistic research target seamlessly integrating multimodality, conversation context, fine-granularity, and also covering the changing sentiment dynamics as well as cognitive causal rationales. This paper bridges the gaps by introducing a multimodal conversational ABSA, where two novel subtasks are proposed: 1) Panoptic Sentiment Sextuple Extraction, panoramically recognizing holder, target, aspect, opinion, sentiment, rationale from multi-turn multi-party multimodal dialogue. 2) Sentiment Flipping Analysis, detecting the dynamic sentiment transformation throughout the conversation with the causal reasons. To benchmark the tasks, we construct PanoSent, a dataset annotated both manually and automatically, featuring high quality, large scale, multimodality …",https://dl.acm.org/doi/abs/10.1145/3664647.3680705
Erik Cambria,Multilingual Emotion Recognition: Discovering the Variations of Lexical Semantics between Languages,2024,Proceedings of IJCNN,6,"Xulang Zhang, Rui Mao, Erik Cambria",Xulang Zhang,Erik Cambria,3,"The task of multilingual emotion recognition holds significant importance in cross-cultural communication and data mining. While prior research has concentrated on enhancing classification accuracy using state-of-the-art techniques, it has often overlooked a crucial linguistic aspect—the semantic disparities across different languages. This study aims to address this gap by introducing a novel method to identify lexical semantic variations in diverse languages. The detected semantic variation features are subsequently injected into a multilingual emotion recognition model to enhance its performance within a target language. Notably, existing multilingual pre-trained language models are likely biased toward English word meanings, leading to inaccurate emotion predictions in other languages due to the misinterpretation of semantics. Our proposed semantic variation injection method tackles this limitation, resulting in improved accuracy. These findings contribute to the ongoing development of robust and culturally sensitive emotion recognition systems, offering valuable insights for both the linguistics and computational linguistics communities engaged in multilingual research.",http://ww.sentic.net/multilingual-emotion-recognition.pdf
Erik Cambria,Self-supervised Utterance Order Prediction for Emotion Recognition in Conversations,2024,Neurocomputing,6,"Dazhi Jiang, Hao Liu, Geng Tu, Runguo Wei, Erik Cambria",Dazhi Jiang,Erik Cambria,5,"As the order of the utterances in a conversation changes, the meaning of the utterance also changes, and sometimes, this will cause different semantics or emotions. However, the existing representation learning models do not pay close attention to capturing the internal semantic differences of utterance caused by the change of utterance order. Based on this, we build a self-supervised utterance order prediction approach to learn the logical order of utterance, which helps understand the deep semantic relationship between adjacent utterances. Specially, the utterance binary composed of two adjacent utterances, which are ordered or disordered, is fed to the self-supervised model so that the self-supervised model can obtain firm representation learning ability for the semantic differences of the adjacent sentences. The self-supervised method is applied to the downstream conversation emotion recognition task to test …",https://www.sciencedirect.com/science/article/pii/S0925231224001413
Erik Cambria,Enhancing Arabic-text Feature Extraction Utilizing Label-semantic Augmentation in Few/Zero-shot Learning,2023,Expert Systems,6,"Seham Basabain, Erik Cambria, Khalid Alomar, Amir Hussain",Seham Basabain,Amir Hussain,4,"A growing amount of research use pre‐trained language models to address few/zero‐shot text classification problems. Most of these studies neglect the semantic information hidden implicitly beneath the natural language names of class labels and develop a meta learner from the input texts solely. In this work, we demonstrate how label information can be utilized to extract enhanced feature representation of the input text from a Transformer‐based pre‐trained language model such as AraBERT. In addition, how this approach can improve performance when the data resources are scarce like in the Arabic language and the input text is short with little semantic information as is the case using tweets. The work also applies zero‐shot text classification to predict new classes with no training examples across different domains including sarcasm detection and sentiment analysis using the information in the last layer of a …",https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13329
Erik Cambria,A Semantics-Aware Approach for Multilingual Natural Language Inference,2023,Language Resources and Evaluation,6,"Phuong Le-Hong, Erik Cambria",Phuong Le-Hong,Erik Cambria,2,"This paper introduces a semantics-aware approach to natural language inference which allows neural network models to perform better on natural language inference benchmarks. We propose to incorporate explicit lexical and concept-level semantics from knowledge bases to improve inference accuracy. We conduct an extensive evaluation of four models using different sentence encoders, including continuous bag-of-words, convolutional neural network, recurrent neural network, and the transformer model. Experimental results demonstrate that semantics-aware neural models give better accuracy than those without semantics information. On average of the three strong models, our semantic-aware approach improves natural language inference in different languages.",https://link.springer.com/article/10.1007/s10579-023-09635-6
Erik Cambria,New Avenues in Mobile Tourism,2020,Proceedings of IJCNN,6,"Claudia Guerreiro, Erik Cambria, Hien T Nguyen",Claudia Guerreiro,Hien T Nguyen,3,"This paper analyzes the increasing importance of mobile technologies in the tourism industry by reviewing, examining and synthesizing studies related to it. The main aim of this paper is to provide academics and practitioners with the current developments and practices of the alleged mobile tourism. In particular, we investigate the key enablers of mobile tourism, namely: social media marketing, sentiment analysis, recommender systems, Internet of Things, and virtual assistants. Finally, we focus on investigating how mobile technologies are significantly altering the tourism industry as well as providing an agenda for future research.",https://ieeexplore.ieee.org/abstract/document/9207561/
Erik Cambria,MuSe 2020--The First International Multimodal Sentiment Analysis in Real-life Media Challenge and Workshop,2020,Proceedings of ACM Multimedia,6,"Lukas Stappen, Alice Baird, Georgios Rizos, Panagiotis Tzirakis, Xinchen Du, Felix Hafner, Lea Schumann, Adria Mallol-Ragolta, Björn W Schuller, Iulia Lefter, Erik Cambria, Ioannis Kompatsiaris",Lukas Stappen,Ioannis Kompatsiaris,12,"Multimodal Sentiment Analysis in Real-life Media (MuSe) 2020 is a Challenge-based Workshop focusing on the tasks of sentiment recognition, as well as emotion-target engagement and trustworthiness detection by means of more comprehensively integrating the audio-visual and language modalities. The purpose of MuSe 2020 is to bring together communities from different disciplines; mainly, the audio-visual emotion recognition community (signal-based), and the sentiment analysis community (symbol-based). We present three distinct sub-challenges: MuSe-Wild, which focuses on continuous emotion (arousal and valence) prediction; MuSe-Topic, in which participants recognise domain-specific topics as the target of 3-class (low, medium, high) emotions; and MuSe-Trust, in which the novel aspect of trustworthiness is to be predicted. In this paper, we provide detailed information on MuSe-CaR, the first of its kind in-the-wild database, which is utilised for the challenge, as well as the state-of-the-art features and modelling approaches applied. For each sub-challenge, a competitive baseline for participants is set; namely, on test we report for MuSe-Wild a combined (valence and arousal) CCC of .2568, for MuSe-Topic a score (computed as 0.34 UAR + 0.66F1) of 76.78 % on the 10-class topic and 40.64 % on the 3-class emotion prediction, and for MuSe-Trust a CCC of .4359.",https://arxiv.org/abs/2004.14858
Erik Cambria,New Trends of Learning in Computational Intelligence (Part II) [Guest Editorial],2015,IEEE Computational Intelligence Magazine,6,"Guang-Bin Huang, Erik Cambria, Kar-Ann Toh, Bernard Widrow, Zongben Xu",Guang-Bin Huang,Zongben Xu,5,The articles in this special section examine new trends and developments in computational intelligence programs and applications.,https://ieeexplore.ieee.org/abstract/document/7160853/
Erik Cambria,"Sentic Computing for Social Media Analysis, Representation, and Retrieval",2013,,6,"Erik Cambria, Marco Grassi, Soujanya Poria, Amir Hussain",Erik Cambria,Amir Hussain,4,"As the web is rapidly evolving, web users are evolving with it. In the era of social colonisation, people are getting more and more enthusiastic about interacting, sharing and collaborating through social networks, online communities, blogs, wikis and other online collaborative media. In recent years, this collective intelligence has spread to many different areas in the web, with particular focus on fields related to our everyday life such as commerce, tourism, education, and health. These online social data, however, remain hardly accessible to computers, as they are specifically meant for human consumption. To overcome such obstacle, we need to explore more concept-level approaches that rely more on the implicit semantic texture of natural language, rather than its explicit syntactic structure. To this end, we further develop and apply sentic computing tools and techniques to the development of a novel …",https://link.springer.com/chapter/10.1007/978-1-4471-4555-4_9
Erik Cambria,Self-training Large Language Models through Knowledge Detection,2024,Proceedings of EMNLP,5,"Wei Jie Yeo, Teddy Ferdinan, Przemyslaw Kazienko, Ranjan Satapathy, Erik Cambria",Wei Jie Yeo,Erik Cambria,5,"Large language models (LLMs) often necessitate extensive labeled datasets and training compute to achieve impressive performance across downstream tasks. This paper explores a self-training paradigm, where the LLM autonomously curates its own labels and selectively trains on unknown data samples identified through a reference-free consistency method. Empirical evaluations demonstrate significant improvements in reducing hallucination in generation across multiple subjects. Furthermore, the selective training framework mitigates catastrophic forgetting in out-of-distribution benchmarks, addressing a critical limitation in training LLMs. Our findings suggest that such an approach can substantially reduce the dependency on large labeled datasets, paving the way for more scalable and cost-effective language model training.",https://arxiv.org/abs/2406.11275
Erik Cambria,Plausible Extractive Rationalization through Semi-Supervised Entailment Signal,2024,Proceedings of ACL,5,"Wei Jie Yeo, Ranjan Satapathy, Erik Cambria",Wei Jie Yeo,Erik Cambria,3,"The increasing use of complex and opaque black box models requires the adoption of interpretable measures, one such option is extractive rationalizing models, which serve as a more interpretable alternative. These models, also known as Explain-Then-Predict models, employ an explainer model to extract rationales and subsequently condition the predictor with the extracted information. Their primary objective is to provide precise and faithful explanations, represented by the extracted rationales. In this paper, we take a semi-supervised approach to optimize for the plausibility of extracted rationales. We adopt a pre-trained natural language inference (NLI) model and further fine-tune it on a small set of supervised rationales (). The NLI predictor is leveraged as a source of supervisory signals to the explainer via entailment alignment. We show that, by enforcing the alignment agreement between the explanation and answer in a question-answering task, the performance can be improved without access to ground truth labels. We evaluate our approach on the ERASER dataset and show that our approach achieves comparable results with supervised extractive models and outperforms unsupervised approaches by .",https://arxiv.org/abs/2402.08479
Erik Cambria,SenticVec: Toward Robust and Human-Centric Neurosymbolic Sentiment Analysis,2024,Proceedings of ACL,5,"Xulang Zhang, Rui Mao, Erik Cambria",Xulang Zhang,Erik Cambria,3,"Recent developments in natural language processing were enabled by deep neural networks, which excel in various tasks through strong data fitting and latent feature modeling abilities. However, certain challenges linked to deep nets and supervised deep learning deserve considerations, eg, extensive computing resources, knowledge forgetting, etc. Previous research attempted to tackle these challenges individually through irrelative techniques. However, they do not instigate fundamental shifts in the learning paradigm. In this work, we propose a novel neurosymbolic method for sentiment analysis to tackle these issues. We also propose a novel sentiment-pragmatic knowledge base that places emphasis on human subjectivity within varying domain annotations. We conducted extensive experiments to show that our neurosymbolic framework for sentiment analysis stands out for its lightweight nature, robustness across domains and languages, efficient few-shot training, and rapid convergence.",https://sentic.net/neurosymbolic-sentiment-analysis.pdf
Erik Cambria,A Dynamic Dual-Graph Neural Network for Stock Price Movement Prediction,2024,Proceedings of IJCNN,5,"Kelvin Du, Rui Mao, Frank Xing, Erik Cambria",Kelvin Du,Erik Cambria,4,"The prediction of stock price movements is challenging due to the inherently dynamic and complex characteristics of financial markets. A current research gap is the lack of exploration into the complex interrelationships inherent in stock price dynamics, often analyzing predictions in isolation with an implicit presumption that solely the historical data of a given stock influences its future trend. However, stock prices are impacted by a diverse array of driving factors that extend beyond the traditionally examined historical prices, encompassing influences such as inter-stock correlations. In this paper, we present a predictive approach using a dynamic dual-graph neural network. The network combines textual data and quantitative metrics to capture multiple dynamic relationships. Specifically, We have developed a price relationship graph (PRG) and a semantic relationship graph (SRG), which are later integrated using a graph attention neural network. The effectiveness of our neural architecture is validated through extensive testing on two benchmark datasets for stock movement prediction, illustrating its superior performance compared to other graph-based networks for stock market prediction.",https://ww.sentic.net/dynamic-dual-graph-neural-network-for-stock-prediction.pdf
Erik Cambria,Fusion and Discrimination: A Multimodal Graph Contrastive Learning Framework for Multimodal Sarcasm Detection,2024,IEEE Transactions on Affective Computing,5,"Bin Liang, Lin Gui, Yulan He, Erik Cambria, Ruifeng Xu",Bin Liang,Ruifeng Xu,5,"Identifying sarcastic clues from both textual and visual information has become an important research issue, called Multimodal Sarcasm Detection. In this paper, we investigate multimodal sarcasm detection from a novel perspective, where a multimodal graph contrastive learning strategy is proposed to fuse and distinguish the sarcastic clues for textual modality and visual modality. Specifically, we first utilize object detection to derive the crucial visual regions accompanied by their captions of the images, which allows better learning of the key visual regions of visual modality. In addition, to make full use of the semantic information of the visual modality, we employ optical character recognition to extract the textual content in the images. Then, based on image regions, the textual content of visual modality, and the context of the textual modality, we build a multimodal graph for each sample to model the intricate …",https://ieeexplore.ieee.org/abstract/document/10477507/
Erik Cambria,Integrating Graph Embedding and Neural Models for Improving Transition-based Dependency Parsing,2024,Neural Computing and Applications,5,"Phuong Le-Hong, Erik Cambria",Phuong Le-Hong,Erik Cambria,2,"This paper introduces an effective method for improving dependency parsing which is based on a graph embedding model. The model helps extract local and global connectivity patterns between tokens. This method allows neural network models to perform better on dependency parsing benchmarks. We propose to incorporate node embeddings trained by a graph embedding algorithm into a bidirectional recurrent neural network scheme. The new model outperforms a baseline reference using a state-of-the-art method on three dependency treebanks for both low-resource and high-resource natural languages, namely Indonesian, Vietnamese and English. We also show that the popular pretraining technique of BERT would not pick up on the same kind of signal as graph embeddings. The new parser together with all trained models is made available under an open-source license, facilitating community …",https://link.springer.com/article/10.1007/s00521-023-09223-3
Erik Cambria,A Multi-task Learning Model for Gold-two-mention Co-reference Resolution,2023,Proceedings of IJCNN,5,"Ruicheng Liu, Guanyi Chen, Rui Mao, Erik Cambria",Ruicheng Liu,Erik Cambria,4,"The task of resolving repeated objects in natural languages is known as co-reference resolution. It is an important part of modern natural language processing and semantic cognition as these implicit relationships are particularly difficult in natural language understanding in downstream tasks. Mention identification and mention linking are the two sub-tasks in the general co-reference resolution research community. Gold-two-mention style co-reference resolution is a special type of co-reference resolution that focuses on linking the ambiguous pronoun to one of the two candidate antecedents. In this paper, we proposed a joint learning model that learns mention identification and mention linking tasks together, because we find that the learning of mention identification can provide supportive dependent information for the learning of mention linking. As far as we know, we propose the first model that introduces a multi …",https://ieeexplore.ieee.org/abstract/document/10191719/
Erik Cambria,Sarcasm Detection in News Headlines using Supervised Learning,2022,Proceedings of IEEE AIDE,5,"Ashok Kumar Jayaraman, Tina Esther Trueman, Gayathri Ananthakrishnan, Satanik Mitra, Qian Liu, Erik Cambria",Ashok Kumar Jayaraman,Erik Cambria,6,"Nowadays, social media has an enormous amount of news content with a sarcastic message. It is often expressed in the form of verbal and non-verbal. In this paper, the authors aim to identify sarcasm in news headlines using supervised learning. We address this task with the Bag-of-words features, context-independent features, and context-dependent features. Specifically, the authors employ seven supervised learning models, namely, Naïve Bayes-support vector machine, logistic regression, bidirectional gated recurrent units, Bidirectional encoders representation from Transformers (BERT), DistilBERT, and RoBERTa. Our experimental results indicate that RoBERTa achieves a better performance than others.",https://ieeexplore.ieee.org/abstract/document/10060855/
Erik Cambria,An N-gram-Based BERT Model for Sentiment Classification Using Movie Reviews,2022,Proceedings of IEEE AIDE,5,"Tina Esther Trueman, Ashok Jayaraman Kumar, Gayathri Ananthakrishnan, Erik Cambria, Satanik Mitra",Tina Esther Trueman,Satanik Mitra,5,"An abundance of product reviews and opinions is being produced every day across the internet and other media. Sentiment analysis analyzes those data and classifies them as positive or negative. In this paper, a classification model is proposed for n-gram sentiment analysis using BERT. Specifically, the large IMDB movie review dataset is used that contains 50K instances. This dataset is tokenized and encoded into unigrams, bigrams, and trigrams and their combinations such as unigram and bigram, bigram and trigram, and unigram, bigram, and trigram. The proposed BERT model employs on these extracted features. Then, this model is evaluated using the F1 score and its micro, macro, and weighted-average scores. The model shows comparable results to state-of-the-art methods for all n-gram features. In particular, the model achieves 94.64% highest accuracy for the combination of bigram and trigram …",https://ieeexplore.ieee.org/abstract/document/10060044/
Erik Cambria,Does Social Media Sentiment Predict Bitcoin Trading Volume?,2022,Proceedings of ICIS,5,"Jayit Saha, Smit Patel, Frank Xing, Erik Cambria",Jayit Saha,Erik Cambria,4,"Social media sentiment is proven to be an important feature in financial forecasting. While the effect of sentiment is complex and time-varying for traditional financial assets, its role in cryptocurrency markets is unclear. This research explores the predictive power of public sentiment on Bitcoin trading volume. We develop a novel sentiment analysis pipeline for processing Bitcoin-related tweets and achieve state-of-the-art accuracy on a benchmark dataset. Our pipeline also leverages information gain theory to incorporate the impact of textual and non-textual features. We use such features to discern a nonlinear relationship between public sentiment and Bitcoin trading volume and discover the optimal predictive horizon for Bitcoin. This research provides a useful module and a foundation for future studies and understanding of Bitcoin market dynamics, and its interaction with social media buzzing.",https://w.sentic.net/social-media-sentiment-and-bitcoin-trading-volume.pdf
Erik Cambria,Landmark Calibration for Facial Expressions and Fish Classification,2022,"Signal, Image and Video Processing",5,"Iti Chaturvedi, Qian Chen, Erik Cambria, Desmond McConnell",Iti Chaturvedi,Desmond McConnell,4,"This paper considers the automatic labeling of emotions in face images found on social media. Facial landmarks are commonly used to classify the emotions from a face image. However, it is difficult to accurately segment landmarks for some faces and for subtle emotions. Previous authors used a Gaussian prior for the refinement of landmarks, but their model often gets stuck in a local minima. Instead, the calibration of the landmarks with respect to the known emotion class label using principal component analysis is proposed in this paper. Next, the face image is generated from the landmarks using an image translation model. The proposed model is evaluated on the classification of facial expressions and also for fish identification underwater and outperforms baselines in accuracy by over .",https://link.springer.com/article/10.1007/s11760-021-01943-0
Erik Cambria,TOMN: Constituent-based Tagging Scheme,2021,Time Expression and Named Entity Recognition,5,"Xiaoshi Zhong, Erik Cambria",Xiaoshi Zhong,Erik Cambria,2,"The characteristics of time expressions drive us to design a learning-based method named TOMN to model time expressions. TOMN defines a constituent-based tagging scheme named TOMN scheme with four tags, namely T, O, M, and N, indicating the constituents of time expression, namely Time token, Modifier, Numeral, and the words Outside time expression. In modeling, TOMN assigns a word with a TOMN tag under conditional random fields with minimal features. Essentially, our constituent-based TOMN scheme overcomes the problem of inconsistent tag assignment that is caused by the conventional position-based tagging schemes (e.g., BIO scheme and BILOU scheme). Evaluation shows that TOMN is equally or more effective than state-of-the-art methods on various datasets, and much more robust on cross-datasets.",https://link.springer.com/chapter/10.1007/978-3-030-78961-9_5
Erik Cambria,Learning Visual Concepts in Images Using Temporal Convolutional Networks,2018,Proceedings of IEEE SSCI,5,"Qian Chen, Iti Chaturvedi, Soujanya Poria, Erik Cambria, Lorenzo Malandri",Qian Chen,Lorenzo Malandri,5,,
Erik Cambria,GECKA3D: A 3D Game Engine for Commonsense Knowledge Acquisition,2016,Proceedings of FLAIRS,5,"Erik Cambria, Tam V Nguyen, Brian Cheng, Kenneth Kwok, Jose Sepulveda",Erik Cambria,Jose Sepulveda,5,"Commonsense knowledge representation and reasoning is key for tasks such as artificial intelligence and natural language understanding. Since commonsense consists of information that humans take for granted, gathering it is an extremely difficult task. In this paper, we introduce a novel 3D game engine for commonsense knowledge acquisition (GECKA3D) which aims to collect commonsense from game designers through the development of serious games. GECKA3D integrates the potential of serious games and games with a purpose. This provides a platform for the acquisition of re-usable and multi-purpose knowledge, and also enables the development of games that can provide entertainment value and teach players something meaningful about the actual world they live in.",https://cdn.aaai.org/ocs/12785/12785-57654-1-PB.pdf
Erik Cambria,Switching Between Different Ways to Think,2011,,5,"Erik Cambria, Thomas Mazzocco, Amir Hussain, Tariq Durrani",Erik Cambria,Tariq Durrani,4,,
Erik Cambria,A Survey on Pragmatic Processing Techniques,2025,Information Fusion,4,"Rui Mao, Mengshi Ge, Sooji Han, Wei Li, Kai He, Luyao Zhu, Erik Cambria",Rui Mao,Erik Cambria,7,"Pragmatics, situated in the domains of linguistics and computational linguistics, explores the influence of context on language interpretation, extending beyond the literal meaning of expressions. It constitutes a fundamental element for natural language understanding in machine intelligence. With the advancement of large language models, the research focus in natural language processing has predominantly shifted toward high-level task processing, inadvertently downplaying the importance of foundational pragmatic processing tasks. Nevertheless, pragmatics serves as a crucial medium for unraveling human language cognition. The exploration of pragmatic processing stands as a pivotal facet in realizing linguistic intelligence. This survey encompasses important pragmatic processing techniques for subjective and emotive tasks, such as personality recognition, sarcasm detection, metaphor understanding …",https://www.sciencedirect.com/science/article/pii/S1566253524004901
Erik Cambria,HIPPL: Hierarchical Intent-Inferring Pointer Network with Pseudo Labeling for Consistent Persona-Driven Dialogue Generation,2024,IEEE Computational Intelligence Magazine,4,"Luyao Zhu, Wei Li, Rui Mao, Erik Cambria",Luyao Zhu,Erik Cambria,4,"Despite the recent advancements in dialogue systems, persona-driven chatbots are still in their infancy. Previous studies on persona-driven dialogue generation demonstrated its ability in generating responses that contain more detailed persona information. However, the challenge of maintaining persona consistency and contextual coherence still persists in persona-driven dialogue generation. Moreover, current methods have limitations in processing multi-source inputs and identifying interlocutor intents due to the absence of trustworthy labels and effective modeling. Additionally, numerous approaches rely on pre-trained large-scale language models that require costly computational resources. To address these challenges, a lightweight hierarchical intent-inferring pointer network is proposed for multi-source persona-driven dialogue generation. The proposed method involves detecting interlocutor intents in …",https://ieeexplore.ieee.org/abstract/document/10709813/
Erik Cambria,Towards Responsible Recommender Systems,2024,IEEE Intelligent Systems,4,"Przemysław Kazienko, Erik Cambria",Przemysław Kazienko,Erik Cambria,2,"Recommender systems have transformed our digital experiences in many regards. We enumerate six of their positive effects on the economy and humans, such as greater user satisfaction, time savings, broadening user horizons, and positive behavioral nudging. However, it is crucial to acknowledge the potential downsides inherent in their design. One significant concern is that these algorithms often prioritize the interests of the company deploying them, aiming to maximize profits and user engagement rather than solely focusing on enhancing user experience. Therefore, we also list and consider two use cases and six negative long-term impacts on humans, including addiction, reduced ability to think critically, less autonomy, and weakened human relationships caused by more and more human-like virtual assistants. Despite the undeniable utility of recommender systems, it is imperative to approach them …",https://ieeexplore.ieee.org/abstract/document/10570365/
Erik Cambria,SarcNet: A Multilingual Multimodal Sarcasm Detection Dataset,2024,Proceedings of LREC-COLING,4,"Tan Yue, Xuzhao Shi, Rui Mao, Zonghai Hu, Erik Cambria",Tan Yue,Erik Cambria,5,"Sarcasm poses a challenge in linguistic analysis due to its implicit nature, involving an intended meaning that contradicts the literal expression. The advent of social networks has propelled the utilization of multimodal data to enhance sarcasm detection performance. In prior multimodal sarcasm detection datasets, a single label is assigned to a multimodal instance. Subsequent experiments often highlight the superiority of multimodal models by demonstrating their improvements compared to unimodal models based on these unified labels across multiple modalities. However, our investigation revealed that numerous instances of sarcasm cannot be identified using a single modality. Humans employ the conflict between a statement and factual information as a cue to detect sarcasm, and these cues can stem from different modalities. Then, a unified label for a multimodal instance may be not suitable for the associated text or image. In this work, we introduce SarcNet, a multilingual and multimodal sarcasm detection dataset in English and Chinese, consisting of 3,335 image-text pair samples. We provide annotations for sarcasm in visual, textual, and multimodal data, respectively, resulting in over 10,000 labeled instances. The separated annotation schema for unimodal and multimodal data facilitates a more accurate and reasonable assessment of unimodal and multimodal models.",https://aclanthology.org/2024.lrec-main.1248/
Erik Cambria,Granular Syntax Processing with Multi-task and Curriculum Learning,2024,Cognitive Computation,4,"Xulang Zhang, Rui Mao, Erik Cambria",Xulang Zhang,Erik Cambria,3,"Syntactic processing techniques are the foundation of natural language processing (NLP), supporting many downstream NLP tasks. In this paper, we conduct pair-wise multi-task learning (MTL) on syntactic tasks with different granularity, namely Sentence Boundary Detection (SBD), text chunking, and Part-of-Speech (PoS) tagging, so as to investigate the extent to which they complement each other. We propose a novel soft parameter-sharing mechanism to share local and global dependency information that is learned from both target tasks. We also propose a curriculum learning (CL) mechanism to improve MTL with non-parallel labeled data. Using non-parallel labeled data in MTL is a common practice, whereas it has not received enough attention before. For example, our employed PoS tagging data do not have text chunking labels. When learning PoS tagging and text chunking together, the proposed CL …",https://link.springer.com/article/10.1007/s12559-024-10320-1
Erik Cambria,Few Pixels Attacks with Generative Model,2023,Pattern Recognition,4,"Yang Li, Quan Pan, Zhaowen Feng, Erik Cambria",Yang Li,Erik Cambria,4,"Adversarial attacks have attracted much attention in recent years, and a number of works have demonstrated the effectiveness of attacks on the entire image at perturbation generation. However, in practice, specially designed perturbation of the entire image is impractical. Some work has crafted adversarial samples with a few scrambled pixels by advanced search, e.g., SparseFool, OnePixel, etc., but they take more time to find such pixels that can be perturbed. Therefore, to construct the adversarial samples with few pixels perturbed in an end-to-end way, we propose a new framework, in which a dual-decoder VAE for perturbations finding is designed. To make adversarial learning more effective, we proposed a new version of the adversarial loss by considering the generalization. To evaluate the sophistication of the proposed framework, we compared it with more than a dozen existing related attack methods. The …",https://www.sciencedirect.com/science/article/pii/S0031320323005472
Erik Cambria,Guest Editorial: Neurosymbolic AI for Sentiment Analysis,2023,IEEE Transactions on Affective Computing,4,"Frank Xing, Iti Chaturvedi, Erik Cambria, Amir Hussain, Bjorn Schuller",Frank Xing,Bjorn Schuller,5,"Neural network-based methods, especially deep learning, have been a burgeoning area in AI research and have been successful in tackling the expanding data volume as we move into a digital age. Today, the neural network-based methods are not only used for low-level cognitive tasks, such as recognizing objects and spotting keywords, but they have also been deployed in various industrial information systems to assist high-level decision-making. In natural language processing, there have been two milestones for the past decade: one is word2vec [1], a group of neural models that learn word embeddings (vector representations of words) from large datasets; and one is the most recent GPT-based models [2], which combine reinforcement learning with a generative transformer in order to enable multi-round end-to-end conversations. While producing highly accurate predictions on datasets and generating …",https://ieeexplore.ieee.org/abstract/document/10254631/
Erik Cambria,Adaptive Knowledge Distillation between Text and Speech Pre-trained Models,2023,Proceedings of IEEE ICASSP,4,"Jinjie Ni, Yukun Ma, Wen Wang, Qian Chen, Dianwen Ng, Han Lei, Trung Hieu Nguyen, Chong Zhang, Bin Ma, Erik Cambria",Jinjie Ni,Erik Cambria,10,"Learning on a massive amount of speech corpus leads to the recent success of many self-supervised speech models. With knowledge distillation, these models may also benefit from the knowledge encoded by language models that are pre-trained on rich sources of texts. The distillation process, however, is challenging due to the modal disparity between textual and speech embedding spaces. This paper studies metric-based distillation to align the embedding space of text and speech with only a small amount of data without modifying the model structure. Since the semantic and granularity gap between text and speech has been omitted in literature, which impairs the distillation, we propose the Prior-informed Adaptive knowledge Distillation (PAD) that adaptively leverages text/speech units of variable granularity and prior distributions to achieve better global and local alignments between text and speech pre …",https://ieeexplore.ieee.org/abstract/document/10096950/
Erik Cambria,Gaussian Correction for Adversarial Learning of Boundaries,2022,Signal Processing: Image Communication,4,"Iti Chaturvedi, Qian Chen, Roy Welsch, Kishor Thapa, Erik Cambria",Iti Chaturvedi,Erik Cambria,5,"Social networking sites often monitor the response to brands, events and activities during personal chats or videos. Here, the facial expression of the speaker can be used for automatic ranking of products. However, manual classification of videos puts the identity of the speaker at risk. There is imminent danger of fake videos circulating that are generated using style transfer. In this paper, we target both these challenges by using an adversarial model that can segment a face from the background scenery and occlusions. The segmentation for a fake video will be of poor quality compared to a real video. Previous segmentation models could only be trained on a few objects and failed on scenic images with occlusions. Here we propose an image translator that learns the boundaries of objects during training using Gaussian correction. To determine the parameters of the Gaussian distribution we make use of a …",https://www.sciencedirect.com/science/article/pii/S092359652200128X
Erik Cambria,A Prototype System for Monitoring Emotion and Sentiment Trends Towards Nuclear Energy on Twitter Using Deep Learning,2021,Proceedings of ICADL,4,"Snehameena Arumugam, Likai Peng, Jin-Cheon Na, Guangze Lin, Roopika Ganesh, Xiaoyin Li, Qing Chen, Shirley S Ho, Erik Cambria",Snehameena Arumugam,Erik Cambria,9,"Nuclear energy is one of controversial topics that affects people’s lives, and it is important for policy makers to analyze what people feel towards the subject. But manual analysis of related user-generated contents on social media platforms is a daunting task, and automatic data analysis and visualization come to help. So, in this research, we firstly developed a model for classifying the emotion of nuclear energy related tweets and another model for the aspect-based sentiment analysis of nuclear energy tweets using the BERT (Bidirectional Encoder Representations from Transformers). After that, we developed a prototype system for visualization of the analyzed results stored in the database. The user interface dashboards of the system allow users to monitor emotion and sentiment trends towards nuclear energy by analyzing recent nuclear energy tweets crawled weekly.",https://link.springer.com/chapter/10.1007/978-3-030-91669-5_36
Erik Cambria,Sentiment Analysis of Influential Messages for Political Election Forecasting,2019,Proceedings of CICLing,4,"Oumayma Oueslati, Moez Ben Hajhmida, Habib Ounelli, Erik Cambria",Oumayma Oueslati,Erik Cambria,4," In this paper, we explore the use of sentiment analysis of influential messages on social media to improve political election forecasting. While social media users are not necessarily representative of the overall electors, bias correction of users messages is critical for producing a reliable forecast. The observation motivates our work is that people on social media consult the messages of each other before taking a decision, this means that social media users influence each other. We first built a classifier to detect politically influential messages based on different aspects (messages content, time, sentiment, and emotion). Then, we predicted electoral candidates votes using sentiment degree of influential messages. We applied our proposed model to the 2016 United States presidential election. We conducted experiments at different intervals of times. Results show that our approach achieves better performance than …",https://link.springer.com/chapter/10.1007/978-3-031-24340-0_21
Erik Cambria,MEMN: Multimodal Emotional Memory Network for Emotion Recognition in Dyadic Conversational Videos,2018,Proceedings of NAACL,4,"Devamanyu Hazarika, Soujanya Poria, Amir Zadeh, Erik Cambria, Louis-Philippe Morency, Roger Zimmerman",Devamanyu Hazarika,Roger Zimmerman,6,,
Erik Cambria,Basic Tasks of Sentiment Analysis,2017,,4,"Iti Chaturvedi, Soujanya Poria, Erik Cambria",Iti Chaturvedi,Erik Cambria,3,"Subjectivity detection is the task of identifying objective and subjective sentences. Objective sentences are those which do not exhibit any sentiment. So, it is desired for a sentiment analysis engine to find and separate the objective sentences for further analysis, e.g., polarity detection. In subjective sentences, opinions can often be expressed on one or multiple topics. Aspect extraction is a subtask of sentiment analysis that consists in identifying opinion targets in opinionated text, i.e., in detecting the specific aspects of a product or service the opinion holder is either praising or complaining about.",https://arxiv.org/abs/1710.06536
Erik Cambria,ASR Hypothesis Reranking Using Prior-Informed Restricted Boltzmann Machine,2017,Proceedings of CICLing,4,"Yukun Ma, Erik Cambria, Benjamin Bigot",Yukun Ma,Benjamin Bigot,3,"Discriminative language models (DLMs) have been widely used for reranking competing hypotheses produced by an Automatic Speech Recognition (ASR) system. While existing DLMs suffer from limited generalization power, we propose a novel DLM based on a discriminatively trained Restricted Boltzmann Machine (RBM). The hidden layer of the RBM improves generalization and allows for employing additional prior knowledge, including pre-trained parameters and entity-related prior. Our approach outperforms the single-layer-perceptron (SLP) reranking model, and fusing our approach with SLP achieves up to 1.3% absolute Word Error Rate (WER) reduction and a relative 180% improvement in terms of WER reduction over the SLP reranker. In particular, it shows that proposed prior informed RBM reranker achieves largest ASR error reduction (3.1% absolute WER) on content words.",https://link.springer.com/chapter/10.1007/978-3-319-77113-7_39
Erik Cambria,Learning Word Vectors in Deep Walk using Convolution,2017,Proceedings of FLAIRS,4,"Iti Chaturvedi, Sandro Cavallari, Erik Cambria, Vincent Zheng",Iti Chaturvedi,Vincent Zheng,4,"Textual queries in networks such as Twitter can have more than one label, resulting in a multi-label classification problem. To reduce computational costs, a low-dimensional representation of a large network is learned that preserves proximity among nodes in the same community. Similar to sequences of words in a sentence, DeepWalk considers sequences of nodes in a shallow graph and clustering is done using hierarchical softmax in an unsupervised manner. In this paper, we generate network abstractions at different levels using deep convolutional neural networks. Since class labels of connected nodes in a network keep changing, we consider a fuzzy recurrent feedback controller to ensure robustness to noise.",https://cdn.aaai.org/ocs/15485/15485-68674-1-PB.pdf
Erik Cambria,GpSense: A GPU-Friendly Method for Common-Sense Subgraph Matching in Massively Parallel Architectures,2016,Proceedings of CICLing,4,"Ha-Nguyen Tran, Erik Cambria",Ha-Nguyen Tran,Erik Cambria,2,"In the context of commonsense reasoning, spreading activation is used to select relevant concepts in a graph of commonsense knowledge. When such a graph starts growing, however, the number of relevant concepts selected during spreading activation tends to diminish. In the literature, such an issue has been addressed in different ways but two other important issues have been rather under-researched, namely: performance and scalability. Both issues are caused by the fact that many new nodes, i.e., natural language concepts, are continuously integrated into the graph. Both issues can be solved by means of GPU accelerated computing, which offers unprecedented performance by offloading compute-intensive portions of the application to the GPU, while the remainder of the code still runs on the CPU. To this end, we propose a GPU-friendly method, termed GpSense, which is designed for massively …",https://link.springer.com/chapter/10.1007/978-3-319-75477-2_39
Erik Cambria,Common and Common-Sense Knowledge Integration for Concept-Level Sentiment Analysis,2014,Proceedings of FLAIRS,4,"Erik Cambria, Newton Howard",Erik Cambria,Newton Howard,2,"In the era of Big Data, knowledge integration is key for tasks such as social media aggregation, opinion mining, and cyber-issue detection. The integration of different kinds of knowledge coming from multiple sources, however, is often a problematic issue as it either requires a lot of manual effort in defining aggregation rules or suffers from noise generated by automatic integration techniques. In this work, we propose a method based on conceptual primitives for efficiently integrating pieces of knowledge coming from different common and common-sense resources, which we test in the field of concept-level sentiment analysis.",https://cdn.aaai.org/ocs/7955/7955-36718-1-PB.pdf
Erik Cambria,"Development of a Diplomatic, Information, Military, Health, and Economic Effects Modeling System",2013,International Journal of Privacy and Health Information Management,4,"Newton Howard, Erik Cambria",Newton Howard,Erik Cambria,2,"Having a clear picture of different facets of the current situation is key in the conduct of tactical operations within a theater. To this end, the ensemble application of sentic computing and intention awareness techniques is hereby examined to develop a novel analysis framework for estimating the effects of diplomatic, informational, military, health, and economic activities in the context of a theater of operations. A set of candidate models of the flow and evolution of population beliefs and intentions is evaluated and recommended as the starting point for developing an effects modeling system for tactical commanders. In particular, the following needs were identified:(1) understanding and representing the underlying causality within the population;(2) formulating models that are both sensitive and computable;(3) validating the predictions of population beliefs, intentions, and behaviors by model.",https://www.igi-global.com/article/development-diplomatic-information-military-health/77003
Erik Cambria,Towards IMACA: Intelligent Multimodal Affective Conversational Agent,2012,Neural Information Processing,4,"Amir Hussain, Erik Cambria, Thomas Mazzocco, Marco Grassi, Qiu-Feng Wang, Tariq Durrani",Amir Hussain,Tariq Durrani,6,"A key aspect when trying to achieve natural interaction in machines is multimodality. Besides verbal communication, in fact, humans interact also through many other channels, e.g., facial expressions, gestures, eye contact, posture, and voice tone. Such channels convey not only semantics, but also emotional cues that are essential for interpreting the message transmitted. The importance of the affective information and the capability of properly managing it, in fact, has been more and more understood as fundamental for the development of a new generation of emotion-aware applications for several scenarios like e-learning, e-health, and human-computer interaction. To this end, this work investigates the adoption of different paradigms in the fields of text, vocal, and video analysis, in order to lay the basis for the development of an intelligent multimodal affective conversational agent.",https://link.springer.com/chapter/10.1007/978-3-642-34475-6_79
Erik Cambria,Has Multimodal Learning Delivered Universal Intelligence in Healthcare? A Comprehensive Survey,2025,Information Fusion,3,"Qika Lin, Yifan Zhu, Xin Mei, Ling Huang, Jingying Ma, Kai He, Zhen Peng, Erik Cambria, Mengling Feng",Qika Lin,Mengling Feng,9,"The rapid development of artificial intelligence has constantly reshaped the field of intelligent healthcare and medicine. As a vital technology, multimodal learning has increasingly garnered interest due to data complementarity, comprehensive information fusion, and great application potential. Currently, numerous researchers are dedicating their attention to this field, conducting extensive studies and constructing abundant intelligent systems. Naturally, an open question arises that has multimodal learning delivered universal intelligence in healthcare? To answer the question, we adopt three unique viewpoints for a holistic analysis. Firstly, we conduct a comprehensive survey of the current progress of medical multimodal learning from the perspectives of datasets, task-oriented methods, and universal foundation models. Based on them, we further discuss the proposed question from five issues to explore the real …",https://www.sciencedirect.com/science/article/pii/S1566253524005736
Erik Cambria,Dialogue Emotion Model based on Local-Global Context Encoder and Commonsense Knowledge Fusion Attention,2024,International Journal of Machine Learning and Cybernetics,3,"Dazhi Jiang, Weilun Yu, Chengming Li, Xiping Hu, Wenhua Zhu, Erik Cambria",Dazhi Jiang,Erik Cambria,6,"Emotion Recognition in Conversation (ERC) is a task aimed at predicting the emotions conveyed by an utterance in a dialogue. It is common in ERC research to integrate intra-utterance, local contextual, and global contextual information to obtain the utterance vectors. However, there exist complex semantic dependencies among these factors, and failing to model these dependencies accurately can adversely affect the effectiveness of emotion recognition. Moreover, to enhance the semantic dependencies within the context, researchers commonly introduce external commonsense knowledge after modeling it. However, injecting commonsense knowledge into the model simply without considering its potential impact can introduce unexpected noise. To address these issues, we propose a dialogue emotion model based on local–global context encoder and commonsense knowledge fusion attention. The local …",https://link.springer.com/article/10.1007/s13042-023-02066-3
Erik Cambria,How Can Natural Language Processing and Generative AI Address Grand Challenges of Quantitative User Personas?,2023,Proceedings of the International Conference on Human-Computer Interaction,3,"Joni Salminen, Soon-gyo Jung, Hind Almerekhi, Erik Cambria, Bernard Jansen",Joni Salminen,Bernard Jansen,5,"Human-computer interaction (HCI) and natural language processing (NLP) can engage in mutually beneficial collaboration. This article summarizes previous literature to identify grand challenges for the application of NLP in quantitative user personas (QUPs), which exemplifies such collaboration. Grand challenges provide a collaborative starting point for researchers working at the intersection of NLP and QUPs, towards improved user experiences. NLP research could also benefit from focusing on generating user personas by introducing new solutions to specific NLP tasks, such as classification and generation. We also discuss the novel opportunities introduced by Generative AI to address the grand challenges, offering illustrative examples.",https://link.springer.com/chapter/10.1007/978-3-031-48057-7_14
Erik Cambria,Task-Aware Self-Supervised Framework for Dialogue Discourse Parsing,2023,Proceedings of EMNLP,3,"Wei Li, Luyao Zhu, Wei Shao, Zonglin Yang, Erik Cambria",Wei Li,Erik Cambria,5,"Dialogue discourse parsing is a fundamental natural language processing task. It can benefit a series of conversation-related downstream tasks including dialogue summarization and emotion recognition in conversations. However, existing parsing approaches are constrained by predefined relation types, which can impede the adaptability of the parser for downstream tasks. To this end, we propose to introduce a task-aware paradigm to improve the versatility of the parser in this paper. Moreover, to alleviate error propagation and learning bias, we design a graph-based discourse parsing model termed DialogDP. Building upon the symmetrical property of matrix-embedded parsing graphs, we have developed an innovative self-supervised mechanism that leverages both bottom-up and top-down parsing strategies. This approach allows the parsing graphs to mutually regularize and enhance each other. Empirical studies on dialogue discourse parsing datasets and a downstream task demonstrate the effectiveness and flexibility of our framework.© 2023 Association for Computational Linguistics.",https://scholars.cityu.edu.hk/en/publications/publication(fb44a5e3-67ac-4498-af30-e80323d00b97).html
Erik Cambria,Non-Fungible Tokens: What Makes Them Valuable?,2023,Proceedings of ICDM Workshops,3,"Zheng Leitter, Erik Cambria",Zheng Leitter,Erik Cambria,2,"Non-Fungible Tokens (NFTs) have revolutionized various industries and aspects of the digital world in several ways. Built on blockchain technology, NFTs provide a secure and transparent way to establish ownership and provenance of unique digital or physical items. This has wide-ranging implications, from art and collectibles to virtual real estate and digital goods. While NFTs offer many benefits, however, they also raise concerns, including environmental impacts due to energy-intensive blockchain networks, copyright and plagiarism issues, and speculative bubbles in the NFT market. In this work, we collected 200,000 tweets about NFTs and employed state-of-the-art neurosymbolic AI tools to better understand what are the online conversation drivers and sentiments around NFTs and, hence, gain insights about what makes them valuable.",https://ieeexplore.ieee.org/abstract/document/10411571/
Erik Cambria,"Knowledge Representation for Conceptual, Motivational, and Affective Processes in Natural Language Communication",2023,Proceedings of BICS,3,"Seng-Beng Ho, Zhaoxia Wang, Boon-Kiat Quek, Erik Cambria",Seng-Beng Ho,Erik Cambria,4,"Natural language communication is an intricate and complex process. The speaker usually begins with an intention and motivation of what is to be communicated, and what outcomes are expected from the communication, while taking into consideration the listener’s mental model to concoct an appropriate sentence. Likewise, the listener has to interpret the speaker’s message, and respond accordingly, also with the speaker’s mental model in mind. Doing this successfully entails the appropriate representation of the conceptual, motivational, and affective processes that underlie language generation and understanding. Whereas big-data approaches in language processing (such as chatbots and machine translation) have performed well, achieving natural language based communication in human-robot collaboration is non-trivial, and requires a deeper representation of the conceptual, motivational, and affective …",https://link.springer.com/chapter/10.1007/978-981-97-1417-9_2
Erik Cambria,Socio-Affective Computing,2021,,3,"Amir Hussain, Erik Cambria",Amir Hussain,Erik Cambria,2,"The scenario when investors need to manage a large number of financial assets has an essential difference from what most of the people do for stock movement prediction today. Unlike the situation of considering a single stock, investors need to consider co-movement of related stocks and control risk within a certain level. In traditional asset allocation models, expected returns and correlations of financial assets are difficult to estimate from historical price series, which are nonstationary and volatile. Therefore, we resort to textual knowledge hidden behind the huge amount of unstructured market information produced by human beings. In fact, one of the central research topics of this book include incorporating natural language processing techniques into several asset allocation models and finding the proper variables in financial models that naturally link to the contents of financial reports and the market sentiment.New perspectives investigated in the book extend the current framework of the Markowitz model and the Black-Litterman model by re-thinking asset expected returns and asset correlations. Instead of relying on the price series themselves, external information can be used. We try to inject into these two concepts new connotations—asset expected returns and asset correlations not in terms of numerical calculation but in terms of what we know about the assets. Both sub-symbolic AI and symbolic AI approaches are explored in this book, for semantic linkage and market view modeling, which are associated with key variables in asset allocation models.",https://www.academia.edu/download/109884126/bfm_978-3-030-30263-4_2F1.pdf
Erik Cambria,Sentic Neurons: Expanding Intention Awareness,2020,,3,"Newton Howard, Erik Cambria",Newton Howard,Erik Cambria,2,"Embodiments of the present invention may provide techniques to create a new framework by this invention applying the theory of Sentic Computing. For example, in an embodiment of the present invention, a computer-implemented method for data analysis may comprise receiving input data representing circumstantial semantics, processing the received input data representing circumstantial semantics with Intention Awareness processing, receiving input data representing conceptual and affective information associated with objects and actors of the operating environment, processing the received input data representing conceptual and affective information associated with objects and actors of the operating environment with Sentic Computing, generating a mapping of the Intention Awareness processing data to a first multi-dimensional coordinate vector, generating a mapping of the Sentic Computing processed …",https://patents.google.com/patent/US10846601B1/en
Erik Cambria,Discrete Classification of Upper Limb Motions Using Myoelectric Interface,2015,Proceedings of ICORR,3,"Chris Wilson Antuvan, Federica Bisio, Erik Cambria, Lorenzo Masia",Chris Wilson Antuvan,Lorenzo Masia,4,"Electromyografic signals offer insights into understanding the intent and extent of motion of the musculoskeletal system. This information could be utilized in developing controllers for applications such as prostheses and orthosis, and in general assistive technology. This paper presents a myoelectric based interface to control five discrete upper limb motions involving the shoulder and elbow joint. Four subjects performed the experiment, which consisted of two separate phases: the training and testing phase. Extreme Learning Machine algorithm is used to classify the myoelectric signals to the control motions. The data collected during the training phase is used to train the parameters of the decoder, and the data from the testing phase is used to quantify the performance of the decoder. The muscle activations of each subject are used to manipulate a virtual human avatar. The graphical visualization serves to provide …",https://ieeexplore.ieee.org/abstract/document/7281241/
Erik Cambria,Recent Trends of Multimodal Affective Computing: A Survey from NLP Perspective,2025,arXiv preprint arXiv:2409.07388,2,"Guimin Hu, Yi Xin, Weimin Lyu, Haojian Huang, Chang Sun, Zhihong Zhu, Lin Gui, Ruichu Cai, Erik Cambria, Hasti Seifi",Guimin Hu,Hasti Seifi,10,"Multimodal affective computing (MAC) has garnered increasing attention due to its broad applications in analyzing human behaviors and intentions, especially in text-dominated multimodal affective computing field. This survey presents the recent trends of multimodal affective computing from NLP perspective through four hot tasks: multimodal sentiment analysis, multimodal emotion recognition in conversation, multimodal aspect-based sentiment analysis and multimodal multi-label emotion recognition. The goal of this survey is to explore the current landscape of multimodal affective research, identify development trends, and highlight the similarities and differences across various tasks, offering a comprehensive report on the recent progress in multimodal affective computing from an NLP perspective. This survey covers the formalization of tasks, provides an overview of relevant works, describes benchmark datasets, and details the evaluation metrics for each task. Additionally, it briefly discusses research in multimodal affective computing involving facial expressions, acoustic signals, physiological signals, and emotion causes. Additionally, we discuss the technical approaches, challenges, and future directions in multimodal affective computing. To support further research, we released a repository that compiles related works in multimodal affective computing, providing detailed resources and references for the community.",https://arxiv.org/abs/2409.07388
Erik Cambria,XTime: A General Rule-based Method for Time Expression Recognition and Normalization,2024,Knowledge-Based Systems,2,"Xiaoshi Zhong, Chenyu Jin, Mengyu An, Erik Cambria",Xiaoshi Zhong,Erik Cambria,4,"Time expression (a.k.a., timex) recognition and normalization (TERN) is a crucial task for downstream research. However, previous studies have overlooked the critical characteristics of timexes that significantly impact the task. To gain deeper insights, we conduct an analysis across four diverse English datasets to examine the key attributes of timex constituents. Our analysis reveals several noteworthy observations, such as: timexes tend to very short; the majority of timexes contain time tokens; there exist strong mapping relationships between time tokens and timex types; there exists a priority relationship among timex types; and timex values exhibit only some standard formats. Based on these insights, we propose a novel general rule-based method termed XTime1 to recognize timexes from free text and normalize them into standard formats. Notably, XTime’s rules are designed in a general and heuristic manner …",https://www.sciencedirect.com/science/article/pii/S0950705124005550
Erik Cambria,A Cognitive Analysis of CEO Speeches and Their Effects on Stock Markets,2024,Proceedings of the International Conference on Financial Technology,2,"Rohan Manro, Rui Mao, Liza Dahiya, Yu Ma, Erik Cambria",Rohan Manro,Erik Cambria,5,"The cognitive state of a CEO can have a great impact on the company’s operational results and stock market performance. Conventional cognitive analysis often relies on interviews with cognitive scientists or psychologists, which are not readily scalable for big data applications in finance. In this work, we leverage a novel method to analyze the cognitive states of top-tier managers of 14 well-known companies. We analyze the concept mappings from their speeches and metaphorical expressions over 15 years. We also conduct breakdown analysis for the concept mappings, according to the trends of stock prices. We identify four distinct types of stock market performance and illustrate the featured concept mappings associated with each category. These representative concept mappings reflect the cognitive states of CEOs and provide insights into which cognitive states are most likely to correlate with positive stock market performance.",http://ww.sentic.net/cognitive-analysis-of-ceo-speeches-and-their-effects-on-stock-markets.pdf
Erik Cambria,Negation Blindness in Large Language Models: Unveiling the ‘NO Syndrome’ in Image Generation,2024,AI Open,2,"Mohammad Nadeem, Shahab Saquib Sohail, Erik Cambria, Björn Schuller, Amir Hussain",Mohammad Nadeem,Amir Hussain,5,"Foundational Large Language Models (LLMs) have changed the way we perceive technology. They have been shown to excel in tasks ranging from poem writing and coding to essay generation and puzzle solving. With the incorporation of image generation capability, they have become more comprehensive and versatile AI tools. At the same time, researchers are striving to identify the limitations of these tools to improve them further. Currently identified flaws include hallucination, biases, and bypassing restricted commands to generate harmful content. In the present work, we have identified a fundamental limitation related to the image generation ability of LLMs, and termed it The NO Syndrome. This negation blindness refers to LLMs inability to correctly comprehend NO related natural language prompts to generate the desired images. Interestingly, all tested LLMs including GPT-4, Gemini, and Copilot were found to be suffering from this syndrome. To demonstrate the generalization of this limitation, we carried out simulation experiments and conducted entropy-based and benchmark statistical analysis tests on various LLMs in multiple languages, including English, Hindi, and French. We conclude that the NO syndrome is a significant flaw in current LLMs that needs to be addressed. A related finding of this study showed a consistent discrepancy between image and textual responses as a result of this NO syndrome. We posit that the introduction of a negation context-aware reinforcement learning based feedback loop between the LLMs textual response and generated image could help ensure the generated text is based on both the LLMs …",https://arxiv.org/abs/2409.00105
Erik Cambria,Explainable Stock Price Movement Prediction using Contrastive Learning,2024,Proceedings of CIKM,2,"Kelvin Du, Rui Mao, Frank Xing, Erik Cambria",Kelvin Du,Erik Cambria,4,"Predicting stock price movements is a high-stakes task that demands explainability for human decision-makers. A key shortcoming in current methods is treating sub-predictions independently, without learning from accumulated experiences. We propose a novel triplet network for contrastive learning to enhance the explainability of stock movement prediction by considering instances of ""integrated textual information and quantitative indicators"". We refer to the target past-l-day tweet-price time series as the ""anchor instance"". Each anchor instance is paired with a ""positive instance"" characterized by highly correlated return trends yet significant differences across the entire feature space, and a ""negative instance"" that exhibits similar return trends along with high proximity in the feature space. The model is designed with the objective of (1) minimizing the cross entropy loss between input logits and target, (2) minimizing …",https://dl.acm.org/doi/abs/10.1145/3627673.3679544
Erik Cambria,AdaCLF: An Adaptive Curriculum Learning Framework for Emotional Support Conversation,2024,IEEE Intelligent Systems,2,"Geng Tu, Taiyu Niu, Ruifeng Xu, Bin Bin Liang, Erik Cambria",Geng Tu,Erik Cambria,5,"Emotional support conversation (ESC) aims to alleviate emotional distress using data-driven approaches trained on human-generated responses. However, the subjective and open-ended nature of human conversations presents challenges in training ESC models due to uneven complexities in query–response pairs. This uneven complexity impedes the efficiency and effectiveness of learning in ESC models. Based on this, we propose an adaptive curriculum learning framework (AdaCLF) to dynamically choose courses of varying complexity according to the learning status of the ESC model. AdaCLF consists of two main components: the student model (referred to as the ESC model) and the teacher model (responsible for selecting appropriate data to enhance the student model’s training). The framework operates within the reinforcement learning paradigm, where the teacher model utilizes feedback from the …",https://ieeexplore.ieee.org/abstract/document/10614927/
Erik Cambria,Predicting Word Vectors for Microtext,2024,Expert Systems,2,"Iti Chaturvedi, Ranjan Satapathy, Curtis Lynch, Erik Cambria",Iti Chaturvedi,Erik Cambria,4,"The use of computer‐mediated communication has resulted in a new form of written text called Microtext, which is very different from well‐written text. Most previous approaches deal with microtext at the character level rather than just words resulting in increased processing time. In this paper, we propose to transform static word vectors to dynamic form by modelling the effect of neighbouring words and their sentiment strength in the AffectiveSpace. To evaluate the approach, we crawled Tweets from diverse topics and human annotation was used to label their sentiments. We also normalized the tweets to fix phonetic variations, spelling errors, and abbreviations manually. A total of 1432 out‐of‐vocabulary (OOV) texts and their IV texts made it to the final corpus with their corresponding polarity. To assess the quality of the corpus, we used several OOV classifiers such as linear regression and observed over 90 …",https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13589
Erik Cambria,Text-based Personality Prediction Using XLNet,2024,,2,"Ashok Kumar Jayaraman, Gayathri Ananthakrishnan, Tina Esther Trueman, Erik Cambria",Ashok Kumar Jayaraman,Erik Cambria,4,"Personality is a dynamic and organized set of characteristics that distinguish a person in thinking patterns, behaviors, emotions, and motivations based on biological and environmental factors. In particular, personality is a broad subject that is widely studied in various domains such as mental healthcare, web intelligence, and recommendation systems. Traditionally, researchers used psychology methods via psycholinguistic approaches (word counting in specific texts) to identify personality. Recently, social media data have been used for studies on personality. Psychologists and scientists are determining the personality of a person with the Myers–Briggs Type Indicator (MBTI) and Big Five model. Moreover, transformers-based models have shown better results in natural language processing tasks with context-dependent features. In this chapter, we propose a text-based personality prediction system using XLNet …",https://www.sciencedirect.com/science/article/pii/S0065245823000542
Erik Cambria,Entri: Ensemble Learning with Tri-Level Representations for Explainable Scene Recognition,2023,"Social Science Research Network, 4482110",2,"Amirhossein Aminimehr, Amirali Molaei, Erik Cambria",Amirhossein Aminimehr,Erik Cambria,3,"Scene recognition based on deep-learning has made significant progress, but there are still limitations in its performance due to challenges posed by inter-class similarities and intra-class dissimilarities. Furthermore, prior research has primarily focused on improving classification accuracy, yet it has given less attention to achieving interpretable, precise scene classification. Therefore, we are motivated to propose EnTri, an ensemble scene recognition framework that employs ensemble learning using a hierarchy of visual features. EnTri represents features at three distinct levels of detail: pixel-level, semantic segmentation-level, and object class and frequency level. By incorporating distinct feature encoding schemes of differing complexity and leveraging ensemble strategies, our approach aims to improve classification accuracy while enhancing transparency and interpretability via visual and textual explanations. To achieve interpretability, we devised an extension algorithm that generates both visual and textual explanations highlighting various properties of a given scene that contribute to the final prediction of its category. This includes information about objects, statistics, spatial layout, and textural details. Through experiments on benchmark scene classification datasets, EnTri has demonstrated superiority in terms of recognition accuracy, achieving competitive performance compared to state-of-the-art approaches, with an accuracy of 87.69%, 75.56%, and 99.17% on the MIT67, SUN397, and UIUC8 datasets, respectively.",https://arxiv.org/abs/2307.12442
Erik Cambria,Selecting Language Models Features via Software-Hardware Co-Design,2023,Proceedings of IEEE ICASSP,2,"Vlad Pandelea, Edoardo Ragusa, Paolo Gastaldo, Erik Cambria",Vlad Pandelea,Erik Cambria,4,"The availability of new datasets and deep learning techniques have led to a surge of effort directed towards the creation of new models that can exploit the large amount of data. However, little attention has been given to the development of models that are not only accurate, but also suitable for user-specific use or geared towards resource-constrained devices. Fine-tuning deep models on edge devices is impractical and, often, user customization stands on the sub-optimal feature-extractor/classifier paradigm. Here, we propose a method to fully utilize the intermediate outputs of the popular large pre-trained models in natural language processing when used as frozen feature extractors, and further close the gap between their fine-tuning and more computationally efficient solutions. We reach this goal exploiting the concept of software-hardware co-design and propose a methodical procedure, inspired by Neural …",https://ieeexplore.ieee.org/abstract/document/10097191/
Erik Cambria,A Hotel Ranking Model through Online Reviews with Aspect-Based Sentiment Analysis,2023,International Journal of Information Technology & Decision Making,2,"Tian-Hui You, Ling-Ling Tao, Erik Cambria",Tian-Hui You,Erik Cambria,3,"The number of online textual reviews on each hotel aspect can reflect the tourist preference difference on distinct aspects. Therefore, not only online textual reviews but their numbers have a significant impact on tourists’ hotel selection decisions. Motivated by this observation, this study proposes a hotel ranking model for hotel selection based on the sentiment analysis of online textual reviews by considering the differences in the number of reviews on different aspects. We explicitly model the differences in the number of reviews on aspects through the confidence interval estimation. In addition, the AS-Capsules model, which can jointly perform aspect detection and aspect-level sentiment classification with high accuracy, is employed for sentiment analysis. We conducted a case study on TripAdvisor.com, the experimental results show that our proposed model is able to effectively assist the tourists in making the …",https://www.worldscientific.com/doi/abs/10.1142/S0219622022500626
Erik Cambria,BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on Twitter,2023,Proceedings of ICDM Workshops,2,"Hasan Kemik, Nusret Özateş, Meysam Asgari-Chenaghlu, Yang Li, Erik Cambria",Hasan Kemik,Erik Cambria,5,"Protection of human rights is one of the most important problems of the modern world. In this paper, we construct a Twitter dataset that covers one of the most significant human rights contradiction in recent years which affected the whole world: the George Floyd incident. We propose a labeled dataset for topic detection that contains about 17 million tweets. These Tweets are collected from 25 May 2020 to 21 August 2020, covering about 90 days from the start of the incident. We labeled the dataset by monitoring most trending news topics from global and local newspapers and used TF-IDF and LDA as baselines. We evaluated the results of these two methods with three different k values for precision, recall and F1-score.",https://ieeexplore.ieee.org/abstract/document/10411619/
Erik Cambria,Marshall-Olkin Power-Law Distributions in Length-Frequency of Entities,2023,Knowledge-Based Systems,2,"Xiaoshi Zhong, Xiang Yu, Erik Cambria, Jagath Rajapakse",Xiaoshi Zhong,Jagath Rajapakse,4,"Entities involve important concepts with concrete meanings and play important roles in numerous linguistic tasks. Entities have different forms in different linguistic tasks and researchers treat those different forms as different concepts. In this paper, we are curious to know whether there are some common characteristics that connect those different forms of entities. Specifically, we investigate the underlying distributions of entities from different types and different languages, trying to figure out some common characteristics behind those diverse entities. After analyzing twelve datasets about different types of entities and eighteen datasets about entities in different languages, we find that while these entities are dramatically diverse from each other in many aspects, their length-frequencies can be well characterized by a family of Marshall–Olkin power-law (MOPL) distributions. We conduct experiments on those thirty …",https://www.sciencedirect.com/science/article/pii/S0950705123006925
Erik Cambria,Stress Identification in Online Social Networks,2022,Proceedings of ICDM Workshops,2,"Ashok J Kumar, Tina Esther Trueman, Erik Cambria",Ashok J Kumar,Erik Cambria,3,"Online social networks have become one of the primary ways of communication to individuals. It rapidly gen-erates a large volume of textual and non-textual data such as images, audio, and videos. In particular, textual data plays a vital role in detecting mental health-related problems such as stress, depression, anxiety, and emotional and behavioral disorders. In this paper, we identify the mental stress of online users in social networks using a transformers-based RoBERTa model and an autoregressive model, also called XLNet. We implement this model in both a constrained system and an unconstrained system. The constrained system maintains the gold standard datasets such as training, validation, and testing. On the other hand, the unconstrained system divides the given dataset into user-specific training, validation, and test sets. Our results indicate that the proposed transformers-based RoBERTa model …",https://ieeexplore.ieee.org/abstract/document/10031052/
Erik Cambria,DUSE: A New Benchmark Dataset for Drug User Sentiment Extraction,2021,Proceedings of ICDM Workshops,2,"Ashok J Kumar, Erik Cambria, Tina Esther Trueman",Ashok J Kumar,Tina Esther Trueman,3,"Social media continuously produce a huge volume of data in different formats and different domains. In particular, patients’ and caregivers’ written medical texts play an important role among individuals, medical doctors, and drug developers for understanding drug users’ sentiment. However, automatic sentiment detection is a challenging problem in medical settings due to a lack of data with age group, gender, treatment duration, and so on. Therefore, we present a drug review dataset for the most reviewed 100 drugs. Especially, we collected 88K instances from WebMD which is one of the largest online health service providers. Empirically, we explore strongly labeled data and weakly labeled data for automatic sentiment detection using BERT, which learns context-dependent features. We show that the BERT model yields better accuracy than the baseline models.",https://ieeexplore.ieee.org/abstract/document/9679908/
Erik Cambria,Data Analysis,2021,Time Expression and Named Entity Recognition,2,"Xiaoshi Zhong, Erik Cambria",Xiaoshi Zhong,Erik Cambria,2,"We analyze four diverse datasets about time expressions for their intrinsic characteristics and find five such common characteristics; similarly we analyze two well-known benchmark datasets about named entities for their intrinsic characteristics and find three such common characteristics. For the common characteristics of time expressions, firstly, most time expressions are very short, consisting of about 2 words on average; secondly, most time expressions contain at least one time-related word that can distinguish time expressions from common text; thirdly, only a small group of words are used to express time information; fourthly, words in time expressions demonstrate similar syntactic behaviour; and finally, time expressions are formed by loose structure, with more than 53.5% of time tokens appearing in different positions within time expressions. For the common characteristics of named entities, firstly, most …",https://link.springer.com/chapter/10.1007/978-3-030-78961-9_3
Erik Cambria,COAL: Convolutional Online Adaptation Learning for Opinion Mining,2020,Proceedings of ICDM Workshops,2,"Iti Chaturvedi, Edoardo Ragusa, Paolo Gastaldo, Erik Cambria",Iti Chaturvedi,Erik Cambria,4,"Thanks to recent advances in machine learning, some say AI is the new engine and data is the new coal. Mining this ‘coal’ from the ever-growing Social Web, however, can be a formidable task. In this work, we address this problem in the context of sentiment analysis using convolutional online adaptation learning (COAL). In particular, we consider semi-supervised learning of convolutional features, which we use to train an online model. Such a model, which can be trained in one domain but also used to predict sentiment in other domains, outperforms the baseline in the range of 5-20%.",https://ieeexplore.ieee.org/abstract/document/9346448/
Erik Cambria,A Novel Non-Iterative Parameter Estimation Method for Interval Type-2 Fuzzy Neural Networks Based on a Dynamic Cost Function,2019,Proceedings of FUZZ-IEEE,2,"Mojtaba Ahmadieh Khanesar, Saima Hassan, Erik Cambria, Erdal Kayacan",Mojtaba Ahmadieh Khanesar,Erdal Kayacan,4,"Non-iterative methods for parameter estimation for interval type-2 neuro-fuzzy structure are fast to implement, when compared to online methods, and need no -or a few- parameters to be tuned. In this paper, a novel dynamic cost function, which defines a relationship between the current and past errors, is defined. The minimization of the aforementioned cost function results in a decreasing sequence of error which makes the proposed method numerically more stable when compared to least squares-based methods. It is a well-known phenomenon that a matrix inversion may cause problems if the matrix to be inverted is ill-defined i.e. its condition number is far bigger than one. The use of a dynamic relationship between the current and past error adds more degrees of freedom which makes it possible to improve the condition number of the matrix. Comprehensive simulation studies are presented for the prediction of …",https://ieeexplore.ieee.org/abstract/document/8858985/
Erik Cambria,Semantic Sentiment Analysis Challenge at ESWC2018,2018,"Semantic Web Challenges: 5th SemWebEval Challenge at ESWC 2018, Heraklion, Greece, June 3–7, 2018, Revised Selected Papers 5",2,"Mauro Dragoni, Erik Cambria",Mauro Dragoni,Erik Cambria,2,"Sentiment Analysis is a widely studied research field in both research and industry, and there are different approaches for addressing sentiment analysis related tasks. Sentiment Analysis engines implement approaches spanning from lexicon-based techniques, to machine learning, or involving syntactical rules analysis. Such systems are already evaluated in international research challenges. However, Semantic Sentiment Analysis approaches, which take into account or rely also on large semantic knowledge bases and implement Semantic Web best practices, are not under specific experimental evaluation and comparison by other international challenges. Such approaches may potentially deliver higher performance, since they are also able to analyze the implicit, semantics features associated with natural language concepts. In this paper, we present the fifth edition of the Semantic Sentiment Analysis …",https://link.springer.com/chapter/10.1007/978-3-030-00072-1_10
Erik Cambria,“Hang in There”: Lexical and Visual Analysis to Identify Posts Warranting Empathetic Responses,2017,Proceedings of FLAIRS,2,"Mimansa Jaiswal, Sairam Tabibu, Erik Cambria",Mimansa Jaiswal,Erik Cambria,3,"In the past few years, social media has risen as a platform where people express and share personal incidences about abuse, violence and mental health issues. There is a need to pinpoint such posts and learn the kind of response expected. For this purpose, we understand the sentiment that a personal story elicits on different posts present on different social media sites, on the topics of abuse or mental health. In this paper, we propose a method supported by hand-crafted features to judge if the post requires an empathetic response. The model is trained upon posts from various web-pages and corresponding comments, on both the captions and the images. We were able to obtain 80% accuracy in tagging posts requiring empathetic responses.",https://cdn.aaai.org/ocs/15505/15505-68677-1-PB.pdf
Erik Cambria,Sentic Computing: A Common-Sense-Based Framework for Concept-Level Sentiment Analysis,2015,,2,"Erik Cambria, Amir Hussain",Erik Cambria,Amir Hussain,2,,
Erik Cambria,Using Word Sense as a Latent Variable in LDA Can Improve Topic Modeling,2014,Proceedings of ICAART,2,"Yunqing Xia, Guoyu Tang, Huan Zhao, Erik Cambria, Thomas Fang Zheng",Yunqing Xia,Thomas Fang Zheng,5,"Since proposed, LDA have been successfully used in modeling text documents. So far, words are the common features to induce latent topic, which are later used in document representation. Observation on documents indicates that the polysemous words can make the latent topics less discriminative, resulting in less accurate document representation. We thus argue that the semantically deterministic word senses can improve quality of the latent topics. In this work, we proposes a series of word sense aware LDA models which use word sense as an extra latent variable in topic induction. Preliminary experiments on document clustering on benchmark datasets show that word sense can indeed improve topic modeling.",https://www.scitepress.org/PublishedPapers/2014/48897/
Erik Cambria,Disambiguating Word Sentiment Polarity Through Bayesian Modeling and Opinion-Level Features,2014,Proceedings of ICML Workshops,2,"Yunqing Xia, Huan Zhao, Erik Cambria, Amir Hussain",Yunqing Xia,Amir Hussain,4,"Many opinion words carry different polarity in different context, posing huge challenges to sentiment analysis research. Previous work on contextual polarity disambiguation makes use of term-level context such as word and patterns, and resolves the polarity with patternbased methods, PMI-based statistical techniques and machine learning methods. The major shortcoming of all such approaches lies in that termlevel features are sometimes ineffective in resolving the polarity. In this work, opinion-level features are studied and a Bayesian model is designed to disambiguate word sentiment polarity. Experiments with Opinmine corpus show that the opinion-level Bayesian model achieves significant performance gain in word polarity disambiguation in two domains.",http://sentic.net/wisdom2014xia.pdf
Erik Cambria,Sentic Neural Networks: A Novel Cognitive Model for Affective Common Sense Reasoning,2012,,2,"Thomas Mazzocco, Erik Cambria, Amir Hussain, Qiu-Feng Wang",Thomas Mazzocco,Qiu-Feng Wang,4,"In human cognition, the capacity to reason and make decisions is strictly dependent on our common sense knowledge about the world and our inner emotional states: we call this ability affective common sense reasoning. In previous works, graph mining and multi-dimensionality reduction techniques have been employed in attempt to emulate such a process and, hence, to semantically and affectively analyze natural language text. In this work, we exploit a novel cognitive model based on the combined use of principal component analysis and artificial neural networks to perform reasoning on a knowledge base obtained by merging a graph representation of common sense with a linguistic resource for the lexical representation of affect. Results show a noticeable improvement in emotion recognition from natural language text and pave the way for more bio-inspired approaches to the emulation of affective …",https://link.springer.com/chapter/10.1007/978-3-642-31561-9_2
Erik Cambria,MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses,2025,arXiv preprint arXiv:2410.07076,1,"Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou",Zonglin Yang,Dongzhan Zhou,9,"Scientific discovery contributes largely to human society's prosperity, and recent progress shows that LLMs could potentially catalyze this process. However, it is still unclear whether LLMs can discover novel and valid hypotheses in chemistry. In this work, we investigate this central research question: Can LLMs automatically discover novel and valid chemistry research hypotheses given only a chemistry research background (consisting of a research question and/or a background survey), without limitation on the domain of the research question? After extensive discussions with chemistry experts, we propose an assumption that a majority of chemistry hypotheses can be resulted from a research background and several inspirations. With this key insight, we break the central question into three smaller fundamental questions. In brief, they are: (1) given a background question, whether LLMs can retrieve good inspirations; (2) with background and inspirations, whether LLMs can lead to hypothesis; and (3) whether LLMs can identify good hypotheses to rank them higher. To investigate these questions, we construct a benchmark consisting of 51 chemistry papers published in Nature, Science, or a similar level in 2024 (all papers are only available online since 2024). Every paper is divided by chemistry PhD students into three components: background, inspirations, and hypothesis. The goal is to rediscover the hypothesis, given only the background and a large randomly selected chemistry literature corpus consisting the ground truth inspiration papers, with LLMs trained with data up to 2023. We also develop an LLM-based multi-agent framework that …",https://arxiv.org/abs/2410.07076
Erik Cambria,Explainable Natural Language Processing for Corporate Sustainability Analysis,2025,Information Fusion,1,"Keane Ong, Rui Mao, Ranjan Satapathy, Erik Cambria, Johan Sulaeman, Gianmarco Mengaldo",Keane Ong,Gianmarco Mengaldo,6,"Sustainability commonly refers to entities, such as individuals, companies, and institutions, having a non-detrimental (or even positive) impact on the environment, society, and the economy. With sustainability becoming a synonym of acceptable and legitimate behaviour, it is being increasingly demanded and regulated. Several frameworks and standards have been proposed to measure the sustainability impact of corporations, including United Nations’ sustainable development goals and the recently introduced global sustainability reporting framework, amongst others. However, the concept of corporate sustainability is complex due to the diverse and intricate nature of firm operations (i.e. geography, size, business activities, interlinks with other stakeholders). As a result, corporate sustainability assessments are plagued by subjectivity both within data that reflect corporate sustainability efforts (i.e. corporate …",https://www.sciencedirect.com/science/article/pii/S1566253524005049
Erik Cambria,Detecting Signs of Depression using Social Media Texts through an Ensemble of Ensemble Classifiers,2025,IEEE Transactions on Affective Computing,1,"Raymond Chiong, Gregorius Satia Budhi, Erik Cambria",Raymond Chiong,Erik Cambria,3,"Artificial intelligence-based machine learning models have been widely used to explore and address various mental health-related problems in recent years, including depression. In this study, we present an ensemble approach to complement the 90 unique input features that we proposed in a previous study on depression detection using social media texts. Our proposed Ensemble of Ensemble Classifiers (EECs) combines many ensemble models, including Bagging Predictors, Random Forests,",http://ww.sentic.net/detecting-signs-of-depression.pdf
Erik Cambria,Neurosymbolic AI for Mining Key Aspects of Socially Responsible Investing,2024,Proceedings of ICDM Workshops,1,"Wihan van der Heever, Ranjan Satapathy, Erik Cambria, Siow Mong Goh",Wihan van der Heever,Siow Mong Goh,4,"Environmental, Social, and Governance (ESG) factors have become critical for assessing corporate sustainability and ethical responsibility. However, the vast volume of unstructured data available across corporate reports, social media, and news sources poses a challenge for systematic ESG analysis. This paper explores the application of neurosymbolic AI, which combines neural networks’ pattern recognition capabilities with the structured reasoning of symbolic AI, to mine key aspects of ESG from large-scale, diverse data sources. By leveraging SenticNet for concept parsing and deep learning for sentiment analysis, we extract relevant ESG metrics, classify corporate practices, and identify trends. This hybrid approach enhances both the interpretability and scalability of ESG analysis, providing more accurate insights into corporate behaviors and their impact on sustainability goals. Results demonstrate that neurosymbolic AI not only improves the extraction of meaningful ESG aspects but also enables real-time monitoring, supporting data-driven decision-making for investors, regulators, and stakeholders.",https://sentic.net/ai-for-socially-responsible-investing.pdf
Erik Cambria,Prompted Aspect Key Point Analysis for Quantitative Review Summarization,2024,Proceedings of ACL,1,"An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Erik Cambria",An Quang Tang,Erik Cambria,4,"Key Point Analysis (KPA) aims for quantitative summarization that provides key points (KPs) as succinct textual summaries and quantities measuring their prevalence. KPA studies for arguments and reviews have been reported in the literature. A majority of KPA studies for reviews adopt supervised learning to extract short sentences as KPs before matching KPs to review comments for quantification of KP prevalence. Recent abstractive approaches still generate KPs based on sentences, often leading to KPs with overlapping and hallucinated opinions, and inaccurate quantification. In this paper, we propose Prompted Aspect Key Point Analysis (PAKPA) for quantitative review summarization. PAKPA employs aspect sentiment analysis and prompted in-context learning with Large Language Models (LLMs) to generate and quantify KPs grounded in aspects for business entities, which achieves faithful KPs with accurate quantification, and removes the need for large amounts of annotated data for supervised training. Experiments on the popular review dataset Yelp and the aspect-oriented review summarization dataset SPACE show that our framework achieves state-of-the-art performance. Source code and data are available at: https://github.com/antangrocket1312/PAKPA",https://arxiv.org/abs/2407.14049
Erik Cambria,Through the MUD: A Multi-Defendant Charge Prediction Benchmark with Linked Crime Elements,2024,Proceedings of ACL,1,"Xiao Wei, Xu Qi, Hang Yu, Qian Liu, Erik Cambria",Xiao Wei,Erik Cambria,5,"The current charge prediction datasets mostly focus on single-defendant criminal cases. However, real-world criminal cases usually involve multiple defendants whose criminal facts are intertwined. In an early attempt to fill this gap, we introduce a new benchmark that encompasses legal cases involving multiple defendants, where each defendant is labeled with a charge and four types of crime elements, ie, Object Element, Objective Element, Subject Element, and Subjective Element. Based on the dataset, we further develop an interpretable model called EJudge that incorporates crime elements and legal rules to infer charges. We observe that predicting crime charges while providing corresponding rationales benefits the interpretable AI system. Extensive experiments show that EJudge significantly surpasses state-of-the-art methods, which verify the importance of crime elements and legal rules in multi-defendant charge prediction. The source code and dataset are available at https://anonymous. 4open. science/r/MCP_1-6010.",https://aclanthology.org/2024.acl-long.158/
Erik Cambria,Explainable AI for Stress and Depression Detection in the Cyberspace and Beyond,2024,Proceedings of PAKDD Workshops,1,"Erik Cambria, Balázs Gulyás, Joyce S Pang, Nigel V Marsh, Mythily Subramaniam",Erik Cambria,Mythily Subramaniam,5,"Stress and depression have emerged as prevalent challenges in contemporary society, deeply intertwined with the complexities of modern life. This paper delves into the multifaceted nature of these phenomena, exploring their intricate relationship with various socio-cultural, technological, and environmental factors through the application of neurosymbolic AI to social media content. Through a quantitative and qualitative analysis of results, we elucidate the profound impact of technological advancements on information processing, work culture, and social dynamics, highlighting the role of digital connectivity in exacerbating stressors. Economic pressures and social isolation further compound these challenges, contributing to a pervasive sense of unease and disconnection. Environmental stressors, including climate change, add another layer of complexity, fostering existential concerns about the future. Moreover …",https://link.springer.com/chapter/10.1007/978-981-97-2650-9_9
Erik Cambria,Arabic Text Classification based on Analogical Proportions,2024,Expert Systems,1,"Myriam Bounhas, Bilel Elayeb, Amina Chouigui, Amir Hussain, Erik Cambria",Myriam Bounhas,Erik Cambria,5,"Text classification is the process of labelling a given set of text documents with predefined classes or categories. Existing Arabic text classifiers are either applying classic Machine Learning algorithms such as k‐NN and SVM or using modern deep learning techniques. The former are assessed using small text collections and their accuracy is still subject to improvement while the latter are efficient in classifying big data collections and show limited effectiveness in classifying small corpora with a large number of categories. This paper proposes a new approach to Arabic text classification to treat small and large data collections while improving the classification rates of existing classifiers. We first demonstrate the ability of analogical proportions (AP) (statements of the form ‘x is to  as  is to ’), which have recently been shown to be effective in classifying ‘structured’ data, to classify ‘unstructured’ text documents …",https://onlinelibrary.wiley.com/doi/abs/10.1111/exsy.13609
Erik Cambria,"MICE: A Crosslinguistic Emotion Corpus in Malay, Indonesian, Chinese and English",2024,Proceedings of PAKDD Workshops,1,"Ng Bee Chin, Yosephine Susanto, Erik Cambria",Ng Bee Chin,Erik Cambria,3,"MICE is a corpus of emotion words in four languages which is currently working progress. There are two sections to this study, Part I: Emotion word corpus and Part II: Emotion word survey. In Part 1, the method of how the emotion data is culled for each of the four languages will be described and very preliminary data will be presented. In total, we identified 3,750 emotion expressions in Malay, 6,657 in Indonesian, 3,347 in Mandarin Chinese and 8,683 in English. We are currently evaluating and double checking the corpus and doing further analysis on the distribution of these emotion expressions. Part II Emotion word survey involved an online language survey which collected information on how speakers assigned the emotion words into basic emotion categories, the rating for valence and intensity as well as biographical information of all the respondents.",https://arxiv.org/abs/2106.04831
Erik Cambria,MRAC'23: 1st International Workshop on Multimodal and Responsible Affective Computing,2023,,1,"Zheng Lian, Erik Cambria, Guoying Zhao, Björn W Schuller, Jianhua Tao",Zheng Lian,Jianhua Tao,5,"Multimodal emotion recognition has become an important research topic due to its wide applications in human-computer interaction. Over the last few decades, the technology has made remarkable progress with the development of deep learning. However, existing technologies are hard to meet the demand for practical applications. To this end, we organize this workshop to bring together researchers in this field to further discuss recent research and future directions.",https://dl.acm.org/doi/abs/10.1145/3581783.3610936
Erik Cambria,Management Information Systems,2023,ACM Transactions on Management Information Systems,1,"Bibhuti Bhusan Mishra, D Ramesh, SS Kanhere, DR Edla, E Rubin, I Benbasat, K Du, F Xing, E Cambria, CEH Chua, F Niederman, M Siering",Bibhuti Bhusan Mishra,M Siering,12,"Cloud storage stimulated the interest of both industry and academic research communities due to its significant management, performance, and cost [1, 2]. Cloud users enjoy the outstanding services of cloud storage; however, it includes severe issues about the security of outsourced data [3, 4]. Specifically, the Cloud Service Provider (CSP) is an independent uncontrolled entity, so the outsourced data could be corrupted whenever CSP is malicious. For example, CSP may hide data loss or corruption incidents for reputation and produce forged proof-values to pass the auditing procedure with incorrect data intact for corrupted outsourced data. In most state-of-the-art models, users always encrypt the outsourced data, which is the most effective technique for ensuring data confidentiality. As in these models, the outsourced data is not under the direct control of users, and they are concerned about the integrity of the …",https://dl.acm.org/doi/pdf/10.1145/3605933
Erik Cambria,ALLEGET Keynote Remarks: Emerging Topics in Sentiment Analysis,2023,Proceedings of the International Conference on Intelligent Environments Workshops,1,Erik Cambria,Erik Cambria,Erik Cambria,1,"Sentiment analysis has become an indispensable tool in various domains, including e-business, e-commerce, e-tourism, e-mobility, e-governance, e-security, e-learning, and e-health. By analyzing public opinion and preferences, organizations and policymakers can make data-driven decisions to improve their products, services, and policies. The implementation of sentiment analysis across these domains not only enhances customer satisfaction and engagement but also contributes to the overall growth and development of these industries.",https://ebooks.iospress.nl/volumearticle/63285
Erik Cambria,Making Sense of Sentiments for Aesthetic Plastic Surgery,2022,Proceedings of ICDM Workshops,1,"Anand Choudhary, Erik Cambria",Anand Choudhary,Erik Cambria,2,"With social media pervading all aspects of our life, the opinions expressed by netizens are a gold mine ready to be exploited in a meaningful way to influence all major public do-mains. Sentiment analysis is a way to interpret this unstructured data using AI tools. It is a well-known fact that there has been a 'Zoom Boom’ in the field of aesthetic plastic surgery due to the COVID-19 pandemic and the same has put the focus of attention sharply on our appearance. Polarity detection of tweets published on popular aesthetic plastic surgery procedures before and after the onset of COVID can provide great insights for aesthetic plastic surgeons and the health industry at large. In this work, we develop an end-to-end system for the sentiment analysis of such tweets incorporating a state-of-the-art fine-tuned deep learning model, an ingenious 'keyword search and filter approach’ and SenticNet. Our system was tested on a large …",https://ieeexplore.ieee.org/abstract/document/10031161/
Erik Cambria,Guest Editorial: A Decade of Sentic Computing,2022,Cognitive Computation,1,"Erik Cambria, Amir Hussain",Erik Cambria,Amir Hussain,2,"The opportunity to capture the opinions of the general public has raised growing interest both within the scientific community, leading to many exciting open challenges, and in the business world due to the remarkable range of benefits envisaged, including from marketing, business intelligence, and financial prediction. Mining opinions and sentiments from natural language, however, is an extremely difficult task as it involves a deep understanding of most of the explicit and implicit, regular and irregular, syntactical and semantic rules appropriate of a language. Existing approaches to sentiment analysis mainly rely on parts of text in which opinions are explicitly expressed such as polarity terms, affect words, and their co-occurrence frequencies. However, opinions and sentiments are often conveyed implicitly through latent semantics, which make purely syntactical approaches ineffective. Concept-level approaches …",https://link.springer.com/article/10.1007/s12559-021-09972-0
Erik Cambria,An Attention-Based Model for Learning Dynamic Interaction Networks,2018,Proceedings of IJCNN,1,"Sandro Cavallari, Vincent W Zheng, Hongyun Cai, Erik Cambria",Sandro Cavallari,Erik Cambria,4,"In the physical world, complex systems are generally created as the composition of multiple primitive components that interact with each other rather than a single monolithic structure. Recently, spatio-temporal graphs received a reasonable amount of attention from the research community since they emerged as a natural representational tool able to capture the interactive and interrelated structure of a complex problem. To better understand the nature of complex systems, there is the need to define models that can easily explain the learned causal relationship. To this end, we propose an attentive model able to learn and project the relational structure into a fixed-size embedding. Such representation naturally captures the dynamic influence that each neighbors exert over a given vertex providing a valuable description of the problem setting. The proposed architecture has been extensively evaluated against strong …",https://ieeexplore.ieee.org/abstract/document/8852191/
Erik Cambria,Efficient Semantic Search over Structured Web Data: A GPU Approach,2017,Proceedings of CICLing,1,"Ha-Nguyen Tran, Erik Cambria, Hoang Giang Do",Ha-Nguyen Tran,Hoang Giang Do,3,"Semantic search is an advanced topic in information retrieval which has attracted increasing attention in recent years. The growing availability of structured semantic data offers opportunities for semantic search engines, which can support more expressive queries able to address complex information needs. However, due to the fact that many new concepts (mined from the Web or learned through crowd-sourcing) are continuously integrated into knowledge bases, those search engines face the challenging performance issue of scalability. In this paper, we present a parallel method, termed gSparql, which utilizes the massive computation power of general-purpose GPUs to accelerate the performance of query processing and inference. Our method is based on the backward-chaining approach which makes inferences at query time. Experimental results show that gSparql outperforms the state-of-the-art …",https://link.springer.com/chapter/10.1007/978-3-319-77116-8_41
Erik Cambria,Commonsense Knowledge as the Glue in a Hybrid Model of Computational Creativity,2014,Proceedings of ICDM Workshops,1,"Andres Gomez de Silva Garza, Erik Cambria, Rafael Perez Y Perez",Andres Gomez de Silva Garza,Rafael Perez Y Perez,3,"In this paper, we describe on-going work on the ensemble of two models for computational creativity using commonsense knowledge. The GENCAD model of computational creativity proposes the use of an evolutionary algorithm (EA) that employs a population of exemplars as a starting point for its search, unlike traditional EAs, which employ a randomly-generated initial population. The EA, operating on this population, is then used to generate new potentially creative solutions. GENCAD has been instantiated in the domains of structural design of tall buildings and feng shui-compliant residential floor-plan design. The MEXICA model of computational creativity also begins with a set of exemplars as a starting point, but it analyzes these exemplars based on a domain theory. The generalized model that is obtained from analyzing the set of exemplars is then used to guide the generation of new solutions. MEXICA has …",https://ieeexplore.ieee.org/abstract/document/7022619/
Erik Cambria,Collective Copyright: Enabling the Natural Evolution of Content Creation in the Web Era,2014,Proceedings of WWW Workshops,1,"Emanuele Lunadei, Christian Valdivia Torres, Erik Cambria",Emanuele Lunadei,Erik Cambria,3,"The way people create and share content has radically changed in the past few years thanks to the advent of social networks, web communities, blogs, wikis, and other online collaborative media. Such online social data are continuously growing in a way that makes it difficult to efficiently aggregate them, since they are the expression of a multitude of single content creators that most of the times show only a small percentage of originality. The act of 'sharing' is still tied to a pre-Internet fashion that sees it as a step following (and never preceding) content creation, as enforced by the rules of publishing and copyright. In the Internet era, the pieces of the puzzle of a valuable work might be scattered throughout the whole Web. In order to hinder the obsolete create-then-share trend that is killing creativity and usefulness of the Web, we propose a novel concept of copyright, which allows content to be shared while being …",https://dl.acm.org/doi/abs/10.1145/2567948.2602197
Erik Cambria,WebSci@UHI: Teaching Web Science in a Web Science Fashion,2013,Proceedings of ICEL,1,"Erik Cambria, Ian Barnes, Elizabeth Brooks, Chris Eckl",Erik Cambria,Chris Eckl,4,"WebSci@ UHI is a new undergraduate course providing a thorough and comprehensive introduction to the technological, social, political, economic, and psychological aspects of the 20 years of the Web. It explores the breadth of disciplines that today contribute to Web Science research in a Web Science fashion, that is, through a novel approach to teaching that exploits recent Social Web technologies for delivering the course beyond space, time, and matter.",https://www.researchgate.net/profile/Charity-Ndeya-Ndereya/publication/288051189_Academic_staff's_challenges_in_adopting_blended_learning_Reality_at_a_developing_university/links/5d763cb6299bf1cb80935ec4/Academic-staffs-challenges-in-adopting-blended-learning-Reality-at-a-developing-university.pdf#page=525
Erik Cambria,Sentic Maxine: Multimodal Affective Fusion and Emotional Paths,2012,,1,"Isabelle Hupont, Erik Cambria, Eva Cerezo, Amir Hussain, Sandra Baldassarri",Isabelle Hupont,Sandra Baldassarri,5,"The capability of perceiving and expressing emotions through different modalities is a key issue for the enhancement of human-agent interaction. In this paper, an architecture for the development of intelligent multimodal affective interfaces is presented. It is based on the integration of Sentic Computing, a new opinion mining and sentiment analysis paradigm based on AI and Semantic Web techniques, with a facial emotional classifier and Maxine, a powerful multimodal animation engine for managing virtual agents and 3D scenarios. One of the main distinguishing features of the system is that it does not simply perform emotional classification in terms of a set of discrete emotional labels but it operates in a novel continuous 2D emotional space, enabling the output of a continuous emotional path that characterizes user’s affective progress over time. Another key factor is the fusion methodology proposed …",https://link.springer.com/chapter/10.1007/978-3-642-31362-2_61
Erik Cambria,Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses,,2nd AI4Research Workshop: Towards a Knowledge-grounded Scientific Research Lifecycle,1,"Zonglin Yang, Wanhao Liu, Ben Gao, Tong Xie, Yuqiang Li, Wanli Ouyang, Soujanya Poria, Erik Cambria, Dongzhan Zhou",Zonglin Yang,Dongzhan Zhou,9,"Scientific discovery contributes largely to the prosperity of human society, and recent progress shows that LLMs could potentially catalyst the process. However, it is still unclear whether LLMs can discover novel and valid hypotheses in chemistry. In this work, we investigate this main research question: whether LLMs can automatically discover novel and valid chemistry research hypotheses, given only a research question? With extensive discussions with chemistry experts, we adopt the assumption that a majority of chemistry hypotheses can be resulted from a research background question and several inspirations. With this key insight, we break the main question into three smaller fundamental questions. In brief, they are: (1) given a background question, whether LLMs can retrieve good inspirations; (2) with background and inspirations, whether LLMs can lead to hypothesis; and (3) whether LLMs can identify good hypotheses to rank them higher. To investigate these questions, we construct a benchmark consisting of 51 chemistry papers published in Nature or a similar level in 2024 (all papers are only available online since 2024). Every paper is divided by chemistry PhD students into three components: background, inspirations, and hypothesis. The goal is to rediscover the hypothesis given only the background and a large chemistry literature corpus consisting the ground truth inspiration papers, with LLMs trained with data up to 2023. We also develop an LLM-based multi-agent framework that leverages the assumption, consisting of three stages reflecting the more smaller questions. The proposed method can rediscover many hypotheses …",https://openreview.net/forum?id=8wahnrgLty
Erik Cambria,Insight at the Right Spot: Provide Decisive Subgraph Information to Graph LLM with Reinforcement Learning,2025,Information Fusion,0,"Tiesunlong Shen, Erik Cambria, Jin Wang, Yi Cai, Xuejie Zhang",Tiesunlong Shen,Xuejie Zhang,5,"Large language models (LLMs) cannot see or understand graphs. The current Graph LLM method transform graph structures into a format LLMs understands, utilizing LLM as a predictor to perform graph-learning task. However, these approaches have underperformed in graph-learning tasks. The issues arise because these methods typically rely on a fixed neighbor hop count for the target node set by expert experience, limiting the LLM’s access to only a certain range of neighbor information. Due to the black-box nature of LLM, it is challenging to determine which specific pieces of neighborhood information can effectively assist LLMs in making accurate inferences, which prevents LLMs from generating correct inferences. This study proposes to assist LLM in gaining insight at the right spot by providing decisive subgraph information to Graph LLM with reinforcement learning (Spider). A reinforcement subgraph …",https://www.sciencedirect.com/science/article/pii/S1566253524006389
Erik Cambria,Towards Rich Emotions in 3D Avatars: A Text-to-3D Avatar Generation Benchmark,2025,arXiv preprint arXiv:2412.02508,0,"Haidong Xu, Meishan Zhang, Hao Ju, Zhedong Zheng, Hongyuan Zhu, Erik Cambria, Min Zhang, Hao Fei",Haidong Xu,Hao Fei,8,"Producing emotionally dynamic 3D facial avatars with text derived from spoken words (Emo3D) has been a pivotal research topic in 3D avatar generation. While progress has been made in general-purpose 3D avatar generation, the exploration of generating emotional 3D avatars remains scarce, primarily due to the complexities of identifying and rendering rich emotions from spoken words. This paper reexamines Emo3D generation and draws inspiration from human processes, breaking down Emo3D into two cascading steps: Text-to-3D Expression Mapping (T3DEM) and 3D Avatar Rendering (3DAR). T3DEM is the most crucial step in determining the quality of Emo3D generation and encompasses three key challenges: Expression Diversity, Emotion-Content Consistency, and Expression Fluidity. To address these challenges, we introduce a novel benchmark to advance research in Emo3D generation. First, we present EmoAva, a large-scale, high-quality dataset for T3DEM, comprising 15,000 text-to-3D expression mappings that characterize the aforementioned three challenges in Emo3D generation. Furthermore, we develop various metrics to effectively evaluate models against these identified challenges. Next, to effectively model the consistency, diversity, and fluidity of human expressions in the T3DEM step, we propose the Continuous Text-to-Expression Generator, which employs an autoregressive Conditional Variational Autoencoder for expression code generation, enhanced with Latent Temporal Attention and Expression-wise Attention mechanisms. Finally, to further enhance the 3DAR step on rendering higher-quality subtle …",https://arxiv.org/abs/2412.02508
Erik Cambria,Discovering the Cognitive Bias of Toxic Language through Metaphorical Concept Mappings,2025,Cognitive Computation,0,"Mengshi Ge, Rui Mao, Erik Cambria",Mengshi Ge,Erik Cambria,3,,
Erik Cambria,Knowing What and Why: Causal Emotion Entailment for Emotion Recognition in Conversations,2025,Expert Systems with Applications,0,"Hao Liu, Runguo Wei, Geng Tu, Jiali Lin, Dazhi Jiang, Erik Cambria",Hao Liu,Erik Cambria,6,,
Erik Cambria,Towards Faithful Natural Language Explanations: A Study Using Activation Patching in Large Language Models,2025,arXiv preprint arXiv:2410.14155,0,"Wei Jie Yeo, Ranjan Satapthy, Erik Cambria",Wei Jie Yeo,Erik Cambria,3,"Large Language Models (LLMs) are capable of generating persuasive Natural Language Explanations (NLEs) to justify their answers. However, the faithfulness of these explanations should not be readily trusted at face value. Recent studies have proposed various methods to measure the faithfulness of NLEs, typically by inserting perturbations at the explanation or feature level. We argue that these approaches are neither comprehensive nor correctly designed according to the established definition of faithfulness. Moreover, we highlight the risks of grounding faithfulness findings on out-of-distribution samples. In this work, we leverage a causal mediation technique called activation patching, to measure the faithfulness of an explanation towards supporting the explained answer. Our proposed metric, Causal Faithfulness quantifies the consistency of causal attributions between explanations and the corresponding model outputs as the indicator of faithfulness. We experimented across models varying from 2B to 27B parameters and found that models that underwent alignment tuning tend to produce more faithful and plausible explanations. We find that Causal Faithfulness is a promising improvement over existing faithfulness tests by taking into account the model's internal computations and avoiding out of distribution concerns that could otherwise undermine the validity of faithfulness assessments. We release the code in \url{https://github.com/wj210/Causal-Faithfulness}",https://arxiv.org/abs/2410.14155
Erik Cambria,Natural Language Processing in Finance: A Survey,2025,Information Fusion,0,"Kelvin Du, Yazhi Zhao, Rui Mao, Frank Xing, Erik Cambria",Kelvin Du,Erik Cambria,5,"This survey presents an in-depth review of the transformative role of Natural Language Processing (NLP) in finance, highlighting its impact on ten major financial applications: (1) financial sentiment analysis, (2) financial narrative processing, (3) financial forecasting, (4) portfolio management, (5) question answering, virtual assistant and chatbot, (6) risk management, (7) regulatory compliance monitoring, (8) Environmental, Social, Governance (ESG) and sustainable finance, (9) explainable artificial intelligence (XAI) in finance and (10) NLP for digital assets. With the integration of vast amounts of unstructured financial data and advanced NLP techniques, the study explores how NLP enables data-driven decision-making and innovation in the financial sector, alongside the limitations and challenges. By providing a comprehensive analysis of NLP applications combining both academic and industrial perspectives, this …",https://www.sciencedirect.com/science/article/pii/S1566253524005335
Erik Cambria,Explainable and User-Controllable Profiles Including ChatGPT-Memory: Toward Better LLM Recommendations,2025,Available at SSRN 4982389,0,"Stanisław Woźniak, Sidney Suen, Bartłomiej Koptyra, Maria Kazienko-Sobczuk, Aleksander Szczęsny, Przemysław Kazienko, Jan Kocoń, Erik Cambria, Kenneth Kwok",Stanisław Woźniak,Kenneth Kwok,9,,
Erik Cambria,Learning Chain for Clause Awareness: Triplex-Contrastive Learning for Emotion Recognition in Conversations,2025,Neural Computing and Applications,0,"Jiazhen Liang, Wai Li, Qingshan Zhong, Jun Huang, Dazhi Jiang, Erik Cambria",Jiazhen Liang,Erik Cambria,6,,
Erik Cambria,A Comparative Analysis of Metaphorical Cognition in ChatGPT and Human Minds,2025,Cognitive Computation,0,"Rui Mao, Guanyi Chen, Xiao Li, Mengshi Ge, Erik Cambria",Rui Mao,Erik Cambria,5,"ChatGPT represents a significant advancement in the field of Artificial Intelligence (AI), showcasing the development of a robust AI system capable of multitasking and generating human-like language. At present, many scholars have done evaluations on ChatGPT in terms of language, reasoning, and scientific knowledge abilities, based on benchmarks or well-crafted questions. However, to the best of our knowledge, there is currently no existing comparative analysis from a cognitive perspective that directly assesses ChatGPT alongside humans. Metaphor, serving as a manifestation of linguistic creativity, provides a valuable avenue for examining cognition. This is due to the mapping relationship it establishes between the target and source conceptual domains, reflecting distinct cognitive patterns. In this paper, we use a metaphor processing tool, MetaPro, to analyze the cognitive differences between ChatGPT and …",https://link.springer.com/article/10.1007/s12559-024-10393-y
Erik Cambria,A Client-Server Based Recognition System: Non-Contact Single/Multiple Emotional and Behavioral State Assessment Methods,2025,Computer Methods and Programs in Biomedicine,0,"Xianxun Zhu, Zhaozhao Liu, Erik Cambria, Xiaohan Yu, Xuhui Fan, Hui Chen, Rui Wang",Xianxun Zhu,Rui Wang,7,"Background and Objectives: In the current global health landscape, there is an increasing demand for rapid and accurate assessment of mental states. Traditional assessment methods typically rely on face-to-face interactions, which are not only time-consuming but also highly subjective. Addressing this issue, this study aims to develop a client–server-based, non-contact multimodal emotion and behavior recognition system to enhance the efficiency and accuracy of mental state assessments.MethodsThis study designed and implemented a multimodal assessment system integrating voice, text, facial expressions, and body movements. Utilizing a client–server architecture, the system optimizes diagnostic efficiency and decision-making accuracy through an intuitive visual interface. The system’s effectiveness was validated and tested in actual hospital settings.ResultsThe system demonstrated exceptional …",https://www.sciencedirect.com/science/article/pii/S0169260724005571
Erik Cambria,Prompting Large Language Models for Few-Shot Named Entity Recognition,2025,Available at SSRN 4870736,0,"Xiaoshi Zhong, Yufei Zhao, Erik Cambria, Jagath C Rajapakse",Xiaoshi Zhong,Jagath C Rajapakse,4,,
Erik Cambria,ArabiziVec: A Set of Arabizi Word Embeddings for Informal Arabic Sentiment Analysis,2025,Expert Systems,0,"Asrita Venkata, Oumaima Oueslati, Erik Cambria, Yashvardhan Sharma",Asrita Venkata,Yashvardhan Sharma,4,"Authors’ addresses: Asrita Venkata Mandalam, BITS Pilani, Pilani Campus, Vidya Vihar, Pilani, India, f20171179@ pilani. bitspilani. ac. in; Oumaima Oueslati, SenticNet, Singapore, oummaymma@ gmail. com; Erik Cambria, Nanyang Technological University, Singapore, cambria@ ntu. edu. sg; Yashvardhan Sharma, BITS Pilani, Pilani Campus, Vidya Vihar, Pilani, India, yash@ pilani. bits-pilani. ac. in.",https://www.sentic.net/arabizivec.pdf
Erik Cambria,Gender Bias in Text-to-Video Generation Models: A case study of Sora,2024,arXiv preprint arXiv:2501.01987,0,"Mohammad Nadeem, Shahab Saquib Sohail, Erik Cambria, Björn W Schuller, Amir Hussain",Mohammad Nadeem,Amir Hussain,5,"The advent of text-to-video generation models has revolutionized content creation as it produces high-quality videos from textual prompts. However, concerns regarding inherent biases in such models have prompted scrutiny, particularly regarding gender representation. Our study investigates the presence of gender bias in OpenAI's Sora, a state-of-the-art text-to-video generation model. We uncover significant evidence of bias by analyzing the generated videos from a diverse set of gender-neutral and stereotypical prompts. The results indicate that Sora disproportionately associates specific genders with stereotypical behaviors and professions, which reflects societal prejudices embedded in its training data.",https://arxiv.org/abs/2501.01987
Erik Cambria,KE-RSIC: Remote Sensing Image Captioning Based on Knowledge Embedding,2024,IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing,0,"Kangda Cheng, Erik Cambria, Jinlong Liu, Yushi Chen, Zhilu Wu",Kangda Cheng,Zhilu Wu,5,"Current remote sensing image captioning (RSIC) methods often struggle to provide accurate and comprehensive descriptions due to their reliance on networks designed for natural images. Due to limited domain-specific knowledge in remote sensing, these networks often fail to accurately reflect the intrinsic semantic information of remote sensing categories. This paper proposes a novel Knowledge-Embedded Remote Sensing Image Captioning model (KE-RSIC). We first define two types of remote sensing knowledge: general knowledge within the field of remote sensing, and specific knowledge that is relevant to the input image. To acquire general knowledge, we construct a remote sensing knowledge graph and propose a general knowledge embedding method, enabling semantic correlations between entities and relationships in remote sensing knowledge graphs. The generated entity embeddings and …",https://ieeexplore.ieee.org/abstract/document/10818406/
Erik Cambria,MuSe'24: The 5th Multimodal Sentiment Analysis Challenge and Workshop: Social Perception & Humor,2024,,0,"Lukas Christ, Shahin Amiriparian, Andreas König, Simone Eulitz, Erik Cambria, Björn W Schuller",Lukas Christ,Björn W Schuller,6,"The 5th Multimodal Sentiment Analysis Challenge (MuSe), a workshop in conjunction with ACM Multimedia '24, is focused on Multimodal Machine Learning in the domain of Affective Computing. Two different sub-challenges are proposed: Social Perception Sub-Challenge(MuSe-Perception) is a regression task on 16 different perceived characteristics including arrogance, sincerity and likability. For this, the novel LMU-ELP dataset is introduced, consisting of short audiovisual recordings of 177 subjects annotated by MTurk workers. Cross-Cultural Humour Detection Sub-Challenge(MuSe-Humor) poses the problem of cross-cultural humor recognition. An extension of the Passau Spontaneous Football Coach Humour (Passau-SFCH) dataset featuring football coach press conference recordings is utilized in this task. The training set consists of German data, while the test data comprises English recordings only. In …",https://dl.acm.org/doi/abs/10.1145/3689062.3695939
Erik Cambria,MRAC'24 Track 2: 2nd International Workshop on Multimodal and Responsible Affective Computing,2024,,0,"Zheng Lian, Bin Liu, Rui Liu, Kele Xu, Erik Cambria, Guoying Zhao, Björn W Schuller, Jianhua Tao",Zheng Lian,Jianhua Tao,8,"MRAC'24 is the continuation of last year's MRAC'23. The main goal of this workshop is to promote the application of affective computing technology in real-world scenarios. We have equipped this workshop with MER'24 Challenge, which provides a platform for participants to fairly evaluate their algorithms. This year, we accepted 13 papers, including one baseline paper for MER'24. For the other 12 papers, 10 of them are related to MER'24 and 2 belong to the field of affective computing. Hope to see you at our workshop, which will be held on the afternoon of November 1st.",https://dl.acm.org/doi/abs/10.1145/3689092.3696103
Erik Cambria,Pragmatics Processing,2024,,0,Erik Cambria,Erik Cambria,Erik Cambria,1,"Pragmatics, situated in the domains of linguistics and computational linguistics, explores the influence of context on language interpretation, extending beyond the literal meaning of expressions. It constitutes a fundamental element for NLU in machine intelligence. In the current era dominated by LLMs, the research focus in NLU has predominantly shifted towards high-level task processing, inadvertently downplaying the importance of foundational pragmatic processing tasks. Nevertheless, pragmatics serves as a crucial medium for unraveling human language cognition. The exploration of Pragmatics Processing stands as a pivotal facet in realizing linguistic intelligence. This chapter encompasses important pragmatic processing techniques, namely: metaphor understanding, sarcasm detection, personality recognition, aspect extraction, and polarity detection. It spans theoretical research, the forefront of pragmatic …",https://link.springer.com/chapter/10.1007/978-3-031-73974-3_4
Erik Cambria,Natural Language Understanding & AI,2024,,0,Erik Cambria,Erik Cambria,Erik Cambria,1,"In this chapter, we delve into the critical role that natural language understanding (NLU) plays in shaping the future of artificial intelligence (AI). To set the stage, we begin by defining what constitutes an NLU system. Next, we explore how NLU can drive the evolution of next-generation AI systems, which promise to be more reliable, responsible, and personalized. To this end, we introduce the seven pillars for the future of AI, which represent the foundational elements necessary to advance AI technology in a way that is more transparent and reliable. Next, we propose the concept of responsible recommender systems, which incorporate ethical guidelines and user-centric principles to ensure recommendations are not only relevant but also fair, unbiased, and respectful of user privacy. Lastly, we present a framework for personalized sentiment analysis, which aims at making AI systems more responsive and attuned to …",https://link.springer.com/chapter/10.1007/978-3-031-73974-3_1
Erik Cambria,Syntactics Processing,2024,,0,Erik Cambria,Erik Cambria,Erik Cambria,1,"Computational syntactics processing is a fundamental technique in NLU. It normally serves as a preprocessing method to transform natural language into structured and normalized texts, yielding syntactic features for downstream task learning. This chapter proposes a systematic review of low-level syntactic processing techniques, namely: microtext normalization, sentence boundary disambiguation, POS tagging, text chunking, and lemmatization. In particular, we summarize and categorize widely used methods in the aforementioned syntactic analysis tasks, investigate the challenges, and yield possible research directions to overcome the challenges in future work.",https://link.springer.com/chapter/10.1007/978-3-031-73974-3_2
Erik Cambria,Knowledge Representation & Reasoning,2024,,0,Erik Cambria,Erik Cambria,Erik Cambria,1,"Commonsense knowledge acquisition and representation is a core topic in AI, which is crucial for building more sophisticated and human-like AI systems. Existing commonsense knowledge bases organize facts in an isolated manner, like bag of facts, lacking the cognitive-level connections that humans commonly possess. People have the ability to efficiently organize vast amounts of knowledge by linking or generalizing concepts using a limited set of conceptual primitives that serve as the fundamental building blocks of reasoning. Such primitives are basic, foundational elements of thought that humans use to make sense of the world. By combining and recombining these primitives, people can construct complex ideas, solve problems, and understand new concepts. In this chapter, we describe the development of a commonsense knowledge base, termed PrimeNet, to emulate this cognitive mechanism. PrimeNet …",https://link.springer.com/chapter/10.1007/978-3-031-73974-3_5
Erik Cambria,Semantics Processing,2024,,0,Erik Cambria,Erik Cambria,Erik Cambria,1,"Semantics processing is a fundamental research domain in computational linguistics. In the era of LLMs, the advancement of research in this domain appears to be decelerating. However, the study of semantics is multi-dimensional in linguistics. The research depth and breadth of semantics processing can be largely improved with new technologies. In this chapter, we analyze five semantic processing tasks: WSD, NER, concept extraction, anaphora resolution, and subjectivity detection.We survey theoretical research in these fields, advanced methods, and downstream applications, with the hope of encouraging scholars to focus on these fine-grained NLU tasks. The review of theoretical research may also inspire new tasks and technologies in this domain. Finally, we compare different semantic processing techniques and summarize their technical trends, application trends, and future directions.",https://link.springer.com/chapter/10.1007/978-3-031-73974-3_3
Erik Cambria,Understanding Public Opinion towards ESG and Green Finance with the Use of Explainable Artificial Intelligence,2024,Mathematics,0,"Wihan van der Heever, Ranjan Satapathy, Ji Min Park, Erik Cambria",Wihan van der Heever,Erik Cambria,4,"This study leverages explainable artificial intelligence (XAI) techniques to analyze public sentiment towards Environmental, Social, and Governance (ESG) factors, climate change, and green finance. It does so by developing a novel multi-task learning framework combining aspect-based sentiment analysis, co-reference resolution, and contrastive learning to extract nuanced insights from a large corpus of social media data. Our approach integrates state-of-the-art models, including the SenticNet API, for sentiment analysis and implements multiple XAI methods such as LIME, SHAP, and Permutation Importance to enhance interpretability. Results reveal predominantly positive sentiment towards environmental topics, with notable variations across ESG categories. The contrastive learning visualization demonstrates clear sentiment clustering while highlighting areas of uncertainty. This research contributes to the field by providing an interpretable, trustworthy AI system for ESG sentiment analysis, offering valuable insights for policymakers and business stakeholders navigating the complex landscape of sustainable finance and climate action. The methodology proposed in this paper advances the current state of AI in ESG and green finance in several ways. By combining aspect-based sentiment analysis, co-reference resolution, and contrastive learning, our approach provides a more comprehensive understanding of public sentiment towards ESG factors than traditional methods. The integration of multiple XAI techniques (LIME, SHAP, and Permutation Importance) offers a transparent view of the subtlety of the model’s decision-making process …",https://www.mdpi.com/2227-7390/12/19/3119
Erik Cambria,Barrier Function to Skin Elasticity in Talking Head,2024,Cognitive Computation,0,"Iti Chaturvedi, Vlad Pandelea, Erik Cambria, Roy Welsch, Bithin Datta",Iti Chaturvedi,Bithin Datta,5,"In this paper, we target the problem of generating facial expressions from a piece of audio. This is challenging since both audio and video have inherent characteristics that are distinct from the other. Some words may have identical lip movements, and speech impediments may prevent lip-reading in some individuals. Previous approaches to generating such a talking head suffered from stiff expressions. This is because they focused only on lip movements and the facial landmarks did not contain the information flow from the audio. Hence, in this work, we employ spatio-temporal independent component analysis to accurately sync the audio with the corresponding face video. Proper word formation also requires control over the face muscles that can be captured using a barrier function. We first validated the approach on the diffusion of salt water in coastal areas using a synthetic finite element simulation. Next, we …",https://link.springer.com/article/10.1007/s12559-024-10344-7
Erik Cambria,Interest-Driven Community Detection on Attributed Heterogeneous Information Networks,2024,Information Fusion,0,"Mengyue Liu, Jun Liu, Yixiang Dong, Rui Mao, Erik Cambria",Mengyue Liu,Erik Cambria,5,"Community structures within attributed heterogeneous information networks (AHINs) serve as valuable tools for comprehending the functional properties inherent in the real-world systems they mirror. The diverse semantics embedded in AHINs play a pivotal role in shaping distinct community formations. Many existing methods detect communities in AHINs based on the same-type nodes without specifying semantic meanings, resulting in unclear and potentially ambiguous outcomes. Additionally, by adopting a simple strategy that focuses solely on either graph structures or node attributes, they fail to sufficiently integrate heterogeneous information and maintain semantic consistency throughout the entire detection process. In this paper, we propose IDCD, a user-interest-driven community detection framework on AHINs, which groups heterogeneous nodes following specified user guidance for semantics-clear results …",https://www.sciencedirect.com/science/article/pii/S1566253524003038
Erik Cambria,Cross-domain NER with Generated Task-Oriented Knowledge: An Empirical Study from Information Density Perspective,2024,Proceedings of EMNLP,0,"Zhihao Zhang, Sophia Yat Mei Lee, Junshuang Wu, Dong Zhang, Shoushan Li, Erik Cambria, Guodong Zhou",Zhihao Zhang,Guodong Zhou,7,"Cross-domain Named Entity Recognition (CDNER) is crucial for Knowledge Graph (KG) construction and natural language processing (NLP), enabling learning from source to target domains with limited data. Previous studies often rely on manually collected entity-relevant sentences from the web or attempt to bridge the gap between tokens and entity labels across domains. These approaches are time-consuming and inefficient, as these data are often weakly correlated with the target task and require extensive pre-training. To address these issues, we propose automatically generating task-oriented knowledge (GTOK) using large language models (LLMs), focusing on the reasoning process of entity extraction. Then, we employ task-oriented pre-training (TOPT) to facilitate domain adaptation. Additionally, current cross-domain NER methods often lack explicit explanations for their effectiveness. Therefore, we introduce the concept of information density to better evaluate the model’s effectiveness before performing entity recognition. We conduct systematic experiments and analyses to demonstrate the effectiveness of our proposed approach and the validity of using information density for model evaluation.",https://aclanthology.org/2024.emnlp-main.95/
Erik Cambria,Understanding the Hidden State of Language Models from the Perspective of Sentiment Analysis,2024,Proceedings of ICDM Workshops,0,"Kaicheng Xue, Xulang Zhang, Rui Mao, Erik Cambria",Kaicheng Xue,Erik Cambria,4,,
Erik Cambria,Evaluating Vision Language Models in Detecting Learning Engagement,2024,Proceedings of ICDM Workshops,0,"Jayant Teotia, Xulang Zhang, Rui Mao, Erik Cambria",Jayant Teotia,Erik Cambria,4,,
Erik Cambria,Sentiment Analysis on Climate Change for Sustainable Investment,2024,Proceedings of ICDM Workshops,0,"Keane Ong, Rui Mao, Deeksha Varshney, Ranjan Satapathy, Erik Cambria, Gianmarco Mengaldo",Keane Ong,Gianmarco Mengaldo,6,,
Erik Cambria,Vanessa 🦋: Visual Connotation and Aesthetic Attributes Understanding Network for Multimodal Aspect-based Sentiment Analysis,2024,Proceedings of EMNLP,0,"Luwei Xiao, Rui Mao, Xulang Zhang, Liang He, Erik Cambria",Luwei Xiao,Erik Cambria,5,"Prevailing research concentrates on superficial features or descriptions of images, revealing a significant gap in the systematic exploration of their connotative and aesthetic attributes. Furthermore, the use of cross-modal relation detection modules to eliminate noise from comprehensive image representations leads to the omission of subtle contextual information. In this paper, we present a Visual Connotation and Aesthetic Attributes Understanding Network (Vanessa) for Multimodal Aspect-based Sentiment Analysis. Concretely, Vanessa incorporates a Multi-Aesthetic Attributes Aggregation (MA3) module that models intra-and inter-dependencies among bi-modal representations as well as emotion-laden aesthetic attributes. Moreover, we devise a self-supervised contrastive learning framework to explore the pairwise relevance between images and text via the Gaussian distribution of their CLIP scores. By dynamically clustering and merging multi-modal tokens, Vanessa effectively captures both implicit and explicit sentimental cues. Extensive experiments on widely adopted two benchmarks verify Vanessa’s effectiveness.",https://aclanthology.org/2024.findings-emnlp.671/
Erik Cambria,Guest Editorial: Cognitive Analysis for Humans and AI,2024,Cognitive Computation,0,"Rui Mao, Qian Liu, Xiao Li, Erik Cambria, Amir Hussain",Rui Mao,Amir Hussain,5,"The primary goal of studying artificial intelligence (AI) is to develop systems capable of simulating human intelligence, allowing machines to perform tasks that involve learning, reasoning, perception, and decision-making. While the advancement of deep neural networks has enabled AI to achieve human-like accuracy across a wide range of tasks, this accuracy does not equate to human-level intelligence [1]. Current AI systems, particularly those based on deep neural networks, rely on learning from large datasets to identify distribution patterns for task processing [2]. In contrast, human intelligence manifests not only accurate task performance but also complex cognitive processes, such as memorizing, learning, reasoning, and mental organization, that allow individuals to learn from limited data, adapt to new situations, and make ethical judgments. Thus, understanding human cognitive patterns is essential for …",https://link.springer.com/article/10.1007/s12559-024-10352-7
Erik Cambria,Are Foundation Models the Next-Generation Social Media Content Moderators?,2024,IEEE Intelligent Systems,0,"Mohammad Nadeem, Laeeba Javed, Shahab Saquib Sohail, Erik Cambria, Amir Hussain",Mohammad Nadeem,Amir Hussain,5,"Recent progress in artificial intelligence (AI) tools and systems has been significant, especially in their reasoning and efficiency. Notable examples include generative AI-based large language models (LLMs) like Generative Pre-trained Transformer 3.5 (GPT-3.5), GPT-4, and Gemini, among others. In our work, we evaluated the effectiveness of fine-tuned deep learning models compared to general-purpose LLMs in moderating image-based content. We used deep learning models such as convolutional neural networks, ResNet50, and VGG-16, trained them for violence detection on an image dataset, and tested them on a separate dataset. The same test dataset was also evaluated using Large Language and Vision Assistant (LLaVa) and GPT-4, two LLMs that can process images. The results demonstrate that VGG-16 model had the highest accuracy at 0.94, while LLaVa had the lowest at 0.66. GPT-4 showed …",https://ieeexplore.ieee.org/abstract/document/10779331/
Erik Cambria,Multilingual Sentiment Analysis for Investigating Perceptions of Globalization,2024,Proceedings of ICDM Workshops,0,"Anagha Ani, Erik Cambria",Anagha Ani,Erik Cambria,2,,
Erik Cambria,A Multi-Label Based Symbolic and Subsymbolic Artificial Intelligence Approach for Toxicity Detection,2024,Proceedings of the Congress on Intelligent Systems,0,"Ashok Jayaraman Kumar, Tina Esther Trueman, Gayathri Ananthakrishnan, S Abirami, Erik Cambria, Satanik Mitra",Ashok Jayaraman Kumar,Satanik Mitra,6,,
Erik Cambria,Two Heads are Better than One: Zero-shot Cognitive Reasoning via Multi-LLM Knowledge Fusion,2024,Proceedings of CIKM,0,"Liang Liu, Dong Zhang, Shoushan Li, Guodong Zhou, Erik Cambria",Liang Liu,Erik Cambria,5,"Cognitive reasoning holds a significant place within Natural Language Processing (NLP). Yet, the exploration of zero-shot scenarios, which align more closely with real-life situations than supervised scenarios, has been relatively limited. While a few studies have employed Large Language Models (LLMs) to tackle zero-shot cognitive reasoning tasks, they still grapple with two key challenges: 1) Traditional approaches rely on the chain-of-thought (CoT) mechanism, wherein LLMs are provided with a ""Let's think step by step'' prompt. However, this schema may not accurately understand the meaning of a given question and ignores the possible learned knowledge (e.g., background or commonsense) of the LLMs about the questions, leading to incorrect answers. 2) Previous CoT methods normally exploit a single Large Language Model (LLM) and design many strategies to augment this LLM. We argue that the power …",https://dl.acm.org/doi/abs/10.1145/3627673.3679744
Erik Cambria,Medical Report Generation via Multimodal Spatio-Temporal Fusion,2024,Proceedings of ACM Multimedia,0,"Xin Mei, Rui Mao, Xiaoyan Cai, Libin Yang, Erik Cambria",Xin Mei,Erik Cambria,5,"Medical report generation aims at automating the synthesis of accurate and comprehensive diagnostic reports from radiological images. The task can significantly enhance clinical decision-making and alleviate the workload on radiologists. Existing works normally generate reports from single chest radiographs, although historical examination data also serve as crucial references for radiologists in real-world clinical settings. To address this constraint, we introduce a novel framework that mimics the workflow of radiologists. This framework compares past and present patient images to monitor disease progression and incorporates prior diagnostic reports as references for generating current personalized reports. We tackle the textual diversity challenge in cross-modal tasks by promoting style-agnostic discrete report representation learning and token generation. Furthermore, we propose a novel spatio-temporal …",https://dl.acm.org/doi/abs/10.1145/3664647.3681377
Erik Cambria,"A Review of Chinese Sentiment Analysis: Subjects, Methods, and Trends",2024,Artificial Intelligence Review,0,"Zhaoxia Wang, Xinyue Zhang, Jingfeng Cui, Seng-Beng Ho, Erik Cambria",Zhaoxia Wang,Erik Cambria,5,"Sentiment analysis has emerged as a prominent research domain within the realm of natural language processing, garnering increasing attention and a growing body of literature. While numerous literature reviews have examined sentiment analysis techniques, methods, topics and applications, there remains a gap in the literature concerning thematic trends and research methodologies in sentiment analysis, particularly in the context of Chinese text. This study addresses this gap by presenting a comprehensive survey dedicated to the progression of research subjects, methods and trends in sentiment analysis of Chinese text. Employing a framework that combines keyword co-occurrence analysis with a sophisticated community detection algorithm, this survey offers a novel perspective on the landscape of Chinese sentiment analysis research. By tracing the interplay between research methodologies and …",https://link.springer.com/article/10.1007/s10462-024-10988-9
Erik Cambria,Time Expression Normalization with Meta Time Information,2023,Proceedings of IEEE CSCI,0,"Mengyu An, Chenyu Jin, Xiaoshi Zhong, Erik Cambria",Mengyu An,Erik Cambria,4,"Time expression (a.k.a., timex) normalization is a fundamental task for many downstream researches and applications. Previous researches mainly developed deterministic rules and machine-learning methods for the end-to-end task of timex recognition and normalization (TERN). However, deterministic rules heavily depend on specific domains while machine-learning methods are somewhat unexplainable. To better understand the task, we analyze three diverse benchmark datasets for the characteristics of timex types and values. According to these characteristics, we propose a rule-based method termed MetaTime 1  with three kinds of meta time information to normalize timexes into standard type and value formats. MetaTime is independent of specific domains and textual types. Experimental results on three diverse benchmark datasets demonstrate that MetaTime outperforms four representative state-of-the-art …",https://ieeexplore.ieee.org/abstract/document/10590340/
Erik Cambria,Sentiment Analysis of Primary Historical Sources,2023,Proceedings of ICDM Workshops,0,"Andrea Nanetti, John Pavlopoulos, Erik Cambria",Andrea Nanetti,Erik Cambria,3,"Sentiment analysis is a research area that has experienced considerable growth over the last decade. The scope of sentiment analysis is to extract feelings, opinions, and emotions from text. This paper employs state-of-the-art multilingual sentiment analysis algorithms in the field of primary historical sources to assist historians in discovering new insights. In particular, we use Sentic APIs, a neurosymbolic AI toolkit, to process the travel accounts of Ibn Battuta (in Arabic), Marco Polo (in Italian), and Ma Huan (in Chinese), available in the Engineering Historical Memory web application. Results show that sentiment analysis can be a powerful tool for historians and researchers to extract valuable insights from historical resources, shedding light on the emotions, opinions, and societal changes that shaped the past.",https://ieeexplore.ieee.org/abstract/document/10411590/
Erik Cambria,An Annotation System of a Medical Corpus using Sentiment-based Models for Summarization Applications,2023,,0,"Anupam Mondal, Erik Cambria, Monalisa Dey",Anupam Mondal,Monalisa Dey,3,"The amount of information available is growing exponentially every day, especially in the healthcare domain. In order to gain access to this information, an automated annotation system is essential. This system may assist in understanding relevant queries or medical concepts and their related information from the raw medical corpora quickly and accurately. However, a structured corpus is important to build a domain-specific annotation system for healthcare. In this chapter, we are motivated to prepare a structured corpus using our developed sentiment-based medical annotation system. In addition, we have focused on developing a sentiment-based summarization system that assists in understanding the important observations of the corpus. Hence, first we have collected an unstructured corpus from an online resource, namely MedicineNet. Secondly, we have employed WordNet of Medical Events that is …",https://www.sciencedirect.com/science/article/pii/B9780323905350000124
Erik Cambria,A Hybrid AI Framework for Multi-Label Toxicity Category Detection,2023,Social Science Research Network,0,"Tina Trueman, Abirami Murugappan, Erik Cambria, Satanik Mitra",Tina Trueman,Satanik Mitra,4,,
Erik Cambria,Motivations Behind Seeking Religious and Spiritual Support and Their Impact on Health and Social Outcomes for PLHIV in Singapore,2022,Journal of the International AIDS Society,0,"S Hyder, RKJ Tan, J Dewaele, CS Wong, BC Ng, E Cambria, R Chan, S Banerjee, R Jain",S Hyder,R Jain,9,"Existing literature on religion and HIV identified that people living with HIV who have a religious or spiritual affiliation believe faith helps with coping with illness and finding a renewed sense of purpose in life. Religion is also used to overcome their sense of guilt and shame in engaging in risky behaviors. Singapore is a religiously diverse city-state with 80% of the local population having a religious affiliation. However, there is no existing study on religion and HIV in Singapore, much less a study on religion as a resource for treatment or support in clinical interventions for people living with HIV.",http://ww.sentic.net/seeking-spiritual-support-impact-for-plhiv.pdf
Erik Cambria,"""Fear Really Comes from the Unknowns"": Navigating 'Unknowable' Stigma and Discrimination among People Living with HIV in Singapore",2022,Journal of the International AIDS Society,0,"J Dewaele, S Hyder, RKJ Tan, CS Wong, BC Ng, E Cambria, S Banerjee, R Chan, R Jain",J Dewaele,R Jain,9,,https://scholar.google.com/scholar?cluster=7083783212694244765&hl=en&oi=scholarr
Erik Cambria,SynTime: Token Types and Heuristic Rules,2021,Time Expression and Named Entity Recognition,0,"Xiaoshi Zhong, Erik Cambria",Xiaoshi Zhong,Erik Cambria,2,"According to the five common characteristics of time expressions, we propose a type-based approach named SynTime for time expression recognition. Specifically, we define three main syntactic token types, namely time token, modifier, and numeral, to group time-related token regular expressions. On the types we design general heuristic rules to recognize time expressions. In recognition, SynTime first identifies time tokens from raw text, then searches their surroundings for modifiers and numerals to form time segments, and finally merges the time segments to time expressions. As a light-weight rule-based tagger, SynTime runs in real time, and can be easily expanded by simply adding keywords for the text from different domains and different text types. Evaluation on benchmark datasets and tweets data shows that SynTime outperforms state-of-the-art methods.",https://link.springer.com/chapter/10.1007/978-3-030-78961-9_4
Erik Cambria,UGTO: Uncommon Words and Proper Nouns,2021,Time Expression and Named Entity Recognition,0,"Xiaoshi Zhong, Erik Cambria",Xiaoshi Zhong,Erik Cambria,2,"The conventional position-based tagging schemes that previous research used to model named entities suffer from the problem of inconsistent tag assignment. To overcome the problem of inconsistent tag assignment, we define a constituent-based tagging scheme termed UGTO scheme to model named entities under conditional random fields with uncommon words and proper nouns as features. In addition, many researchers jointly model multiple linguistic tasks with an implicit assumption that these individual tasks can enhance each other via the joint modeling. Before conducting research on jointly modeling multiple tasks, however, such researchers hardly examine whether such assumption is true or not. In this chapter, we empirically examine whether named entity classification improves the performance of named entity recognition as an empirical case of examining whether semantics improves the …",https://link.springer.com/chapter/10.1007/978-3-030-78961-9_6
Erik Cambria,Fusing Phonetic Features and Chinese Character Representation for Sentiment Analysis,2019,,0,"Haiyun Peng, Soujanya Poria, Yang Li, Erik Cambria",Haiyun Peng,Erik Cambria,4,"The Chinese pronunciation system offers two characteristics that distinguish it from other languages: deep phonemic orthography and intonation variations. We are the first to argue that these two important properties can play a major role in Chinese sentiment analysis. Hence, we learn phonetic features of Chinese characters and fuse them with their textual and visual features in order to mimic the way humans read and understand Chinese text. Experimental results on five different Chinese sentiment analysis datasets show that the inclusion of phonetic features significantly and consistently improves the performance of textual and visual representations.",https://link.springer.com/chapter/10.1007/978-3-031-24340-0_12
Erik Cambria,Microtext Normalization for Chatbots,2019,Proceedings of CICLing,0,"Ranjan Satapathy, Erik Cambria, Nadia Magnenat Thalmann",Ranjan Satapathy,Nadia Magnenat Thalmann,3,"With the current upsurge in the usage of social media platforms, the trend of using short text, or microtext, in place of standard English has witnessed a significant rise. This work incorporates microtext normalization into a robot’s chatbot. The work leverages the fact that humans tend to write in different unconstrained ways. This work also involves a binary classifier to detect microtext, which helps in reducing the execution time of the microtext normalization module. The results show an improvement in the chatbot’s understanding and performance increase to most forms of unconstrained languages available on social media. The BLEU score is used to evaluate the efficiency before and after the normalization of sentences. Results show that the microtext normalization technique promises to increase unconstrained text understanding in a pre-trained chatbot.",https://link.springer.com/chapter/10.1007/978-3-031-24337-0_21
Erik Cambria,Classifying World Englishes from a Lexical Perspective: A Corpus-Based Approach,2017,Proceedings of CICLing,0,"Frank Xing, Danyuan Ho, Diyana Hamzah, Erik Cambria",Frank Xing,Erik Cambria,4,"The spread of English has led to the emergence of new English varieties worldwide. Existing quantitative approaches made use of several linguistic criteria, particularly morphological and syntactical features, in investigating variations across English varieties. Taking an alternative lexical perspective to the classification of World Englishes, this paper adopts a corpus-based approach in investigating the lexical frequency across 20 regional English varieties. Specifically, the lexical items in focus include culture-bound terms and words that have undergone semantic shift. The English varieties are categorized following a series of filtering rules and normalization techniques, and a hierarchical cluster of the varieties is subsequently formalized. Our findings generally corroborate with Kachru’s Three Circle of English model, with subtle differences to the Inner Circle-Outer Circle groupings. The taxonomy of the …",https://link.springer.com/chapter/10.1007/978-3-319-77113-7_43
Erik Cambria,Tracing Linguistic Relations in Winning and Losing Sides of Explicit Opposing Groups,2017,Proceedings of FLAIRS,0,"Ceyda Sanli, Anupam Mondal, Erik Cambria",Ceyda Sanli,Erik Cambria,3,"Linguistic relations in oral conversations present how opinions are constructed and developed in a restricted time. The relations bond ideas, arguments, thoughts, and feelings, reshape them during a speech, and finally build knowledge out of all information provided in the conversation. Speakers share a common interest to discuss. It is expected that each speakers reply includes duplicated forms of words from previous speakers. However, linguistic adaptation is observed and evolves in a more complex path than just transferring slightly modified versions of common concepts. A conversation aiming a benefit at the end shows an emergent cooperation inducing the adaptation. Not only cooperation, but also competition drives the adaptation or an opposite scenario and one can capture the dynamic process by tracking how the concepts are linguistically linked. To uncover salient complex dynamic events in verbal communications, we attempt to discover self-organized linguistic relations hidden in a conversation with explicitly stated winners and losers. We examine open access data of the United States Supreme Court. Our understanding is crucial in big data research to guide how transition states in opinion mining and decision-making should be modeled and how this required knowledge to guide the model should be pinpointed, by filtering large amount of data.",https://cdn.aaai.org/ocs/15471/15471-68672-1-PB.pdf
Erik Cambria,Inducing Word Senses for Cross-Lingual Document Clustering,2013,Proceedings of Computational Intelligence and Security,0,"Guoyu Tang, Yunqing Xia, Erik Cambria, Peng Jin",Guoyu Tang,Peng Jin,4,"Cross-lingual document clustering is the task of automatically organizing a large collection of cross-lingual documents into a few groups according to their content or topic. It is well known that language barrier and translation ambiguity are two challenging issues for cross-lingual document representation. To address such issues, we propose to represent cross-lingual documents through statistical word senses, which are learned from a parallel corpus by means of a novel cross-lingual word sense induction model. Furthermore, a sense clustering method is adopted to discover semantic relation of word senses, which are used to represent cross-lingual documents through a sense-based vector space model. Evaluation on a benchmarking dataset shows that the proposed model outperforms two state-of-the-art models in cross-lingual document clustering.",https://ieeexplore.ieee.org/abstract/document/6746429/
Timothy P. Lillicrap,Mastering the game of Go with deep neural networks and tree search,2016,nature,20866,"David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George Van Den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, Demis Hassabis",David Silver,Demis Hassabis,20,"The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses ‘value networks’ to evaluate board positions and ‘policy networks’ to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and …",https://www.nature.com/articles/nature16961%7D
Timothy P. Lillicrap,Continuous control with deep reinforcement learning,2015,ICLR 2016; arXiv preprint arXiv:1509.02971,18153,"Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra",Timothy P Lillicrap,Daan Wierstra,8,,https://scholar.google.com/scholar?cluster=4133004576987558805&hl=en&oi=scholarr
Timothy P. Lillicrap,Asynchronous methods for deep reinforcement learning,2016,arXiv:1602.01783,12254,"Volodymyr Mnih, Adrià Puigdomènech Badia, Mehdi Mirza, Alex Graves, Timothy P. Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu",Volodymyr Mnih,Koray Kavukcuoglu,8,,https://scholar.google.com/scholar?cluster=14460380466928185185&hl=en&oi=scholarr
Timothy P. Lillicrap,Mastering the game of go without human knowledge,2017,nature,11838,"David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George Van Den Driessche, Thore Graepel, Demis Hassabis",David Silver,Demis Hassabis,17,"A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s own move selections and also the winner of AlphaGo’s games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our …",https://www.nature.com/articles/nature24270;
Timothy P. Lillicrap,Matching networks for one shot learning,2016,arXiv preprint arXiv:1606.04080,8877,"Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra",Oriol Vinyals,Daan Wierstra,5,"Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 82.2% to 87.8% and from 88% accuracy to 95% accuracy on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank.",https://proceedings.neurips.cc/paper/2016/hash/90e1357833654983612fb05e3ec9148c-Abstract.html
Timothy P. Lillicrap,"A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play",2018,Science,5047,"David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis",David Silver,Demis Hassabis,13,"The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.",https://www.science.org/doi/abs/10.1126/science.aar6404
Timothy P. Lillicrap,Grandmaster level in StarCraft II using multi-agent reinforcement learning,2019,nature,5013,"Oriol Vinyals, Igor Babuschkin, Wojciech M Czarnecki, Michaël Mathieu, Andrew Dudzik, Junyoung Chung, David H Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang, Laurent Sifre, Trevor Cai, John P Agapiou, Max Jaderberg, Alexander S Vezhnevets, Rémi Leblond, Tobias Pohlen, Valentin Dalibard, David Budden, Yury Sulsky, James Molloy, Tom L Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani Yogatama, Dario Wünsch, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Koray Kavukcuoglu, Demis Hassabis, Chris Apps, David Silver",Oriol Vinyals,David Silver,42,"Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions 1, 2, 3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems 4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent …",https://www.nature.com/articles/s41586-019-1724-z.
Timothy P. Lillicrap,Meta-learning with memory-augmented neural networks,2016,International conference on machine learning,3217,"Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap",Adam Santoro,Timothy Lillicrap,5,"Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of"" one-shot learning."" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms.",http://proceedings.mlr.press/v48/santoro16.html
Timothy P. Lillicrap,"Mastering atari, go, chess and shogi by planning with a learned model",2020,Nature,2682,"Julian Schrittwieser, Ioannis Antonoglou, Thomas Hubert, Karen Simonyan, Laurent Sifre, Simon Schmitt, Arthur Guez, Edward Lockhart, Demis Hassabis, Thore Graepel, Timothy Lillicrap, David Silver",Julian Schrittwieser,David Silver,12,"Constructing agents with planning capabilities has long been one of the main challenges in the pursuit of artificial intelligence. Tree-based planning methods have enjoyed huge success in challenging domains, such as chess 1 and Go 2, where a perfect simulator is available. However, in real-world problems, the dynamics governing the environment are often complex and unknown. Here we present the MuZero algorithm, which, by combining a tree-based search with a learned model, achieves superhuman performance in a range of challenging and visually complex domains, without any knowledge of their underlying dynamics. The MuZero algorithm learns an iterable model that produces predictions relevant to planning: the action-selection policy, the value function and the reward. When evaluated on 57 different Atari games 3—the canonical video game environment for testing artificial intelligence techniques …",https://www.nature.com/articles/s41586-020-03051-4.
Timothy P. Lillicrap,Mastering chess and shogi by self-play with a general reinforcement learning algorithm,2017,arXiv preprint arXiv:1712.01815,2577,"David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy Lillicrap, Karen Simonyan, Demis Hassabis",David Silver,Demis Hassabis,13,"The game of chess is the most widely-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. In contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains. Starting from random play, and given no domain knowledge except the game rules, AlphaZero achieved within 24 hours a superhuman level of play in the games of chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion program in each case.",https://arxiv.org/abs/1712.01815
Timothy P. Lillicrap,Gemini: a family of highly capable multimodal models,2023,arXiv preprint arXiv:2312.11805,2357,"Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Millican, David Silver, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul R Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, Jack Krawczyk, Cosmo Du, Ed Chi, Heng-Tze Cheng, Eric Ni, Purvi Shah, Patrick Kane, Betty Chan, Manaal Faruqui, Aliaksei Severyn, Hanzhao Lin, YaGuang Li, Yong Cheng, Abe Ittycheriah, Mahdis Mahdieh, Mia Chen, Pei Sun, Dustin Tran, Sumit Bagri, Balaji Lakshminarayanan, Jeremiah Liu, Andras Orban, Fabian Güra, Hao Zhou, Xinying Song, Aurelien Boffy, Harish Ganapathy, Steven Zheng, HyunJeong Choe, Ágoston Weisz, Tao Zhu, Yifeng Lu, Siddharth Gopal, Jarrod Kahn, Maciej Kula, Jeff Pitman, Rushin Shah, Emanuel Taropa, Majd Al Merey, Martin Baeuml, Zhifeng Chen, Laurent El Shafey, Yujing Zhang, Olcan Sercinoglu, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr, Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen, Tamara von Glehn, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, Alexandre Frechette, Charlotte Smith, Laura Culp, Lev Proleev, Yi Luan, Xi Chen, James Lottes, Nathan Schucher, Federico Lebron, Alban Rrustemi, Natalie Clay, Phil Crone, Tomas Kocisky, Jeffrey Zhao, Bartek Perz, Dian Yu, Heidi Howard, Adam Bloniarz, Jack W Rae, Han Lu, Laurent Sifre, Marcello Maggioni, Fred Alcober, Dan Garrette, Megan Barnes, Shantanu Thakoor, Jacob Austin, Gabriel Barth-Maron, William Wong, Rishabh Joshi, Rahma Chaabouni, Deeni Fatiha, Arun Ahuja, Gaurav Singh Tomar, Evan Senter, Martin Chadwick, Ilya Kornakov, Nithya Attaluri, Iñaki Iturrate, Ruibo Liu, Yunxuan Li, Sarah Cogan, Jeremy Chen, Chao Jia, Chenjie Gu, Qiao Zhang, Jordan Grimstad, Ale Jakse Hartman, Xavier Garcia, Thanumalayan Sankaranarayana Pillai, Jacob Devlin, Michael Laskin, Diego de Las Casas, Dasha Valter, Connie Tao, Lorenzo Blanco",Gemini Team,Lorenzo Blanco,150,"This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",https://arxiv.org/abs/2312.11805
Timothy P. Lillicrap,Deep reinforcement learning for robotic manipulation,2016,arXiv:1610.00633,2141,"Shixiang Gu, Ethan Holly, Timothy Lillicrap, Sergey Levine",Shixiang Gu,Sergey Levine,4,"Reinforcement learning holds the promise of enabling autonomous robots to learn large repertoires of behavioral skills with minimal human intervention. However, robotic applications of reinforcement learning often compromise the autonomy of the learning process in favor of achieving training times that are practical for real physical systems. This typically involves introducing hand-engineered policy representations and human-supplied demonstrations. Deep reinforcement learning alleviates this limitation by training general-purpose neural network policies, but applications of direct deep reinforcement learning algorithms have so far been restricted to simulated settings and relatively simple tasks, due to their apparent high sample complexity. In this paper, we demonstrate that a recent deep reinforcement learning algorithm based on offpolicy training of deep Q-functions can scale to complex 3D manipulation tasks and can learn deep neural network policies efficiently enough to train on real physical robots. We demonstrate that the training times can be further reduced by parallelizing the algorithm across multiple robots which pool their policy updates asynchronously. Our experimental evaluation shows that our method can learn a variety of 3D manipulation skills in simulation and a complex door opening skill on real robots without any prior demonstrations or manually designed representations.",http://datascienceassn.org/sites/default/files/Deep%20Reinforcement%20Learning%20for%20Robotic%20Manipulation.pdf
Timothy P. Lillicrap,A simple neural network module for relational reasoning,2017,Advances in neural information processing systems,1955,"Adam Santoro, David Raposo, David G Barrett, Mateusz Malinowski, Razvan Pascanu, Peter Battaglia, Timothy Lillicrap",Adam Santoro,Timothy Lillicrap,7,"Relational reasoning is a central component of generally intelligent behavior, but has proven difficult for neural networks to learn. In this paper we describe how to use Relation Networks (RNs) as a simple plug-and-play module to solve problems that fundamentally hinge on relational reasoning. We tested RN-augmented networks on three tasks: visual question answering using a challenging dataset called CLEVR, on which we achieve state-of-the-art, super-human performance; text-based question answering using the bAbI suite of tasks; and complex reasoning about dynamical physical systems. Then, using a curated dataset called Sort-of-CLEVR we show that powerful convolutional networks do not have a general capacity to solve relational questions, but can gain this capacity when augmented with RNs. Thus, by simply augmenting convolutions, LSTMs, and MLPs with RNs, we can remove computational burden from network components that are not well-suited to handle relational reasoning, reduce overall network complexity, and gain a general ability to reason about the relations between entities and their properties.",https://proceedings.neurips.cc/paper_files/paper/2017/hash/e6acf4b0f69f6f6e60e9a815938aa1ff-Abstract.html
Timothy P. Lillicrap,Learning latent dynamics for planning from pixels,2019,International conference on machine learning,1682,"Danijar Hafner, Timothy Lillicrap, Ian Fischer, Ruben Villegas, David Ha, Honglak Lee, James Davidson",Danijar Hafner,James Davidson,7,"Planning has been very successful for control tasks with known environment dynamics. To leverage planning in unknown environments, the agent needs to learn the dynamics from interactions with the world. However, learning dynamics models that are accurate enough for planning has been a long-standing challenge, especially in image-based domains. We propose the Deep Planning Network (PlaNet), a purely model-based agent that learns the environment dynamics from images and chooses actions through fast online planning in latent space. To achieve high performance, the dynamics model must accurately predict the rewards ahead for multiple time steps. We approach this using a latent dynamics model with both deterministic and stochastic transition components. Moreover, we propose a multi-step variational inference objective that we name latent overshooting. Using only pixel observations, our agent solves continuous control tasks with contact dynamics, partial observability, and sparse rewards, which exceed the difficulty of tasks that were previously solved by planning with learned models. PlaNet uses substantially fewer episodes and reaches final performance close to and sometimes higher than strong model-free algorithms.",https://proceedings.mlr.press/v97/hafner19a.html
Timothy P. Lillicrap,Dream to control: Learning behaviors by latent imagination,2019,arXiv preprint arXiv:1912.01603,1440,"Danijar Hafner, Timothy Lillicrap, Jimmy Ba, Mohammad Norouzi",Danijar Hafner,Mohammad Norouzi,4,"Learned world models summarize an agent's experience to facilitate learning complex behaviors. While learning world models from high-dimensional sensory inputs is becoming feasible through deep learning, there are many potential ways for deriving behaviors from them. We present Dreamer, a reinforcement learning agent that solves long-horizon tasks from images purely by latent imagination. We efficiently learn behaviors by propagating analytic gradients of learned state values back through trajectories imagined in the compact state space of a learned world model. On 20 challenging visual control tasks, Dreamer exceeds existing approaches in data-efficiency, computation time, and final performance.",https://arxiv.org/abs/1912.01603
Timothy P. Lillicrap,Continuous deep Q-learning with model-based acceleration,2016,ICML2016; arXiv:1603.00748 [cs.LG],1348,"Shixiang Gu, Timothy Lillicrap, Ilya Sutskever, Sergey Levine",Shixiang Gu,Sergey Levine,4,"Model-free reinforcement learning has been successfully applied to a range of challenging problems, and has recently been extended to handle large neural network policies and value functions. However, the sample complexity of model-free algorithms, particularly when using high-dimensional function approximators, tends to limit their applicability to physical systems. In this paper, we explore algorithms and representations to reduce the sample complexity of deep reinforcement learning for continuous control tasks. We propose two complementary techniques for improving the efficiency of such algorithms. First, we derive a continuous variant of the Q-learning algorithm, which we call normalized advantage functions (NAF), as an alternative to the more commonly used policy gradient and actor-critic methods. NAF representation allows us to apply Q-learning with experience replay to continuous tasks, and substantially improves performance on a set of simulated robotic control tasks. To further improve the efficiency of our approach, we explore the use of learned models for accelerating model-free reinforcement learning. We show that iteratively refitted local linear models are especially effective for this, and demonstrate substantially faster learning on domains where such models are applicable.",http://proceedings.mlr.press/v48/gu16.html
Timothy P. Lillicrap,Experience replay for continual learning,2019,Advances in neural information processing systems,1181,"David Rolnick, Arun Ahuja, Jonathan Schwarz, Timothy Lillicrap, Gregory Wayne",David Rolnick,Gregory Wayne,5,"Interacting with a complex world involves continual learning, in which tasks and data distributions change over time. A continual learning system should demonstrate both plasticity (acquisition of new knowledge) and stability (preservation of old knowledge). Catastrophic forgetting is the failure of stability, in which new experience overwrites previous experience. In the brain, replay of past experience is widely believed to reduce forgetting, yet it has been largely overlooked as a solution to forgetting in deep reinforcement learning. Here, we introduce CLEAR, a replay-based method that greatly reduces catastrophic forgetting in multi-task reinforcement learning. CLEAR leverages off-policy learning and behavioral cloning from replay to enhance stability, as well as on-policy learning to preserve plasticity. We show that CLEAR performs better than state-of-the-art deep learning techniques for mitigating forgetting, despite being significantly less complicated and not requiring any knowledge of the individual tasks being learned.",https://proceedings.neurips.cc/paper_files/paper/2019/hash/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Abstract.html
Timothy P. Lillicrap,Starcraft ii: A new challenge for reinforcement learning,2017,arXiv preprint arXiv:1708.04782,1138,"Oriol Vinyals, Timo Ewalds, Sergey Bartunov, Petko Georgiev, Alexander Sasha Vezhnevets, Michelle Yeo, Alireza Makhzani, Heinrich Küttler, John Agapiou, Julian Schrittwieser, John Quan, Stephen Gaffney, Stig Petersen, Karen Simonyan, Tom Schaul, Hado Van Hasselt, David Silver, Timothy Lillicrap, Kevin Calderone, Paul Keet, Anthony Brunasso, David Lawrence, Anders Ekermo, Jacob Repp, Rodney Tsing",Oriol Vinyals,Rodney Tsing,25,"This paper introduces SC2LE (StarCraft II Learning Environment), a reinforcement learning environment based on the StarCraft II game. This domain poses a new grand challenge for reinforcement learning, representing a more difficult class of problems than considered in most prior work. It is a multi-agent problem with multiple players interacting; there is imperfect information due to a partially observed map; it has a large action space involving the selection and control of hundreds of units; it has a large state space that must be observed solely from raw input feature planes; and it has delayed credit assignment requiring long-term strategies over thousands of steps. We describe the observation, action, and reward specification for the StarCraft II domain and provide an open source Python-based interface for communicating with the game engine. In addition to the main game maps, we provide a suite of mini-games focusing on different elements of StarCraft II gameplay. For the main game maps, we also provide an accompanying dataset of game replay data from human expert players. We give initial baseline results for neural networks trained from this data to predict game outcomes and player actions. Finally, we present initial baseline results for canonical deep reinforcement learning agents applied to the StarCraft II domain. On the mini-games, these agents learn to achieve a level of play that is comparable to a novice player. However, when trained on the main game, these agents are unable to make significant progress. Thus, SC2LE offers a new and challenging environment for exploring deep reinforcement learning algorithms and …",https://arxiv.org/abs/1708.04782
Timothy P. Lillicrap,A deep learning framework for neuroscience,2019,,1057,"Blake A Richards, Timothy P Lillicrap, Philippe Beaudoin, Yoshua Bengio, Rafal Bogacz, Amelia Christensen, Claudia Clopath, Rui Ponte Costa, Archy de Berker, Surya Ganguli, Colleen J Gillon, Danijar Hafner, Adam Kepecs, Nikolaus Kriegeskorte, Peter Latham, Grace W Lindsay, Kenneth D Miller, Richard Naud, Christopher C Pack, Panayiota Poirazi, Pieter Roelfsema, João Sacramento, Andrew Saxe, Benjamin Scellier, Anna C Schapiro, Walter Senn, Greg Wayne, Daniel Yamins, Friedemann Zenke, Joel Zylberberg, Denis Therien, Konrad P Kording",Blake A Richards,Konrad P Kording,32,"Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In artificial neural networks, the three components specified by design are the objective functions, the learning rules and the architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help …",https://www.nature.com/articles/s41593-019-0520-2
Timothy P. Lillicrap,Backpropagation and the brain,2020,,1002,"Timothy P Lillicrap, Adam Santoro, Luke Marris, Colin J Akerman, Geoffrey Hinton",Timothy P Lillicrap,Geoffrey Hinton,5,"During learning, the brain modifies synapses to improve behaviour. In the cortex, synapses are embedded within multilayered networks, making it difficult to determine the effect of an individual synaptic modification on the behaviour of the system. The backpropagation algorithm solves this problem in deep artificial neural networks, but historically it has been viewed as biologically problematic. Nonetheless, recent developments in neuroscience and the successes of artificial neural networks have reinvigorated interest in whether backpropagation offers insights for understanding learning in the cortex. The backpropagation algorithm learns quickly by computing synaptic updates using feedback connections to deliver error signals. Although feedback connections are ubiquitous in the cortex, it is difficult to see how they could deliver the error signals required by strict formulations of backpropagation. Here we build on …",https://www.nature.com/articles/s41583-020-0277-3
Timothy P. Lillicrap,Random synaptic feedback weights support error backpropagation for deep learning,2016,Nature communications,974,"Timothy P Lillicrap, Daniel Cownden, Douglas B Tweed, Colin J Akerman",Timothy P Lillicrap,Colin J Akerman,4,"The brain processes information through multiple layers of neurons. This deep architecture is representationally powerful, but complicates learning because it is difficult to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame by multiplying error signals with all the synaptic weights on each neuron’s axon and further downstream. However, this involves a precise, symmetric backward connectivity pattern, which is thought to be impossible in the brain. Here we demonstrate that this strong architectural constraint is not required for effective error propagation. We present a surprisingly simple mechanism that assigns blame by multiplying errors by even random synaptic weights. This mechanism can transmit teaching signals across multiple layers of neurons and performs as effectively as backpropagation on a variety of tasks. Our results help reopen …",https://www.nature.com/articles/ncomms13276
Timothy P. Lillicrap,Why copy others? Insights from the social learning strategies tournament,2010,Science,956,"Luke Rendell, Robert Boyd, Daniel Cownden, Marquist Enquist, Kimmo Eriksson, Marc W Feldman, Laurel Fogarty, Stefano Ghirlanda, Timothy Lillicrap, Kevin N Laland",Luke Rendell,Kevin N Laland,10,"Social learning (learning through observation or interaction with other individuals) is widespread in nature and is central to the remarkable success of humanity, yet it remains unclear why copying is profitable and how to copy most effectively. To address these questions, we organized a computer tournament in which entrants submitted strategies specifying how to use social learning and its asocial alternative (for example, trial-and-error learning) to acquire adaptive behavior in a complex environment. Most current theory predicts the emergence of mixed strategies that rely on some combination of the two types of learning. In the tournament, however, strategies that relied heavily on social learning were found to be remarkably successful, even when asocial information was no more costly than social information. Social learning proved advantageous because individuals frequently demonstrated the highest-payoff …",https://www.science.org/doi/abs/10.1126/science.1184719
Timothy P. Lillicrap,Mastering atari with discrete world models,2020,arXiv preprint arXiv:2010.02193,911,"Danijar Hafner, Timothy Lillicrap, Mohammad Norouzi, Jimmy Ba",Danijar Hafner,Jimmy Ba,4,"Intelligent agents need to generalize from past experience to achieve goals in complex environments. World models facilitate such generalization and allow learning behaviors from imagined outcomes to increase sample-efficiency. While learning world models from image inputs has recently become feasible for some tasks, modeling Atari games accurately enough to derive successful behaviors has remained an open challenge for many years. We introduce DreamerV2, a reinforcement learning agent that learns behaviors purely from predictions in the compact latent space of a powerful world model. The world model uses discrete representations and is trained separately from the policy. DreamerV2 constitutes the first agent that achieves human-level performance on the Atari benchmark of 55 tasks by learning behaviors inside a separately trained world model. With the same computational budget and wall-clock time, Dreamer V2 reaches 200M frames and surpasses the final performance of the top single-GPU agents IQN and Rainbow. DreamerV2 is also applicable to tasks with continuous actions, where it learns an accurate world model of a complex humanoid robot and solves stand-up and walking from only pixel inputs.",https://arxiv.org/abs/2010.02193
Timothy P. Lillicrap,Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,2024,arXiv preprint arXiv:2403.05530,875,"Gemini Team, Petko Georgiev, Ving Ian Lei, Ryan Burnell, Libin Bai, Anmol Gulati, Garrett Tanzer, Damien Vincent, Zhufeng Pan, Shibo Wang, Soroosh Mariooryad, Yifan Ding, Xinyang Geng, Fred Alcober, Roy Frostig, Mark Omernick, Lexi Walker, Cosmin Paduraru, Christina Sorokin, Andrea Tacchetti, Colin Gaffney, Samira Daruki, Olcan Sercinoglu, Zach Gleicher, Juliette Love, Paul Voigtlaender, Rohan Jain, Gabriela Surita, Kareem Mohamed, Rory Blevins, Junwhan Ahn, Tao Zhu, Kornraphop Kawintiranon, Orhan Firat, Yiming Gu, Yujing Zhang, Matthew Rahtz, Manaal Faruqui, Natalie Clay, Justin Gilmer, JD Co-Reyes, Ivo Penchev, Rui Zhu, Nobuyuki Morioka, Kevin Hui, Krishna Haridasan, Victor Campos, Mahdis Mahdieh, Mandy Guo, Samer Hassan, Kevin Kilgour, Arpi Vezer, Heng-Tze Cheng, Raoul de Liedekerke, Siddharth Goyal, Paul Barham, DJ Strouse, Seb Noury, Jonas Adler, Mukund Sundararajan, Sharad Vikram, Dmitry Lepikhin, Michela Paganini, Xavier Garcia, Fan Yang, Dasha Valter, Maja Trebacz, Kiran Vodrahalli, Chulayuth Asawaroengchai, Roman Ring, Norbert Kalb, Livio Baldini Soares, Siddhartha Brahma, David Steiner, Tianhe Yu, Fabian Mentzer, Antoine He, Lucas Gonzalez, Bibo Xu, Raphael Lopez Kaufman, Laurent El Shafey, Junhyuk Oh, Tom Hennigan, George van den Driessche, Seth Odoom, Mario Lucic, Becca Roelofs, Sid Lall, Amit Marathe, Betty Chan, Santiago Ontanon, Luheng He, Denis Teplyashin, Jonathan Lai, Phil Crone, Bogdan Damoc, Lewis Ho, Sebastian Riedel, Karel Lenc, Chih-Kuan Yeh, Aakanksha Chowdhery, Yang Xu, Mehran Kazemi, Ehsan Amid, Anastasia Petrushkina, Kevin Swersky, Ali Khodaei, Gowoon Chen, Chris Larkin, Mario Pinto, Geng Yan, Adria Puigdomenech Badia, Piyush Patil, Steven Hansen, Dave Orr, Sebastien MR Arnold, Jordan Grimstad, Andrew Dai, Sholto Douglas, Rishika Sinha, Vikas Yadav, Xi Chen, Elena Gribovskaya, Jacob Austin, Jeffrey Zhao, Kaushal Patel, Paul Komarek, Sophia Austin, Sebastian Borgeaud, Linda Friso, Abhimanyu Goyal, Ben Caine, Kris Cao, Da-Woon Chung, Matthew Lamm, Gabe Barth-Maron, Thais Kagohara, Kate Olszewska, Mia Chen, Kaushik Shivakumar, Rishabh Agarwal, Harshal Godhia, Ravi Rajwar, Javier Snaider, Xerxes Dotiwalla, Yuan Liu, Aditya Barua, Victor Ungureanu, Yuan Zhang, Bat-Orgil Batsaikhan",Gemini Team,Bat-Orgil Batsaikhan,150,"In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",https://arxiv.org/abs/2403.05530
Timothy P. Lillicrap,Vector-based navigation using grid-like representations in artificial agents,2018,Nature,784,"Andrea Banino, Caswell Barry, Benigno Uria, Charles Blundell, Timothy Lillicrap, Piotr Mirowski, Alexander Pritzel, Martin J Chadwick, Thomas Degris, Joseph Modayil, Greg Wayne, Hubert Soyer, Fabio Viola, Brian Zhang, Ross Goroshin, Neil Rabinowitz, Razvan Pascanu, Charlie Beattie, Stig Petersen, Amir Sadik, Stephen Gaffney, Helen King, Koray Kavukcuoglu, Demis Hassabis, Raia Hadsell, Dharshan Kumaran",Andrea Banino,Dharshan Kumaran,26,"Deep neural networks have achieved impressive successes in fields ranging from object recognition to complex games such as Go,. Navigation, however, remains a substantial challenge for artificial agents, with deep neural networks trained by reinforcement learning, – failing to rival the proficiency of mammalian spatial behaviour, which is underpinned by grid cells in the entorhinal cortex. Grid cells are thought to provide a multi-scale periodic representation that functions as a metric for coding space, and is critical for integrating self-motion (path integration),, and planning direct trajectories to goals (vector-based navigation),,. Here we set out to leverage the computational functions of grid cells to develop a deep reinforcement learning agent with mammal-like navigational abilities. We first trained a recurrent network to perform path integration, leading to the emergence of representations resembling grid cells, as …",https://www.nature.com/articles/s41586-018-0102-6
Timothy P. Lillicrap,Deep reinforcement learning in large discrete action spaces,2016,arXiv:1512.07679,784,"Gabriel Dulac-Arnold, Richard Evans, Hado van Hasselt, Peter Sunehag, Timothy Lillicrap, Jonathan Hunt, Timothy Mann, Theophane Weber, Thomas Degris, Ben Coppin",Gabriel Dulac-Arnold,Ben Coppin,10,"Being able to reason in an environment with a large number of discrete actions is essential to bringing reinforcement learning to a larger class of problems. Recommender systems, industrial plants and language models are only some of the many real-world tasks involving large numbers of discrete actions for which current methods are difficult or even often impossible to apply. An ability to generalize over the set of actions as well as sub-linear complexity relative to the size of the set are both necessary to handle such tasks. Current approaches are not able to provide both of these, which motivates the work in this paper. Our proposed approach leverages prior information about the actions to embed them in a continuous space upon which it can generalize. Additionally, approximate nearest-neighbor methods allow for logarithmic-time lookup complexity relative to the number of actions, which is necessary for time-wise tractable training. This combined approach allows reinforcement learning methods to be applied to large-scale learning problems previously intractable with current methods. We demonstrate our algorithm's abilities on a series of tasks having up to one million actions.",https://arxiv.org/abs/1512.07679
Timothy P. Lillicrap,Learning continuous control policies by stochastic value gradients,2015,Advances in neural information processing systems,697,"Nicolas Heess, Gregory Wayne, David Silver, Timothy Lillicrap, Tom Erez, Yuval Tassa",Nicolas Heess,Yuval Tassa,6,"We present a unified framework for learning continuous control policies usingbackpropagation. It supports stochastic control by treating stochasticity in theBellman equation as a deterministic function of exogenous noise. The productis a spectrum of general policy gradient algorithms that range from model-freemethods with value functions to model-based methods without value functions. We use learned models but only require observations from the environment insteadof observations from model-predicted trajectories, minimizing the impactof compounded model errors. We apply these algorithms first to a toy stochasticcontrol problem and then to several physics-based control problems in simulation. One of these variants, SVG (1), shows the effectiveness of learning models, valuefunctions, and policies simultaneously in continuous domains.",https://proceedings.neurips.cc/paper_files/paper/2015/hash/148510031349642de5ca0c544f31b2ef-Abstract.html
Timothy P. Lillicrap,Distributed distributional deterministic policy gradients,2018,arXiv preprint arXiv:1804.08617,685,"Gabriel Barth-Maron, Matthew W Hoffman, David Budden, Will Dabney, Dan Horgan, Dhruva Tb, Alistair Muldal, Nicolas Heess, Timothy Lillicrap",Gabriel Barth-Maron,Timothy Lillicrap,9,"This work adopts the very successful distributional perspective on reinforcement learning and adapts it to the continuous control setting. We combine this within a distributed framework for off-policy learning in order to develop what we call the Distributed Distributional Deep Deterministic Policy Gradient algorithm, D4PG. We also combine this technique with a number of additional, simple improvements such as the use of -step returns and prioritized experience replay. Experimentally we examine the contribution of each of these individual components, and show how they interact, as well as their combined contributions. Our results show that across a wide variety of simple control tasks, difficult manipulation tasks, and a set of hard obstacle-based locomotion tasks the D4PG algorithm achieves state of the art performance.",https://arxiv.org/abs/1804.08617
Timothy P. Lillicrap,Deepmind control suite,2018,arXiv preprint arXiv:1801.00690,657,"Yuval Tassa, Yotam Doron, Alistair Muldal, Tom Erez, Yazhe Li, Diego de Las Casas, David Budden, Abbas Abdolmaleki, Josh Merel, Andrew Lefrancq, Timothy Lillicrap, Martin Riedmiller",Yuval Tassa,Martin Riedmiller,12,"The DeepMind Control Suite is a set of continuous control tasks with a standardised structure and interpretable rewards, intended to serve as performance benchmarks for reinforcement learning agents. The tasks are written in Python and powered by the MuJoCo physics engine, making them easy to use and modify. We include benchmarks for several learning algorithms. The Control Suite is publicly available at https://www.github.com/deepmind/dm_control . A video summary of all tasks is available at http://youtu.be/rAai4QzcYbs .",https://arxiv.org/abs/1801.00690
Timothy P. Lillicrap,Continuous control with deep reinforcement learning. arXiv 2015,1935,arXiv preprint arXiv:1509.02971,624,"Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra",Timothy P Lillicrap,Daan Wierstra,8,,https://scholar.google.com/scholar?cluster=4132768501938656050&hl=en&oi=scholarr
Timothy P. Lillicrap,Compressive transformers for long-range sequence modelling,2019,arXiv preprint arXiv:1911.05507,593,"Jack W Rae, Anna Potapenko, Siddhant M Jayakumar, Timothy P Lillicrap",Jack W Rae,Timothy P Lillicrap,4,"We present the Compressive Transformer, an attentive sequence model which compresses past memories for long-range sequence learning. We find the Compressive Transformer obtains state-of-the-art language modelling results in the WikiText-103 and Enwik8 benchmarks, achieving 17.1 ppl and 0.97 bpc respectively. We also find it can model high-frequency speech effectively and can be used as a memory mechanism for RL, demonstrated on an object matching task. To promote the domain of long-range sequence learning, we propose a new open-vocabulary language modelling benchmark derived from books, PG-19.",https://arxiv.org/abs/1911.05507
Timothy P. Lillicrap,Alphastar: Mastering the real-time strategy game starcraft ii,2019,DeepMind blog,573,"Oriol Vinyals, Igor Babuschkin, Junyoung Chung, Michael Mathieu, Max Jaderberg, Wojciech M Czarnecki, Andrew Dudzik, Aja Huang, Petko Georgiev, Richard Powell, Timo Ewalds, Dan Horgan, Manuel Kroiss, Ivo Danihelka, John Agapiou, Junhyuk Oh, Valentin Dalibard, David Choi, Laurent Sifre, Yury Sulsky, Sasha Vezhnevets, James Molloy, Trevor Cai, David Budden, Tom Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Toby Pohlen, Yuhuai Wu, Dani Yogatama, Julia Cohen, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Chris Apps, Koray Kavukcuoglu, Demis Hassabis, David Silver",Oriol Vinyals,David Silver,40,,https://scholar.google.com/scholar?cluster=9693871144264407160&hl=en&oi=scholarr
Timothy P. Lillicrap,Relational deep reinforcement learning,2018,arXiv preprint arXiv:1806.01830,535,"Vinicius Zambaldi, David Raposo, Adam Santoro, Victor Bapst, Yujia Li, Igor Babuschkin, Karl Tuyls, David Reichert, Timothy Lillicrap, Edward Lockhart, Murray Shanahan, Victoria Langston, Razvan Pascanu, Matthew Botvinick, Oriol Vinyals, Peter Battaglia",Vinicius Zambaldi,Peter Battaglia,16,"We introduce an approach for deep reinforcement learning (RL) that improves upon the efficiency, generalization capacity, and interpretability of conventional approaches through structured perception and relational reasoning. It uses self-attention to iteratively reason about the relations between entities in a scene and to guide a model-free policy. Our results show that in a novel navigation and planning task called Box-World, our agent finds interpretable solutions that improve upon baselines in terms of sample complexity, ability to generalize to more complex scenes than experienced during training, and overall performance. In the StarCraft II Learning Environment, our agent achieves state-of-the-art performance on six mini-games -- surpassing human grandmaster performance on four. By considering architectural inductive biases, our work opens new directions for overcoming important, but stubborn, challenges in deep RL.",https://arxiv.org/abs/1806.01830
Timothy P. Lillicrap,Mastering diverse domains through world models,2023,arXiv preprint arXiv:2301.04104,511,"Danijar Hafner, Jurgis Pasukonis, Jimmy Ba, Timothy Lillicrap",Danijar Hafner,Timothy Lillicrap,4,"Developing a general algorithm that learns to solve tasks across a wide range of applications has been a fundamental challenge in artificial intelligence. Although current reinforcement learning algorithms can be readily applied to tasks similar to what they have been developed for, configuring them for new application domains requires significant human expertise and experimentation. We present DreamerV3, a general algorithm that outperforms specialized methods across over 150 diverse tasks, with a single configuration. Dreamer learns a model of the environment and improves its behavior by imagining future scenarios. Robustness techniques based on normalization, balancing, and transformations enable stable learning across domains. Applied out of the box, Dreamer is the first algorithm to collect diamonds in Minecraft from scratch without human data or curricula. This achievement has been posed as a significant challenge in artificial intelligence that requires exploring farsighted strategies from pixels and sparse rewards in an open world. Our work allows solving challenging control problems without extensive experimentation, making reinforcement learning broadly applicable.",https://arxiv.org/abs/2301.04104
Timothy P. Lillicrap,Towards deep learning with segregated dendrites,2017,Elife,464,"Jordan Guerguiev, Timothy P Lillicrap, Blake A Richards",Jordan Guerguiev,Blake A Richards,3,"Deep learning has led to significant advances in artificial intelligence, in part, by adopting strategies motivated by neurophysiology. However, it is unclear whether deep learning could occur in the real brain. Here, we show that a deep learning algorithm that utilizes multi-compartment neurons might help us to understand how the neocortex optimizes cost functions. Like neocortical pyramidal neurons, neurons in our model receive sensory information and higher-order feedback in electrotonically segregated compartments. Thanks to this segregation, neurons in different layers of the network can coordinate synaptic weight updates. As a result, the network learns to categorize images better than a single layer network. Furthermore, we show that our algorithm takes advantage of multilayer architectures to identify useful higher-order representations—the hallmark of deep learning. This work demonstrates that deep learning can be achieved using segregated dendritic compartments, which may help to explain the morphology of neocortical pyramidal neurons.",https://elifesciences.org/articles/22901
Timothy P. Lillicrap,Q-prop: Sample-efficient policy gradient with an off-policy critic,2016,arXiv preprint arXiv:1611.02247,415,"Shixiang Gu, Timothy Lillicrap, Zoubin Ghahramani, Richard E Turner, Sergey Levine",Shixiang Gu,Sergey Levine,5,"Model-free deep reinforcement learning (RL) methods have been successful in a wide variety of simulated domains. However, a major obstacle facing deep RL in the real world is their high sample complexity. Batch policy gradient methods offer stable learning, but at the cost of high variance, which often requires large batches. TD-style methods, such as off-policy actor-critic and Q-learning, are more sample-efficient but biased, and often require costly hyperparameter sweeps to stabilize. In this work, we aim to develop methods that combine the stability of policy gradients with the efficiency of off-policy RL. We present Q-Prop, a policy gradient method that uses a Taylor expansion of the off-policy critic as a control variate. Q-Prop is both sample efficient and stable, and effectively combines the benefits of on-policy and off-policy methods. We analyze the connection between Q-Prop and existing model-free algorithms, and use control variate theory to derive two variants of Q-Prop with conservative and aggressive adaptation. We show that conservative Q-Prop provides substantial gains in sample efficiency over trust region policy optimization (TRPO) with generalized advantage estimation (GAE), and improves stability over deep deterministic policy gradient (DDPG), the state-of-the-art on-policy and off-policy methods, on OpenAI Gym's MuJoCo continuous control environments.",https://arxiv.org/abs/1611.02247
Timothy P. Lillicrap,dm_control: Software and tasks for continuous control,2020,Software Impacts,403,"Saran Tunyasuvunakool, Alistair Muldal, Yotam Doron, Siqi Liu, Steven Bohez, Josh Merel, Tom Erez, Timothy Lillicrap, Nicolas Heess, Yuval Tassa",Saran Tunyasuvunakool,Yuval Tassa,10,"The dm_control software package is a collection of Python libraries and task suites for reinforcement learning agents in an articulated-body simulation. Infrastructure includes a wrapper for the MuJoCo physics engine and libraries for procedural model manipulation and task authoring. Task suites include the Control Suite, a set of standardized tasks intended to serve as performance benchmarks, a locomotion framework and task families, and a set of manipulation tasks with a robot arm and snap-together bricks. An adjunct tech report and interactive tutorial are also provided.",https://www.sciencedirect.com/science/article/pii/S2665963820300099
Timothy P. Lillicrap,Memory-based control with recurrent neural networks,2015,"Deep Reinforcement Learning Workshop, NIPS",402,"Nicolas Heess, Jonathan J Hunt, Timothy P Lillicrap, David Silver",Nicolas Heess,David Silver,4,"Partially observed control problems are a challenging aspect of reinforcement learning. We extend two related, model-free algorithms for continuous control -- deterministic policy gradient and stochastic value gradient -- to solve partially observed domains using recurrent neural networks trained with backpropagation through time. We demonstrate that this approach, coupled with long-short term memory is able to solve a variety of physical control problems exhibiting an assortment of memory requirements. These include the short-term integration of information from noisy sensors and the identification of system parameters, as well as long-term memory problems that require preserving information over many time steps. We also demonstrate success on a combined exploration and memory problem in the form of a simplified version of the well-known Morris water maze task. Finally, we show that our approach can deal with high-dimensional observations by learning directly from pixels. We find that recurrent deterministic and stochastic policies are able to learn similarly good solutions to these tasks, including the water maze where the agent must learn effective search strategies.",https://arxiv.org/abs/1512.04455
Timothy P. Lillicrap,Measuring abstract reasoning in neural networks,2018,International conference on machine learning,384,"Adam Santoro, Felix Hill, David Barrett, Ari Morcos, Timothy Lillicrap",Adam Santoro,Timothy Lillicrap,5,"Whether neural networks can learn abstract reasoning or whether they merely rely on superficial statistics is a topic of recent debate. Here, we propose a dataset and challenge designed to probe abstract reasoning, inspired by a well-known human IQ test. To succeed at this challenge, models must cope with various generalisation’regimes’ in which the training data and test questions differ in clearly-defined ways. We show that popular models such as ResNets perform poorly, even when the training and test sets differ only minimally, and we present a novel architecture, with structure designed to encourage reasoning, that does significantly better. When we vary the way in which the test questions and training data differ, we find that our model is notably proficient at certain forms of generalisation, but notably weak at others. We further show that the model’s ability to generalise improves markedly if it is trained to …",https://scholar.google.com/scholar?cluster=8130223618438655741&hl=en&oi=scholarr
Timothy P. Lillicrap,Learning to learn without gradient descent by gradient descent,2017,International Conference on Machine Learning,353,"Yutian Chen, Matthew W Hoffman, Sergio Gómez Colmenarejo, Misha Denil, Timothy P Lillicrap, Matt Botvinick, Nando Freitas",Yutian Chen,Nando Freitas,7,"We learn recurrent neural network optimizers trained on simple synthetic functions by gradient descent. We show that these learned optimizers exhibit a remarkable degree of transfer in that they can be used to efficiently optimize a broad range of derivative-free black-box functions, including Gaussian process bandits, simple control objectives, global optimization benchmarks and hyper-parameter tuning tasks. Up to the training horizon, the learned optimizers learn to trade-off exploration and exploitation, and compare favourably with heavily engineered Bayesian optimization packages for hyper-parameter tuning.",http://proceedings.mlr.press/v70/chen17e.html
Timothy P. Lillicrap,Episodic curiosity through reachability,2018,arXiv preprint arXiv:1810.02274,349,"Nikolay Savinov, Anton Raichuk, Raphaël Marinier, Damien Vincent, Marc Pollefeys, Timothy Lillicrap, Sylvain Gelly",Nikolay Savinov,Sylvain Gelly,7,"Rewards are sparse in the real world and most of today's reinforcement learning algorithms struggle with such sparsity. One solution to this problem is to allow the agent to create rewards for itself - thus making rewards dense and more suitable for learning. In particular, inspired by curious behaviour in animals, observing something novel could be rewarded with a bonus. Such bonus is summed up with the real task reward - making it possible for RL algorithms to learn from the combined reward. We propose a new curiosity method which uses episodic memory to form the novelty bonus. To determine the bonus, the current observation is compared with the observations in memory. Crucially, the comparison is done based on how many environment steps it takes to reach the current observation from those in memory - which incorporates rich information about environment dynamics. This allows us to overcome the known ""couch-potato"" issues of prior work - when the agent finds a way to instantly gratify itself by exploiting actions which lead to hardly predictable consequences. We test our approach in visually rich 3D environments in ViZDoom, DMLab and MuJoCo. In navigational tasks from ViZDoom and DMLab, our agent outperforms the state-of-the-art curiosity method ICM. In MuJoCo, an ant equipped with our curiosity module learns locomotion out of the first-person-view curiosity only.",https://arxiv.org/abs/1810.02274
Timothy P. Lillicrap,Data-efficient deep reinforcement learning for dexterous manipulation,2017,arXiv preprint arXiv:1704.03073,334,"Ivaylo Popov, Nicolas Heess, Timothy Lillicrap, Roland Hafner, Gabriel Barth-Maron, Matej Vecerik, Thomas Lampe, Yuval Tassa, Tom Erez, Martin Riedmiller",Ivaylo Popov,Martin Riedmiller,10,"Deep learning and reinforcement learning methods have recently been used to solve a variety of problems in continuous control domains. An obvious application of these techniques is dexterous manipulation tasks in robotics which are difficult to solve using traditional control theory or hand-engineered approaches. One example of such a task is to grasp an object and precisely stack it on another. Solving this difficult and practically relevant problem in the real world is an important long-term goal for the field of robotics. Here we take a step towards this goal by examining the problem in simulation and providing models and techniques aimed at solving it. We introduce two extensions to the Deep Deterministic Policy Gradient algorithm (DDPG), a model-free Q-learning based method, which make it significantly more data-efficient and scalable. Our results show that by making extensive use of off-policy data and replay, it is possible to find control policies that robustly grasp objects and stack them. Further, our results hint that it may soon be feasible to train successful stacking policies by collecting interactions on real robots.",https://arxiv.org/abs/1704.03073
Timothy P. Lillicrap,Assessing the scalability of biologically-motivated deep learning algorithms and architectures,2018,Advances in neural information processing systems,303,"Sergey Bartunov, Adam Santoro, Blake Richards, Luke Marris, Geoffrey E Hinton, Timothy Lillicrap",Sergey Bartunov,Timothy Lillicrap,6,"The backpropagation of error algorithm (BP) is impossible to implement in a real brain. The recent success of deep networks in machine learning and AI, however, has inspired proposals for understanding how the brain might learn across multiple layers, and hence how it might approximate BP. As of yet, none of these proposals have been rigorously evaluated on tasks where BP-guided deep learning has proved critical, or in architectures more structured than simple fully-connected networks. Here we present results on scaling up biologically motivated models of deep learning on datasets which need deep networks with appropriate architectures to achieve good performance. We present results on the MNIST, CIFAR-10, and ImageNet datasets and explore variants of target-propagation (TP) and feedback alignment (FA) algorithms, and explore performance in both fully-and locally-connected architectures. We also introduce weight-transport-free variants of difference target propagation (DTP) modified to remove backpropagation from the penultimate layer. Many of these algorithms perform well for MNIST, but for CIFAR and ImageNet we find that TP and FA variants perform significantly worse than BP, especially for networks composed of locally connected units, opening questions about whether new architectures and algorithms are required to scale these approaches. Our results and implementation details help establish baselines for biologically motivated deep learning schemes going forward.",https://proceedings.neurips.cc/paper/2018/hash/63c3ddcc7b23daa1e42dc41f9a44a873-Abstract.html
Timothy P. Lillicrap,Relational recurrent neural networks,2018,Advances in neural information processing systems,278,"Adam Santoro, Ryan Faulkner, David Raposo, Jack Rae, Mike Chrzanowski, Theophane Weber, Daan Wierstra, Oriol Vinyals, Razvan Pascanu, Timothy Lillicrap",Adam Santoro,Timothy Lillicrap,10,"Memory-based neural networks model temporal data by leveraging an ability to remember information for long periods. It is unclear, however, whether they also have an ability to perform complex relational reasoning with the information they remember. Here, we first confirm our intuitions that standard memory architectures may struggle at tasks that heavily involve an understanding of the ways in which entities are connected--ie, tasks involving relational reasoning. We then improve upon these deficits by using a new memory module--a Relational Memory Core (RMC)--which employs multi-head dot product attention to allow memories to interact. Finally, we test the RMC on a suite of tasks that may profit from more capable relational reasoning across sequential information, and show large gains in RL domains (BoxWorld & Mini PacMan), program evaluation, and language modeling, achieving state-of-the-art results on the WikiText-103, Project Gutenberg, and GigaWord datasets.",https://proceedings.neurips.cc/paper/2018/hash/e2eabaf96372e20a9e3d4b5f83723a61-Abstract.html
Timothy P. Lillicrap,Gemini: A family of highly capable multimodal models,2023,arXiv preprint arXiv:2312.11805,274,"Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, Katie Millican, David Silver, Slav Petrov, Melvin Johnson, Ioannis Antonoglou, Julian Schrittwieser, Amelia Glaese, Jilin Chen, Emily Pitler, Timothy P Lillicrap, Angeliki Lazaridou, Orhan Firat, James Molloy, Michael Isard, Paul Ronald Barham, Tom Hennigan, Benjamin Lee, Fabio Viola, Malcolm Reynolds, Yuanzhong Xu, Ryan Doherty, Eli Collins, Clemens Meyer, Eliza Rutherford, Erica Moreira, Kareem Ayoub, Megha Goel, George Tucker, Enrique Piqueras, Maxim Krikun, Iain Barr, Nikolay Savinov, Ivo Danihelka, Becca Roelofs, Anaïs White, Anders Andreassen, Tamara von Glehn, Lakshman Yagati, Mehran Kazemi, Lucas Gonzalez, Misha Khalman, Jakub Sygnowski, et al.",Rohan Anil,et al.,52,,https://scholar.google.com/scholar?cluster=2660291786151583136&hl=en&oi=scholarr
Timothy P. Lillicrap,Learning and transfer of modulated locomotor controllers,2016,arXiv:1610.05182 [cs.RO],235,"Nicolas Heess, Greg Wayne, Yuval Tassa, Timothy Lillicrap, Martin Riedmiller, David Silver",Nicolas Heess,David Silver,6,"We study a novel architecture and training procedure for locomotion tasks. A high-frequency, low-level ""spinal"" network with access to proprioceptive sensors learns sensorimotor primitives by training on simple tasks. This pre-trained module is fixed and connected to a low-frequency, high-level ""cortical"" network, with access to all sensors, which drives behavior by modulating the inputs to the spinal network. Where a monolithic end-to-end architecture fails completely, learning with a pre-trained spinal module succeeds at multiple high-level tasks, and enables the effective exploration required to learn from sparse rewards. We test our proposed architecture on three simulated bodies: a 16-dimensional swimming snake, a 20-dimensional quadruped, and a 54-dimensional humanoid. Our results are illustrated in the accompanying video at https://youtu.be/sboPYvhpraQ",https://arxiv.org/abs/1610.05182
Timothy P. Lillicrap,Unsupervised predictive memory in a goal-directed agent,2018,arXiv preprint arXiv:1803.10760,209,"Greg Wayne, Chia-Chun Hung, David Amos, Mehdi Mirza, Arun Ahuja, Agnieszka Grabska-Barwinska, Jack Rae, Piotr Mirowski, Joel Z Leibo, Adam Santoro, Mevlana Gemici, Malcolm Reynolds, Tim Harley, Josh Abramson, Shakir Mohamed, Danilo Rezende, David Saxton, Adam Cain, Chloe Hillier, David Silver, Koray Kavukcuoglu, Matt Botvinick, Demis Hassabis, Timothy Lillicrap",Greg Wayne,Timothy Lillicrap,24,"Animals execute goal-directed behaviours despite the limited range and scope of their sensors. To cope, they explore environments and store memories maintaining estimates of important information that is not presently available. Recently, progress has been made with artificial intelligence (AI) agents that learn to perform tasks from sensory input, even at a human level, by merging reinforcement learning (RL) algorithms with deep neural networks, and the excitement surrounding these results has led to the pursuit of related ideas as explanations of non-human animal learning. However, we demonstrate that contemporary RL algorithms struggle to solve simple tasks when enough information is concealed from the sensors of the agent, a property called ""partial observability"". An obvious requirement for handling partially observed tasks is access to extensive memory, but we show memory is not enough; it is critical that the right information be stored in the right format. We develop a model, the Memory, RL, and Inference Network (MERLIN), in which memory formation is guided by a process of predictive modeling. MERLIN facilitates the solution of tasks in 3D virtual reality environments for which partial observability is severe and memories must be maintained over long durations. Our model demonstrates a single learning agent architecture that can solve canonical behavioural tasks in psychology and neurobiology without strong simplifying assumptions about the dimensionality of sensory input or the duration of experiences.",https://arxiv.org/abs/1803.10760
Timothy P. Lillicrap,Backpropagation through time and the brain,2019,,204,"Timothy P Lillicrap, Adam Santoro",Timothy P Lillicrap,Adam Santoro,2,"It has long been speculated that the backpropagation-of-error algorithm (backprop) may be a model of how the brain learns. Backpropagation-through-time (BPTT) is the canonical temporal-analogue to backprop used to assign credit in recurrent neural networks in machine learning, but there's even less conviction about whether BPTT has anything to do with the brain. Even in machine learning the use of BPTT in classic neural network architectures has proven insufficient for some challenging temporal credit assignment (TCA) problems that we know the brain is capable of solving. Nonetheless, recent work in machine learning has made …",https://www.sciencedirect.com/science/article/pii/S0959438818302009
Timothy P. Lillicrap,Deep compressed sensing,2019,International Conference on Machine Learning,202,"Yan Wu, Mihaela Rosca, Timothy Lillicrap",Yan Wu,Timothy Lillicrap,3,"Compressed sensing (CS) provides an elegant framework for recovering sparse signals from compressed measurements. For example, CS can exploit the structure of natural images and recover an image from only a few random measurements. Unlike popular autoencoding models, reconstruction in CS is posed as an optimisation problem that is separate from sensing. CS is flexible and data efficient, but its application has been restricted by the strong assumption of sparsity and costly reconstruction process. A recent approach that combines CS with neural network generators has removed the constraint of sparsity, but reconstruction remains slow. Here we propose a novel framework that significantly improves both the performance and speed of signal recovery by jointly training a generator and the optimisation process for reconstruction via meta-learning. We explore training the measurements with different objectives, and derive a family of models based on minimising measurement errors. We show that Generative Adversarial Nets (GANs) can be viewed as a special case in this family of models. Borrowing insights from the CS perspective, we develop a novel way of improving GANs using gradient information from the discriminator.",http://proceedings.mlr.press/v97/wu19d.html
Timothy P. Lillicrap,Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning,2017,Advances in neural information processing systems,200,"Shixiang Shane Gu, Timothy Lillicrap, Richard E Turner, Zoubin Ghahramani, Bernhard Schölkopf, Sergey Levine",Shixiang Shane Gu,Sergey Levine,6,"Off-policy model-free deep reinforcement learning methods using previously collected data can improve sample efficiency over on-policy policy gradient techniques. On the other hand, on-policy algorithms are often more stable and easier to use. This paper examines, both theoretically and empirically, approaches to merging on-and off-policy updates for deep reinforcement learning. Theoretical results show that off-policy updates with a value function estimator can be interpolated with on-policy policy gradient updates whilst still satisfying performance bounds. Our analysis uses control variate methods to produce a family of policy gradient algorithms, with several recently proposed algorithms being special cases of this family. We then provide an empirical comparison of these techniques with the remaining algorithmic details fixed, and show how different mixing of off-policy gradient estimates with on-policy samples contribute to improvements in empirical performance. The final algorithm provides a generalization and unification of existing deep policy gradient techniques, has theoretical guarantees on the bias introduced by off-policy updates, and improves on the state-of-the-art model-free deep RL methods on a number of OpenAI Gym continuous control benchmarks.",https://proceedings.neurips.cc/paper/2017/hash/a1d7311f2a312426d710e1c617fcbc8c-Abstract.html
Timothy P. Lillicrap,Scaling Memory-Augmented Neural Networks with Sparse Reads and Writes,2016,NIPS 2017; arXiv:1610.09027,187,"Jack W Rae, Jonathan J Hunt, Tim Harley, Ivo Danihelka, Andrew Senior, Greg Wayne, Alex Graves, Timothy P Lillicrap",Jack W Rae,Timothy P Lillicrap,8,"Neural networks augmented with external memory have the ability to learn algorithmic solutions to complex tasks. These models appear promising for applications such as language modeling and machine translation. However, they scale poorly in both space and time as the amount of memory grows---limiting their applicability to real-world domains. Here, we present an end-to-end differentiable memory access scheme, which we call Sparse Access Memory (SAM), that retains the representational power of the original approaches whilst training efficiently with very large memories. We show that SAM achieves asymptotic lower bounds in space and time complexity, and find that an implementation runs  faster and with  less physical memory than non-sparse models. SAM learns with comparable data efficiency to existing models on a range of synthetic tasks and one-shot Omniglot character recognition, and can scale to tasks requiring  s of time steps and memories. As well, we show how our approach can be adapted for models that maintain temporal associations between memories, as with the recently introduced Differentiable Neural Computer.",https://proceedings.neurips.cc/paper/2016/hash/3fab5890d8113d0b5a4178201dc842ad-Abstract.html
Timothy P. Lillicrap,Random feedback weights support learning in deep neural networks,2014,arXiv preprint arXiv:1411.0247,187,"Timothy P Lillicrap, Daniel Cownden, Douglas B Tweed, Colin J Akerman",Timothy P Lillicrap,Colin J Akerman,4,"The brain processes information through many layers of neurons. This deep architecture is representationally powerful, but it complicates learning by making it hard to identify the responsible neurons when a mistake is made. In machine learning, the backpropagation algorithm assigns blame to a neuron by computing exactly how it contributed to an error. To do this, it multiplies error signals by matrices consisting of all the synaptic weights on the neuron's axon and farther downstream. This operation requires a precisely choreographed transport of synaptic weight information, which is thought to be impossible in the brain. Here we present a surprisingly simple algorithm for deep learning, which assigns blame by multiplying error signals by random synaptic weights. We show that a network can learn to extract useful information from signals sent through these random feedback connections. In essence, the network learns to learn. We demonstrate that this new mechanism performs as quickly and accurately as backpropagation on a variety of problems and describe the principles which underlie its function. Our demonstration provides a plausible basis for how a neuron can be adapted using error signals generated at distal locations in the brain, and thus dispels long-held assumptions about the algorithmic constraints on learning in neural circuits.",https://arxiv.org/abs/1411.0247
Timothy P. Lillicrap,Deep learning without weight transport,2019,Advances in neural information processing systems,178,"Mohamed Akrout, Collin Wilson, Peter Humphreys, Timothy Lillicrap, Douglas B Tweed",Mohamed Akrout,Douglas B Tweed,5,"Current algorithms for deep learning probably cannot run in the brain because they rely on weight transport, where forward-path neurons transmit their synaptic weights to a feedback path, in a way that is likely impossible biologically. An algorithm called feedback alignment achieves deep learning without weight transport by using random feedback weights, but it performs poorly on hard visual-recognition tasks. Here we describe two mechanisms—a neural circuit called a weight mirror and a modification of an algorithm proposed by Kolen and Pollack in 1994—both of which let the feedback path learn appropriate synaptic weights quickly and accurately even in large networks, without weight transport or complex wiring. Tested on the ImageNet visual-recognition task, these mechanisms outperform both feedback alignment and the newer sign-symmetry method, and nearly match backprop, the standard algorithm of deep learning, which uses weight transport.",https://proceedings.neurips.cc/paper_files/paper/2019/hash/f387624df552cea2f369918c5e1e12bc-Abstract.html
Timothy P. Lillicrap,Catalyzing next-generation artificial intelligence through neuroai,2023,,172,"Anthony Zador, Sean Escola, Blake Richards, Bence Ölveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Körding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S Tolias, Doris Tsao",Anthony Zador,Doris Tsao,27,"Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities – inherited from over 500 million years of evolution – that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI.",https://www.nature.com/articles/s41467-023-37180-x
Timothy P. Lillicrap,Continuous control with deep reinforcement learning,2009,Found. Trends® Mach. Learn,165,"Yoshua Bengio, TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T Erez, D Wierstra",Yoshua Bengio,D Wierstra,7,,https://scholar.google.com/scholar?cluster=13032163835084690400&hl=en&oi=scholarr
Timothy P. Lillicrap,Dendritic solutions to the credit assignment problem,2019,,161,"Blake A Richards, Timothy P Lillicrap",Blake A Richards,Timothy P Lillicrap,2,"Guaranteeing that synaptic plasticity leads to effective learning requires a means for assigning credit to each neuron for its contribution to behavior. The ‘credit assignment problem’refers to the fact that credit assignment is non-trivial in hierarchical networks with multiple stages of processing. One difficulty is that if credit signals are integrated with other inputs, then it is hard for synaptic plasticity rules to distinguish credit-related activity from non-credit-related activity. A potential solution is to use the spatial layout and non-linear properties of dendrites to distinguish credit signals from other inputs. In cortical pyramidal …",https://www.sciencedirect.com/science/article/pii/S0959438818300485
Timothy P. Lillicrap,Preference distributions of primary motor cortex neurons reflect control solutions optimized for limb biomechanics,2013,Neuron,155,"Timothy P Lillicrap, Stephen H Scott",Timothy P Lillicrap,Stephen H Scott,2,"Neurons in monkey primary motor cortex (M1) tend to be most active for certain directions of hand movement and joint-torque loads applied to the limb. The origin and function of these biases in preference distribution are unclear but may be key to understanding the causal role of M1 in limb control. We demonstrate that these distributions arise naturally in a network model that commands muscle activity and is optimized to control movements and counter applied forces. In the model, movement and load preference distributions matching those observed empirically are only evident when particular features of the musculoskeletal system were included: limb geometry, intersegmental dynamics, and the force-length/velocity properties of muscle were dominant factors in dictating movement preferences, and the presence of biarticular muscles dictated load preferences. Our results suggest a general principle: neural …",https://www.cell.com/neuron/fulltext/S0896-6273(12)00992-0
Timothy P. Lillicrap,Optimizing agent behavior over long time scales by transporting value,2019,Nature communications,144,"Chia-Chun Hung, Timothy Lillicrap, Josh Abramson, Yan Wu, Mehdi Mirza, Federico Carnevale, Arun Ahuja, Greg Wayne",Chia-Chun Hung,Greg Wayne,8,"Humans prolifically engage in mental time travel. We dwell on past actions and experience satisfaction or regret. More than storytelling, these recollections change how we act in the future and endow us with a computationally important ability to link actions and consequences across spans of time, which helps address the problem of long-term credit assignment: the question of how to evaluate the utility of actions within a long-duration behavioral sequence. Existing approaches to credit assignment in AI cannot solve tasks with long delays between actions and consequences. Here, we introduce a paradigm where agents use recall of specific memories to credit past actions, allowing them to solve problems that are intractable for existing algorithms. This paradigm broadens the scope of problems that can be investigated in AI and offers a mechanistic account of behaviors that may inspire models in neuroscience …",https://www.nature.com/articles/s41467-019-13073-w
Timothy P. Lillicrap,Temporal evolution of “automatic gain-scaling”,2009,Journal of neurophysiology,144,"J Andrew Pruszynski, Isaac Kurtzer, Timothy P Lillicrap, Stephen H Scott",J Andrew Pruszynski,Stephen H Scott,4,"The earliest neural response to a mechanical perturbation, the short-latency stretch response (R1: 20–45 ms), is known to exhibit “automatic gain-scaling” whereby its magnitude is proportional to preperturbation muscle activity. Because gain-scaling likely reflects an intrinsic property of the motoneuron pool (via the size-recruitment principle), counteracting this property poses a fundamental challenge for the nervous system, which must ultimately counter the absolute change in load regardless of the initial muscle activity (i.e., show no gain-scaling). Here we explore the temporal evolution of gain-scaling in a simple behavioral task where subjects stabilize their arm against different background loads and randomly occurring torque perturbations. We quantified gain-scaling in four elbow muscles (brachioradialis, biceps long, triceps lateral, triceps long) over the entire sequence of muscle activity following perturbation …",https://journals.physiology.org/doi/abs/10.1152/jn.00085.2009
Timothy P. Lillicrap,Androidinthewild: A large-scale dataset for android device control,2024,Advances in Neural Information Processing Systems,129,"Christopher Rawles, Alice Li, Daniel Rodriguez, Oriana Riva, Timothy Lillicrap",Christopher Rawles,Timothy Lillicrap,5,"There is a growing interest in device-control systems that can interpret human natural language instructions and execute them on a digital device by directly controlling its user interface. We present a dataset for device-control research, Android in the Wild (AitW), which is orders of magnitude larger than current datasets. The dataset contains human demonstrations of device interactions, including the screens and actions, and corresponding natural language instructions. It consists of 715k episodes spanning 30k unique instructions, four versions of Android (v10–13), and eight device types (Pixel 2 XL to Pixel 6) with varying screen resolutions. It contains multi-step tasks that require semantic understanding of language and visual context. This dataset poses a new challenge: actions available through the user interface must be inferred from their visual appearance, and, instead of simple UI element-based actions, the action space consists of precise gestures (eg, horizontal scrolls to operate carousel widgets). We organize our dataset to encourage robustness analysis of device-control systems, ie, how well a system performs in the presence of new task descriptions, new applications, or new platform versions. We develop two agents and report performance across the dataset. The dataset is available at https://github. com/google-research/google-research/tree/master/androidinthe_wild.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/bbbb6308b402fe909c39dd29950c32e0-Abstract-Datasets_and_Benchmarks.html
Timothy P. Lillicrap,Discovering Objects and Their Relations from Entangled Scene Representations,2017,arXiv preprint arXiv:1702.05068,129,David Raposo,David Raposo,David Raposo,1,,https://scholar.google.com/scholar?cluster=17075890751298607392&hl=en&oi=scholarr
Timothy P. Lillicrap,Logan: Latent optimisation for generative adversarial networks,2019,arXiv preprint arXiv:1912.00953,115,"Yan Wu, Jeff Donahue, David Balduzzi, Karen Simonyan, Timothy Lillicrap",Yan Wu,Timothy Lillicrap,5,"Training generative adversarial networks requires balancing of delicate adversarial dynamics. Even with careful tuning, training may diverge or end up in a bad equilibrium with dropped modes. In this work, we improve CS-GAN with natural gradient-based latent optimisation and show that it improves adversarial dynamics by enhancing interactions between the discriminator and the generator. Our experiments demonstrate that latent optimisation can significantly improve GAN training, obtaining state-of-the-art performance for the ImageNet () dataset. Our model achieves an Inception Score (IS) of  and an Fr\'echet Inception Distance (FID) of , an improvement of  and  in IS and FID respectively, compared with the baseline BigGAN-deep model with the same architecture and number of parameters.",https://arxiv.org/abs/1912.00953
Timothy P. Lillicrap,"& Wierstra, D.(2015). Continuous control with deep reinforcement learning",,arXiv preprint arXiv:1509.02971,110,"TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T Erez, Y Tassa",TP Lillicrap,Y Tassa,6,,https://scholar.google.com/scholar?cluster=15740630838900381866&hl=en&oi=scholarr
Timothy P. Lillicrap,A data-driven approach for learning to control computers,2022,International Conference on Machine Learning,106,"Peter C Humphreys, David Raposo, Tobias Pohlen, Gregory Thornton, Rachita Chhaparia, Alistair Muldal, Josh Abramson, Petko Georgiev, Adam Santoro, Timothy Lillicrap",Peter C Humphreys,Timothy Lillicrap,10,"It would be useful for machines to use computers as humans do so that they can aid us in everyday tasks. This is a setting in which there is also the potential to leverage large-scale expert demonstrations and human judgements of interactive behaviour, which are two ingredients that have driven much recent success in AI. Here we investigate the setting of computer control using keyboard and mouse, with goals specified via natural language. Instead of focusing on hand-designed curricula and specialized action spaces, we focus on developing a scalable method centered on reinforcement learning combined with behavioural priors informed by actual human-computer interactions. We achieve state-of-the-art and human-level mean performance across all tasks within the MiniWob++ benchmark, a challenging suite of computer control problems, and find strong evidence of cross-task transfer. These results demonstrate the usefulness of a unified human-agent interface when training machines to use computers. Altogether our results suggest a formula for achieving competency beyond MiniWob++ and towards controlling computers, in general, as a human would.",https://proceedings.mlr.press/v162/humphreys22a.html
Timothy P. Lillicrap,The functional specialization of visual cortex emerges from training parallel pathways with self-supervised predictive learning,2021,Advances in Neural Information Processing Systems,99,"Shahab Bakhtiari, Patrick Mineault, Timothy Lillicrap, Christopher Pack, Blake Richards",Shahab Bakhtiari,Blake Richards,5,"The visual system of mammals is comprised of parallel, hierarchical specialized pathways. Different pathways are specialized in so far as they use representations that are more suitable for supporting specific downstream behaviours. In particular, the clearest example is the specialization of the ventral ("" what"") and dorsal ("" where"") pathways of the visual cortex. These two pathways support behaviours related to visual recognition and movement, respectively. To-date, deep neural networks have mostly been used as models of the ventral, recognition pathway. However, it is unknown whether both pathways can be modelled with a single deep ANN. Here, we ask whether a single model with a single loss function can capture the properties of both the ventral and the dorsal pathways. We explore this question using data from mice, who like other mammals, have specialized pathways that appear to support recognition and movement behaviours. We show that when we train a deep neural network architecture with two parallel pathways using a self-supervised predictive loss function, we can outperform other models in fitting mouse visual cortex. Moreover, we can model both the dorsal and ventral pathways. These results demonstrate that a self-supervised predictive learning approach applied to parallel pathway architectures can account for some of the functional specialization seen in mammalian visual systems.",https://proceedings.neurips.cc/paper_files/paper/2021/hash/d384dec9f5f7a64a36b5c8f03b8a6d92-Abstract.html
Timothy P. Lillicrap,An investigation of model-free planning,2019,International Conference on Machine Learning,99,"Arthur Guez, Mehdi Mirza, Karol Gregor, Rishabh Kabra, Sébastien Racanière, Théophane Weber, David Raposo, Adam Santoro, Laurent Orseau, Tom Eccles, Greg Wayne, David Silver, Timothy Lillicrap",Arthur Guez,Timothy Lillicrap,13,"The field of reinforcement learning (RL) is facing increasingly challenging domains with combinatorial complexity. For an RL agent to address these challenges, it is essential that it can plan effectively. Prior work has typically utilized an explicit model of the environment, combined with a specific planning algorithm (such as tree search). More recently, a new family of methods have been proposed that learn how to plan, by providing the structure for planning via an inductive bias in the function approximator (such as a tree structured neural network), trained end-to-end by a model-free RL algorithm. In this paper, we go even further, and demonstrate empirically that an entirely model-free approach, without special structure beyond standard neural network components such as convolutional networks and LSTMs, can learn to exhibit many of the characteristics typically associated with a model-based planner. We measure our agent’s effectiveness at planning in terms of its ability to generalize across a combinatorial and irreversible state space, its data efficiency, and its ability to utilize additional thinking time. We find that our agent has many of the characteristics that one might expect to find in a planning algorithm. Furthermore, it exceeds the state-of-the-art in challenging combinatorial domains such as Sokoban and outperforms other model-free approaches that utilize strong inductive biases toward planning.",https://proceedings.mlr.press/v97/guez19a.html
Timothy P. Lillicrap,Noise contrastive priors for functional uncertainty,2020,Uncertainty in Artificial Intelligence,98,"Danijar Hafner, Dustin Tran, Timothy Lillicrap, Alex Irpan, James Davidson",Danijar Hafner,James Davidson,5,"Obtaining reliable uncertainty estimates of neural network predictions is a long standing challenge. Bayesian neural networks have been proposed as a solution, but it remains open how to specify their prior. In particular, the common practice of an independent normal prior in weight space imposes relatively weak constraints on the function posterior, allowing it to generalize in unforeseen ways on inputs outside of the training distribution. We propose noise contrastive priors (NCPs) to obtain reliable uncertainty estimates. The key idea is to train the model to output high uncertainty for data points outside of the training distribution. NCPs do so using an input prior, which adds noise to the inputs of the current mini batch, and an output prior, which is a wide distribution given these inputs. NCPs are compatible with any model that can output uncertainty estimates, are easy to scale, and yield reliable uncertainty estimates throughout training. Empirically, we show that NCPs prevent overfitting outside of the training distribution and result in uncertainty estimates that are useful for active learning. We demonstrate the scalability of our method on the flight delays data set, where we significantly improve upon previously published results.",https://proceedings.mlr.press/v115/hafner20a.html
Timothy P. Lillicrap,Learning to make analogies by contrasting abstract relational structure,2019,arXiv preprint arXiv:1902.00120,97,"Felix Hill, Adam Santoro, David GT Barrett, Ari S Morcos, Timothy Lillicrap",Felix Hill,Timothy Lillicrap,5,"Analogical reasoning has been a principal focus of various waves of AI research. Analogy is particularly challenging for machines because it requires relational structures to be represented such that they can be flexibly applied across diverse domains of experience. Here, we study how analogical reasoning can be induced in neural networks that learn to perceive and reason about raw visual data. We find that the critical factor for inducing such a capacity is not an elaborate architecture, but rather, careful attention to the choice of data and the manner in which it is presented to the model. The most robust capacity for analogical reasoning is induced when networks learn analogies by contrasting abstract relational structures in their input domains, a training method that uses only the input data to force models to learn about important abstract features. Using this technique we demonstrate capacities for complex, visual and symbolic analogy making and generalisation in even the simplest neural network architectures.",https://arxiv.org/abs/1902.00120
Timothy P. Lillicrap,Deep learning with dynamic spiking neurons and fixed feedback weights,2017,Neural computation,91,"Arash Samadi, Timothy P Lillicrap, Douglas B Tweed",Arash Samadi,Douglas B Tweed,3,"Recent work in computer science has shown the power of deep learning driven by the backpropagation algorithm in networks of artificial neurons. But real neurons in the brain are different from most of these artificial ones in at least three crucial ways: they emit spikes rather than graded outputs, their inputs and outputs are related dynamically rather than by piecewise-smooth functions, and they have no known way to coordinate arrays of synapses in separate forward and feedback pathways so that they change simultaneously and identically, as they do in backpropagation. Given these differences, it is unlikely that current deep learning algorithms can operate in the brain, but we that show these problems can be solved by two simple devices: learning rules can approximate dynamic input-output relations with piecewise-smooth functions, and a variation on the feedback alignment algorithm can train deep networks …",https://ieeexplore.ieee.org/abstract/document/7864507/
Timothy P. Lillicrap,Recall traces: Backtracking models for efficient reinforcement learning,2018,arXiv preprint arXiv:1804.00379,83,"Anirudh Goyal, Philemon Brakel, William Fedus, Soumye Singhal, Timothy Lillicrap, Sergey Levine, Hugo Larochelle, Yoshua Bengio",Anirudh Goyal,Yoshua Bengio,8,"In many environments only a tiny subset of all states yield high reward. In these cases, few of the interactions with the environment provide a relevant learning signal. Hence, we may want to preferentially train on those high-reward states and the probable trajectories leading to them. To this end, we advocate for the use of a backtracking model that predicts the preceding states that terminate at a given high-reward state. We can train a model which, starting from a high value state (or one that is estimated to have high value), predicts and sample for which the (state, action)-tuples may have led to that high value state. These traces of (state, action) pairs, which we refer to as Recall Traces, sampled from this backtracking model starting from a high value state, are informative as they terminate in good states, and hence we can use these traces to improve a policy. We provide a variational interpretation for this idea and a practical algorithm in which the backtracking model samples from an approximate posterior distribution over trajectories which lead to large rewards. Our method improves the sample efficiency of both on- and off-policy RL algorithms across several environments and tasks.",https://arxiv.org/abs/1804.00379
Timothy P. Lillicrap,Relevance realization and the emerging framework in cognitive science,2012,Journal of Logic and Computation,79,"John Vervaeke, Timothy P Lillicrap, Blake A Richards",John Vervaeke,Blake A Richards,3,"We argue that an explanation of relevance realization is a pervasive problem within cognitive science, and that it is becoming the criterion of the cognitive in terms of which a new framework for doing cognitive science is emerging. We articulate that framework and then make use of it to provide the beginnings of a theory of relevance realization that incorporates many existing insights implicit within the contributing disciplines of cognitive science. We also introduce some theoretical and potentially technical innovations motivated by the articulation of those insights. Finally, we show how the explication of the framework and development of the theory help to clear up some important incompleteness and confusions within both Montague's work and Sperber and Wilson's theory of relevance.",https://ieeexplore.ieee.org/abstract/document/8132809/
Timothy P. Lillicrap,Imitating interactive intelligence,2020,arXiv preprint arXiv:2012.05672,73,"Josh Abramson, Arun Ahuja, Iain Barr, Arthur Brussee, Federico Carnevale, Mary Cassin, Rachita Chhaparia, Stephen Clark, Bogdan Damoc, Andrew Dudzik, Petko Georgiev, Aurelia Guy, Tim Harley, Felix Hill, Alden Hung, Zachary Kenton, Jessica Landon, Timothy Lillicrap, Kory Mathewson, Soňa Mokrá, Alistair Muldal, Adam Santoro, Nikolay Savinov, Vikrant Varma, Greg Wayne, Duncan Williams, Nathaniel Wong, Chen Yan, Rui Zhu",Josh Abramson,Rui Zhu,29,"A common vision from science fiction is that robots will one day inhabit our physical spaces, sense the world as we do, assist our physical labours, and communicate with us through natural language. Here we study how to design artificial agents that can interact naturally with humans using the simplification of a virtual environment. This setting nevertheless integrates a number of the central challenges of artificial intelligence (AI) research: complex visual perception and goal-directed physical control, grounded language comprehension and production, and multi-agent social interaction. To build agents that can robustly interact with humans, we would ideally train them while they interact with humans. However, this is presently impractical. Therefore, we approximate the role of the human with another learned agent, and use ideas from inverse reinforcement learning to reduce the disparities between human-human and agent-agent interactive behaviour. Rigorously evaluating our agents poses a great challenge, so we develop a variety of behavioural tests, including evaluation by humans who watch videos of agents or interact directly with them. These evaluations convincingly demonstrate that interactive training and auxiliary losses improve agent behaviour beyond what is achieved by supervised learning of actions alone. Further, we demonstrate that agent capabilities generalise beyond literal experiences in the dataset. Finally, we train evaluation models whose ratings of agents agree well with human judgement, thus permitting the evaluation of new agent models without additional effort. Taken together, our results in this virtual environment …",https://arxiv.org/abs/2012.05672
Timothy P. Lillicrap,Asynchronous methods for deep reinforcement learning. arXiv 2016,1783,arXiv preprint arXiv:1602.01783,73,"Volodymyr Mnih, Adria Puigdomenech Badia, Mehdi Mirza, Alex Graves, Timothy P Lillicrap, Tim Harley, David Silver, Koray Kavukcuoglu",Volodymyr Mnih,Koray Kavukcuoglu,8,,https://scholar.google.com/scholar?cluster=16775925670020016423&hl=en&oi=scholarr
Timothy P. Lillicrap,Reliable uncertainty estimates in deep neural networks using noise contrastive priors,2018,stat,72,"Danijar Hafner, Dustin Tran, Alex Irpan, Timothy Lillicrap, James Davidson",Danijar Hafner,James Davidson,5,"Obtaining reliable uncertainty estimates of neural network predictions is a long standing challenge. Bayesian neural networks have been proposed as a solution, but it remains open how to specify the prior. In particular, the common practice of a standard normal prior in weight space imposes only weak regularities, causing the function posterior to possibly generalize in unforeseen ways on out-of-distribution inputs. We propose noise contrastive priors (NCPs). The key idea is to train the model to output high uncertainty for data points outside of the training distribution. NCPs do so using an input prior, which adds noise to the inputs of the current mini batch, and an output prior, which is a wide distribution given these inputs. NCPs are compatible with any model that represents predictive uncertainty, are easy to scale, and yield reliable uncertainty estimates throughout training. Empirically, we show that NCPs offer clear improvements as an addition to existing baselines. We demonstrate the scalability on the flight delays data set, where we significantly improve upon previously published results.",https://www.researchgate.net/profile/Timothy_Lillicrap/publication/326621764_Reliable_Uncertainty_Estimates_in_Deep_Neural_Networks_using_Noise_Contrastive_Priors/links/5b965e2b4585153a531a8af7/Reliable-Uncertainty-Estimates-in-Deep-Neural-Networks-using-Noise-Contrastive-Priors.pdf
Timothy P. Lillicrap,Towards principled unsupervised learning,2015,arxiv:1511.06440 preprint,71,"Ilya Sutskever, Rafal Jozefowicz, Karol Gregor, Danilo Rezende, Tim Lillicrap, Oriol Vinyals",Ilya Sutskever,Oriol Vinyals,6,"General unsupervised learning is a long-standing conceptual problem in machine learning. Supervised learning is successful because it can be solved by the minimization of the training error cost function. Unsupervised learning is not as successful, because the unsupervised objective may be unrelated to the supervised task of interest. For an example, density modelling and reconstruction have often been used for unsupervised learning, but they did not produced the sought-after performance gains, because they have no knowledge of the supervised tasks. In this paper, we present an unsupervised cost function which we name the Output Distribution Matching (ODM) cost, which measures a divergence between the distribution of predictions and distributions of labels. The ODM cost is appealing because it is consistent with the supervised cost in the following sense: a perfect supervised classifier is also perfect according to the ODM cost. Therefore, by aggressively optimizing the ODM cost, we are almost guaranteed to improve our supervised performance whenever the space of possible predictions is exponentially large. We demonstrate that the ODM cost works well on number of small and semi-artificial datasets using no (or almost no) labelled training cases. Finally, we show that the ODM cost can be used for one-shot domain adaptation, which allows the model to classify inputs that differ from the input distribution in significant ways without the need for prior exposure to the new domain.",https://arxiv.org/abs/1511.06440
Timothy P. Lillicrap,Toward next-generation artificial intelligence: Catalyzing the neuroai revolution,2022,arXiv preprint arXiv:2210.08340,65,"Anthony Zador, Sean Escola, Blake Richards, Bence Ölveczky, Yoshua Bengio, Kwabena Boahen, Matthew Botvinick, Dmitri Chklovskii, Anne Churchland, Claudia Clopath, James DiCarlo, Surya Ganguli, Jeff Hawkins, Konrad Koerding, Alexei Koulakov, Yann LeCun, Timothy Lillicrap, Adam Marblestone, Bruno Olshausen, Alexandre Pouget, Cristina Savin, Terrence Sejnowski, Eero Simoncelli, Sara Solla, David Sussillo, Andreas S Tolias, Doris Tsao",Anthony Zador,Doris Tsao,27,"Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities, inherited from over 500 million years of evolution, that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI.",https://arxiv.org/abs/2210.08340
Timothy P. Lillicrap,Generative temporal models with memory,2017,arXiv preprint arXiv:1702.04649,64,"Mevlana Gemici, Chia-Chun Hung, Adam Santoro, Greg Wayne, Shakir Mohamed, Danilo J Rezende, David Amos, Timothy Lillicrap",Mevlana Gemici,Timothy Lillicrap,8,"We consider the general problem of modeling temporal data with long-range dependencies, wherein new observations are fully or partially predictable based on temporally-distant, past observations. A sufficiently powerful temporal model should separate predictable elements of the sequence from unpredictable elements, express uncertainty about those unpredictable elements, and rapidly identify novel elements that may help to predict the future. To create such models, we introduce Generative Temporal Models augmented with external memory systems. They are developed within the variational inference framework, which provides both a practical training methodology and methods to gain insight into the models' operation. We show, on a range of problems with sparse, long-term temporal dependencies, that these models store information from early in a sequence, and reuse this stored information efficiently. This allows them to perform substantially better than existing models based on well-known recurrent neural networks, like LSTMs.",https://arxiv.org/abs/1702.04649
Timothy P. Lillicrap,Automated curricula through setter-solver interactions,2019,arXiv preprint arXiv:1909.12892,63,"Sebastien Racaniere, Andrew K Lampinen, Adam Santoro, David P Reichert, Vlad Firoiu, Timothy P Lillicrap",Sebastien Racaniere,Timothy P Lillicrap,6,"Reinforcement learning algorithms use correlations between policies and rewards to improve agent performance. But in dynamic or sparsely rewarding environments these correlations are often too small, or rewarding events are too infrequent to make learning feasible. Human education instead relies on curricula--the breakdown of tasks into simpler, static challenges with dense rewards--to build up to complex behaviors. While curricula are also useful for artificial agents, hand-crafting them is time consuming. This has lead researchers to explore automatic curriculum generation. Here we explore automatic curriculum generation in rich, dynamic environments. Using a setter-solver paradigm we show the importance of considering goal validity, goal feasibility, and goal coverage to construct useful curricula. We demonstrate the success of our approach in rich but sparsely rewarding 2D and 3D environments, where an agent is tasked to achieve a single goal selected from a set of possible goals that varies between episodes, and identify challenges for future work. Finally, we demonstrate the value of a novel technique that guides agents towards a desired goal distribution. Altogether, these results represent a substantial step towards applying automatic task curricula to learn complex, otherwise unlearnable goals, and to our knowledge are the first to demonstrate automated curriculum generation for goal-conditioned agents in environments where the possible goals vary between episodes.",https://arxiv.org/abs/1909.12892
Timothy P. Lillicrap,Adapting to inversion of the visual field: a new twist on an old problem,2013,Experimental brain research,60,"Timothy P Lillicrap, Pablo Moreno-Briseño, Rosalinda Diaz, Douglas B Tweed, Nikolaus F Troje, Juan Fernandez-Ruiz",Timothy P Lillicrap,Juan Fernandez-Ruiz,6,"While sensorimotor adaptation to prisms that displace the visual field takes minutes, adapting to an inversion of the visual field takes weeks. In spite of a long history of the study, the basis of this profound difference remains poorly understood. Here, we describe the computational issue that underpins this phenomenon and presents experiments designed to explore the mechanisms involved. We show that displacements can be mastered without altering the updated rule used to adjust the motor commands. In contrast, inversions flip the sign of crucial variables called sensitivity derivatives—variables that capture how changes in motor commands affect task error and therefore require an update of the feedback learning rule itself. Models of sensorimotor learning that assume internal estimates of these variables are known and fixed predicted that when the sign of a sensitivity derivative is flipped, adaptations …",https://link.springer.com/article/10.1007/s00221-013-3565-6
Timothy P. Lillicrap,Mixture-of-Depths: Dynamically allocating compute in transformer-based language models,2024,arXiv preprint arXiv:2404.02258,56,"David Raposo, Sam Ritter, Blake Richards, Timothy Lillicrap, Peter Conway Humphreys, Adam Santoro",David Raposo,Adam Santoro,6,"Transformer-based language models spread FLOPs uniformly across input sequences. In this work we demonstrate that transformers can instead learn to dynamically allocate FLOPs (or compute) to specific positions in a sequence, optimising the allocation along the sequence for different layers across the model depth. Our method enforces a total compute budget by capping the number of tokens () that can participate in the self-attention and MLP computations at a given layer. The tokens to be processed are determined by the network using a top- routing mechanism. Since  is defined a priori, this simple procedure uses a static computation graph with known tensor sizes, unlike other conditional computation techniques. Nevertheless, since the identities of the  tokens are fluid, this method can expend FLOPs non-uniformly across the time and model depth dimensions. Thus, compute expenditure is entirely predictable in sum total, but dynamic and context-sensitive at the token-level. Not only do models trained in this way learn to dynamically allocate compute, they do so efficiently. These models match baseline performance for equivalent FLOPS and wall-clock times to train, but require a fraction of the FLOPs per forward pass, and can be upwards of 50\% faster to step during post-training sampling.",https://arxiv.org/abs/2404.02258
Timothy P. Lillicrap,Rotational dynamics in motor cortex are consistent with a feedback controller,2021,Elife,56,"Hari Teja Kalidindi, Kevin P Cross, Timothy P Lillicrap, Mohsen Omrani, Egidio Falotico, Philip N Sabes, Stephen H Scott",Hari Teja Kalidindi,Stephen H Scott,7,"Recent studies have identified rotational dynamics in motor cortex (MC), which many assume arise from intrinsic connections in MC. However, behavioral and neurophysiological studies suggest that MC behaves like a feedback controller where continuous sensory feedback and interactions with other brain areas contribute substantially to MC processing. We investigated these apparently conflicting theories by building recurrent neural networks that controlled a model arm and received sensory feedback from the limb. Networks were trained to counteract perturbations to the limb and to reach toward spatial targets. Network activities and sensory feedback signals to the network exhibited rotational structure even when the recurrent connections were removed. Furthermore, neural recordings in monkeys performing similar tasks also exhibited rotational structure not only in MC but also in somatosensory cortex. Our results argue that rotational structure may also reflect dynamics throughout the voluntary motor system involved in online control of motor actions.",https://elifesciences.org/articles/67256
Timothy P. Lillicrap,"Double-stranded RNA as a not-self alarm signal: to evade, most viruses purine-load their RNAs, but some (HTLV-1, Epstein-Barr) pyrimidine-load",2001,Journal of theoretical biology,56,"AD Cristillo, JR Mortimer, IH Barrette, TP Lillicrap, DR Forsdyke",AD Cristillo,DR Forsdyke,5,"For double-stranded RNA (dsRNA) to signal the presence of foreign (non-self) nucleic acid, self-RNA–self-RNA interactions should be minimized. Indeed, self-RNAs appear to have been fine-tuned over evolutionary time by the introduction of purines in clusters in the loop regions of stem-loop structures. This adaptation should militate against the “kissing” interactions which initiate formation of dsRNA. Our analyses of virus base compositions suggest that, to avoid triggering the host cell's dsRNA surveillance mechanism, most viruses purine-load their RNAs to resemble host RNAs (“stealth” strategy). However, some GC-rich latent viruses (HTLV-1, EBV) pyrimidine-load their RNAs. It is suggested that when virus production begins, these RNAs suddenly increase in concentration and impair host mRNA function by virtue of an excess of complementary “kissing” interactions (“surprise” strategy). Remarkably, the only …",https://www.sciencedirect.com/science/article/pii/S0022519300922331
Timothy P. Lillicrap,Symbolic behaviour in artificial intelligence,2021,arXiv preprint arXiv:2102.03406,55,"Adam Santoro, Andrew Lampinen, Kory Mathewson, Timothy Lillicrap, David Raposo",Adam Santoro,David Raposo,5,"The ability to use symbols is the pinnacle of human intelligence, but has yet to be fully replicated in machines. Here we argue that the path towards symbolically fluent artificial intelligence (AI) begins with a reinterpretation of what symbols are, how they come to exist, and how a system behaves when it uses them. We begin by offering an interpretation of symbols as entities whose meaning is established by convention. But crucially, something is a symbol only for those who demonstrably and actively participate in this convention. We then outline how this interpretation thematically unifies the behavioural traits humans exhibit when they use symbols. This motivates our proposal that the field place a greater emphasis on symbolic behaviour rather than particular computational mechanisms inspired by more restrictive interpretations of symbols. Finally, we suggest that AI research explore social and cultural engagement as a tool to develop the cognitive machinery necessary for symbolic behaviour to emerge. This approach will allow for AI to interpret something as symbolic on its own rather than simply manipulate things that are only symbols to human onlookers, and thus will ultimately lead to AI with more human-like symbolic fluency.",https://arxiv.org/abs/2102.03406
Timothy P. Lillicrap,Retrieval-augmented reinforcement learning,2022,International Conference on Machine Learning,53,"Anirudh Goyal, Abram Friesen, Andrea Banino, Theophane Weber, Nan Rosemary Ke, Adria Puigdomenech Badia, Arthur Guez, Mehdi Mirza, Peter C Humphreys, Ksenia Konyushova, Michal Valko, Simon Osindero, Timothy Lillicrap, Nicolas Heess, Charles Blundell",Anirudh Goyal,Charles Blundell,15,"Most deep reinforcement learning (RL) algorithms distill experience into parametric behavior policies or value functions via gradient updates. While effective, this approach has several disadvantages:(1) it is computationally expensive,(2) it can take many updates to integrate experiences into the parametric model,(3) experiences that are not fully integrated do not appropriately influence the agent’s behavior, and (4) behavior is limited by the capacity of the model. In this paper we explore an alternative paradigm in which we train a network to map a dataset of past experiences to optimal behavior. Specifically, we augment an RL agent with a retrieval process (parameterized as a neural network) that has direct access to a dataset of experiences. This dataset can come from the agent’s past experiences, expert demonstrations, or any other relevant source. The retrieval process is trained to retrieve information from the dataset that may be useful in the current context, to help the agent achieve its goal faster and more efficiently. The proposed method facilitates learning agents that at test time can condition their behavior on the entire dataset and not only the current state, or current trajectory. We integrate our method into two different RL agents: an offline DQN agent and an online R2D2 agent. In offline multi-task problems, we show that the retrieval-augmented DQN agent avoids task interference and learns faster than the baseline DQN agent. On Atari, we show that retrieval-augmented R2D2 learns significantly faster than the baseline R2D2 agent and achieves higher scores. We run extensive ablations to measure the contributions of the components …",https://proceedings.mlr.press/v162/goyal22a.html
Timothy P. Lillicrap,Building machines that learn and think for themselves,2017,Behavioral and Brain Sciences,53,"Matthew Botvinick, David GT Barrett, Peter Battaglia, Nando de Freitas, Darshan Kumaran, Joel Z Leibo, Timothy Lillicrap, Joseph Modayil, Mohamed Shakir, Neil C Rabinowitz, Danilo J Rezende, Adam Santoro, Tom Schaul, Christopher Summerfield, Greg Wayne, Theophane Weber, Daan Wierstra, Shane Legg, Demis Hassabis",Matthew Botvinick,Demis Hassabis,19,"We agree with Lake and colleagues on their list of “key ingredients” for building human-like intelligence, including the idea that model-based reasoning is essential. However, we favor an approach that centers on one additional ingredient: autonomy. In particular, we aim toward agents that can both build and exploit their own internal models, with minimal human hand engineering. We believe an approach centered on autonomous learning has the greatest chance of success as we scale toward real-world complexity, tackling domains for which ready-made formal models are not available. Here, we survey several important examples of the progress that has been made toward building autonomous agents with human-like abilities, and highlight some outstanding challenges.",https://search.proquest.com/openview/6acf95cd14231fab649d777e78bd5644/1?pq-origsite=gscholar&cbl=47829
Timothy P. Lillicrap,Continuous control with deep reinforcement learning. CoRR abs/1509.02971 (2015),2015,arXiv preprint arXiv:1509.02971,53,"Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, Daan Wierstra",Timothy P Lillicrap,Daan Wierstra,8,,https://scholar.google.com/scholar?cluster=93005163953093940&hl=en&oi=scholarr
Timothy P. Lillicrap,Sensitivity derivatives for flexible sensorimotor learning,2008,Neural computation,52,"MN Abdelghani, Timothy P Lillicrap, Douglas B Tweed",MN Abdelghani,Douglas B Tweed,3,"To learn effectively, an adaptive controller needs to know its sensitivity derivatives—the variables that quantify how system performance depends on the commands from the controller. In the case of biological sensorimotor control, no one has explained how those derivatives themselves might be learned, and some authors suggest they are not learned at all but are known innately. Here we show that this knowledge cannot be solely innate, given the adaptive flexibility of neural systems. And we show how it could be learned using forms of information transport that are available in the brain. The mechanism, which we call implicit supervision, helps explain the flexibility and speed of sensorimotor learning and our ability to cope with high-dimensional work spaces and tools.",https://direct.mit.edu/neco/article-abstract/20/8/2085/7349
Timothy P. Lillicrap,Deep reinforcement learning for robotic manipulation,2022,,51,"Sergey Levine, Ethan Holly, Shixiang Gu, Timothy Lillicrap",Sergey Levine,Timothy Lillicrap,4,"Implementations utilize deep reinforcement learning to train a policy neural network that parameterizes a policy for determining a robotic action based on a current state. Some of those implementations collect experience data from multiple robots that operate simultaneously. Each robot generates instances of experience data during iterative performance of episodes that are each explorations of performing a task, and that are each guided based on the policy network and the current policy parameters for the policy network during the episode. The collected experience data is generated during the episodes and is used to train the policy network by iteratively updating policy parameters of the policy network based on a batch of collected experience data. Further, prior to performance of each of a plurality of episodes performed by the robots, the current updated policy parameters can be provided (or retrieved) for …",https://patents.google.com/patent/US11400587B2/en
Timothy P. Lillicrap,The kanerva machine: A generative distributed memory,2018,arXiv preprint arXiv:1804.01756,51,"Yan Wu, Greg Wayne, Alex Graves, Timothy Lillicrap",Yan Wu,Timothy Lillicrap,4,"We present an end-to-end trained memory system that quickly adapts to new data and generates samples like them. Inspired by Kanerva's sparse distributed memory, it has a robust distributed reading and writing mechanism. The memory is analytically tractable, which enables optimal on-line compression via a Bayesian update-rule. We formulate it as a hierarchical conditional generative model, where memory provides a rich data-dependent prior distribution. Consequently, the top-down memory and bottom-up perception are combined to produce the code representing an observation. Empirically, we demonstrate that the adaptive memory significantly improves generative models trained on both the Omniglot and CIFAR datasets. Compared with the Differentiable Neural Computer (DNC) and its variants, our memory model has greater capacity and is significantly easier to train.",https://arxiv.org/abs/1804.01756
Timothy P. Lillicrap,Fast parametric learning with activation memorization,2018,International Conference on Machine Learning,49,"Jack Rae, Chris Dyer, Peter Dayan, Timothy Lillicrap",Jack Rae,Timothy Lillicrap,4,"Neural networks trained with backpropagation often struggle to identify classes that have been observed a small number of times. In applications where most class labels are rare, such as language modelling, this can become a performance bottleneck. One potential remedy is to augment the network with a fast-learning non-parametric model which stores recent activations and class labels into an external memory. We explore a simplified architecture where we treat a subset of the model parameters as fast memory stores. This can help retain information over longer time intervals than a traditional memory, and does not require additional space or compute. In the case of image classification, we display faster binding of novel classes on an Omniglot image curriculum task. We also show improved performance for word-based language models on news reports (GigaWord), books (Project Gutenberg) and Wikipedia articles (WikiText-103)-the latter achieving a state-of-the-art perplexity of 29.2.",https://proceedings.mlr.press/v80/rae18a.html
Timothy P. Lillicrap,International conference on machine learning,2016,,49,"V Mnih, AP Badia, M Mirza, A Graves, T Lillicrap, T Harley, D Silver, K Kavukcuoglu",V Mnih,K Kavukcuoglu,8,,https://scholar.google.com/scholar?cluster=2400222426818286854&hl=en&oi=scholarr
Timothy P. Lillicrap,What does it mean to understand a neural network?,2019,arXiv preprint arXiv:1907.06374,48,"Timothy P Lillicrap, Konrad P Kording",Timothy P Lillicrap,Konrad P Kording,2,"We can define a neural network that can learn to recognize objects in less than 100 lines of code. However, after training, it is characterized by millions of weights that contain the knowledge about many object types across visual scenes. Such networks are thus dramatically easier to understand in terms of the code that makes them than the resulting properties, such as tuning or connections. In analogy, we conjecture that rules for development and learning in brains may be far easier to understand than their resulting properties. The analogy suggests that neuroscience would benefit from a focus on learning and development.",https://arxiv.org/abs/1907.06374
Timothy P. Lillicrap,Creating multimodal interactive agents with imitation and self-supervised learning,2021,arXiv preprint arXiv:2112.03763,47,"DeepMind Interactive Agents Team, Josh Abramson, Arun Ahuja, Arthur Brussee, Federico Carnevale, Mary Cassin, Felix Fischer, Petko Georgiev, Alex Goldin, Mansi Gupta, Tim Harley, Felix Hill, Peter C Humphreys, Alden Hung, Jessica Landon, Timothy Lillicrap, Hamza Merzic, Alistair Muldal, Adam Santoro, Guy Scully, Tamara von Glehn, Greg Wayne, Nathaniel Wong, Chen Yan, Rui Zhu",DeepMind Interactive Agents Team,Rui Zhu,25,"A common vision from science fiction is that robots will one day inhabit our physical spaces, sense the world as we do, assist our physical labours, and communicate with us through natural language. Here we study how to design artificial agents that can interact naturally with humans using the simplification of a virtual environment. We show that imitation learning of human-human interactions in a simulated world, in conjunction with self-supervised learning, is sufficient to produce a multimodal interactive agent, which we call MIA, that successfully interacts with non-adversarial humans 75% of the time. We further identify architectural and algorithmic techniques that improve performance, such as hierarchical action selection. Altogether, our results demonstrate that imitation of multi-modal, real-time human behaviour may provide a straightforward and surprisingly effective means of imbuing agents with a rich behavioural prior from which agents might then be fine-tuned for specific purposes, thus laying a foundation for training capable agents for interactive robots or digital assistants. A video of MIA's behaviour may be found at https://youtu.be/ZFgRhviF7mY",https://arxiv.org/abs/2112.03763
Timothy P. Lillicrap,Method of training a neural network,2016,,46,"Timothy Lillicrap, Colin Akerman, Douglas Tweed, Daniel Cownden",Timothy Lillicrap,Daniel Cownden,4,"0007 According to a first aspect of the invention there is provided a method of training a neural network having at least an input layer, a hidden layer and an output layer, and a plurality of forward weight matrices encoding connection weights between Successive pairs of layers, the method com prising the steps of: 0008 (a) providing an input to the input layer, the input having an associated expected output, 0009 (b) receiving a generated output at the output layer, 0010 (c) generating an error vector from the difference between the generated output and expected output, 0011 (d) for at least one pair of the layers, generating a change matrix, the change matrix being the product of a fixed random feedback weight matrix and the error vector, and 0012 (e) modifying the forward weight matrix for the at least one pair of the layers in accordance with the change matrix.",https://patents.google.com/patent/US20160162781A1/en
Timothy P. Lillicrap,Meta-learning neural bloom filters,2019,International Conference on Machine Learning,44,"Jack Rae, Sergey Bartunov, Timothy Lillicrap",Jack Rae,Timothy Lillicrap,3,"There has been a recent trend in training neural networks to replace data structures that have been crafted by hand, with an aim for faster execution, better accuracy, or greater compression. In this setting, a neural data structure is instantiated by training a network over many epochs of its inputs until convergence. In applications where inputs arrive at high throughput, or are ephemeral, training a network from scratch is not practical. This motivates the need for few-shot neural data structures. In this paper we explore the learning of approximate set membership over a set of data in one-shot via meta-learning. We propose a novel memory architecture, the Neural Bloom Filter, which is able to achieve significant compression gains over classical Bloom Filters and existing memory-augmented neural networks.",http://proceedings.mlr.press/v97/rae19a.html
Timothy P. Lillicrap,"kavukcuoglu, k.; and Wierstra, D. 2016. Matching networks for one shot learning",,Advances in neural information processing systems,44,"O Vinyals, C Blundell, T Lillicrap",O Vinyals,T Lillicrap,3,,https://scholar.google.com/scholar?cluster=5583423781232034891&hl=en&oi=scholarr
Timothy P. Lillicrap,Automated curriculum generation through setter-solver interactions,2020,International conference on learning representations,43,"Sebastien Racaniere, Andrew Lampinen, Adam Santoro, David Reichert, Vlad Firoiu, Timothy Lillicrap",Sebastien Racaniere,Timothy Lillicrap,6,"Reinforcement learning algorithms use correlations between policies and rewards to improve agent performance.   But in dynamic or sparsely rewarding environments these correlations are often too small,  or rewarding events are too infrequent to make learning feasible. Human education instead relies on curricula –the breakdown of tasks into simpler, static challenges with dense rewards– to build up to complex behaviors.  While curricula are also useful for artificial agents, hand-crafting them is time consuming.  This has lead researchers to explore automatic curriculum generation. Here we explore automatic curriculum generation in rich,dynamic environments.  Using a setter-solver paradigm we show the importance of considering goal validity, goal feasibility, and goal coverage to construct useful curricula.  We demonstrate the success of our approach in rich but sparsely rewarding 2D and 3D environments, where an agent is tasked to achieve a single goal selected from a set of possible goals that varies between episodes, and identify challenges for future work.  Finally, we demonstrate the value of a novel technique that guides agents towards a desired goal distribution. Altogether, these results represent a substantial step towards applying automatic task curricula to learn complex,  otherwise unlearnable goals,  and to our knowledge are the first to demonstrate automated curriculum generation for goal-conditioned agents in environments where the possible goals vary between episodes.",https://openreview.net/forum?id=H1e0Wp4KvH
Timothy P. Lillicrap,Training generative adversarial networks by solving ordinary differential equations,2020,Advances in Neural Information Processing Systems,41,"Chongli Qin, Yan Wu, Jost Tobias Springenberg, Andy Brock, Jeff Donahue, Timothy Lillicrap, Pushmeet Kohli",Chongli Qin,Pushmeet Kohli,7,"The instability of Generative Adversarial Network (GAN) training has frequently been attributed to gradient descent. Consequently, recent methods have aimed to tailor the models and training procedures to stabilise the discrete updates. In contrast, we study the continuous-time dynamics induced by GAN training. Both theory and toy experiments suggest that these dynamics are in fact surprisingly stable. From this perspective, we hypothesise that instabilities in training GANs arise from the integration error in discretising the continuous dynamics. We experimentally verify that well-known ODE solvers (such as Runge-Kutta) can stabilise training-when combined with a regulariser that controls the integration error. Our approach represents a radical departure from previous methods which typically use adaptive optimisation and stabilisation techniques that constrain the functional space (eg Spectral Normalisation). Evaluation on CIFAR-10 and ImageNet shows that our method outperforms several strong baselines, demonstrating its efficacy.",https://proceedings.neurips.cc/paper/2020/hash/3c8f9a173f749710d6377d3150cf90da-Abstract.html
Timothy P. Lillicrap,Entropic Policy Composition with Generalized Policy Improvement and Divergence Correction.,2018,arXiv preprint arXiv:1812.02216,41,"Jonathan J Hunt, André Barreto, Timothy P Lillicrap, Nicolas Heess",Jonathan J Hunt,Nicolas Heess,4,"Deep reinforcement learning (RL) algorithms have made great strides in recent years. An important remaining challenge is the ability to quickly transfer existing skills to novel tasks, and to combine existing skills with newly acquired ones. In domains where tasks are solved by composing skills this capacity holds the promise of dramatically reducing the data requirements of deep RL algorithms, and hence increasing their applicability. Recent work has studied ways of composing behaviors represented in the form of action-value functions. We analyze these methods to highlight their strengths and weaknesses, and point out situations where each of them is susceptible to poor performance. To perform this analysis we extend generalized policy improvement to the max-entropy framework and introduce a method for the practical implementation of successor features in continuous action spaces. Then we propose a novel approach which, in principle, recovers the optimal policy during transfer. This method works by explicitly learning the (discounted, future) divergence between policies. We study this approach in the tabular case and propose a scalable variant that is applicable in multi-dimensional continuous action spaces. We compare our approach with existing ones on a range of nontrivial continuous control problems with compositional structure, and demonstrate qualitatively better performance despite not requiring simultaneous observation of all task rewards.",https://me.net.nz/files/publications/hunt2018.pdf
Timothy P. Lillicrap,A meta-learning approach to (re) discover plasticity rules that carve a desired function into a neural network,2020,Advances in Neural Information Processing Systems,40,"Basile Confavreux, Friedemann Zenke, Everton Agnes, Timothy Lillicrap, Tim Vogels",Basile Confavreux,Tim Vogels,5,"The search for biologically faithful synaptic plasticity rules has resulted in a large body of models. They are usually inspired by--and fitted to--experimental data, but they rarely produce neural dynamics that serve complex functions. These failures suggest that current plasticity models are still under-constrained by existing data. Here, we present an alternative approach that uses meta-learning to discover plausible synaptic plasticity rules. Instead of experimental data, the rules are constrained by the functions they implement and the structure they are meant to produce. Briefly, we parameterize synaptic plasticity rules by a Volterra expansion and then use supervised learning methods (gradient descent or evolutionary strategies) to minimize a problem-dependent loss function that quantifies how effectively a candidate plasticity rule transforms an initially random network into one with the desired function. We first validate our approach by re-discovering previously described plasticity rules, starting at the single-neuron level and``Oja’s rule'', a simple Hebbian plasticity rule that captures the direction of most variability of inputs to a neuron (ie, the first principal component). We expand the problem to the network level and ask the framework to find Oja’s rule together with an anti-Hebbian rule such that an initially random two-layer firing-rate network will recover several principal components of the input space after learning. Next, we move to networks of integrate-and-fire neurons with plastic inhibitory afferents. We train for rules that achieve a target firing rate by countering tuned excitation. Our algorithm discovers a specific subset of the manifold of rules …",https://proceedings.neurips.cc/paper/2020/hash/bdbd5ebfde4934142c8a88e7a3796cd5-Abstract.html
Timothy P. Lillicrap,Monte Carlo Tree Search Boosts Reasoning via Iterative Preference Learning,2024,arXiv preprint arXiv:2405.00451,39,"Yuxi Xie, Anirudh Goyal, Wenyue Zheng, Min-Yen Kan, Timothy P Lillicrap, Kenji Kawaguchi, Michael Shieh",Yuxi Xie,Michael Shieh,7,"We introduce an approach aimed at enhancing the reasoning capabilities of Large Language Models (LLMs) through an iterative preference learning process inspired by the successful strategy employed by AlphaZero. Our work leverages Monte Carlo Tree Search (MCTS) to iteratively collect preference data, utilizing its look-ahead ability to break down instance-level rewards into more granular step-level signals. To enhance consistency in intermediate steps, we combine outcome validation and stepwise self-evaluation, continually updating the quality assessment of newly generated data. The proposed algorithm employs Direct Preference Optimization (DPO) to update the LLM policy using this newly generated step-level preference data. Theoretical analysis reveals the critical importance of using on-policy sampled data for successful self-improving. Extensive evaluations on various arithmetic and commonsense reasoning tasks demonstrate remarkable performance improvements over existing models. For instance, our approach outperforms the Mistral-7B Supervised Fine-Tuning (SFT) baseline on GSM8K, MATH, and SciQ, with substantial percentage increases in accuracy to  (+),  (+), and  (+), respectively. Additionally, our research delves into the training and inference compute tradeoff, providing insights into how our method effectively maximizes performance gains.",https://arxiv.org/abs/2405.00451
Timothy P. Lillicrap,Meta-learning deep energy-based memory models,2019,arXiv preprint arXiv:1910.02720,38,"Sergey Bartunov, Jack W Rae, Simon Osindero, Timothy P Lillicrap",Sergey Bartunov,Timothy P Lillicrap,4,"We study the problem of learning associative memory -- a system which is able to retrieve a remembered pattern based on its distorted or incomplete version. Attractor networks provide a sound model of associative memory: patterns are stored as attractors of the network dynamics and associative retrieval is performed by running the dynamics starting from a query pattern until it converges to an attractor. In such models the dynamics are often implemented as an optimization procedure that minimizes an energy function, such as in the classical Hopfield network. In general it is difficult to derive a writing rule for a given dynamics and energy that is both compressive and fast. Thus, most research in energy-based memory has been limited either to tractable energy models not expressive enough to handle complex high-dimensional objects such as natural images, or to models that do not offer fast writing. We present a novel meta-learning approach to energy-based memory models (EBMM) that allows one to use an arbitrary neural architecture as an energy model and quickly store patterns in its weights. We demonstrate experimentally that our EBMM approach can build compressed memories for synthetic and natural data, and is capable of associative retrieval that outperforms existing memory systems in terms of the reconstruction error and compression rate.",https://arxiv.org/abs/1910.02720
Timothy P. Lillicrap,Reinforcement learning using advantage estimates,2022,,35,"Shixiang Gu, Timothy Paul Lillicrap, Ilya Sutskever, Sergey Vladimir Levine",Shixiang Gu,Sergey Vladimir Levine,4,"US 2017/0228662 A1 Aug. 10, 2017 Related US Application Data Provisional application No. 62/293,250, filed on Feb.",https://patents.google.com/patent/US11288568B2/en
Timothy P. Lillicrap,Matching networks for one shot learning. arXiv 2016,,arXiv preprint arXiv:1606.04080,34,"Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu, Daan Wierstra",Oriol Vinyals,Daan Wierstra,5,,https://scholar.google.com/scholar?cluster=14240037355404761844&hl=en&oi=scholarr
Timothy P. Lillicrap,Improving multimodal interactive agents with reinforcement learning from human feedback,2022,arXiv preprint arXiv:2211.11602,32,"Josh Abramson, Arun Ahuja, Federico Carnevale, Petko Georgiev, Alex Goldin, Alden Hung, Jessica Landon, Jirka Lhotka, Timothy Lillicrap, Alistair Muldal, George Powell, Adam Santoro, Guy Scully, Sanjana Srivastava, Tamara von Glehn, Greg Wayne, Nathaniel Wong, Chen Yan, Rui Zhu",Josh Abramson,Rui Zhu,19,"An important goal in artificial intelligence is to create agents that can both interact naturally with humans and learn from their feedback. Here we demonstrate how to use reinforcement learning from human feedback (RLHF) to improve upon simulated, embodied agents trained to a base level of competency with imitation learning. First, we collected data of humans interacting with agents in a simulated 3D world. We then asked annotators to record moments where they believed that agents either progressed toward or regressed from their human-instructed goal. Using this annotation data we leveraged a novel method - which we call ""Inter-temporal Bradley-Terry"" (IBT) modelling - to build a reward model that captures human judgments. Agents trained to optimise rewards delivered from IBT reward models improved with respect to all of our metrics, including subsequent human judgment during live interactions with agents. Altogether our results demonstrate how one can successfully leverage human judgments to improve agent behaviour, allowing us to use reinforcement learning in complex, embodied domains without programmatic reward functions. Videos of agent behaviour may be found at https://youtu.be/v_Z9F2_eKk4.",https://arxiv.org/abs/2211.11602
Timothy P. Lillicrap,Towards biologically plausible convolutional networks,2021,Advances in Neural Information Processing Systems,32,"Roman Pogodin, Yash Mehta, Timothy Lillicrap, Peter E Latham",Roman Pogodin,Peter E Latham,4,"Convolutional networks are ubiquitous in deep learning. They are particularly useful for images, as they reduce the number of parameters, reduce training time, and increase accuracy. However, as a model of the brain they are seriously problematic, since they require weight sharing-something real neurons simply cannot do. Consequently, while neurons in the brain can be locally connected (one of the features of convolutional networks), they cannot be convolutional. Locally connected but non-convolutional networks, however, significantly underperform convolutional ones. This is troublesome for studies that use convolutional networks to explain activity in the visual system. Here we study plausible alternatives to weight sharing that aim at the same regularization principle, which is to make each neuron within a pool react similarly to identical inputs. The most natural way to do that is by showing the network multiple translations of the same image, akin to saccades in animal vision. However, this approach requires many translations, and doesn't remove the performance gap. We propose instead to add lateral connectivity to a locally connected network, and allow learning via Hebbian plasticity. This requires the network to pause occasionally for a sleep-like phase of"" weight sharing"". This method enables locally connected networks to achieve nearly convolutional performance on ImageNet and improves their fit to the ventral stream data, thus supporting convolutional networks as a model of the visual stream.",https://proceedings.neurips.cc/paper/2021/hash/746b02b6680562f44ad7526675bac026-Abstract.html
Timothy P. Lillicrap,Learning from unexpected events in the neocortical microcircuit,2021,BioRxiv,29,"Colleen J Gillon, Jason E Pina, Jérôme A Lecoq, Ruweida Ahmed, Yazan N Billeh, Shiella Caldejon, Peter Groblewski, Timothy M Henley, India Kato, Eric Lee, Jennifer Luviano, Kyla Mace, Chelsea Nayan, Thuyanh V Nguyen, Kat North, Jed Perkins, Sam Seid, Matthew T Valley, Ali Williford, Yoshua Bengio, Timothy P Lillicrap, Blake A Richards, Joel Zylberberg",Colleen J Gillon,Joel Zylberberg,23,"Scientists have long conjectured that the neocortex learns the structure of the environment in a predictive, hierarchical manner. To do so, expected, predictable features are differentiated from unexpected ones by comparing bottom-up and top-down streams of data. It is theorized that the neocortex then changes the representation of incoming stimuli, guided by differences in the responses to expected and unexpected events. Such differences in cortical responses have been observed; however, it remains unknown whether these unexpected event signals govern subsequent changes in the brain’s stimulus representations, and, thus, govern learning. Here, we show that unexpected event signals predict subsequent changes in responses to expected and unexpected stimuli in individual neurons and distal apical dendrites that are tracked over a period of days. These findings were obtained by observing layer 2/3 and layer 5 pyramidal neurons in primary visual cortex of awake, behaving mice using two-photon calcium imaging. We found that many neurons in both layers 2/3 and 5 showed large differences between their responses to expected and unexpected events. These unexpected event signals also determined how the responses evolved over subsequent days, in a manner that was different between the somata and distal apical dendrites. This difference between the somata and distal apical dendrites may be important for hierarchical computation, given that these two compartments tend to receive bottom-up and top-down information, respectively. Together, our results provide novel evidence that the neocortex indeed instantiates a predictive …",https://www.biorxiv.org/content/10.1101/2021.01.15.426915.abstract
Timothy P. Lillicrap,AndroidWorld: A dynamic benchmarking environment for autonomous agents,2024,arXiv preprint arXiv:2405.14573,28,"Christopher Rawles, Sarah Clinckemaillie, Yifan Chang, Jonathan Waltz, Gabrielle Lau, Marybeth Fair, Alice Li, William Bishop, Wei Li, Folawiyo Campbell-Ajala, Daniel Toyama, Robert Berry, Divya Tyamagundlu, Timothy Lillicrap, Oriana Riva",Christopher Rawles,Oriana Riva,15,"Autonomous agents that execute human tasks by controlling computers can enhance human productivity and application accessibility. Yet, progress in this field will be driven by realistic and reproducible benchmarks. We present AndroidWorld, a fully functioning Android environment that provides reward signals for 116 programmatic task workflows across 20 real world Android applications. Unlike existing interactive environments, which provide a static test set, AndroidWorld dynamically constructs tasks that are parameterized and expressed in natural language in unlimited ways, thus enabling testing on a much larger and realistic suite of tasks. Reward signals are derived from the computer's system state, making them durable across task variations and extensible across different apps. To demonstrate AndroidWorld's benefits and mode of operation, we introduce a new computer control agent, M3A. M3A can complete 30.6% of the AndroidWorld's tasks, leaving ample room for future work. Furthermore, we adapt a popular desktop web agent to work on Android, which we find to be less effective on mobile, suggesting future research is needed to achieve universal, cross-domain agents. Finally, we conduct a robustness analysis by testing M3A against a range of task variations on a representative subset of tasks, demonstrating that variations in task parameters can significantly alter the complexity of a task and therefore an agent's performance, highlighting the importance of testing agents under diverse conditions. AndroidWorld and the experiments in this paper are available at https://github.com/google-research/android_world.",https://arxiv.org/abs/2405.14573
Timothy P. Lillicrap,Large-scale retrieval for reinforcement learning,2022,Advances in Neural Information Processing Systems,27,"Peter Humphreys, Arthur Guez, Olivier Tieleman, Laurent Sifre, Théophane Weber, Timothy Lillicrap",Peter Humphreys,Timothy Lillicrap,6,"Effective decision making involves flexibly relating past experiences and relevant contextual information to a novel situation. In deep reinforcement learning (RL), the dominant paradigm is for an agent to amortise information that helps decision-making into its network weights via gradient descent on training losses. Here, we pursue an alternative approach in which agents can utilise large-scale context-sensitive database lookups to support their parametric computations. This allows agents to directly learn in an end-to-end manner to utilise relevant information to inform their outputs. In addition, new information can be attended to by the agent, without retraining, by simply augmenting the retrieval dataset. We study this approach for offline RL in 9x9 Go, a challenging game for which the vast combinatorial state space privileges generalisation over direct matching to past experiences. We leverage fast, approximate nearest neighbor techniques in order to retrieve relevant data from a set of tens of millions of expert demonstration states. Attending to this information provides a significant boost to prediction accuracy and game-play performance over simply using these demonstrations as training trajectories, providing a compelling demonstration of the value of large-scale retrieval in offline RL agents.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/7eca17ef54789b0663cab421f2e9dbf5-Abstract-Conference.html
Timothy P. Lillicrap,Inclusive fitness analysis on mathematical groups,2011,Evolution,25,"Peter Taylor, Timothy Lillicrap, Daniel Cownden",Peter Taylor,Daniel Cownden,3,"Recent work on the evolution of behaviour is set in a structured population, providing a systematic way to describe gene flow and behavioural interactions. To obtain analytical results one needs a structure with considerable regularity. Our results apply to such “homogeneous” structures (e.g., lattices, cycles, and island models). This regularity has been formally described by a “node‐transitivity” condition but in mathematics, such internal symmetry is powerfully described by the theory of mathematical groups. Here, this theory provides elegant direct arguments for a more general version of a number of existing results. Our main result is that in large “group‐structured” populations, primary fitness effects on others play no role in the evolution of the behaviour. The competitive effects of such a trait cancel the primary effects, and the inclusive fitness effect is given by the direct effect of the actor on its own fitness. This …",https://academic.oup.com/evolut/article-abstract/65/3/849/6854008
Timothy P. Lillicrap,Temporal evolution of both premotor and motor cortical tuning properties reflect changes in limb biomechanics,2015,Journal of neurophysiology,24,"Aaron J Suminski, Philip Mardoum, Timothy P Lillicrap, Nicholas G Hatsopoulos",Aaron J Suminski,Nicholas G Hatsopoulos,4,"A prevailing theory in the cortical control of limb movement posits that premotor cortex initiates a high-level motor plan that is transformed by the primary motor cortex (MI) into a low-level motor command to be executed. This theory implies that the premotor cortex is shielded from the motor periphery, and therefore, its activity should not represent the low-level features of movement. Contrary to this theory, we show that both dorsal (PMd) and ventral premotor (PMv) cortexes exhibit population-level tuning properties that reflect the biomechanical properties of the periphery similar to those observed in M1. We recorded single-unit activity from M1, PMd, and PMv and characterized their tuning properties while six rhesus macaques performed a reaching task in the horizontal plane. Each area exhibited a bimodal distribution of preferred directions during execution consistent with the known biomechanical anisotropies of …",https://journals.physiology.org/doi/abs/10.1152/jn.00486.2014
Timothy P. Lillicrap,The brain-computer metaphor debate is useless: A matter of semantics,2022,,22,"Blake A Richards, Timothy P Lillicrap",Blake A Richards,Timothy P Lillicrap,2,"It is commonly assumed that usage of the word “computer” in the brain sciences reflects a metaphor. However, there is no single definition of the word “computer” in use. In fact, based on the usage of the word “computer” in computer science, a computer is merely some physical machinery that can in theory compute any computable function. According to this definition the brain is literally a computer; there is no metaphor. But, this deviates from how the word “computer” is used in other academic disciplines. According to the definition used outside of computer science, “computers” are human-made devices that engage in sequential processing of inputs to produce outputs. According to this definition, brains are not computers, and arguably, computers serve as a weak metaphor for brains. Thus, we argue that the recurring brain-computer metaphor debate is actually just a semantic disagreement, because brains are either literally computers or clearly not very much like computers at all, depending on one's definitions. We propose that the best path forward is simply to put the debate to rest, and instead, have researchers be clear about which definition they are using in their work. In some circumstances, one can use the definition from computer science and simply ask, what type of computer is the brain? In other circumstances, it is important to use the other definition, and to clarify the ways in which our brains are radically different from the laptops, smartphones, and servers that surround us in modern life.",https://www.frontiersin.org/articles/10.3389/fcomp.2022.810358/full
Timothy P. Lillicrap,Learning attractor dynamics for generative memory,2018,Advances in Neural Information Processing Systems,22,"Yan Wu, Gregory Wayne, Karol Gregor, Timothy Lillicrap",Yan Wu,Timothy Lillicrap,4,"A central challenge faced by memory systems is the robust retrieval of a stored pattern in the presence of interference due to other stored patterns and noise. A theoretically well-founded solution to robust retrieval is given by attractor dynamics, which iteratively cleans up patterns during recall. However, incorporating attractor dynamics into modern deep learning systems poses difficulties: attractor basins are characterised by vanishing gradients, which are known to make training neural networks difficult. In this work, we exploit recent advances in variational inference and avoid the vanishing gradient problem by training a generative distributed memory with a variational lower-bound-based Lyapunov function. The model is minimalistic with surprisingly few parameters. Experiments shows it converges to correct patterns upon iterative retrieval and achieves competitive performance as both a memory model and a generative model.",https://proceedings.neurips.cc/paper/2018/hash/6e4243f5511fd6ef0f03e9f386d54403-Abstract.html
Timothy P. Lillicrap,Primary motor cortex neurons classified in a postural task predict muscle activation patterns in a reaching task,2016,Journal of Neurophysiology,21,"Ethan A Heming, Timothy P. Lillicrap, Mohsen Omrani, Troy M. Herter, J. Andrew Pruszynski, Stephen H. Scott",Ethan A Heming,Stephen H. Scott,6,"Primary motor cortex (M1) activity correlates with many motor variables, making it difficult to demonstrate how it participates in motor control. We developed a two-stage process to separate the process of classifying the motor field of M1 neurons from the process of predicting the spatiotemporal patterns of its motor field during reaching. We tested our approach with a neural network model that controlled a two-joint arm to show the statistical relationship between network connectivity and neural activity across different motor tasks. In rhesus monkeys, M1 neurons classified by this method showed preferred reaching directions similar to their associated muscle groups. Importantly, the neural population signals predicted the spatiotemporal dynamics of their associated muscle groups, although a subgroup of atypical neurons reversed their directional preference, suggesting a selective role in antagonist control. These …",https://journals.physiology.org/doi/abs/10.1152/jn.00971.2015
Timothy P. Lillicrap,Metacognitive Capabilities of LLMs: An Exploration in Mathematical Problem Solving,2024,arXiv preprint arXiv:2405.12205,20,"Aniket Didolkar, Anirudh Goyal, Nan Rosemary Ke, Siyuan Guo, Michal Valko, Timothy Lillicrap, Danilo Rezende, Yoshua Bengio, Michael Mozer, Sanjeev Arora",Aniket Didolkar,Sanjeev Arora,10,"Metacognitive knowledge refers to humans' intuitive knowledge of their own thinking and reasoning processes. Today's best LLMs clearly possess some reasoning processes. The paper gives evidence that they also have metacognitive knowledge, including ability to name skills and procedures to apply given a task. We explore this primarily in context of math reasoning, developing a prompt-guided interaction procedure to get a powerful LLM to assign sensible skill labels to math questions, followed by having it perform semantic clustering to obtain coarser families of skill labels. These coarse skill labels look interpretable to humans. To validate that these skill labels are meaningful and relevant to the LLM's reasoning processes we perform the following experiments. (a) We ask GPT-4 to assign skill labels to training questions in math datasets GSM8K and MATH. (b) When using an LLM to solve the test questions, we present it with the full list of skill labels and ask it to identify the skill needed. Then it is presented with randomly selected exemplar solved questions associated with that skill label. This improves accuracy on GSM8k and MATH for several strong LLMs, including code-assisted models. The methodology presented is domain-agnostic, even though this article applies it to math problems.",https://arxiv.org/abs/2405.12205
Timothy P. Lillicrap,Evaluating long-term memory in 3d mazes,2022,arXiv preprint arXiv:2210.13383,18,"Jurgis Pasukonis, Timothy Lillicrap, Danijar Hafner",Jurgis Pasukonis,Danijar Hafner,3,"Intelligent agents need to remember salient information to reason in partially-observed environments. For example, agents with a first-person view should remember the positions of relevant objects even if they go out of view. Similarly, to effectively navigate through rooms agents need to remember the floor plan of how rooms are connected. However, most benchmark tasks in reinforcement learning do not test long-term memory in agents, slowing down progress in this important research direction. In this paper, we introduce the Memory Maze, a 3D domain of randomized mazes specifically designed for evaluating long-term memory in agents. Unlike existing benchmarks, Memory Maze measures long-term memory separate from confounding agent abilities and requires the agent to localize itself by integrating information over time. With Memory Maze, we propose an online reinforcement learning benchmark, a diverse offline dataset, and an offline probing evaluation. Recording a human player establishes a strong baseline and verifies the need to build up and retain memories, which is reflected in their gradually increasing rewards within each episode. We find that current algorithms benefit from training with truncated backpropagation through time and succeed on small mazes, but fall short of human performance on the large mazes, leaving room for future algorithmic designs to be evaluated on the Memory Maze.",https://arxiv.org/abs/2210.13383
Timothy P. Lillicrap,On the stability and scalability of node perturbation learning,2022,Advances in Neural Information Processing Systems,17,"Naoki Hiratani, Yash Mehta, Timothy Lillicrap, Peter E Latham",Naoki Hiratani,Peter E Latham,4,"To survive, animals must adapt synaptic weights based on external stimuli and rewards. And they must do so using local, biologically plausible, learning rules--a highly nontrivial constraint. One possible approach is to perturb neural activity (or use intrinsic, ongoing noise to perturb it), determine whether performance increases or decreases, and use that information to adjust the weights. This algorithm--known as node perturbation--has been shown to work on simple problems, but little is known about either its stability or its scalability with respect to network size. We investigate these issues both analytically, in deep linear networks, and numerically, in deep nonlinear ones. We show analytically that in deep linear networks with one hidden layer, both learning time and performance depend very weakly on hidden layer size. However, unlike stochastic gradient descent, when there is model mismatch between the student and teacher networks, node perturbation is always unstable. The instability is triggered by weight diffusion, which eventually leads to very large weights. This instability can be suppressed by weight normalization, at the cost of bias in the learning rule. We confirm numerically that a similar instability, and to a lesser extent scalability, exist in deep nonlinear networks trained on both a motor control task and image classification tasks. Our study highlights the limitations and potential of node perturbation as a biologically plausible learning rule in the brain.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/cf38eb1549024cce4b3d2c1bb87a6c27-Abstract-Conference.html
Timothy P. Lillicrap,Augmenting neural networks with external memory,2021,,17,"Adam Anthony Santoro, Daniel Pieter Wiestra, Timothy Paul Lillicrap, Sergey Bartunov, Ivo Danihelka",Adam Anthony Santoro,Ivo Danihelka,5,"Primary Examiner Li B. Zhen Assistant Examiner Markus A. Vasquez (74) Attorney, Agent, or Firm—Fish & Richardson PC (57) ABSTRACT Methods, systems, and apparatus, including computer pro grams encoded on computer storage media, for augmenting neural networks with an external memory. One of the systems includes a controller neural network that includes a Least Recently Used Access (LRUA) subsystem configured to: maintain a respective usage weight for each of a plurality of locations in the external memory, and for each of the plurality of time steps: generate a respective reading weight for each location using a read key, read data from the locations in accordance with the reading weights, generate a respective writing weight for each of the locations from a respective reading weight from a preceding time step and the respective usage weight for the location, write a write vector to the locations in …",https://patents.google.com/patent/US10885426B2/en
Timothy P. Lillicrap,Augmenting neural networks with sparsely-accessed external memory,2021,,15,"Ivo Danihelka, Gregory Duncan Wayne, Fu-Min Wang, Edward Thomas Grefenstette, Jack William Rae, Alexander Benjamin Graves, Timothy Paul Lillicrap, Timothy James Alexander Harley, Jonathan James Hunt",Ivo Danihelka,Jonathan James Hunt,9,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for augmenting neural networks with an external memory. One of the systems includes a sparse memory access subsystem that is configured to perform operations comprising generating a sparse set of reading weights that includes a respective reading weight for each of the plurality of locations in the external memory using the read key, reading data from the plurality of locations in the external memory in accordance with the sparse set of reading weights, generating a set of writing weights that includes a respective writing weight for each of the plurality of locations in the external memory, and writing the write vector to the plurality of locations in the external memory in accordance with the writing weights.",https://patents.google.com/patent/US11151443B2/en
Timothy P. Lillicrap,Scalable and compressive neural network data storage system,2020,,15,"Jack William Rae, Timothy Paul Lillicrap, Sergey Bartunov",Jack William Rae,Sergey Bartunov,3,A system for compressed data storage using a neural network. The system comprises a memory comprising a plurality of memory locations configured to store data; a query neural network configured to process a representation of an input data item to generate a query; an immutable key data store comprising key data for indexing the plurality of memory locations; an addressing system configured to process the key data and the query to generate a weighting associated with the plurality of memory locations; a memory read system configured to generate output memory data from the memory based upon the generated weighting associated with the plurality of memory locations and the data stored at the plurality of memory locations; and a memory write system configured to write received write data to the memory based upon the generated weighting associated with the plurality of memory locations.,https://patents.google.com/patent/US10846588B2/en
Timothy P. Lillicrap,Data-efficient reinforcement learning for continuous control tasks,2020,,15,"Martin Riedmiller, Roland Hafner, Mel Vecerik, Timothy Paul Lillicrap, Thomas Lampe, Ivaylo Popov, Gabriel Barth-Maron, Nicolas Manfred Otto Heess",Martin Riedmiller,Nicolas Manfred Otto Heess,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for data-efficient reinforcement learning. One of the systems is a system for training an actor neural network used to select actions to be performed by an agent that interacts with an environment by receiving observations characterizing states of the environment and, in response to each observation, performing an action selected from a continuous space of possible actions, wherein the actor neural network maps observations to next actions in accordance with values of parameters of the actor neural network, and wherein the system comprises: a plurality of workers, wherein each worker is configured to operate independently of each other worker, wherein each worker is associated with a respective agent replica that interacts with a respective replica of the environment during the training of the actor neural network.",https://patents.google.com/patent/US10664725B2/en
Timothy P. Lillicrap,Clonal relationships impact neuronal tuning within a phylogenetically ancient vertebrate brain structure,2014,Current Biology,14,"Alistair M Muldal, Timothy P Lillicrap, Blake A Richards, Colin J Akerman",Alistair M Muldal,Colin J Akerman,4,"Understanding how neurons acquire specific response properties is a major goal in neuroscience. Recent studies in mouse neocortex have shown that ""sister neurons"" derived from the same cortical progenitor cell have a greater probability of forming synaptic connections with one another [1, 2] and are biased to respond to similar sensory stimuli [3, 4]. However, it is unknown whether such lineage-based rules contribute to functional circuit organization across different species and brain regions [5]. To address this question, we examined the influence of lineage on the response properties of neurons within the optic tectum, a visual brain area found in all vertebrates [6]. Tectal neurons possess well-defined spatial receptive fields (RFs) whose center positions are retinotopically organized [7]. If lineage relationships do not influence the functional properties of tectal neurons, one prediction is that the RF positions of …",https://www.cell.com/current-biology/fulltext/S0960-9822(14)00841-0
Timothy P. Lillicrap,Physically embedded planning problems: New challenges for reinforcement learning,2020,arXiv preprint arXiv:2009.05524,13,"Mehdi Mirza, Andrew Jaegle, Jonathan J Hunt, Arthur Guez, Saran Tunyasuvunakool, Alistair Muldal, Théophane Weber, Peter Karkus, Sébastien Racaniere, Lars Buesing, Timothy Lillicrap, Nicolas Heess",Mehdi Mirza,Nicolas Heess,12,"Recent work in deep reinforcement learning (RL) has produced algorithms capable of mastering challenging games such as Go, chess, or shogi. In these works the RL agent directly observes the natural state of the game and controls that state directly with its actions. However, when humans play such games, they do not just reason about the moves but also interact with their physical environment. They understand the state of the game by looking at the physical board in front of them and modify it by manipulating pieces using touch and fine-grained motor control. Mastering complicated physical systems with abstract goals is a central challenge for artificial intelligence, but it remains out of reach for existing RL algorithms. To encourage progress towards this goal we introduce a set of physically embedded planning problems and make them publicly available. We embed challenging symbolic tasks (Sokoban, tic-tac-toe, and Go) in a physics engine to produce a set of tasks that require perception, reasoning, and motor control over long time horizons. Although existing RL algorithms can tackle the symbolic versions of these tasks, we find that they struggle to master even the simplest of their physically embedded counterparts. As a first step towards characterizing the space of solution to these tasks, we introduce a strong baseline that uses a pre-trained expert game player to provide hints in the abstract space to an RL agent's policy while training it on the full sensorimotor control task. The resulting agent solves many of the tasks, underlining the need for methods that bridge the gap between abstract planning and embodied control. See illustrating …",https://arxiv.org/abs/2009.05524
Timothy P. Lillicrap,One-shot learning with memory-augmented neural networks. arXiv 2016,2016,arXiv preprint arXiv:1605.06065,13,"Adam Santoro, Sergey Bartunov, Matthew Botvinick, Daan Wierstra, Timothy Lillicrap",Adam Santoro,Timothy Lillicrap,5,,https://scholar.google.com/scholar?cluster=8200938275125378246&hl=en&oi=scholarr
Timothy P. Lillicrap,Training reinforcement learning agents to learn farsighted behaviors by predicting in latent space,2021,,11,"Danijar Hafner, Mohammad Norouzi, Timothy Paul Lillicrap",Danijar Hafner,Timothy Paul Lillicrap,3,"BACKGROUND [0002] This specification relates to reinforcement learn ing [0003] In a reinforcement learning system, an agent inter acts with an environment by performing actions that are selected by the reinforcement learning system in response to receiving observations that characterize the current state of the environment.",https://patents.google.com/patent/US20210158162A1/en
Timothy P. Lillicrap,Intra-agent speech permits zero-shot task acquisition,2022,Advances in Neural Information Processing Systems,10,"Chen Yan, Federico Carnevale, Petko I Georgiev, Adam Santoro, Aurelia Guy, Alistair Muldal, Chia-Chun Hung, Joshua Abramson, Timothy Lillicrap, Gregory Wayne",Chen Yan,Gregory Wayne,10,"Human language learners are exposed to a trickle of informative, context-sensitive language, but a flood of raw sensory data. Through both social language use and internal processes of rehearsal and practice, language learners are able to build high-level, semantic representations that explain their perceptions. Here, we take inspiration from such processes of"" inner speech"" in humans (Vygotsky, 1934) to better understand the role of intra-agent speech in embodied behavior. First, we formally pose intra-agent speech as a semi-supervised problem and develop two algorithms that enable visually grounded captioning with little labeled language data. We then experimentally compute scaling curves over different amounts of labeled data and compare the data efficiency against a supervised learning baseline. Finally, we incorporate intra-agent speech into an embodied, mobile manipulator agent operating in a 3D virtual world, and show that with as few as 150 additional image captions, intra-agent speech endows the agent with the ability to manipulate and answer questions about a new object without any related task-directed experience (zero-shot). Taken together, our experiments suggest that modelling intra-agent speech is effective in enabling embodied agents to learn new tasks efficiently and without direct interaction experience.",https://proceedings.neurips.cc/paper_files/paper/2022/hash/1074541383db5ef12d6ac66d2f8e8d34-Abstract-Conference.html
Timothy P. Lillicrap,Beyond tabula-rasa: a modular reinforcement learning approach for physically embedded 3d sokoban,2020,arXiv preprint arXiv:2010.01298,10,"Peter Karkus, Mehdi Mirza, Arthur Guez, Andrew Jaegle, Timothy Lillicrap, Lars Buesing, Nicolas Heess, Theophane Weber",Peter Karkus,Theophane Weber,8,"Intelligent robots need to achieve abstract objectives using concrete, spatiotemporally complex sensory information and motor control. Tabula rasa deep reinforcement learning (RL) has tackled demanding tasks in terms of either visual, abstract, or physical reasoning, but solving these jointly remains a formidable challenge. One recent, unsolved benchmark task that integrates these challenges is Mujoban, where a robot needs to arrange 3D warehouses generated from 2D Sokoban puzzles. We explore whether integrated tasks like Mujoban can be solved by composing RL modules together in a sense-plan-act hierarchy, where modules have well-defined roles similarly to classic robot architectures. Unlike classic architectures that are typically model-based, we use only model-free modules trained with RL or supervised learning. We find that our modular RL approach dramatically outperforms the state-of-the-art monolithic RL agent on Mujoban. Further, learned modules can be reused when, e.g., using a different robot platform to solve the same task. Together our results give strong evidence for the importance of research into modular RL designs. Project website: https://sites.google.com/view/modular-rl/",https://arxiv.org/abs/2010.01298
Timothy P. Lillicrap,Equilibrium aggregation: Encoding sets via optimization,2022,Uncertainty in Artificial Intelligence,9,"Sergey Bartunov, Fabian B Fuchs, Timothy P Lillicrap",Sergey Bartunov,Timothy P Lillicrap,3,"Processing sets or other unordered, potentially variable-sized inputs in neural networks is usually handled by aggregating a number of input tensors into a single representation. While a number of aggregation methods already exist from simple sum pooling to multi-head attention, they are limited in their representational power both from theoretical and empirical perspectives. On the search of a principally more powerful aggregation strategy, we propose an optimization-based method called Equilibrium Aggregation. We show that many existing aggregation methods can be recovered as special cases of Equilibrium Aggregation and that it is provably more efficient in some important cases. Equilibrium Aggregation can be used as a drop-in replacement in many existing architectures and applications. We validate its efficiency on three different tasks: median estimation, class counting, and molecular property prediction. In all experiments, Equilibrium Aggregation achieves higher performance than the other aggregation techniques we test.",https://proceedings.mlr.press/v180/bartunov22a.html
Timothy P. Lillicrap,"DaanWierstra, et al.,“",2016,"Matching networks for one shot learning,” inAdvances in neural information processing systems",9,"Oriol Vinyals, Charles Blundell, Timothy Lillicrap, Koray Kavukcuoglu",Oriol Vinyals,Koray Kavukcuoglu,4,,https://scholar.google.com/scholar?cluster=18204458099529179412&hl=en&oi=scholarr
Timothy P. Lillicrap,Complex spatiotemporal tuning in human upper-limb muscles,2010,Journal of neurophysiology,9,"J Andrew Pruszynski, Timothy P Lillicrap, Stephen H Scott",J Andrew Pruszynski,Stephen H Scott,3,"Correlations between neural activity in primary motor cortex (M1) and arm kinematics have recently been shown to be temporally extensive and spatially complex. These results provide a sophisticated account of M1 processing and suggest that M1 neurons encode high-level movement trajectories, termed “pathlets.” However, interpreting pathlets is difficult because the mapping between M1 activity and arm kinematics is indirect: M1 activity can generate movement only via spinal circuitry and the substantial complexities of the musculoskeletal system. We hypothesized that filter-like complexities of the musculoskeletal system are sufficient to generate temporally extensive and spatially complex correlations between motor commands and arm kinematics. To test this hypothesis, we extended the computational and experimental method proposed for extracting pathlets from M1 activity to extract pathlets from muscle …",https://journals.physiology.org/doi/abs/10.1152/jn.00791.2009
Timothy P. Lillicrap,others. 2016. Matching networks for one shot learning,,Advances in neural information processing systems,9,"Oriol Vinyals, Charles Blundell, Tim Lillicrap, Daan Wierstra",Oriol Vinyals,Daan Wierstra,4,,https://scholar.google.com/scholar?cluster=13849657721379482544&hl=en&oi=scholarr
Timothy P. Lillicrap,BCI learning phenomena can be explained by gradient-based optimization,2022,bioRxiv,8,"Peter C Humphreys, Kayvon Daie, Karel Svoboda, Matthew Botvinick, Timothy P Lillicrap",Peter C Humphreys,Timothy P Lillicrap,5,"Brain-computer interface (BCI) experiments have shown that animals are able to adapt their recorded neural activity in order to receive reward. Recent studies have highlighted two phenomena. First, the speed at which a BCI task can be learned is dependent on how closely the required neural activity aligns with pre-existing activity patterns: learning “out-of-manifold” tasks is slower than “in-manifold” tasks. Second, learning happens by “re-association”: the overall distribution of neural activity patterns does not change significantly during task learning. These phenomena have been presented as distinctive aspects of BCI learning. Here we show, using simulations and theoretical analysis, that both phenomena result from the simple assumption that behaviour and representations are improved via gradient-based algorithms. We invoke Occam’s Razor to suggest that this straightforward explanation should be pre-ferred when accounting for these experimental observations.",https://www.biorxiv.org/content/10.1101/2022.12.08.519453.abstract
Timothy P. Lillicrap,Can neocortical feedback alter the sign of plasticity?,2018,,8,"Blake A Richards, Timothy P Lillicrap",Blake A Richards,Timothy P Lillicrap,2,"The recent Review by Roelfsema and Holtmaat (Control of synaptic plasticity in deep cortical networks. Nat. Rev. Neurosci. 19, 166–180 (2018)) 1 provides a much-needed guide to learning in deep cortical networks. The importance of credit assignment for deep cortical networks has come into focus recently with the success of deep learning in artificial intelligence 2. The learning algorithm that is typically used for credit assignment in deep artificial neural networks, the backpropagation-of-error algorithm 3, is biologically infeasible 4. Yet, its successful application to complicated tasks suggests that credit assignment is important for learning in non-trivial circumstances, whether in artificial or biological neural networks.As Roelfsema and Holtmaat note, the focus in neuroscience to date has been either on Hebbian plasticity mechanisms 5, or three-factor Hebbian plasticity rules that incorporate a global reward …",https://www.nature.com/articles/s41583-018-0049-5
Timothy P. Lillicrap,Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context,2024,ArXiv preprint,7,"M Reid Gemini-Team, N Savinov, D Teplyashin, D Lepikhin, T Lillicrap, J-b Alayrac, R Soricut, A Lazaridou, O Firat, J Schrittwieser",M Reid Gemini-Team,J Schrittwieser,10,,https://scholar.google.com/scholar?cluster=8977677285339990032&hl=en&oi=scholarr
Timothy P. Lillicrap,Matching networks for one shot learning Advances in Neural Information Processing System 29,2016,,7,"O Vinyals, C Blundell, T Lillicrap, K Kavukcuoglu, D Wierstra",O Vinyals,D Wierstra,5,,https://scholar.google.com/scholar?cluster=14006675506534551077&hl=en&oi=scholarr
Timothy P. Lillicrap,Continuous deep q-learning with model-based acceleration. arXiv 2016,,arXiv preprint arXiv:1603.00748,7,"S Gu, T Lillicrap, I Sutskever, S Levine",S Gu,S Levine,4,,https://scholar.google.com/scholar?cluster=194909943185548446&hl=en&oi=scholarr
Timothy P. Lillicrap,"Is coding a relevant metaphor for building AI? A commentary on"" Is coding a relevant metaphor for the brain?"", by Romain Brette",2019,arXiv preprint arXiv:1904.10396,6,"Adam Santoro, Felix Hill, David Barrett, David Raposo, Matthew Botvinick, Timothy Lillicrap",Adam Santoro,Timothy Lillicrap,6,"Brette contends that the neural coding metaphor is an invalid basis for theories of what the brain does. Here, we argue that it is an insufficient guide for building an artificial intelligence that learns to accomplish short- and long-term goals in a complex, changing environment.",https://arxiv.org/abs/1904.10396
Timothy P. Lillicrap,Proceedings of the 30th International Conference on Neural Information Processing Systems,2016,,6,"O Vinyals, C Blundell, T Lillicrap, K Kavukcuoglu, D Wierstra",O Vinyals,D Wierstra,5,,https://scholar.google.com/scholar?cluster=11110820568276328454&hl=en&oi=scholarr
Timothy P. Lillicrap,Compressed sensing using neural networks,2024,,5,"Yan Wu, Timothy Paul Lillicrap, Mihaela Rosca",Yan Wu,Mihaela Rosca,3,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for compressed sensing using neural networks. One of the methods includes receiving an input measurement of an input data item; for each of one or more optimization steps: processing a latent representation using a generator neural network to generate a candidate reconstructed data item, processing the candidate reconstructed data item using a measurement neural network to generate a measurement of the candidate reconstructed data item, and updating the latent representation to reduce an error between the measurement and the input measurement; and processing the latent representation after the one or more optimization steps using the generator neural network to generate a reconstruction of the input data item.",https://patents.google.com/patent/US12032523B2/en
Timothy P. Lillicrap,Responses of pyramidal cell somata and apical dendrites in mouse visual cortex over multiple days,2023,Scientific Data,5,"Colleen J Gillon, Jérôme A Lecoq, Jason E Pina, Ruweida Ahmed, Yazan N Billeh, Shiella Caldejon, Peter Groblewski, Timothy M Henley, India Kato, Eric Lee, Jennifer Luviano, Kyla Mace, Chelsea Nayan, Thuyanh V Nguyen, Kat North, Jed Perkins, Sam Seid, Matthew T Valley, Ali Williford, Yoshua Bengio, Timothy P Lillicrap, Joel Zylberberg, Blake A Richards",Colleen J Gillon,Blake A Richards,23,"The apical dendrites of pyramidal neurons in sensory cortex receive primarily top-down signals from associative and motor regions, while cell bodies and nearby dendrites are heavily targeted by locally recurrent or bottom-up inputs from the sensory periphery. Based on these differences, a number of theories in computational neuroscience postulate a unique role for apical dendrites in learning. However, due to technical challenges in data collection, little data is available for comparing the responses of apical dendrites to cell bodies over multiple days. Here we present a dataset collected through the Allen Institute Mindscope’s OpenScope program that addresses this need. This dataset comprises high-quality two-photon calcium imaging from the apical dendrites and the cell bodies of visual cortical pyramidal neurons, acquired over multiple days in awake, behaving mice that were presented with visual stimuli …",https://www.nature.com/articles/s41597-023-02214-y
Timothy P. Lillicrap,Selecting reinforcement learning actions using a low-level controller,2021,,5,"Nicolas Manfred Otto Heess, Timothy Paul Lillicrap, Gregory Duncan Wayne, Yuval Tassa",Nicolas Manfred Otto Heess,Yuval Tassa,4,"Methods, systems, and apparatus for selecting actions to be performed by an agent interacting with an environment. One system includes a high-level controller neural network, low-level controller network, and subsystem. The high-level controller neural network receives an input observation and processes the input observation to generate a high-level output defining a control signal for the low-level controller. The low-level controller neural network receives a desig nated component of an input observation and processes the designated component and an input control signal to gener ate a low-level output that defines an action to be performed by the agent in response to the input observation. The subsystem receives a current observation characterizing a current state of the environment, determines whether criteria are satisfied for generating a new control signal, and based on the determination, provides …",https://patents.google.com/patent/US11210585B1/en
Timothy P. Lillicrap,Controlling agents over long time scales using temporal value transport,2020,,5,"Gregory Duncan Wayne, Timothy Paul Lillicrap, Chia-Chun Hung, Joshua Simon Abramson",Gregory Duncan Wayne,Joshua Simon Abramson,4,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network system used to control an agent interacting with an environment to perform a specified task. One of the methods includes causing the agent to perform a task episode in which the agent attempts to perform the specified task; for each of one or more particular time steps in the sequence: generating a modified reward for the particular time step from (i) the actual reward at the time step and (ii) value predictions at one or more time steps that are more than a threshold number of time steps after the particular time step in the sequence; and training, through reinforcement learning, the neural network system using at least the modified rewards for the particular time steps.",https://patents.google.com/patent/US10789511B2/en
Timothy P. Lillicrap,Temporal encoding of movement in motor cortical neurons,2007,,5,"J Andrew Pruszynski, Angela M Coderre, Timothy P Lillicrap, Isaac Kurtzer",J Andrew Pruszynski,Isaac Kurtzer,4,"Although it is broadly accepted that primary motor cortex (M1) plays a critical role in controlling volitional arm movement, considerable debate remains about the details of the implementation. Most studies assume that individual M1 neurons encode time-invariant movement features within a direction, velocity, or force coordinate frame (Scott, 2003). For example, a neuron that encodes hand movements away from the body does not change this relationship over the duration of a reach.",https://www.jneurosci.org/content/27/38/10076.short
Timothy P. Lillicrap,Continuous control with deep reinforcement learning,2022,arXiv,4,"TP Lillicrap, JJ Hunt, A Pritzel, N Heess, T Erez, Y Tassa, D Silver, D Wierstra",TP Lillicrap,D Wierstra,8,"▪ 2014: Silver et al (Deepmind)▪ Uses Off-Policy Actor Critic▪ Stochastic policy gradients require integration over state and actions.○ You have to account for all the actions that you might take in that state.▪ Deterministic policy gradients only require integration over state.○ You know exactly which action you will take, so only consider that one.▪ Much faster learning in large action spaces.",https://www.cs.utexas.edu/~robertom/cs391r_fall2022/slides/CS391R%20Paper%20Presentation_Jeff%20Bonyun.pdf
Timothy P. Lillicrap,Training an unsupervised memory-based prediction system to learn compressed representations of an environment,2021,,4,"Gregory Duncan Wayne, Chia-Chun Hung, David Antony Amos, Mehdi Mirza Mohammadi, Arun Ahuja, Timothy Paul Lillicrap",Gregory Duncan Wayne,Timothy Paul Lillicrap,6,"Inventors: Gregory Duncan Wayne, London (GB); Chia-Chun Hung, London (GB); David Antony Amos, London (GB); Mehdi Mirza Mohammadi, London (GB); Arun Ahuja, London (GB); Timothy Paul Lillicrap, London (GB)",https://patents.google.com/patent/US20210034969A1/en
Timothy P. Lillicrap,Matching Networks for One Shot Learning. NIPS (2016),,,4,"Oriol Vinyals, Charles Blundell, T Lillicrap, Koray Kavukcuoglu, Daan Wierstra",Oriol Vinyals,Daan Wierstra,5,,https://scholar.google.com/scholar?cluster=8383236405361711366&hl=en&oi=scholarr
Timothy P. Lillicrap,Responses to pattern-violating visual stimuli evolve differently over days in somata and distal apical dendrites,2024,Journal of Neuroscience,3,"Colleen J Gillon, Jason E Pina, Jérôme A Lecoq, Ruweida Ahmed, Yazan N Billeh, Shiella Caldejon, Peter Groblewski, Timothy M Henley, Eric Lee, Jennifer Luviano, Kyla Mace, Chelsea Nayan, Thuyanh V Nguyen, Kat North, Jed Perkins, Sam Seid, Matthew T Valley, Ali Williford, Yoshua Bengio, Timothy P Lillicrap, Blake A Richards, Joel Zylberberg",Colleen J Gillon,Joel Zylberberg,22,"Scientists have long conjectured that the neocortex learns patterns in sensory data to generate top-down predictions of upcoming stimuli. In line with this conjecture, different responses to pattern-matching vs pattern-violating visual stimuli have been observed in both spiking and somatic calcium imaging data. However, it remains unknown whether these pattern-violation signals are different between the distal apical dendrites, which are heavily targeted by top-down signals, and the somata, where bottom-up information is primarily integrated. Furthermore, it is unknown how responses to pattern-violating stimuli evolve over time as an animal gains more experience with them. Here, we address these unanswered questions by analyzing responses of individual somata and dendritic branches of layer 2/3 and layer 5 pyramidal neurons tracked over multiple days in primary visual cortex of awake, behaving female and …",https://www.jneurosci.org/content/44/5/e1009232023.abstract
Timothy P. Lillicrap,Evaluating multimodal interactive agents,2022,arXiv preprint arXiv:2205.13274,3,"Josh Abramson, Arun Ahuja, Federico Carnevale, Petko Georgiev, Alex Goldin, Alden Hung, Jessica Landon, Timothy Lillicrap, Alistair Muldal, Blake Richards, Adam Santoro, Tamara von Glehn, Greg Wayne, Nathaniel Wong, Chen Yan",Josh Abramson,Chen Yan,15,"Creating agents that can interact naturally with humans is a common goal in artificial intelligence (AI) research. However, evaluating these interactions is challenging: collecting online human-agent interactions is slow and expensive, yet faster proxy metrics often do not correlate well with interactive evaluation. In this paper, we assess the merits of these existing evaluation metrics and present a novel approach to evaluation called the Standardised Test Suite (STS). The STS uses behavioural scenarios mined from real human interaction data. Agents see replayed scenario context, receive an instruction, and are then given control to complete the interaction offline. These agent continuations are recorded and sent to human annotators to mark as success or failure, and agents are ranked according to the proportion of continuations in which they succeed. The resulting STS is fast, controlled, interpretable, and representative of naturalistic interactions. Altogether, the STS consolidates much of what is desirable across many of our standard evaluation metrics, allowing us to accelerate research progress towards producing agents that can interact naturally with humans. A video may be found at https://youtu.be/YR1TngGORGQ.",https://arxiv.org/abs/2205.13274
Timothy P. Lillicrap,Continuous latent search for combinatorial optimization,2020,Learning Meets Combinatorial Algorithms at NeurIPS2020,3,"Sergey Bartunov, Vinod Nair, Peter Battaglia, Tim Lillicrap",Sergey Bartunov,Tim Lillicrap,4,"Combinatorial optimization problems are notoriously hard because they often require enumeration of the exponentially large solution space.   Both classical solving techniques and machine learning-based approaches usually address combinatorial optimization problems by manipulating solutions in their original discrete form.   In contrast, we propose a framework that consists of reparametrizing the original discrete solution space into a continuous latent space in which the problem can be (approximately) solved by running continuous optimization methods.   We achieve this by learning a surrogate function that is shaped to correlate with the original objective when the latent solution is decoded back to the original solution space.   We show that this approach can learn efficient solution strategies and is useful as a primal heuristic inside the widely-used open-source solver SCIP.",https://openreview.net/forum?id=P3FX9pUev-
Timothy P. Lillicrap,&WIERSTRA D.(2016). Matching networks for one shot learning,,"D. LEE, M. SUGIYAMA, U. LUXBURG, I. GUYON & R. GARNETT, Éds., Advances in Neural Information Processing Systems",3,"O Vinyals, C Blundell, Tim Lillicrap, K KAVUKCUOGLU",O Vinyals,K KAVUKCUOGLU,4,,https://scholar.google.com/scholar?cluster=5951020864910458539&hl=en&oi=scholarr
Timothy P. Lillicrap,Deep reinforcement learning for robotic manipulation,2024,,2,"Sergey Levine, Ethan Holly, Shixiang Gu, Timothy Lillicrap",Sergey Levine,Timothy Lillicrap,4,"Implementations utilize deep reinforcement learning to train a policy neural network that parameterizes a policy for determining a robotic action based on a current state. Some of those implementations collect experience data from multiple robots that operate simultaneously. Each robot generates instances of experience data during iterative performance of episodes that are each explorations of performing a task, and that are each guided based on the policy network and the current policy parameters for the policy network during the episode. The collected experience data is generated during the episodes and is used to train the policy network by iteratively updating policy parameters of the policy network based on a batch of collected experience data. Further, prior to performance of each of a plurality of episodes performed by the robots, the current updated policy parameters can be provided (or retrieved) for …",https://patents.google.com/patent/US11897133B2/en
Timothy P. Lillicrap,Controlling agents over long time scales using temporal value transport,2023,,2,"Gregory Duncan Wayne, Timothy Paul Lillicrap, Chia-Chun Hung, Joshua Simon Abramson",Gregory Duncan Wayne,Joshua Simon Abramson,4,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network system used to control an agent interacting with an environment to perform a specified task. One of the methods includes causing the agent to perform a task episode in which the agent attempts to perform the specified task; for each of one or more particular time steps in the sequence: generating a modified reward for the particular time step from (i) the actual reward at the time step and (ii) value predictions at one or more time steps that are more than a threshold number of time steps after the particular time step in the sequence; and training, through reinforcement learning, the neural network system using at least the modified rewards for the particular time steps.",https://patents.google.com/patent/US11769049B2/en
Timothy P. Lillicrap,Vector-based navigation using grid-like representations in artificial agents,2018,,2,"Alexander Pritzel, Andrea Banino, Benigno Uria, Brian C Zhang, Caswell Barry, Charles Blundell, Charlie Beattie, Demis Hassabis, Dharshan Kumaran, Fabio Viola, Greg Wayne, Helen King, Hubert Soyer, Joseph Modayil, Koray Kavukcuoglu, Martin J Chadwick, Neil Rabinowitz, Piotr Mirowski, Raia Hadsell, Razvan Pascanu, Ross Goroshin, Stephen Gaffney, Stig Vilholm Petersen, Thomas Degris, Timothy Lillicrap",Alexander Pritzel,Timothy Lillicrap,25,"Efficient navigation is a fundamental component of mammalian behaviour but remains challenging for artificial agents. Mammalian spatial behaviour is underpinned by grid cells in the entorhinal cortex, providing a multi-scale periodic representation that functions as a metric for coding space. Grid cells are viewed as critical for integrating self-motion (path integration) and planning direct trajectories to goals (vector-based navigation). We report, for the first time, that brain-like grid representations can emerge as the product of optimizing a recurrent network to perform the task of path integration-providing a normative perspective on the role of grid cells as a compact code for representing space. We show that grid cells provide an effective basis set to optimize the primary objective of navigation through deep reinforcement learning (RL)-the rapid discovery and exploitation of goals in complex, unfamiliar, and changeable …",https://research.google/pubs/vector-based-navigation-using-grid-like-representations-in-artificial-agents/
Timothy P. Lillicrap,"& Hassabis, D.(2016). Mastering the game of Go with deep neural networks and tree search",,Nature,2,"D Silver, A Huang, CJ Maddison, A Guez, L Sifre, G Van Den Driessche",D Silver,G Van Den Driessche,6,,https://scholar.google.com/scholar?cluster=2753194105019827094&hl=en&oi=scholarr
Timothy P. Lillicrap,Can foundation models actively gather information in interactive environments to test hypotheses?,2024,arXiv preprint arXiv:2412.06438,1,"Nan Rosemary Ke, Danny P Sawyer, Hubert Soyer, Martin Engelcke, David P Reichert, Drew A Hudson, John Reid, Alexander Lerchner, Danilo Jimenez Rezende, Timothy P Lillicrap, Michael Mozer, Jane X Wang",Nan Rosemary Ke,Jane X Wang,12,"While problem solving is a standard evaluation task for foundation models, a crucial component of problem solving -- actively and strategically gathering information to test hypotheses -- has not been closely investigated. To assess the information gathering abilities of foundation models in interactive environments, we introduce a framework in which a model must determine the factors influencing a hidden reward function by iteratively reasoning about its previously gathered information and proposing its next exploratory action to maximize information gain at each step. We implement this framework in both a text-based environment, which offers a tightly controlled setting and enables high-throughput parameter sweeps, and in an embodied 3D environment, which requires addressing complexities of multi-modal interaction more relevant to real-world applications. We further investigate whether approaches such as self-correction and increased inference time improve information gathering efficiency. In a relatively simple task that requires identifying a single rewarding feature, we find that LLM's information gathering capability is close to optimal. However, when the model must identify a conjunction of rewarding features, performance is suboptimal. The hit in performance is due partly to the model translating task description to a policy and partly to the model's effectiveness in using its in-context memory. Performance is comparable in both text and 3D embodied environments, although imperfect visual object recognition reduces its accuracy in drawing conclusions from gathered information in the 3D embodied case. For single-feature-based …",https://arxiv.org/abs/2412.06438
Timothy P. Lillicrap,Continuous control with deep reinforcement learning,2023,,1,"Timothy Paul Lillicrap, Jonathan James Hunt, Alexander Pritzel, Nicolas Manfred Otto Heess, Tom Erez, Yuval Tassa, David Silver, Daniel Pieter Wierstra",Timothy Paul Lillicrap,Daniel Pieter Wierstra,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training an actor neural network used to select actions to be performed by an agent interacting with an environment. One of the methods includes obtaining a minibatch of experience tuples; and updating current values of the parameters of the actor neural network, comprising: for each experience tuple in the minibatch: processing the training observation and the training action in the experience tuple using a critic neural network to determine a neural network output for the experience tuple, and determining a target neural network output for the experience tuple; updating current values of the parameters of the critic neural network using errors between the target neural network outputs and the neural network outputs; and updating the current values of the parameters of the actor neural network using the critic …",https://patents.google.com/patent/US11803750B2/en
Timothy P. Lillicrap,Retrieval augmented reinforcement learning,2024,,0,"Anirudh Goyal, Andrea Banino, Abram Luke Friesen, Theophane Guillaume Weber, Adrià Puigdomènech Badia, Nan Ke, Simon Osindero, Timothy Paul Lillicrap, Charles Blundell",Anirudh Goyal,Charles Blundell,9,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for controlling a reinforcement learning agent in an environment to perform a task using a retrieval-augmented action selection process. One of the methods includes receiving a current observation characterizing a current state of the environment; processing an encoder network input comprising the current observation to determine a policy neural network hidden state that corresponds to the current observation; maintaining a plurality of trajectories generated as a result of the reinforcement learning agent interacting with the environment; selecting one or more trajectories from the plurality of trajectories; updating the policy neural network hidden state using update data determined from the one or more selected trajectories; and processing the updated hidden state using a policy neural network to generate a policy …",https://patents.google.com/patent/US20240320506A1/en
Timothy P. Lillicrap,"The refinement paradox and cumulative cultural evolution: Complex products of collective improvement favor conformist outcomes, blind copying, and hyper-credulity",2024,PLOS Computational Biology,0,"Elena Miu, Luke Rendell, Sam Bowles, Rob Boyd, Daniel Cownden, Magnus Enquist, Kimmo Eriksson, Marcus W Feldman, Timothy Lillicrap, Richard McElreath, Stuart Murray, James Ounsley, Kevin N Lala",Elena Miu,Kevin N Lala,13,"Social learning is common in nature, yet cumulative culture (where knowledge and technology increase in complexity and diversity over time) appears restricted to humans. To understand why, we organized a computer tournament in which programmed entries specified when to learn new knowledge and when to refine (i.e. improve) existing knowledge. The tournament revealed a ‘refinement paradox’: refined behavior afforded higher payoffs as individuals converged on a small number of successful behavioral variants, but refining did not generally pay. Paradoxically, entries that refined only in certain conditions did best during behavioral improvement, while simple copying entries thrived when refinement levels were high. Cumulative cultural evolution may be rare in part because sophisticated strategies for improving knowledge and technology are initially advantageous, yet complex culture, once achieved, favors conformity, blind imitation and hyper-credulity.",https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012436
Timothy P. Lillicrap,Continuous control with deep reinforcement learning,2024,,0,"Timothy Paul Lillicrap, Jonathan James Hunt, Alexander Pritzel, Nicolas Manfred Otto Heess, Tom Erez, Yuval Tassa, David Silver, Daniel Pieter Wierstra",Timothy Paul Lillicrap,Daniel Pieter Wierstra,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training an actor neural network used to select actions to be performed by an agent interacting with an environment. One of the methods includes obtaining a minibatch of experience tuples; and updating current values of the parameters of the actor neural network, comprising: for each experience tuple in the minibatch: processing the training observation and the training action in the experience tuple using a critic neural network to determine a neural network output for the experience tuple, and determining a target neural network output for the experience tuple; updating current values of the parameters of the critic neural network using errors between the target neural network outputs and the neural network outputs; and updating the current values of the parameters of the actor neural network using the critic …",https://patents.google.com/patent/US20240177002A1/en
Timothy P. Lillicrap,Scalable and compressive neural network data storage system,2024,,0,"Jack William Rae, Timothy Paul Lillicrap, Sergey Bartunov",Jack William Rae,Sergey Bartunov,3,A system for compressed data storage using a neural network. The system comprises a memory comprising a plurality of memory locations configured to store data; a query neural network configured to process a representation of an input data item to generate a query; an immutable key data store comprising key data for indexing the plurality of memory locations; an addressing system configured to process the key data and the query to generate a weighting associated with the plurality of memory locations; a memory read system configured to generate output memory data from the memory based upon the generated weighting associated with the plurality of memory locations and the data stored at the plurality of memory locations; and a memory write system configured to write received write data to the memory based upon the generated weighting associated with the plurality of memory locations.,https://patents.google.com/patent/US11983617B2/en
Timothy P. Lillicrap,Deep reinforcement learning for robotic manipulation,2024,,0,"Sergey Levine, Ethan Holly, Shixiang Gu, Timothy Lillicrap",Sergey Levine,Timothy Lillicrap,4,"Implementations utilize deep reinforcement learning to train a policy neural network that parameterizes a policy for determining a robotic action based on a current state. Some of those implementations collect experience data from multiple robots that operate simultaneously. Each robot generates instances of experience data during iterative performance of episodes that are each explorations of performing a task, and that are each guided based on the policy network and the current policy parameters for the policy network during the episode. The collected experience data is generated during the episodes and is used to train the policy network by iteratively updating policy parameters of the policy network based on a batch of collected experience data. Further, prior to performance of each of a plurality of episodes performed by the robots, the current updated policy parameters can be provided (or retrieved) for …",https://patents.google.com/patent/US20240131695A1/en
Timothy P. Lillicrap,Data-efficient reinforcement learning for continuous control tasks,2024,,0,"Martin Riedmiller, Roland Hafner, Mel Vecerik, Timothy Paul Lillicrap, Thomas Lampe, Ivaylo Popov, Gabriel Barth-Maron, Nicolas Manfred Otto Heess",Martin Riedmiller,Nicolas Manfred Otto Heess,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for data-efficient reinforcement learning. One of the systems is a system for training an actor neural network used to select actions to be performed by an agent that interacts with an environment by receiving observations characterizing states of the environment and, in response to each observation, performing an action selected from a continuous space of possible actions, wherein the actor neural network maps observations to next actions in accordance with values of parameters of the actor neural network, and wherein the system comprises: a plurality of workers, wherein each worker is configured to operate independently of each other worker, wherein each worker is associated with a respective agent replica that interacts with a respective replica of the environment during the training of the actor neural network.",https://patents.google.com/patent/US20240062035A1/en
Timothy P. Lillicrap,Augmenting attention-based neural networks to selectively attend to past inputs,2024,,0,"Jack William Rae, Anna Potapenko, Timothy Paul Lillicrap",Jack William Rae,Timothy Paul Lillicrap,3,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing a machine learning task on a network input that is a sequence to generate a network output. In one aspect, one of the methods includes, for each particular sequence of layer inputs: for each attention layer in the neural network: maintaining episodic memory data; maintaining compressed memory data; receiving a layer input to be processed by the attention layer; and applying an attention mechanism over (i) the compressed representation in the compressed memory data for the layer,(ii) the hidden states in the episodic memory data for the layer, and (iii) the respective hidden state at each of the plurality of input positions in the particular network input to generate a respective activation for each input position in the layer input.",https://patents.google.com/patent/US20240046103A1/en
Timothy P. Lillicrap,Selecting reinforcement learning actions using a low-level controller,2024,,0,"Nicolas Manfred Otto Heess, Timothy Paul Lillicrap, Gregory Duncan Wayne, Yuval Tassa",Nicolas Manfred Otto Heess,Yuval Tassa,4,"Methods, systems, and apparatus for selecting actions to be performed by an agent interacting with an environment. One system includes a high-level controller neural network, low-level controller network, and subsystem. The high-level controller neural network receives an input observation and processes the input observation to generate a high-level output defining a control signal for the low-level controller. The low-level controller neural network receives a designated component of an input observation and processes the designated component and an input control signal to generate a low-level output that defines an action to be performed by the agent in response to the input observation. The subsystem receives a current observation characterizing a current state of the environment, determines whether criteria are satisfied for generating a new control signal, and based on the determination, provides …",https://patents.google.com/patent/US11875258B1/en
Timothy P. Lillicrap,"The refinement paradox and cumulative cultural evolution: collective improvement in knowledge favors conformity, blind copying and hyper-credulity",2024,bioRxiv,0,"Elena Miu, Luke Rendell, Sam Bowles, Rob Boyd, Daniel Cownden, Magnus Enquist, Kimmo Eriksson, Marcus W Feldman, Timothy Lillicrap, Richard McElreath, Stuart Murray, James Ounsley, Kevin N Lala",Elena Miu,Kevin N Lala,13,"Social learning is common in nature, yet cumulative culture (where knowledge and technology increase in complexity and diversity over time) appears restricted to humans. To understand why, we organized a computer tournament in which programmed entries specified when to learn new knowledge and when to refine (i.e. improve) existing knowledge. The tournament revealed a 'refinement paradox': refined behavior afforded higher payoffs as individuals converged on a small number of successful behavioral variants, but refining did not generally pay. Paradoxically, entries that refined only in certain conditions did best during behavioral improvement, while simple copying entries thrived when refinement levels were high. Cumulative cultural evolution may be rare in part because sophisticated strategies for improving knowledge and technology are initially advantageous, yet complex culture, once achieved, favors conformity, blind imitation and hyper-credulity.",https://www.biorxiv.org/content/10.1101/2024.03.22.586239.abstract
Timothy P. Lillicrap,Augmenting attentioned-based neural networks to selectively attend to past inputs,2023,,0,"Jack William Rae, Anna Potapenko, Timothy Paul Lillicrap",Jack William Rae,Timothy Paul Lillicrap,3,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing a machine learning task on a network input that is a sequence to generate a network output. In one aspect, one of the methods includes, for each particular sequence of layer inputs: for each attention layer in the neural network: maintaining episodic memory data; maintaining compressed memory data; receiving a layer input to be processed by the attention layer; and applying an attention mechanism over (i) the compressed representation in the compressed memory data for the layer,(ii) the hidden states in the episodic memory data for the layer, and (iii) the respective hidden state at each of the plurality of input positions in the particular network input to generate a respective activation for each input position in the layer input.",https://patents.google.com/patent/US11829884B2/en
Timothy P. Lillicrap,Data-efficient reinforcement learning for continuous control tasks,2023,,0,"Martin Riedmiller, Roland Hafner, Mel Vecerik, Timothy Paul Lillicrap, Thomas Lampe, Ivaylo Popov, Gabriel Barth-Maron, Nicolas Manfred Otto Heess",Martin Riedmiller,Nicolas Manfred Otto Heess,8,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for data-efficient reinforcement learning. One of the systems is a system for training an actor neural network used to select actions to be performed by an agent that interacts with an environment by receiving observations characterizing states of the environment and, in response to each observation, performing an action selected from a continuous space of possible actions, wherein the actor neural network maps observations to next actions in accordance with values of parameters of the actor neural network, and wherein the system comprises: a plurality of workers, wherein each worker is configured to operate independently of each other worker, wherein each worker is associated with a respective agent replica that interacts with a respective replica of the environment during the training of the actor neural network.",https://patents.google.com/patent/US11741334B2/en
Timothy P. Lillicrap,Learned computer control using pointing device and keyboard actions,2023,,0,"Peter Conway Humphreys, Timothy Paul Lillicrap, Tobias Markus Pohlen, Adam Anthony Santoro",Peter Conway Humphreys,Adam Anthony Santoro,4,"2024-07-01 Assigned to DEEPMIND TECHNOLOGIES LIMITED reassignment DEEPMIND TECHNOLOGIES LIMITED ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: POHLEN, Tobias Markus, HUMPHREYS, Peter Conway, LILLICRAP, TIMOTHY PAUL, SANTORO, Adam Anthony",https://patents.google.com/patent/US20230244325A1/en
Timothy P. Lillicrap,Controlling interactive agents using multi-modal inputs,2023,,0,"Joshua Simon Abramson, Arun Ahuja, Federico Javier Carnevale, Petko Ivanov Georgiev, Chia-Chun Hung, Timothy Paul Lillicrap, Alistair Michael Muldal, Adam Anthony Santoro, Tamara Louise Von Glehn, Jessica Paige Landon, Gregory Duncan Wayne, Chen Yan, Rui Zhu",Joshua Simon Abramson,Rui Zhu,13,"2023-01-09 Assigned to DEEPMIND TECHNOLOGIES LIMITED reassignment DEEPMIND TECHNOLOGIES LIMITED ASSIGNMENT OF ASSIGNORS INTEREST (SEE DOCUMENT FOR DETAILS). Assignors: ABRAMSON, Joshua Simon, LANDON, JESSICA PAIGE, LILLICRAP, TIMOTHY PAUL, CARNEVALE, FEDERICO JAVIER, WAYNE, Gregory Duncan, ZHU, Rui, VON GLEHN, TAMARA LOUISE, AHUJA, ARUN, GEORGIEV, PETKO IVANOV, MULDAL, ALISTAIR MICHAEL, SANTORO, Adam Anthony, YAN, CHEN, HUNG, CHIA-CHUN",https://patents.google.com/patent/US20230178076A1/en
Timothy P. Lillicrap,On the Stability and Scalability of Node Perturbation Learning,2023,,0,"Yash Mehta, Timothy Lillicrap, Peter Latham",Yash Mehta,Peter Latham,3,"To survive, animals must adapt synaptic weights based on external stimuli and rewards. And they must do so using local, biologically plausible, learning rules – a highly nontrivial constraint. One possible approach is to perturb neural activity (or use intrinsic, ongoing noise to perturb it), determine whether performance increases or decreases, and use that information to adjust the weights. This algorithm – known as node perturbation – has been shown to work on simple problems, but little is known about either its stability or its scalability with respect to network size. We investigate these issues both analytically, in deep linear networks, and numerically, in deep nonlinear ones. We show analytically that in deep linear networks with one hidden layer, both learning time and performance depend very weakly on hidden layer size. However, unlike stochastic gradient descent, when there is model mismatch between the student and teacher networks, node perturbation is always unstable. The instability is triggered by weight diffusion, which eventually leads to very large weights. This instability can be suppressed by weight normalization, at the cost of bias in the learning rule. We confirm numerically that a similar instability, and to a lesser extent scalability, exist in deep nonlinear networks trained on both a motor control task and image classification tasks. Our study highlights the limitations and potential of node perturbation as a biologically plausible learning rule in the brain.",https://discovery.ucl.ac.uk/id/eprint/10166318/
Timothy P. Lillicrap,Reinforcement learning using advantage estimates,2022,,0,"Shixiang Gu, Timothy Paul Lillicrap, Ilya Sutskever, Sergey Vladimir Levine",Shixiang Gu,Sergey Vladimir Levine,4,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for computing Q values for actions to be performed by an agent interacting with an environment from a continuous action space of actions. In one aspect, a system includes a value subnetwork configured to receive an observation characterizing a current state of the environment and process the observation to generate a value estimate; a policy subnetwork configured to receive the observation and process the observation to generate an ideal point in the continuous action space; and a subsystem configured to receive a particular point in the continuous action space representing a particular action; generate an advantage estimate for the particular action; and generate a Q value for the particular action that is an estimate of an expected return resulting from the agent performing the particular action when the …",https://patents.google.com/patent/US20220284266A1/en
Timothy P. Lillicrap,Energy-based associative memory neural networks,2022,,0,"Sergey Bartunov, Jack William Rae, Timothy Paul Lillicrap, Simon Osindero",Sergey Bartunov,Simon Osindero,4,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for implementing associative memory. In one aspect a system comprises an associative memory neural network to process an input to generate an output that defines an energy corresponding to the input. A reading subsystem retrieves stored information from the associative memory neural network. The reading subsystem performs operations including receiving a given, ie query, input and retrieving a data element from the associative memory neural network that is associated with the given input. The retrieving is performed by iteratively adjusting the given input using the associative memory neural network.",https://patents.google.com/patent/US20220180147A1/en
Timothy P. Lillicrap,Is coding a relevant metaphor for building AI?,2019,Behavioral and Brain Sciences,0,"David Barrett, David Raposo, Matt Botvinick, Timothy Lillicrap",David Barrett,Timothy Lillicrap,4,"Brette contends that the neural coding metaphor is an invalid basis for theories of what the brain does. Here, we argue that it is an insufficient guide for building an artificial intelligence that learns to accomplish short-and long-term goals in a complex, changing environment.",https://search.proquest.com/openview/d545baf41da487ee0133584754c7c913/1?pq-origsite=gscholar&cbl=47829
Timothy P. Lillicrap,Modelling motor cortex using neural network control laws,2014,,0,Timothy Paul Lillicrap,Timothy Paul Lillicrap,Timothy Paul Lillicrap,1,"The ease with which our brains learn to control our bodies belies intricate neural processing which remains poorly understood. We know that a network of brain regions work together in a carefully coordinated fashion to allow us to move from one place to another. In mammals, we know that the motor cortex plays a central role in this process, but precisely how its activity contributes to control is a matter of long and continued debate. In this thesis we demonstrate the need for developing mechanistic neural network models to address this question. Using such models, we show that contentious response properties of non-human primate primary motor cortex (M1) neurons can be understood as reflecting control processes which take into account the physics of the body. And we develop new computational techniques for teaching neural network models how to execute control. In the first study (Chapter 2), we critically …",https://search.proquest.com/openview/5b2902b476aadf685e2e8455c5b81ca9/1?pq-origsite=gscholar&cbl=18750&diss=y
Timothy P. Lillicrap,Royal Netherlands Academy of Arts and Sciences (KNAW),,,0,"BA Richards, TP Lillicrap, P Beaudoin, Y Bengio, R Bogacz, A Christensen, C Clopath, RP Costa, A de Berker, S Ganguli, CJ Gillon, D Hafner, A Kepecs, N Kriegeskorte, P Latham, GW Lindsay",BA Richards,GW Lindsay,16,"Systems neuroscience seeks explanations for how the brain implements a wide variety of perceptual, cognitive and motor tasks. Conversely, artificial intelligence attempts to design computational systems based on the tasks they will have to solve. In the case of artificial neural networks, the three components specified by design are the objective functions, the learning rules, and architectures. With the growing success of deep learning, which utilizes brain-inspired architectures, these three designed components have increasingly become central to how we model, engineer and optimize complex artificial learning systems. Here we argue that a greater focus on these components would also benefit systems neuroscience. We give examples of how this optimization-based framework can drive theoretical and experimental progress in neuroscience. We contend that this principled perspective on systems neuroscience will help to generate more rapid progress.",https://pure.knaw.nl/ws/files/13024854/Richards_et_al.pdf
Timothy P. Lillicrap,Introduction to the Virtual Collection on Machine Learning in Aerospace,,,0,"I Antonoglou, V Panneershelvam, M Lanctot, S Dieleman, D Grewe, J Nham, N Kalchbrenner, I Sutskever, T Lillicrap, M Leach, K Kavukcuoglu, T Graepel, D Hassabis",I Antonoglou,D Hassabis,13,"Scale Visual Recognition Competition 2012 (ILSVRC2012), online database, Stanford Vision Lab, Stanford, CA, https://image-net. org/challenges/LSVRC/2012/results. html [retrieved 19 April 2023]), excitement was largely confined to the specific field of ML. However, the AlphaGo shock (Silver, D., Huang, A., Maddison, CJ, Guez, A., Sifre, L., van den Driessche, G., Schrittwieser, J., Antonoglou, I., Panneershelvam, V., Lanctot, M., Dieleman, S., Grewe, D., Nham, J., Kalchbrenner, N., Sutskever, I., Lillicrap, T., Leach, M., Kavukcuoglu, K., Graepel, T., and Hassabis, D.,“Mastering the Game of Go with Deep Neural Networks and Tree Search,” Nature, Vol. 529, No. 28, 2016, pp. 484–489. 10.1038/nature16961) was strong enough to cause researchers in other fields to question their skepticism of data-driven methods and to consider that machine learning techniques might resolve fundamental problems that they face …",https://arc.aiaa.org/doi/pdf/10.2514/1.I011299%40jais.2023.Virtual_Collection.issue-2
Timothy P. Lillicrap,"Alet, F., Doblar, D., Zhou, A., Tenenbaum, J., Kawaguchi, K., and Finn, C.(2021). Noether networks: meta-learning useful conserved quantities. Advances in Neural Information Processing Systems, 34: 16384–16397. Alver, S. and Precup, D.(2021). What is going on inside recurrent meta reinforcement learning agents? arXiv preprint arXiv: 2104.14644.",,,0,"S Baik, M Choi, J Choi, H Kim, KM Lee, DG Barrett, F Hill, A Santoro, AS Morcos, T Lillicrap, P Bateni, R Goyal, V Masrani, F Wood, L Sigal",S Baik,L Sigal,15,"For sine wave regression, we use the same base-learner network as Finn et al.(2017), ie, a fullyconnected feed-forward network consisting of a single input node followed by two hidden layers with 40 ReLU nodes each and a final single-node output layer.For few-shot image classification problems, we use the same base-learner network as used by Snell et al.(2017) and Chen et al.(2019). This network is a stack of four identical convolutional blocks. Each block consists of 64 convolutions of size 3× 3, batch normalization, a ReLU nonlinearity, and a 2D max-pooling layer with a kernel size of 2. The resulting embeddings of the 84× 84× 3 input images are flattened and fed into a dense layer with N nodes (one for every class in a task). The base-learner is trained to minimize the cross-entropy loss on the query set, conditioned on the support set.",https://scholarlypublications.universiteitleiden.nl/access/item%3A3704826/download
Timothy P. Lillicrap,"AI> ML> deep> DNN supervised (regression, classification), unsupervised, reinforcement neuroscience diverge, converge Hasson, Uri, Samuel A. Nastase, and Ariel Goldstein.” Direct fit to nature: An evolutionary perspective on biological and artificial neural networks.” Neuron 105",,International Journal of Automation and Computing,0,"TP Lillicrap, A Santoro, L Marris, CJ Akerman, G Hinton",TP Lillicrap,G Hinton,5,"LeCun, Yann, Yoshua Bengio, and Geoffrey Hinton.” Deep learning.” Nature 521, no. 7553 (2015): 436-444. linear vs nonlinear coefficients in functions under mild assumptions linear depth vs exponential breadth Telgarsky, M.(2016, June). Benefits of depth in neural networks. In Conference on learning theory (pp. 1517-1539). PMLR. Poggio, T., Mhaskar, H., Rosasco, L., Miranda, B., & Liao, Q.(2017). Why and when can deep-but not shallow-networks avoid the curse of dimensionality: a review. International Journal of Automation and Computing, 14 (5), 503-519. architecture, activation, training tools appendix XOR example",https://fab.cba.mit.edu/classes/MAS.864/text/Machine_Learning.pdf
Timothy P. Lillicrap,Supplementary: Training Generative Adversarial Networks by Solving Ordinary Differential Equations,,,0,"Chongli Qin, Yan Wu, Jost Tobias Springenberg, Andrew Brock, Jeff Donahue, Timothy P Lillicrap, Pushmeet Kohli",Chongli Qin,Pushmeet Kohli,7,"We present details on the proofs from the main paper in Sections AC. We include analysis on the effects of regularisation on the truncation error (Section D). Update rules for the ODE solvers considered in the main paper are presented in Section E. The connections between our method and Consensus optimisation, SGA and extragradient are reported in Section F. Further details of experiments/additional experimental results are in Section GH. Image samples are shown in Section I.",https://proceedings.neurips.cc/paper_files/paper/2020/file/3c8f9a173f749710d6377d3150cf90da-Supplemental.pdf
Timothy P. Lillicrap,Interpolated Policy Gradient,,,0,"Shixiang Gu, Timothy Lillicrap, Zoubin Ghahramani, Richard E Turner, Bernhard Schölkopf, Sergey Levine",Shixiang Gu,Sergey Levine,6,"First, the expected return J (π) of a policy π can be written as the sum of the expected return J (π) of another policy π and the expected advantage term between the two policies in the equation, where Aπ (st, at) is the advantage of policy π,",https://proceedings.neurips.cc/paper_files/paper/2017/file/a1d7311f2a312426d710e1c617fcbc8c-Supplemental.zip
Timothy P. Lillicrap,Deep learning with segregated dendrites,,,0,"Jordan Guerguiev, Timothy P Lillicrap, Blake A Richards",Jordan Guerguiev,Blake A Richards,3,"Deep learning in multilayer neural networks has revolutionized artificial intelligence (AI). The key to deep learning is assigning credit to each neuron for its role in producing behavior. In AI, credit assignment is done using the backpropagation algorithm. However, backpropagation requires a separate feedback pathway with neurons that communicate error derivatives via symmetric weights, and there is no experimental evidence for this type of feedback in the brain. Here, we show that an algorithm that utilizes multi-compartment neurons can perform credit assignment without a separate error pathway. Like pyramidal neurons, neurons in our model receive bottom-up sensory information and top-down feedback in electrotonically segregated dendritic compartments. Thanks to this segregation, neurons in different layers can be assigned credit for their contribution to behavior. As a result, multilayer versions of the network can learn to categorize images better than single layer versions. This work demonstrates that biologically feasible deep learning is possible using segregated dendritic compartments, which may help to explain the morphology of neocortical pyramidal neurons.",https://www2.securecms.com/CCNeuro/docs-0/591b3ec768ed3f0d5357b894.pdf
Pranav Rajpurkar,"SQuAD: 100,000+ Questions for Machine Comprehension of Text",2016,Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing,9220,"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang",Pranav Rajpurkar,Percy Liang,4,,https://scholar.google.com/scholar?cluster=11037830585227643418&hl=en&oi=scholarr
Pranav Rajpurkar,CheXNet: Radiologist-Level Pneumonia Detection on Chest X-Rays with Deep Learning,2017,arXiv preprint arXiv:1711.05225,3553,"Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, Matthew P Lungren, Andrew Y Ng",Pranav Rajpurkar,Andrew Y Ng,12,,https://scholar.google.com/scholar?cluster=9682167363029940541&hl=en&oi=scholarr
Pranav Rajpurkar,Know What You Don't Know: Unanswerable Questions for SQuAD,2018,Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics,3162,"Pranav Rajpurkar, Robin Jia, Percy Liang",Pranav Rajpurkar,Percy Liang,3,"Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86% F1 on SQuAD 1.1 achieves only 66% F1 on SQuAD 2.0.",https://arxiv.org/abs/1806.03822
Pranav Rajpurkar,Chexpert: A large chest radiograph dataset with uncertainty labels and expert comparison,2019,Proceedings of the AAAI conference on artificial intelligence,2893,"Jeremy Irvin, Pranav Rajpurkar, Michael Ko, Yifan Yu, Silviana Ciurea-Ilcus, Chris Chute, Henrik Marklund, Behzad Haghgoo, Robyn Ball, Katie Shpanskaya, Jayne Seekins, David A Mong, Safwan S Halabi, Jesse K Sandberg, Ricky Jones, David B Larson, Curtis P Langlotz, Bhavik N Patel, Matthew P Lungren, Andrew Y Ng",Jeremy Irvin,Andrew Y Ng,20,"Large, labeled datasets have driven deep learning methods to achieve expert-level performance on a variety of medical imaging tasks. We present CheXpert, a large dataset that contains 224,316 chest radiographs of 65,240 patients. We design a labeler to automatically detect the presence of 14 observations in radiology reports, capturing uncertainties inherent in radiograph interpretation. We investigate different approaches to using the uncertainty labels for training convolutional neural networks that output the probability of these observations given the available frontal and lateral radiographs. On a validation set of 200 chest radiographic studies which were manually annotated by 3 board-certified radiologists, we find that different uncertainty approaches are useful for different pathologies. We then evaluate our best model on a test set composed of 500 chest radiographic studies annotated by a consensus of 5 board-certified radiologists, and compare the performance of our model to that of 3 additional radiologists in the detection of 5 selected pathologies. On Cardiomegaly, Edema, and Pleural Effusion, the model ROC and PR curves lie above all 3 radiologist operating points. We release the dataset to the public as a standard benchmark to evaluate performance of chest radiograph interpretation models.",https://aaai.org/ojs/index.php/AAAI/article/view/3834
Pranav Rajpurkar,Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network,2019,Nature medicine,2686,"Awni Y Hannun, Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H Tison, Codie Bourn, Mintu P Turakhia, Andrew Y Ng",Awni Y Hannun,Andrew Y Ng,7,"Computerized electrocardiogram (ECG) interpretation plays a critical role in the clinical ECG workflow. Widely available digital ECG data and the algorithmic paradigm of deep learning present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, a comprehensive evaluation of an end-to-end deep learning approach for ECG analysis across a wide variety of diagnostic classes has not been previously reported. Here, we develop a deep neural network (DNN) to classify 12 rhythm classes using 91,232 single-lead ECGs from 53,549 patients who used a single-lead ambulatory ECG monitoring device. When validated against an independent test dataset annotated by a consensus committee of board-certified practicing cardiologists, the DNN achieved an average area under the receiver operating characteristic curve (ROC) of 0.97. The average F1 score, which is …",https://www.nature.com/articles/s41591-018-0268-3
Pranav Rajpurkar,AI in health and medicine,2022,,1720,"Pranav Rajpurkar, Emma Chen, Oishi Banerjee, Eric J Topol",Pranav Rajpurkar,Eric J Topol,4,"Artificial intelligence (AI) is poised to broadly reshape medicine, potentially improving the experiences of both clinicians and patients. We discuss key findings from a 2-year weekly effort to track and share key developments in medical AI. We cover prospective studies and advances in medical image analysis, which have reduced the gap between research and deployment. We also address several promising avenues for novel medical AI research, including non-image data sources, unconventional problem formulations and human–AI collaboration. Finally, we consider serious technical and ethical challenges in issues spanning from data scarcity to racial bias. As these challenges are addressed, AI’s potential may be realized, making healthcare more accurate, efficient and accessible for patients worldwide.",https://www.nature.com/articles/s41591-021-01614-0
Pranav Rajpurkar,Deep learning for chest radiograph diagnosis: A retrospective comparison of the CheXNeXt algorithm to practicing radiologists,2018,PLOS Medicine,1293,"Pranav Rajpurkar, Jeremy Irvin, Robyn L Ball, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding, Aarti Bagul, Curtis P Langlotz, Bhavik N Patel, Kristen W Yeom, Katie Shpanskaya, Francis G Blankenberg, Jayne Seekins, Timothy J Amrhein, David A Mong, Safwan S Halabi, Evan J Zucker, Andrew Y Ng, Matthew P Lungren",Pranav Rajpurkar,Matthew P Lungren,21,"Chest radiograph interpretation is critical for the detection of thoracic diseases, including tuberculosis and lung cancer, which affect millions of people worldwide each year. This time-consuming task typically requires expert radiologists to read the images, leading to fatigue-based diagnostic error and lack of diagnostic expertise in areas of the world where radiologists are not available. Recently, deep learning approaches have been able to achieve expert-level performance in medical image interpretation tasks, powered by large network architectures and fueled by the emergence of large labeled datasets. The purpose of this study is to investigate the performance of a deep learning algorithm on the detection of pathologies in chest radiographs compared with practicing radiologists.We developed CheXNeXt, a convolutional neural network to concurrently detect the presence of 14 different pathologies, including pneumonia, pleural effusion, pulmonary masses, and nodules in frontal-view chest radiographs. CheXNeXt was trained and internally validated on the ChestX-ray8 dataset, with a held-out validation set consisting of 420 images, sampled to contain at least 50 cases of each of the original pathology labels. On this validation set, the majority vote of a panel of 3 board-certified cardiothoracic specialist radiologists served as reference standard. We compared CheXNeXt’s discriminative performance on the validation set to the performance of 9 radiologists using the area under the receiver operating characteristic curve (AUC). The radiologists included 6 board-certified radiologists (average experience 12 …",https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002686
Pranav Rajpurkar,Cardiologist-Level Arrhythmia Detection with Convolutional Neural Networks,2017,arXiv preprint arXiv:1707.01836,1025,"Pranav Rajpurkar, Awni Y Hannun, Masoumeh Haghpanahi, Codie Bourn, Andrew Y Ng",Pranav Rajpurkar,Andrew Y Ng,5,"We develop an algorithm which exceeds the performance of board certified cardiologists in detecting a wide range of heart arrhythmias from electrocardiograms recorded with a single-lead wearable monitor. We build a dataset with more than 500 times the number of unique patients than previously studied corpora. On this dataset, we train a 34-layer convolutional neural network which maps a sequence of ECG samples to a sequence of rhythm classes. Committees of board-certified cardiologists annotate a gold standard test set on which we compare the performance of our model to that of 6 other individual cardiologists. We exceed the average cardiologist performance in both recall (sensitivity) and precision (positive predictive value).",https://arxiv.org/abs/1707.01836
Pranav Rajpurkar,Foundation models for generalist medical artificial intelligence,2023,,1014,"Michael Moor, Oishi Banerjee, Zahra Shakeri Hossein Abad, Harlan M Krumholz, Jure Leskovec, Eric J Topol, Pranav Rajpurkar",Michael Moor,Pranav Rajpurkar,7,"The exceptionally rapid development of highly flexible, reusable artificial intelligence (AI) models is likely to usher in newfound capabilities in medicine. We propose a new paradigm for medical AI, which we refer to as generalist medical AI (GMAI). GMAI models will be capable of carrying out a diverse set of tasks using very little or no task-specific labelled data. Built through self-supervision on large, diverse datasets, GMAI will flexibly interpret different combinations of medical modalities, including data from imaging, electronic health records, laboratory results, genomics, graphs or medical text. Models will in turn produce expressive outputs such as free-text explanations, spoken recommendations or image annotations that demonstrate advanced medical reasoning abilities. Here we identify a set of high-impact potential applications for GMAI and lay out specific technical capabilities and training datasets necessary …",https://www.nature.com/articles/s41586-023-05881-4
Pranav Rajpurkar,An Empirical Evaluation of Deep Learning on Highway Driving,2015,arXiv preprint arXiv:1504.01716,975,"Brody Huval, Tao Wang, Sameep Tandon, Jeff Kiske, Will Song, Joel Pazhayampallil, Mykhaylo Andriluka, Pranav Rajpurkar, Toki Migimatsu, Royce Cheng-Yue, Fernando Mujica, Adam Coates, Andrew Y Ng",Brody Huval,Andrew Y Ng,13,"Numerous groups have applied a variety of deep learning techniques to computer vision problems in highway perception scenarios. In this paper, we presented a number of empirical evaluations of recent deep learning advances. Computer vision, combined with deep learning, has the potential to bring about a relatively inexpensive, robust solution to autonomous driving. To prepare deep learning for industry uptake and practical applications, neural networks will require large data sets that represent all possible driving environments and scenarios. We collect a large data set of highway data and apply deep learning and computer vision algorithms to problems such as car and lane detection. We show how existing convolutional neural networks (CNNs) can be used to perform lane and vehicle detection while running at frame rates required for a real-time system. Our results lend credence to the hypothesis that deep learning holds promise for autonomous driving.",https://arxiv.org/abs/1504.01716
Pranav Rajpurkar,Deep-learning-assisted diagnosis for knee magnetic resonance imaging: Development and retrospective validation of MRNet,2018,PLOS Medicine,697,"Nicholas Bien, Pranav Rajpurkar, Robyn L Ball, Jeremy Irvin, Allison Park, Erik Jones, Michael Bereket, Bhavik N Patel, Kristen W Yeom, Katie Shpanskaya, Safwan Halabi, Evan Zucker, Gary Fanton, Derek F Amanatullah, Christopher F Beaulieu, Geoffrey M Riley, Russell J Stewart, Francis G Blankenberg, David B Larson, Ricky H Jones, Curtis P Langlotz, Andrew Y Ng, Matthew P Lungren",Nicholas Bien,Matthew P Lungren,23,"Magnetic resonance imaging (MRI) of the knee is the preferred method for diagnosing knee injuries. However, interpretation of knee MRI is time-intensive and subject to diagnostic error and variability. An automated system for interpreting knee MRI could prioritize high-risk patients and assist clinicians in making diagnoses. Deep learning methods, in being able to automatically learn layers of features, are well suited for modeling the complex relationships between medical images and their interpretations. In this study we developed a deep learning model for detecting general abnormalities and specific diagnoses (anterior cruciate ligament [ACL] tears and meniscal tears) on knee MRI exams. We then measured the effect of providing the model’s predictions to clinical experts during interpretation.Our dataset consisted of 1,370 knee MRI exams performed at Stanford University Medical Center between January 1, 2001, and December 31, 2012 (mean age 38.0 years; 569 [41.5%] female patients). The majority vote of 3 musculoskeletal radiologists established reference standard labels on an internal validation set of 120 exams. We developed MRNet, a convolutional neural network for classifying MRI series and combined predictions from 3 series per exam using logistic regression. In detecting abnormalities, ACL tears, and meniscal tears, this model achieved area under the receiver operating characteristic curve (AUC) values of 0.937 (95% CI 0.895, 0.980), 0.965 (95% CI 0.938, 0.993), and 0.847 (95% CI 0.780, 0.914), respectively, on the internal validation set. We also obtained a public dataset of 917 exams …",https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1002699
Pranav Rajpurkar,Multimodal biomedical AI,2022,,656,"Julián N Acosta, Guido J Falcone, Pranav Rajpurkar, Eric J Topol",Julián N Acosta,Eric J Topol,4,"The increasing availability of biomedical data from large biobanks, electronic health records, medical imaging, wearable and ambient biosensors, and the lower cost of genome and microbiome sequencing have set the stage for the development of multimodal artificial intelligence solutions that capture the complexity of human health and disease. In this Review, we outline the key applications enabled, along with the technical and analytical challenges. We explore opportunities in personalized medicine, digital clinical trials, remote monitoring and care, pandemic surveillance, digital twin technology and virtual health assistants. Further, we survey the data, modeling and privacy challenges that must be overcome to realize the full potential of multimodal artificial intelligence in health.",https://www.nature.com/articles/s41591-022-01981-2
Pranav Rajpurkar,MURA: Large Dataset for Abnormality Detection in Musculoskeletal Radiographs,2017,1st Conference on Medical Imaging with Deep Learning,452,"Pranav Rajpurkar, Jeremy Irvin, Aarti Bagul, Daisy Ding, Tony Duan, Hershel Mehta, Brandon Yang, Kaylie Zhu, Dillon Laird, Robyn L Ball, Curtis Langlotz, Katie Shpanskaya, Matthew P Lungren, Andrew Y Ng",Pranav Rajpurkar,Andrew Y Ng,14,"We introduce MURA, a large dataset of musculoskeletal radiographs containing 40,561 images from 14,863 studies, where each study is manually labeled by radiologists as either normal or abnormal. To evaluate models robustly and to get an estimate of radiologist performance, we collect additional labels from six board-certified Stanford radiologists on the test set, consisting of 207 musculoskeletal studies. On this test set, the majority vote of a group of three radiologists serves as gold standard. We train a 169-layer DenseNet baseline model to detect and localize abnormalities. Our model achieves an AUROC of 0.929, with an operating point of 0.815 sensitivity and 0.887 specificity. We compare our model and radiologists on the Cohen's kappa statistic, which expresses the agreement of our model and of each radiologist with the gold standard. Model performance is comparable to the best radiologist performance in detecting abnormalities on finger and wrist studies. However, model performance is lower than best radiologist performance in detecting abnormalities on elbow, forearm, hand, humerus, and shoulder studies. We believe that the task is a good challenge for future research. To encourage advances, we have made our dataset freely available at https://stanfordmlgroup.github.io/competitions/mura .",https://arxiv.org/abs/1712.06957
Pranav Rajpurkar,Self-supervised learning in medicine and healthcare,2022,,377,"Rayan Krishnan, Pranav Rajpurkar, Eric J Topol",Rayan Krishnan,Eric J Topol,3,"The development of medical applications of machine learning has required manual annotation of data, often by medical experts. Yet, the availability of large-scale unannotated data provides opportunities for the development of better machine-learning models. In this Review, we highlight self-supervised methods and models for use in medicine and healthcare, and discuss the advantages and limitations of their application to tasks involving electronic health records and datasets of medical images, bioelectrical signals, and sequences and structures of genes and proteins. We also discuss promising applications of self-supervised learning for the development of models leveraging multimodal datasets, and the challenges in collecting unbiased data for their training. Self-supervised learning may accelerate the development of medical artificial intelligence.",https://www.nature.com/articles/s41551-022-00914-1
Pranav Rajpurkar,CheXbert: Combining Automatic Labelers and Expert Annotations for Accurate Radiology Report Labeling Using BERT,2020,Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing,301,"Akshay Smit, Saahil Jain, Pranav Rajpurkar, Anuj Pareek, Andrew Y Ng, Matthew P Lungren",Akshay Smit,Matthew P Lungren,6,"The extraction of labels from radiology text reports enables large-scale training of medical imaging models. Existing approaches to report labeling typically rely either on sophisticated feature engineering based on medical domain knowledge or manual annotations by experts. In this work, we introduce a BERT-based approach to medical image report labeling that exploits both the scale of available rule-based systems and the quality of expert annotations. We demonstrate superior performance of a biomedically pretrained BERT model first trained on annotations of a rule-based labeler and then finetuned on a small set of expert annotations augmented with automated backtranslation. We find that our final model, CheXbert, is able to outperform the previous best rules-based labeler with statistical significance, setting a new SOTA for report labeling on one of the largest datasets of chest x-rays.",https://arxiv.org/abs/2004.09167
Pranav Rajpurkar,Expert-level detection of pathologies from unannotated chest X-ray images via self-supervised learning,2022,Nature Biomedical Engineering,277,"Ekin Tiu, Ellie Talius, Pujan Patel, Curtis P Langlotz, Andrew Y Ng, Pranav Rajpurkar",Ekin Tiu,Pranav Rajpurkar,6,"In tasks involving the interpretation of medical images, suitably trained machine-learning models often exceed the performance of medical experts. Yet such a high-level of performance typically requires that the models be trained with relevant datasets that have been painstakingly annotated by experts. Here we show that a self-supervised model trained on chest X-ray images that lack explicit annotations performs pathology-classification tasks with accuracies comparable to those of radiologists. On an external validation dataset of chest X-rays, the self-supervised model outperformed a fully supervised model in the detection of three pathologies (out of eight), and the performance generalized to pathologies that were not explicitly annotated for model training, to multiple image-interpretation tasks and to datasets from multiple institutions.",https://www.nature.com/articles/s41551-022-00936-9
Pranav Rajpurkar,Impact of a deep learning assistant on the histopathologic classification of liver cancer,2020,NPJ digital medicine,248,"Amirhossein Kiani, Bora Uyumazturk, Pranav Rajpurkar, Alex Wang, Rebecca Gao, Erik Jones, Yifan Yu, Curtis P Langlotz, Robyn L Ball, Thomas J Montine, Brock A Martin, Gerald J Berry, Michael G Ozawa, Florette K Hazard, Ryanne A Brown, Simon B Chen, Mona Wood, Libby S Allard, Lourdes Ylagan, Andrew Y Ng, Jeanne Shen",Amirhossein Kiani,Jeanne Shen,21,"Artificial intelligence (AI) algorithms continue to rival human performance on a variety of clinical tasks, while their actual impact on human diagnosticians, when incorporated into clinical workflows, remains relatively unexplored. In this study, we developed a deep learning-based assistant to help pathologists differentiate between two subtypes of primary liver cancer, hepatocellular carcinoma and cholangiocarcinoma, on hematoxylin and eosin-stained whole-slide images (WSI), and evaluated its effect on the diagnostic performance of 11 pathologists with varying levels of expertise. Our model achieved accuracies of 0.885 on a validation set of 26 WSI, and 0.842 on an independent test set of 80 WSI. Although use of the assistant did not change the mean accuracy of the 11 pathologists (p = 0.184, OR = 1.281), it significantly improved the accuracy (p = 0.045, OR = 1.499) of a subset of nine pathologists who …",https://www.nature.com/articles/s41746-020-0232-8
Pranav Rajpurkar,The Current and Future State of AI Interpretation of Medical Images,2023,,247,"Pranav Rajpurkar, Matthew P Lungren",Pranav Rajpurkar,Matthew P Lungren,2,"The authors examine the advantages and limitations of current clinical radiologic AI systems, new clinical workflows, and the potential effect of generative AI and large multimodal foundation models.",https://www.nejm.org/doi/full/10.1056/NEJMra2301725
Pranav Rajpurkar,Deep Learning–Assisted Diagnosis of Cerebral Aneurysms Using the HeadXNet Model,2019,JAMA Network Open,245,"Allison Park, Chris Chute, Pranav Rajpurkar, Joe Lou, Robyn L Ball, Katie Shpanskaya, Rashad Jabarkheel, Lily H Kim, Emily McKenna, Joe Tseng, Jason Ni, Fidaa Wishah, Fred Wittber, David S Hong, Thomas J Wilson, Safwan Halabi, Sanjay Basu, Bhavik N Patel, Matthew P Lungren, Andrew Y Ng, Kristen W Yeom",Allison Park,Kristen W Yeom,21,"Deep learning has the potential to augment clinician performance in medical imaging interpretation and reduce time to diagnosis through automated segmentation. Few studies to date have explored this topic.To develop and apply a neural network segmentation model (the HeadXNet model) capable of generating precise voxel-by-voxel predictions of intracranial aneurysms on head computed tomographic angiography (CTA) imaging to augment clinicians’ intracranial aneurysm diagnostic performance.In this diagnostic study, a 3-dimensional convolutional neural network architecture was developed using a training set of 611 head CTA examinations to generate aneurysm segmentations. Segmentation outputs from this support model on a test set of 115 examinations were provided to clinicians. Between August 13, 2018, and October 4, 2018, 8 clinicians …",https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2735471
Pranav Rajpurkar,Moco pretraining improves representation and transferability of chest x-ray models,2021,Medical Imaging with Deep Learning,217,"Hari Sowrirajan, Jingbo Yang, Andrew Y Ng, Pranav Rajpurkar",Hari Sowrirajan,Pranav Rajpurkar,4,"Contrastive learning is a form of self-supervision that can leverage unlabeled data to produce pretrained models. While contrastive learning has demonstrated promising results on natural image classification tasks, its application to medical imaging tasks like chest X-ray interpretation has been limited. In this work, we propose MoCo-CXR, which is an adaptation of the contrastive learning method Momentum Contrast (MoCo), to produce models with better representations and initializations for the detection of pathologies in chest X-rays. In detecting pleural effusion, we find that linear models trained on MoCo-CXR-pretrained representations outperform those without MoCo-CXR-pretrained representations, indicating that MoCo-CXR-pretrained representations are of higher-quality. End-to-end fine-tuning experiments reveal that a model initialized via MoCo-CXR-pretraining outperforms its non-MoCo-CXR-pretrained counterpart. We find that MoCo-CXR-pretraining provides the most benefit with limited labeled training data. Finally, we demonstrate similar results on a target Tuberculosis dataset unseen during pretraining, indicating that MoCo-CXR-pretraining endows models with representations and transferability that can be applied across chest X-ray datasets and tasks.",https://proceedings.mlr.press/v143/sowrirajan21a.html
Pranav Rajpurkar,Human–machine partnership with artificial intelligence for chest radiograph diagnosis,2019,NPJ digital medicine,207,"Bhavik N Patel, Louis Rosenberg, Gregg Willcox, David Baltaxe, Mimi Lyons, Jeremy Irvin, Pranav Rajpurkar, Timothy Amrhein, Rajan Gupta, Safwan Halabi, Curtis Langlotz, Edward Lo, Joseph Mammarappallil, AJ Mariano, Geoffrey Riley, Jayne Seekins, Luyao Shen, Evan Zucker, Matthew P Lungren",Bhavik N Patel,Matthew P Lungren,19,"Human-in-the-loop (HITL) AI may enable an ideal symbiosis of human experts and AI models, harnessing the advantages of both while at the same time overcoming their respective limitations. The purpose of this study was to investigate a novel collective intelligence technology designed to amplify the diagnostic accuracy of networked human groups by forming real-time systems modeled on biological swarms. Using small groups of radiologists, the swarm-based technology was applied to the diagnosis of pneumonia on chest radiographs and compared against human experts alone, as well as two state-of-the-art deep learning AI models. Our work demonstrates that both the swarm-based technology and deep-learning technology achieved superior diagnostic accuracy than the human experts alone. Our work further demonstrates that when used in combination, the swarm-based technology and deep-learning …",https://www.nature.com/articles/s41746-019-0189-7
Pranav Rajpurkar,Med-flamingo: a multimodal medical few-shot learner,2023,Machine Learning for Health (ML4H),203,"Michael Moor, Qian Huang, Shirley Wu, Michihiro Yasunaga, Yash Dalmia, Jure Leskovec, Cyril Zakka, Eduardo Pontes Reis, Pranav Rajpurkar",Michael Moor,Pranav Rajpurkar,9,"Medicine, by its nature, is a multifaceted domain that requires the synthesis of information across various modalities. Medical generative vision-language models {~}(VLMs) make a first step in this direction and promise many exciting clinical applications. However, existing models typically have to be fine-tuned on sizeable down-stream datasets, which poses a significant limitation as in many medical applications data is scarce, necessitating models that are capable of learning from few examples in real-time. Here we propose Med-Flamingo, a multimodal few-shot learner adapted to the medical domain. Based on OpenFlamingo-9B, we continue pre-training on paired and interleaved medical image-text data from publications and textbooks. Med-Flamingo unlocks few-shot generative medical visual question answering {~}(VQA) abilities, which we evaluate on several datasets including a novel challenging open-ended VQA dataset of visual USMLE-style problems. Furthermore, we conduct the first human evaluation for generative medical VQA where physicians review the problems and blinded generations in an interactive app. Med-Flamingo improves performance in generative medical VQA by up to 20 {\}% in clinician’s rating and firstly enables multimodal medical few-shot adaptations, such as rationale generation. We release our model, code, and evaluation app.% under {~}{\} url\{https://github. com/snap-stanford/med-flamingo\}.",https://proceedings.mlr.press/v225/moor23a.html
Pranav Rajpurkar,RadGraph: Extracting Clinical Entities and Relations from Radiology Reports,2021,Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1),186,"Saahil Jain, Ashwin Agrawal, Adriel Saporta, Steven QH Truong, Du Nguyen Duong, Tan Bui, Pierre Chambon, Yuhao Zhang, Matthew P Lungren, Andrew Y Ng, Curtis P Langlotz, Pranav Rajpurkar",Saahil Jain,Pranav Rajpurkar,12,"Extracting structured clinical information from free-text radiology reports can enable the use of radiology report information for a variety of critical healthcare applications. In our work, we present RadGraph, a dataset of entities and relations in full-text chest X-ray radiology reports based on a novel information extraction schema we designed to structure radiology reports. We release a development dataset, which contains board-certified radiologist annotations for 500 radiology reports from the MIMIC-CXR dataset (14,579 entities and 10,889 relations), and a test dataset, which contains two independent sets of board-certified radiologist annotations for 100 radiology reports split equally across the MIMIC-CXR and CheXpert datasets. Using these datasets, we train and test a deep learning model, RadGraph Benchmark, that achieves a micro F1 of 0.82 and 0.73 on relation extraction on the MIMIC-CXR and CheXpert test sets respectively. Additionally, we release an inference dataset, which contains annotations automatically generated by RadGraph Benchmark across 220,763 MIMIC-CXR reports (around 6 million entities and 4 million relations) and 500 CheXpert reports (13,783 entities and 9,908 relations) with mappings to associated chest radiographs. Our freely available dataset can facilitate a wide range of research in medical natural language processing, as well as computer vision and multi-modal learning when linked to chest radiographs.",https://arxiv.org/abs/2106.14463
Pranav Rajpurkar,Benchmarking saliency methods for chest X-ray interpretation,2022,Nature Machine Intelligence,160,"Adriel Saporta, Xiaotong Gui, Ashwin Agrawal, Anuj Pareek, Steven QH Truong, Chanh DT Nguyen, Van-Doan Ngo, Jayne Seekins, Francis G Blankenberg, Andrew Y Ng, Matthew P Lungren, Pranav Rajpurkar",Adriel Saporta,Pranav Rajpurkar,12,"Saliency methods, which produce heat maps that highlight the areas of the medical image that influence model prediction, are often presented to clinicians as an aid in diagnostic decision-making. However, rigorous investigation of the accuracy and reliability of these strategies is necessary before they are integrated into the clinical setting. In this work, we quantitatively evaluate seven saliency methods, including Grad-CAM, across multiple neural network architectures using two evaluation metrics. We establish the first human benchmark for chest X-ray segmentation in a multilabel classification set-up, and examine under what clinical conditions saliency maps might be more prone to failure in localizing important pathologies compared with a human expert benchmark. We find that (1) while Grad-CAM generally localized pathologies better than the other evaluated saliency methods, all seven performed significantly …",https://www.nature.com/articles/s42256-022-00536-x
Pranav Rajpurkar,PENet—a scalable deep-learning model for automated diagnosis of pulmonary embolism using volumetric CT imaging,2020,NPJ digital medicine,141,"Shih-Cheng Huang, Tanay Kothari, Imon Banerjee, Chris Chute, Robyn L Ball, Norah Borus, Andrew Huang, Bhavik N Patel, Pranav Rajpurkar, Jeremy Irvin, Jared Dunnmon, Joseph Bledsoe, Katie Shpanskaya, Abhay Dhaliwal, Roham Zamanian, Andrew Y Ng, Matthew P Lungren",Shih-Cheng Huang,Matthew P Lungren,17,"Pulmonary embolism (PE) is a life-threatening clinical problem and computed tomography pulmonary angiography (CTPA) is the gold standard for diagnosis. Prompt diagnosis and immediate treatment are critical to avoid high morbidity and mortality rates, yet PE remains among the diagnoses most frequently missed or delayed. In this study, we developed a deep learning model—PENet, to automatically detect PE on volumetric CTPA scans as an end-to-end solution for this purpose. The PENet is a 77-layer 3D convolutional neural network (CNN) pretrained on the Kinetics-600 dataset and fine-tuned on a retrospective CTPA dataset collected from a single academic institution. The PENet model performance was evaluated in detecting PE on data from two different institutions: one as a hold-out dataset from the same institution as the training data and a second collected from an external institution to evaluate model …",https://www.nature.com/articles/s41746-020-0266-y
Pranav Rajpurkar,CheXtransfer: Performance and Parameter Efficiency of ImageNet Models for Chest X-Ray Interpretation,2021,"ACM Conference on Health, Inference, and Learning (ACM-CHIL) 2021",127,"Alexander Ke, William Ellsworth, Oishi Banerjee, Andrew Y Ng, Pranav Rajpurkar",Alexander Ke,Pranav Rajpurkar,5,"Deep learning methods for chest X-ray interpretation typically rely on pretrained models developed for ImageNet. This paradigm assumes that better ImageNet architectures perform better on chest X-ray tasks and that ImageNet-pretrained weights provide a performance boost over random initialization. In this work, we compare the transfer performance and parameter efficiency of 16 popular convolutional architectures on a large chest X-ray dataset (CheXpert) to investigate these assumptions. First, we find no relationship between ImageNet performance and CheXpert performance for both models without pretraining and models with pretraining. Second, we find that, for models without pretraining, the choice of model family influences performance more than size within a family for medical imaging tasks. Third, we observe that ImageNet pretraining yields a statistically significant boost in performance across …",https://dl.acm.org/doi/abs/10.1145/3450439.3451867
Pranav Rajpurkar,Combining Human Expertise with Artificial Intelligence: Experimental Evidence from Radiology,2023,,126,"Nikhil Agarwal, Alex Moehring, Pranav Rajpurkar, Tobias Salz",Nikhil Agarwal,Tobias Salz,4,"While Artificial Intelligence (AI) algorithms have achieved performance levels comparable to human experts on various predictive tasks, human experts can still access valuable contextual information not yet incorporated into AI predictions. Humans assisted by AI predictions could outperform both human-alone or AI-alone. We conduct an experiment with professional radiologists that varies the availability of AI assistance and contextual information to study the effectiveness of human-AI collaboration and to investigate how to optimize it. Our findings reveal that (i) providing AI predictions does not uniformly increase diagnostic quality, and (ii) providing contextual information does increase quality. Radiologists do not fully capitalize on the potential gains from AI assistance because of large deviations from the benchmark Bayesian model with correct belief updating. The observed errors in belief updating can be explained by radiologists’ partially underweighting the AI’s information relative to their own and not accounting for the correlation between their own information and AI predictions. In light of these biases, we design a collaborative system between radiologists and AI. Our results demonstrate that, unless the documented mistakes can be corrected, the optimal solution involves assigning cases either to humans or to AI, but rarely to a human assisted by AI.",https://www.nber.org/papers/w31422
Pranav Rajpurkar,CheXaid: deep learning assistance for physician diagnosis of tuberculosis using chest x-rays in patients with HIV,2020,NPJ digital medicine,119,"Pranav Rajpurkar, Chloe O’Connell, Amit Schechter, Nishit Asnani, Jason Li, Amirhossein Kiani, Robyn L Ball, Marc Mendelson, Gary Maartens, Daniël J van Hoving, Rulan Griesel, Andrew Y Ng, Tom H Boyles, Matthew P Lungren",Pranav Rajpurkar,Matthew P Lungren,14,"Tuberculosis (TB) is the leading cause of preventable death in HIV-positive patients, and yet often remains undiagnosed and untreated. Chest x-ray is often used to assist in diagnosis, yet this presents additional challenges due to atypical radiographic presentation and radiologist shortages in regions where co-infection is most common. We developed a deep learning algorithm to diagnose TB using clinical information and chest x-ray images from 677 HIV-positive patients with suspected TB from two hospitals in South Africa. We then sought to determine whether the algorithm could assist clinicians in the diagnosis of TB in HIV-positive patients as a web-based diagnostic assistant. Use of the algorithm resulted in a modest but statistically significant improvement in clinician accuracy (p = 0.002), increasing the mean clinician accuracy from 0.60 (95% CI 0.57, 0.63) without assistance to 0.65 (95% CI 0.60, 0.70) with …",https://www.nature.com/articles/s41746-020-00322-2
Pranav Rajpurkar,Automated coronary calcium scoring using deep learning with multicenter external validation,2021,NPJ digital medicine,106,"David Eng, Christopher Chute, Nishith Khandwala, Pranav Rajpurkar, Jin Long, Sam Shleifer, Mohamed H Khalaf, Alexander T Sandhu, Fatima Rodriguez, David J Maron, Saeed Seyyedi, Daniele Marin, Ilana Golub, Matthew Budoff, Felipe Kitamura, Marcelo Straus Takahashi, Ross W Filice, Rajesh Shah, John Mongan, Kimberly Kallianos, Curtis P Langlotz, Matthew P Lungren, Andrew Y Ng, Bhavik N Patel",David Eng,Bhavik N Patel,24,"Coronary artery disease (CAD), the most common manifestation of cardiovascular disease, remains the most common cause of mortality in the United States. Risk assessment is key for primary prevention of coronary events and coronary artery calcium (CAC) scoring using computed tomography (CT) is one such non-invasive tool. Despite the proven clinical value of CAC, the current clinical practice implementation for CAC has limitations such as the lack of insurance coverage for the test, need for capital-intensive CT machines, specialized imaging protocols, and accredited 3D imaging labs for analysis (including personnel and software). Perhaps the greatest gap is the millions of patients who undergo routine chest CT exams and demonstrate coronary artery calcification, but their presence is not often reported or quantitation is not feasible. We present two deep learning models that automate CAC scoring …",https://www.nature.com/articles/s41746-021-00460-1
Pranav Rajpurkar,AppendiXNet: deep learning for diagnosis of appendicitis from a small dataset of CT exams using video pretraining,2020,Scientific reports,100,"Pranav Rajpurkar, Allison Park, Jeremy Irvin, Chris Chute, Michael Bereket, Domenico Mastrodicasa, Curtis P Langlotz, Matthew P Lungren, Andrew Y Ng, Bhavik N Patel",Pranav Rajpurkar,Bhavik N Patel,10,"The development of deep learning algorithms for complex tasks in digital medicine has relied on the availability of large labeled training datasets, usually containing hundreds of thousands of examples. The purpose of this study was to develop a 3D deep learning model, AppendiXNet, to detect appendicitis, one of the most common life-threatening abdominal emergencies, using a small training dataset of less than 500 training CT exams. We explored whether pretraining the model on a large collection of natural videos would improve the performance of the model over training the model from scratch. AppendiXNet was pretrained on a large collection of YouTube videos called Kinetics, consisting of approximately 500,000 video clips and annotated for one of 600 human action classes, and then fine-tuned on a small dataset of 438 CT scans annotated for appendicitis. We found that pretraining the 3D model on …",https://www.nature.com/articles/s41598-020-61055-6
Pranav Rajpurkar,Medaug: Contrastive learning leveraging patient metadata improves representations for chest x-ray interpretation,2021,Machine Learning for Healthcare Conference,95,"Yen Nhi Truong Vu, Richard Wang, Niranjan Balachandar, Can Liu, Andrew Y Ng, Pranav Rajpurkar",Yen Nhi Truong Vu,Pranav Rajpurkar,6,"Self-supervised contrastive learning between pairs of multiple views of the same image has been shown to successfully leverage unlabeled data to produce meaningful visual representations for both natural and medical images. However, there has been limited work on determining how to select pairs for medical images, where availability of patient metadata can be leveraged to improve representations. In this work, we develop a method to select positive pairs coming from views of possibly different images through the use of patient metadata. We compare strategies for selecting positive pairs for chest X-ray interpretation including requiring them to be from the same patient, imaging study or laterality. We evaluate downstream task performance by fine-tuning the linear layer on 1% of the labeled dataset for pleural effusion classification. Our best performing positive pair selection strategy, which involves using images from the same patient from the same study across all lateralities, achieves a performance increase of 14.4% in mean AUC from the ImageNet pretrained baseline. Our controlled experiments show that the keys to improving down-stream performance on disease classification are (1) using patient metadata to appropriately create positive pairs from different images with the same underlying pathologies, and (2) maximizing the number of different images used in query pairing. In addition, we explore leveraging patient metadata to select hard negative pairs for contrastive learning, but do not find improvement over baselines that do not use metadata. Our method is broadly applicable to medical image interpretation and allows flexibility …",https://proceedings.mlr.press/v149/vu21a.html
Pranav Rajpurkar,Retrieval-Based Chest X-Ray Report Generation Using a Pre-trained Contrastive Language-Image Model,2021,Machine Learning for Health,90,"Mark Endo, Rayan Krishnan, Viswesh Krishna, Andrew Y Ng, Pranav Rajpurkar",Mark Endo,Pranav Rajpurkar,5,"We propose CXR-RePaiR: a retrieval-based radiology report generation approach using a pre-trained contrastive language-image model. Our method generates clinically accurate reports on both in-distribution and out-of-distribution data. CXR-RePaiR outperforms or matches prior report generation methods on clinical metrics, achieving an average F  score of 0.352 (+ 7.98%) on an external radiology dataset (CheXpert). Further, we implement a compression approach used to reduce the size of the reference corpus and speed up the runtime of our retrieval method. With compression, our model maintains similar performance while producing reports 70% faster than the best generative model. Our approach can be broadly useful in improving the diagnostic performance and generalizability of report generation models and enabling their use in clinical workflows.",https://proceedings.mlr.press/v158/endo21a.html
Pranav Rajpurkar,Automated abnormality detection in lower extremity radiographs using deep learning,2019,Nature Machine Intelligence,90,"Maya Varma, Mandy Lu, Rachel Gardner, Jared Dunnmon, Nishith Khandwala, Pranav Rajpurkar, Jin Long, Christopher Beaulieu, Katie Shpanskaya, Li Fei-Fei, Matthew P Lungren, Bhavik N Patel",Maya Varma,Bhavik N Patel,12,"Musculoskeletal disorders are a major healthcare challenge around the world. We investigate the utility of convolutional neural networks (CNNs) in performing generalized abnormality detection on lower extremity radiographs. We also explore the effect of pretraining, dataset size and model architecture on model performance to provide recommendations for future deep learning analyses on extremity radiographs, especially when access to large datasets is challenging. We collected a large dataset of 93,455 lower extremity radiographs of multiple body parts, with each exam labelled as normal or abnormal. A 161-layer densely connected, pretrained CNN achieved an AUC-ROC of 0.880 (sensitivity = 0.714, specificity = 0.961) on this abnormality classification task. Our findings show that a single CNN model can be effectively utilized for the identification of diverse abnormalities in highly variable radiographs of …",https://www.nature.com/articles/s42256-019-0126-0
Pranav Rajpurkar,Evaluating progress in automatic chest x-ray radiology report generation,2023,Patterns,84,"Feiyang Yu, Mark Endo, Rayan Krishnan, Ian Pan, Andy Tsai, Eduardo Pontes Reis, Eduardo Kaiser Ururahy Nunes Fonseca, Henrique Min Ho Lee, Zahra Shakeri Hossein Abad, Andrew Y Ng, Curtis P Langlotz, Vasantha Kumar Venugopal, Pranav Rajpurkar",Feiyang Yu,Pranav Rajpurkar,13,"Artificial intelligence (AI) models for automatic generation of narrative radiology reports from images have the potential to enhance efficiency and reduce the workload of radiologists. However, evaluating the correctness of these reports requires metrics that can capture clinically pertinent differences. In this study, we investigate the alignment between automated metrics and radiologists' scoring of errors in report generation. We address the limitations of existing metrics by proposing new metrics, RadGraph F1 and RadCliQ, which demonstrate stronger correlation with radiologists' evaluations. In addition, we analyze the failure modes of the metrics to understand their limitations and provide guidance for metric selection and interpretation. This study establishes RadGraph F1 and RadCliQ as meaningful metrics for guiding future research in radiology report generation.",https://www.cell.com/patterns/fulltext/S2666-3899(23)00157-5
Pranav Rajpurkar,Evaluation of a machine learning model based on pretreatment symptoms and electroencephalographic features to predict outcomes of antidepressant treatment in adults with depression: a prespecified secondary analysis of a randomized clinical trial,2020,JAMA Network Open,72,"Pranav Rajpurkar, Jingbo Yang, Nathan Dass, Vinjai Vale, Arielle S Keller, Jeremy Irvin, Zachary Taylor, Sanjay Basu, Andrew Ng, Leanne M Williams",Pranav Rajpurkar,Leanne M Williams,10,"Despite the high prevalence and potential outcomes of major depressive disorder, whether and how patients will respond to antidepressant medications is not easily predicted.To identify the extent to which a machine learning approach, using gradient-boosted decision trees, can predict acute improvement for individual depressive symptoms with antidepressants based on pretreatment symptom scores and electroencephalographic (EEG) measures.This prognostic study analyzed data collected as part of the International Study to Predict Optimized Treatment in Depression, a randomized, prospective open-label trial to identify clinically useful predictors and moderators of response to commonly used first-line antidepressant medications. Data collection was conducted at 20 sites spanning 5 countries and including 518 adult outpatients (18-65 years of age) from …",https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2767367
Pranav Rajpurkar,3KG: Contrastive Learning of 12-Lead Electrocardiograms using Physiologically-Inspired Augmentations,2021,Machine Learning for Health,65,"Bryan Gopal, Ryan Han, Gautham Raghupathi, Andrew Ng, Geoff Tison, Pranav Rajpurkar",Bryan Gopal,Pranav Rajpurkar,6,"We propose 3KG, a physiologically-inspired contrastive learning approach that generates views using 3D augmentations of the 12-lead electrocardiogram. We evaluate representation quality by fine-tuning a linear layer for the downstream task of 23-class diagnosis on the PhysioNet 2020 challenge training data and find that 3KG achieves a 9.1% increase in mean AUC over the best self-supervised baseline when trained on 1% of labeled data. Our empirical analysis shows that combining spatial and temporal augmentations produces the strongest representations. In addition, we investigate the effect of this physiologically-inspired pretraining on downstream performance on different disease subgroups and find that 3KG makes the greatest gains for conduction and rhythm abnormalities. Our method allows for flexibility in incorporating other self-supervised strategies and highlights the potential for similar modality-specific augmentations for other biomedical signals.",https://proceedings.mlr.press/v158/gopal21a.html
Pranav Rajpurkar,Clinical Value of Predicting Individual Treatment Effects for Intensive Blood Pressure Therapy: A Machine Learning Experiment to Estimate Treatment Effects from Randomized Trial Data [RETRACTED],2019,Circulation: Cardiovascular Quality and Outcomes,58,"Tony Duan, Pranav Rajpurkar, Dillon Laird, Andrew Y Ng, Sanjay Basu",Tony Duan,Sanjay Basu,5,"Background:The absolute risk reduction (ARR) in cardiovascular events from therapy is generally assumed to be proportional to baseline risk—such that high-risk patients benefit most. Yet newer analyses have proposed using randomized trial data to develop models that estimate individual treatment effects. We tested 2 hypotheses: first, that models of individual treatment effects would reveal that benefit from intensive blood pressure therapy is proportional to baseline risk; and second, that a machine learning approach designed to predict heterogeneous treatment effects—the X-learner meta-algorithm—is equivalent to a conventional logistic regression approach.Methods and Results:We compared conventional logistic regression to the X-learner approach for prediction of 3-year cardiovascular disease event risk reduction from intensive (target systolic blood pressure< 120 mm Hg) versus standard (target< 140 …",https://www.ahajournals.org/doi/abs/10.1161/circoutcomes.118.005010
Pranav Rajpurkar,Incorporating machine learning and social determinants of health indicators into prospective risk adjustment for health plan payments,2020,BMC Public Health,49,"Jeremy A Irvin, Andrew A Kondrich, Michael Ko, Pranav Rajpurkar, Behzad Haghgoo, Bruce E Landon, Robert L Phillips, Stephen Petterson, Andrew Y Ng, Sanjay Basu",Jeremy A Irvin,Sanjay Basu,10,"Background Risk adjustment models are employed to prevent adverse selection, anticipate budgetary reserve needs, and offer care management services to high-risk individuals. We aimed to address two unknowns about risk adjustment: whether machine learning (ML) and inclusion of social determinants of health (SDH) indicators improve prospective risk adjustment for health plan payments. Methods We employed a 2-by-2 factorial design comparing:(i) linear regression versus ML (gradient boosting) and (ii) demographics and diagnostic codes alone, versus additional ZIP code-level SDH indicators. Healthcare claims from privately-insured US adults (2016–2017), and Census data were used for analysis. Data from 1.02 million adults were used for derivation, and data from 0.26 million to assess performance. Model performance was measured using coefficient of determination (R 2), discrimination (C-statistic …",https://link.springer.com/article/10.1186/s12889-020-08735-0
Pranav Rajpurkar,A machine learning algorithm can optimize the day of trigger to improve in vitro fertilization outcomes,2021,Fertility and Sterility,46,"Eduardo Hariton, Ethan A Chi, Gordon Chi, Jerrine R Morris, Jon Braatz, Pranav Rajpurkar, Mitchell Rosen",Eduardo Hariton,Mitchell Rosen,7,"To determine whether a machine learning causal inference model can optimize trigger injection timing to maximize the yield of fertilized oocytes (2PNs) and total usable blastocysts for a given cohort of stimulated follicles.Descriptive and comparative study of new technology.Tertiary academic medical center.Patients undergoing IVF with intracytoplasmic sperm injection from 2008 to 2019 (n = 7,866).Causal inference was performed with the use of a T-learner. Bagged decision trees were used to perform inference. The decision was framed as either triggering on that day or waiting another day. All patient characteristics and stimulation parameters on a given day were used to determine the recommendation.Average outcome improvement in total 2PNs and usable blastocysts compared with the physician’s decision.For evaluation of …",https://www.sciencedirect.com/science/article/pii/S0015028221005124
Pranav Rajpurkar,Randomised controlled trials evaluating artificial intelligence in clinical practice: a scoping review,2024,,43,"Ryan Han, Julián N Acosta, Zahra Shakeri, John PA Ioannidis, Eric J Topol, Pranav Rajpurkar",Ryan Han,Pranav Rajpurkar,6,"This scoping review of randomised controlled trials on artificial intelligence (AI) in clinical practice reveals an expanding interest in AI across clinical specialties and locations. The USA and China are leading in the number of trials, with a focus on deep learning systems for medical imaging, particularly in gastroenterology and radiology. A majority of trials (70 [81%] of 86) report positive primary endpoints, primarily related to diagnostic yield or performance; however, the predominance of single-centre trials, little demographic reporting, and varying reports of operational efficiency raise concerns about the generalisability and practicality of these results. Despite the promising outcomes, considering the likelihood of publication bias and the need for more comprehensive research including multicentre trials, diverse outcome measures, and improved reporting standards is crucial. Future AI trials should prioritise patient …",https://www.thelancet.com/journals/landig/article/PIIS2589-7500(24)00047-5/fulltext?uuid=uuid%3A7e019d4a-a7a6-45e6-9f65-164cb77cdf7c
Pranav Rajpurkar,CheXpedition: Investigating Generalization Challenges for Translation of Chest X-Ray Algorithms to the Clinical Setting,2020,"ACM Conference on Health, Inference, and Learning (CHIL) Workshop 2020",42,"Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Phil Chen, Amirhossein Kiani, Jeremy Irvin, Andrew Y Ng, Matthew P Lungren",Pranav Rajpurkar,Matthew P Lungren,8,"Although there have been several recent advances in the application of deep learning algorithms to chest x-ray interpretation, we identify three major challenges for the translation of chest x-ray algorithms to the clinical setting. We examine the performance of the top 10 performing models on the CheXpert challenge leaderboard on three tasks: (1) TB detection, (2) pathology detection on photos of chest x-rays, and (3) pathology detection on data from an external institution. First, we find that the top 10 chest x-ray models on the CheXpert competition achieve an average AUC of 0.851 on the task of detecting TB on two public TB datasets without fine-tuning or including the TB labels in training data. Second, we find that the average performance of the models on photos of x-rays (AUC = 0.916) is similar to their performance on the original chest x-ray images (AUC = 0.924). Third, we find that the models tested on an external dataset either perform comparably to or exceed the average performance of radiologists. We believe that our investigation will inform rapid translation of deep learning algorithms to safe and effective clinical decision support tools that can be validated prospectively with large impact studies and clinical trials.",https://arxiv.org/abs/2002.11379
Pranav Rajpurkar,Augur: Mining Human Behaviors from Fiction to Power Interactive Systems,2016,Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems,42,"Ethan Fast, William McGrath, Pranav Rajpurkar, Michael S Bernstein",Ethan Fast,Michael S Bernstein,4,"From smart homes that prepare coffee when we wake, to phones that know not to interrupt us during important conversations, our collective visions of HCI imagine a future in which computers understand a broad range of human behaviors. Today our systems fall short of these visions, however, because this range of behaviors is too large for designers or programmers to capture manually. In this paper, we instead demonstrate it is possible to mine a broad knowledge base of human behavior by analyzing more than one billion words of modern fiction. Our resulting knowledge base, Augur, trains vector models that can predict many thousands of user activities from surrounding objects in modern contexts: for example, whether a user may be eating food, meeting with a friend, or taking a selfie. Augur uses these predictions to identify actions that people commonly take on objects in the world and estimate a user's future …",https://dl.acm.org/doi/abs/10.1145/2858036.2858528
Pranav Rajpurkar,Multimodal image-text matching improves retrieval-based chest x-ray report generation,2024,Medical Imaging with Deep Learning,41,"Jaehwan Jeong, Katherine Tian, Andrew Li, Sina Hartung, Subathra Adithan, Fardad Behzadi, Juan Calle, David Osayande, Michael Pohlen, Pranav Rajpurkar",Jaehwan Jeong,Pranav Rajpurkar,10,"Automated generation of clinically accurate radiology reports can improve patient care. Previous report generation methods that rely on image captioning models often generate incoherent and incorrect text due to their lack of relevant domain knowledge, while retrieval-based attempts frequently retrieve reports that are irrelevant to the input image. In this work, we propose Contrastive X-Ray REport Match (X-REM), a novel retrieval-based radiology report generation module that uses an image-text matching score to measure the similarity of a chest X-ray image and radiology report for report retrieval. We observe that computing the image-text matching score with a language-image model can effectively capture the fine-grained interaction between image and text that is often lost when using cosine similarity. X-REM outperforms multiple prior radiology report generation modules in terms of both natural language and clinical metrics. Human evaluation of the generated reports suggests that X-REM increased the number of zero-error reports and decreased the average error severity compared to the baseline retrieval approach. Our code is available at: https://github. com/rajpurkarlab/X-REM",https://proceedings.mlr.press/v227/jeong24a.html
Pranav Rajpurkar,Development and validation of an artificial intelligence system to optimize clinician review of patient records,2021,JAMA network open,41,"Ethan Andrew Chi, Gordon Chi, Cheuk To Tsui, Yan Jiang, Karolin Jarr, Chiraag V Kulkarni, Michael Zhang, Jin Long, Andrew Y Ng, Pranav Rajpurkar, Sidhartha R Sinha",Ethan Andrew Chi,Sidhartha R Sinha,11,"Physicians are required to work with rapidly growing amounts of medical data. Approximately 62% of time per patient is devoted to reviewing electronic health records (EHRs), with clinical data review being the most time-consuming portion.To determine whether an artificial intelligence (AI) system developed to organize and display new patient referral records would improve a clinician’s ability to extract patient information compared with the current standard of care.In this prognostic study, an AI system was created to organize patient records and improve data retrieval. To evaluate the system on time and accuracy, a nonblinded, prospective study was conducted at a single academic medical center. Recruitment emails were sent to all physicians in the gastroenterology division, and 12 clinicians agreed to participate. Each of the clinicians participating in the study …",https://jamanetwork.com/journals/jamanetworkopen/article-abstract/2782216
Pranav Rajpurkar,Improving Radiology Report Generation Systems by Removing Hallucinated References to Non-existent Priors,2022,Machine Learning for Health,40,"Vignav Ramesh, Nathan A Chi, Pranav Rajpurkar",Vignav Ramesh,Pranav Rajpurkar,3,"Current deep learning models trained to generate radiology reports from chest radiographs are capable of producing clinically accurate, clear, and actionable text that can advance patient care. However, such systems all succumb to the same problem: making hallucinated references to non-existent prior reports. Such hallucinations occur because these models are trained on datasets of real-world patient reports that inherently refer to priors. To this end, we propose two methods to remove references to priors in radiology reports:(1) a GPT-3-based few-shot approach to rewrite medical reports without references to priors; and (2) a BioBERT-based token classification approach to directly remove words referring to priors. We use the aforementioned approaches to modify MIMIC-CXR, a publicly available dataset of chest X-rays and their associated free-text radiology reports; we then retrain CXR-RePaiR, a radiology report generation system, on the adapted MIMIC-CXR dataset. We find that our re-trained model—which we call CXR-ReDonE—outperforms previous report generation methods on clinical metrics, achieving an average BERTScore of 0.2351 ($2.57% $ absolute improvement). We expect our approach to be broadly valuable in enabling current radiology report generation systems to be more directly integrated into clinical pipelines.",https://proceedings.mlr.press/v193/ramesh22a.html
Pranav Rajpurkar,Heterogeneity and predictors of the effects of AI assistance on radiologists,2024,Nature Medicine,39,"Feiyang Yu, Alex Moehring, Oishi Banerjee, Tobias Salz, Nikhil Agarwal, Pranav Rajpurkar",Feiyang Yu,Pranav Rajpurkar,6,"The integration of artificial intelligence (AI) in medical image interpretation requires effective collaboration between clinicians and AI algorithms. Although previous studies demonstrated the potential of AI assistance in improving overall clinician performance, the individual impact on clinicians remains unclear. This large-scale study examined the heterogeneous effects of AI assistance on 140 radiologists across 15 chest X-ray diagnostic tasks and identified predictors of these effects. Surprisingly, conventional experience-based factors, such as years of experience, subspecialty and familiarity with AI tools, fail to reliably predict the impact of AI assistance. Additionally, lower-performing radiologists do not consistently benefit more from AI assistance, challenging prevailing assumptions. Instead, we found that the occurrence of AI errors strongly influences treatment outcomes, with inaccurate AI predictions adversely …",https://www.nature.com/articles/s41591-024-02850-w
Pranav Rajpurkar,Deep learning saliency maps do not accurately highlight diagnostically relevant regions for medical image interpretation,2021,,37,"Adriel Saporta, Xiaotong Gui, Ashwin Agrawal, Anuj Pareek, Steven QH Truong, Chanh DT Nguyen, Jayne Seekins, Francis G Blankenberg, Andrew Y Ng, Matthew P Lundgren, Pranav Rajpurkar",Adriel Saporta,Pranav Rajpurkar,11,"Deep learning saliency maps do not accurately highlight diagnostically relevant regions for 
medical image interpretation — The Capital Region of Denmark's Research Portal Skip to main 
navigation Skip to search Skip to main content The Capital Region of Denmark's Research 
Portal Home The Capital Region of Denmark's Research Portal Logo Help & FAQ Dansk 
English Home Hospitals/departments Researchers Research output Activities Prizes Search 
by expertise, name or affiliation Deep learning saliency maps do not accurately highlight 
diagnostically relevant regions for medical image interpretation Adriel Saporta, Xiaotong Gui, 
Ashwin Agrawal, Anuj Pareek, Steven QH Truong, Chanh DT Nguyen, Van Doan Ngo, Jayne 
Seekins, Francis G. Blankenberg, Andrew Y. Ng, Matthew P Lundgren, Pranav Rajpurkar 
Overview Original language English Publisher medRxiv Publication status Published - 2021 …",https://research.regionh.dk/en/publications/deep-learning-saliency-maps-do-not-accurately-highlight-diagnosti
Pranav Rajpurkar,Exploring the Boundaries of GPT-4 in Radiology,2023,arXiv preprint arXiv:2310.14573,33,"Qianchu Liu, Stephanie Hyland, Shruthi Bannur, Kenza Bouzid, Daniel C Castro, Maria Teodora Wetscherek, Robert Tinn, Harshita Sharma, Fernando Pérez-García, Anton Schwaighofer, Pranav Rajpurkar, Sameer Tajdin Khanna, Hoifung Poon, Naoto Usuyama, Anja Thieme, Aditya V Nori, Matthew P Lungren, Ozan Oktay, Javier Alvarez-Valle",Qianchu Liu,Javier Alvarez-Valle,19,"The recent success of general-domain large language models (LLMs) has significantly changed the natural language processing paradigm towards a unified foundation model across domains and applications. In this paper, we focus on assessing the performance of GPT-4, the most capable LLM so far, on the text-based applications for radiology reports, comparing against state-of-the-art (SOTA) radiology-specific models. Exploring various prompting strategies, we evaluated GPT-4 on a diverse range of common radiology tasks and we found GPT-4 either outperforms or is on par with current SOTA radiology models. With zero-shot prompting, GPT-4 already obtains substantial gains ( 10% absolute improvement) over radiology models in temporal sentence similarity classification (accuracy) and natural language inference (). For tasks that require learning dataset-specific style or schema (e.g. findings summarisation), GPT-4 improves with example-based prompting and matches supervised SOTA. Our extensive error analysis with a board-certified radiologist shows GPT-4 has a sufficient level of radiology knowledge with only occasional errors in complex context that require nuanced domain knowledge. For findings summarisation, GPT-4 outputs are found to be overall comparable with existing manually-written impressions.",https://arxiv.org/abs/2310.14573
Pranav Rajpurkar,Improving dermatology classifiers across populations using images generated by large diffusion models,2022,NeurIPS 2022 Workshop on Synthetic Data for Empowering ML Research,32,"Luke W Sagers, James A Diao, Matthew Groh, Pranav Rajpurkar, Adewole S Adamson, Arjun K Manrai",Luke W Sagers,Arjun K Manrai,6,"Dermatological classification algorithms developed without sufficiently diverse training data may generalize poorly across populations. While intentional data collection and annotation offer the best means for improving representation, new computational approaches for generating training data may also aid in mitigating the effects of sampling bias. In this paper, we show that DALLE 2, a large-scale text-to-image diffusion model, can produce photorealistic images of skin disease across skin types. Using the Fitzpatrick 17k dataset as a benchmark, we demonstrate that augmenting training data with DALLE 2-generated synthetic images improves classification of skin disease overall and especially for underrepresented groups.",https://arxiv.org/abs/2211.13352
Pranav Rajpurkar,"Autonomous AI systems in the face of liability, regulations and costs",2023,,31,"Agustina D Saenz, Zach Harned, Oishi Banerjee, Michael D Abràmoff, Pranav Rajpurkar",Agustina D Saenz,Pranav Rajpurkar,5,"Autonomous AI systems in medicine promise improved outcomes but raise concerns about liability, regulation, and costs. With the advent of large-language models, which can understand and generate medical text, the urgency for addressing these concerns increases as they create opportunities for more sophisticated autonomous AI systems. This perspective explores the liability implications for physicians, hospitals, and creators of AI technology, as well as the evolving regulatory landscape and payment models. Physicians may be favored in malpractice cases if they follow rigorously validated AI recommendations. However, AI developers may face liability for failing to adhere to industry-standard best practices during development and implementation. The evolving regulatory landscape, led by the FDA, seeks to ensure transparency, evaluation, and real-world monitoring of AI systems, while payment models such …",https://www.nature.com/articles/s41746-023-00929-1
Pranav Rajpurkar,Contrastive learning of heart and lung sounds for label-efficient diagnosis,2022,Patterns,31,"Pratham N Soni, Siyu Shi, Pranav R Sriram, Andrew Y Ng, Pranav Rajpurkar",Pratham N Soni,Pranav Rajpurkar,5,"Data labeling is often the limiting step in machine learning because it requires time from trained experts. To address the limitation on labeled data, contrastive learning, among other unsupervised learning methods, leverages unlabeled data to learn representations of data. Here, we propose a contrastive learning framework that utilizes metadata for selecting positive and negative pairs when training on unlabeled data. We demonstrate its application in the healthcare domain on heart and lung sound recordings. The increasing availability of heart and lung sound recordings due to adoption of digital stethoscopes lends itself as an opportunity to demonstrate the application of our contrastive learning method. Compared to contrastive learning with augmentations, the contrastive learning model leveraging metadata for pair selection utilizes clinical information associated with lung and heart sound recordings. This …",https://www.cell.com/patterns/fulltext/S2666-3899(21)00267-1?uuid=uuid%3A1cde157d-df32-4a87-9e44-083bd1121e0c
Pranav Rajpurkar,VisualCheXbert: Addressing the Discrepancy Between Radiology Report Labels and Image Labels,2021,"ACM Conference on Health, Inference, and Learning (ACM-CHIL) 2021",31,"Saahil Jain, Akshay Smit, Steven QH Truong, Chanh DT Nguyen, Minh-Thanh Huynh, Mudit Jain, Victoria A Young, Andrew Y Ng, Matthew P Lungren, Pranav Rajpurkar",Saahil Jain,Pranav Rajpurkar,10,"Automatic extraction of medical conditions from free-text radiology reports is critical for supervising computer vision models to interpret medical images. In this work, we show that radiologists labeling reports significantly disagree with radiologists labeling corresponding chest X-ray images, which reduces the quality of report labels as proxies for image labels. We develop and evaluate methods to produce labels from radiology reports that have better agreement with radiologists labeling images. Our best performing method, called VisualCheXbert, uses a biomedically-pretrained BERT model to directly map from a radiology report to the image labels, with a supervisory signal determined by a computer vision model trained to detect medical conditions from chest X-ray images. We find that VisualCheXbert outperforms an approach using an existing radiology report labeler by an average F1 score of 0.14 (95% CI 0.12 …",https://dl.acm.org/doi/abs/10.1145/3450439.3451862
Pranav Rajpurkar,"CheXphoto: 10,000+ photos and transformations of chest X-rays for benchmarking deep learning robustness",2020,Machine Learning for Health,31,"Nick A Phillips, Pranav Rajpurkar, Mark Sabini, Rayan Krishnan, Sharon Zhou, Anuj Pareek, Nguyet Minh Phu, Chris Wang, Mudit Jain, Nguyen Duong Du, Steven QH Truong, Andrew Y Ng, Matthew P Lungren",Nick A Phillips,Matthew P Lungren,13,"Clinical deployment of deep learning algorithms for chest x-ray interpretation requires a solution that can integrate into the vast spectrum of clinical workflows across the world. An appealing approach to scaled deployment is to leverage the ubiquity of smartphones by capturing photos of x-rays to share with clinicians using messaging services like WhatsApp. However, the application of chest x-ray algorithms to photos of chest x-rays requires reliable classification in the presence of artifacts not typically encountered in digital x-rays used to train machine learning models. We introduce CheXphoto, a dataset of smartphone photos and synthetic photographic transformations of chest x-rays sampled from the CheXpert dataset. To generate CheXphoto we (1) automatically and manually captured photos of digital x-rays under different settings, and (2) generated synthetic transformations of digital x-rays targeted to make them look like photos of digital x-rays and x-ray films. We release this dataset as a resource for testing and improving the robustness of deep learning algorithms for automated chest x-ray interpretation on smartphone photos of chest x-rays.",http://proceedings.mlr.press/v136/phillips20a.html
Pranav Rajpurkar,Structured dataset documentation: a datasheet for CheXpert,2021,arXiv preprint arXiv:2105.03020,30,"Christian Garbin, Pranav Rajpurkar, Jeremy Irvin, Matthew P Lungren, Oge Marques",Christian Garbin,Oge Marques,5,"Billions of X-ray images are taken worldwide each year. Machine learning, and deep learning in particular, has shown potential to help radiologists triage and diagnose images. However, deep learning requires large datasets with reliable labels. The CheXpert dataset was created with the participation of board-certified radiologists, resulting in the strong ground truth needed to train deep learning networks. Following the structured format of Datasheets for Datasets, this paper expands on the original CheXpert paper and other sources to show the critical role played by radiologists in the creation of reliable labels and to describe the different aspects of the dataset composition in detail. Such structured documentation intends to increase the awareness in the machine learning and medical communities of the strengths, applications, and evolution of CheXpert, thereby advancing the field of medical image analysis. Another objective of this paper is to put forward this dataset datasheet as an example to the community of how to create detailed and structured descriptions of datasets. We believe that clearly documenting the creation process, the contents, and applications of datasets accelerates the creation of useful and reliable models.",https://arxiv.org/abs/2105.03020
Pranav Rajpurkar,Nasopharyngeal metabolomics and machine learning approach for the diagnosis of influenza,2021,EBioMedicine,28,"Catherine A Hogan, Pranav Rajpurkar, Hari Sowrirajan, Nicholas A Phillips, Anthony T Le, Manhong Wu, Natasha Garamani, Malaya K Sahoo, Mona L Wood, ChunHong Huang, Andrew Y Ng, Justin Mak, Tina M Cowan, Benjamin A Pinsky",Catherine A Hogan,Benjamin A Pinsky,14,"Respiratory virus infections are significant causes of morbidity and mortality, and may induce host metabolite alterations by infecting respiratory epithelial cells. We investigated the use of liquid chromatography quadrupole time-of-flight mass spectrometry (LC/Q-TOF) combined with machine learning for the diagnosis of influenza infection.We analyzed nasopharyngeal swab samples by LC/Q-TOF to identify distinct metabolic signatures for diagnosis of acute illness. Machine learning models were performed for classification, followed by Shapley additive explanation (SHAP) analysis to analyze feature importance and for biomarker discovery.A total of 236 samples were tested in the discovery phase by LC/Q-TOF, including 118 positive samples (40 influenza A 2009 H1N1, 39 influenza H3 and 39 influenza B) as well as 118 age and sex-matched negative controls with acute respiratory …",https://www.thelancet.com/journals/ebiom/article/PIIS2352-3964(21)00339-X/fulltext
Pranav Rajpurkar,DLBCL-Morph: Morphological features computed using deep learning for an annotated digital DLBCL image set,2021,Scientific Data,27,"Damir Vrabac, Akshay Smit, Rebecca Rojansky, Yasodha Natkunam, Ranjana H Advani, Andrew Y Ng, Sebastian Fernandez-Pol, Pranav Rajpurkar",Damir Vrabac,Pranav Rajpurkar,8,"Diffuse Large B-Cell Lymphoma (DLBCL) is the most common non-Hodgkin lymphoma. Though histologically DLBCL shows varying morphologies, no morphologic features have been consistently demonstrated to correlate with prognosis. We present a morphologic analysis of histology sections from 209 DLBCL cases with associated clinical and cytogenetic data. Duplicate tissue core sections were arranged in tissue microarrays (TMAs), and replicate sections were stained with H&E and immunohistochemical stains for CD10, BCL6, MUM1, BCL2, and MYC. The TMAs are accompanied by pathologist-annotated regions-of-interest (ROIs) that identify areas of tissue representative of DLBCL. We used a deep learning model to segment all tumor nuclei in the ROIs, and computed several geometric features for each segmented nucleus. We fit a Cox proportional hazards model to demonstrate the utility of these …",https://www.nature.com/articles/s41597-021-00915-w
Pranav Rajpurkar,The need for medical artificial intelligence that incorporates prior images,2022,,25,"Julián N Acosta, Guido J Falcone, Pranav Rajpurkar",Julián N Acosta,Pranav Rajpurkar,3,"The use of artificial intelligence (AI) has grown dramatically in the past few                     years in the United States and worldwide, with more than 300 AI-enabled devices                     approved by the U.S. Food and Drug Administration (FDA). Most of these                     AI-enabled applications focus on helping radiologists with detection, triage,                     and prioritization of tasks by using data from a single point, but clinical                     practice often encompasses a dynamic scenario wherein physicians make decisions                     on the basis of longitudinal information. Unfortunately, benchmark data sets                     incorporating clinical and radiologic data from several points are scarce, and,                     therefore, the machine learning community has not focused on developing methods                     and architectures suitable for these tasks. Current AI algorithms are not suited                     to tackle key image interpretation …",https://pubs.rsna.org/doi/abs/10.1148/radiol.212830
Pranav Rajpurkar,Implications of race adjustment in lung-function equations,2024,The New England journal of medicine,24,"James A Diao, Yixuan He, Rohan Khazanchi, MJ Nguemeni Tiako, Jonathan I Witonsky, Emma Pierson, Pranav Rajpurkar, Jennifer R Elhawary, Luke Melas-Kyriazi, Albert Yen, Alicia R Martin, Sean Levy, Chirag J Patel, Maha Farhat, Luisa N Borrell, Michael H Cho, Edwin K Silverman, Esteban G Burchard, Arjun K Manrai",James A Diao,Arjun K Manrai,19,"BACKGROUND Adjustment for race is discouraged in lung-function testing, but the implications of adopting race-neutral equations have not been comprehensively quantified. METHODS We obtained longitudinal data from 369,077 participants in the National Health and Nutrition Examination Survey, UK Biobank, the Multi-Ethnic Study of Atherosclerosis, and the Organ Procurement and Transplantation Network. Using these data, we compared the race-based 2012 Global Lung Function Initiative (GLI-2012) equations with race-neutral equations introduced in 2022 (GLI-Global). Evaluated outcomes included national projections of clinical, occupational, and financial reclassifications; individual lung-allocation scores for transplantation priority; and concordance statistics (C statistics) for clinical prediction tasks. RESULTS Among the 249 million persons in the United States between 6 and 79 years of age who are able to produce high-quality spirometric results, the use of GLI-Global equations may …",https://pmc.ncbi.nlm.nih.gov/articles/PMC11305821/
Pranav Rajpurkar,"Machine Vision, Medical AI, and Malpractice",2019,"Zach Harned, Matthew P. Lungren & Pranav Rajpurkar, Comment, Machine Vision, Medical AI, and Malpractice, Harv. JL & Tech. Dig.(2019)",22,"Zach Harned, Matthew P Lungren, Pranav Rajpurkar",Zach Harned,Pranav Rajpurkar,3,"The introduction of novel medical technology into clinical practice gives rise to novel questions of legal liability when something goes wrong. The complexity of the technology is often paralleled by the complexity of the liability analysis, which is why questions of malpractice involving medical artificial intelligence are so vexing. There are myriad medical use cases for artificial intelligence (AI), but some of the most promising applications involve the use of machine vision for imaging diagnostics.",https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3442249
Pranav Rajpurkar,Predicting patient decompensation from continuous physiologic monitoring in the emergency department,2023,npj Digital Medicine,21,"Sameer Sundrani, Julie Chen, Boyang Tom Jin, Zahra Shakeri Hossein Abad, Pranav Rajpurkar, David Kim",Sameer Sundrani,David Kim,6,"Anticipation of clinical decompensation is essential for effective emergency and critical care. In this study, we develop a multimodal machine learning approach to predict the onset of new vital sign abnormalities (tachycardia, hypotension, hypoxia) in ED patients with normal initial vital signs. Our method combines standard triage data (vital signs, demographics, chief complaint) with features derived from a brief period of continuous physiologic monitoring, extracted via both conventional signal processing and transformer-based deep learning on ECG and PPG waveforms. We study 19,847 adult ED visits, divided into training (75%), validation (12.5%), and a chronologically sequential held-out test set (12.5%). The best-performing models use a combination of engineered and transformer-derived features, predicting in a 90-minute window new tachycardia with AUROC of 0.836 (95% CI, 0.800-0.870), new …",https://www.nature.com/articles/s41746-023-00803-0
Pranav Rajpurkar,Q-Pain: A Question Answering Dataset to Measure Social Bias in Pain Management,2021,Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 1),21,"Cécile Logé, Emily Ross, David Yaw Amoah Dadey, Saahil Jain, Adriel Saporta, Andrew Y Ng, Pranav Rajpurkar",Cécile Logé,Pranav Rajpurkar,7,"Recent advances in Natural Language Processing (NLP), and specifically automated Question Answering (QA) systems, have demonstrated both impressive linguistic fluency and a pernicious tendency to reflect social biases. In this study, we introduce Q-Pain, a dataset for assessing bias in medical QA in the context of pain management, one of the most challenging forms of clinical decision-making. Along with the dataset, we propose a new, rigorous framework, including a sample experimental design, to measure the potential biases present when making treatment decisions. We demonstrate its use by assessing two reference Question-Answering systems, GPT-2 and GPT-3, and find statistically significant differences in treatment between intersectional race-gender subgroups, thus reaffirming the risks posed by AI in medical settings, and the need for datasets like ours to ensure safety before medical AI applications are deployed.",https://arxiv.org/abs/2108.01764
Pranav Rajpurkar,BenchMD: A Benchmark for Modality-Agnostic Learning on Medical Images and Sensors,2023,arXiv preprint arXiv:2304.08486,20,"Kathryn Wantlin, Chenwei Wu, Shih-Cheng Huang, Oishi Banerjee, Farah Dadabhoy, Veeral Vipin Mehta, Ryan Wonhee Han, Fang Cao, Raja R Narayan, Errol Colak, Adewole Adamson, Laura Heacock, Geoffrey H Tison, Alex Tamkin, Pranav Rajpurkar",Kathryn Wantlin,Pranav Rajpurkar,15,,https://scholar.google.com/scholar?cluster=9221689236952891694&hl=en&oi=scholarr
Pranav Rajpurkar,A framework for integrating artificial intelligence for clinical care with continuous therapeutic monitoring,2023,,19,"Emma Chen, Shvetank Prakash, Vijay Janapa Reddi, David Kim, Pranav Rajpurkar",Emma Chen,Pranav Rajpurkar,5,"The complex relationships between continuously monitored health signals and therapeutic regimens can be modelled via machine learning. However, the clinical implementation of the models will require changes to clinical workflows. Here we outline ClinAIOps (‘clinical artificial-intelligence operations’), a framework that integrates continuous therapeutic monitoring and the development of artificial intelligence (AI) for clinical care. ClinAIOps leverages three feedback loops to enable the patient to make treatment adjustments using AI outputs, the clinician to oversee patient progress with AI assistance, and the AI developer to receive continuous feedback from both the patient and the clinician. We lay out the central challenges and opportunities in the deployment of ClinAIOps by means of examples of its application in the management of blood pressure, diabetes and Parkinson’s disease. By enabling more frequent …",https://www.nature.com/articles/s41551-023-01115-0
Pranav Rajpurkar,Deep Learning for the Digital Pathologic Diagnosis of Cholangiocarcinoma and Hepatocellular Carcinoma: Evaluating the Impact of a Web-based Diagnostic Assistant,2019,Machine Learning for Health (ML4H) at NeurIPS 2019 - Extended Abstract,18,"Bora Uyumazturk, Amirhossein Kiani, Pranav Rajpurkar, Alex Wang, Robyn L Ball, Rebecca Gao, Yifan Yu, Erik Jones, Curtis P Langlotz, Brock Martin, Gerald J Berry, Michael G Ozawa, Florette K Hazard, Ryanne A Brown, Simon B Chen, Mona Wood, Libby S Allard, Lourdes Ylagan, Andrew Y Ng, Jeanne Shen",Bora Uyumazturk,Jeanne Shen,20,"While artificial intelligence (AI) algorithms continue to rival human performance on a variety of clinical tasks, the question of how best to incorporate these algorithms into clinical workflows remains relatively unexplored. We investigated how AI can affect pathologist performance on the task of differentiating between two subtypes of primary liver cancer, hepatocellular carcinoma (HCC) and cholangiocarcinoma (CC). We developed an AI diagnostic assistant using a deep learning model and evaluated its effect on the diagnostic performance of eleven pathologists with varying levels of expertise. Our deep learning model achieved an accuracy of 0.885 on an internal validation set of 26 slides and an accuracy of 0.842 on an independent test set of 80 slides. Despite having high accuracy on a hold out test set, the diagnostic assistant did not significantly improve performance across pathologists (p-value: 0.184, OR: 1.287 (95% CI 0.886, 1.871)). Model correctness was observed to significantly bias the pathologist decisions. When the model was correct, assistance significantly improved accuracy across all pathologist experience levels and for all case difficulty levels (p-value: < 0.001, OR: 4.289 (95% CI 2.360, 7.794)). When the model was incorrect, assistance significantly decreased accuracy across all 11 pathologists and for all case difficulty levels (p-value < 0.001, OR: 0.253 (95% CI 0.126, 0.507)). Our results highlight the challenges of translating AI models to the clinical setting, especially for difficult subspecialty tasks such as tumor classification. In particular, they suggest that incorrect model predictions could strongly bias an expert's diagnosis …",https://arxiv.org/abs/1911.07372
Pranav Rajpurkar,CheXternal: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays and External Clinical Settings,2021,"ACM Conference on Health, Inference, and Learning (ACM-CHIL) 2021",17,"Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Andrew Y Ng, Matthew P Lungren",Pranav Rajpurkar,Matthew P Lungren,5,"Recent advances in training deep learning models have demonstrated the potential to provide accurate chest X-ray interpretation and increase access to radiology expertise. However, poor generalization due to data distribution shifts in clinical settings is a key barrier to implementation. In this study, we measured the diagnostic performance for 8 different chest X-ray models when applied to (1) smartphone photos of chest X-rays and (2) external datasets without any finetuning. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to test datasets without further tuning. We found that (1) on photos of chest X-rays, all 8 models experienced a statistically significant drop in task performance, but only 3 performed significantly worse than radiologists on average, and (2) on the external set, none of the models performed statistically significantly worse than radiologists, and …",https://dl.acm.org/doi/abs/10.1145/3450439.3451876
Pranav Rajpurkar,Style-Aware Radiology Report Generation with RadGraph and Few-Shot Prompting,2023,arXiv preprint arXiv:2310.17811,16,"Benjamin Yan, Ruochen Liu, David E Kuo, Subathra Adithan, Eduardo Pontes Reis, Stephen Kwak, Vasantha Kumar Venugopal, Chloe P O'Connell, Agustina Saenz, Pranav Rajpurkar, Michael Moor",Benjamin Yan,Michael Moor,11,"Automatically generated reports from medical images promise to improve the workflow of radiologists. Existing methods consider an image-to-report modeling task by directly generating a fully-fledged report from an image. However, this conflates the content of the report (e.g., findings and their attributes) with its style (e.g., format and choice of words), which can lead to clinically inaccurate reports. To address this, we propose a two-step approach for radiology report generation. First, we extract the content from an image; then, we verbalize the extracted content into a report that matches the style of a specific radiologist. For this, we leverage RadGraph -- a graph representation of reports -- together with large language models (LLMs). In our quantitative evaluations, we find that our approach leads to beneficial performance. Our human evaluation with clinical raters highlights that the AI-generated reports are indistinguishably tailored to the style of individual radiologist despite leveraging only a few examples as context.",https://arxiv.org/abs/2310.17811
Pranav Rajpurkar,Augmenting medical image classifiers with synthetic data from latent diffusion models,2023,arXiv preprint arXiv:2308.12453,16,"Luke W Sagers, James A Diao, Luke Melas-Kyriazi, Matthew Groh, Pranav Rajpurkar, Adewole S Adamson, Veronica Rotemberg, Roxana Daneshjou, Arjun K Manrai",Luke W Sagers,Arjun K Manrai,9,"While hundreds of artificial intelligence (AI) algorithms are now approved or cleared by the US Food and Drugs Administration (FDA), many studies have shown inconsistent generalization or latent bias, particularly for underrepresented populations. Some have proposed that generative AI could reduce the need for real data, but its utility in model development remains unclear. Skin disease serves as a useful case study in synthetic image generation due to the diversity of disease appearance, particularly across the protected attribute of skin tone. Here we show that latent diffusion models can scalably generate images of skin disease and that augmenting model training with these data improves performance in data-limited settings. These performance gains saturate at synthetic-to-real image ratios above 10:1 and are substantially smaller than the gains obtained from adding real images. As part of our analysis, we generate and analyze a new dataset of 458,920 synthetic images produced using several generation strategies. Our results suggest that synthetic data could serve as a force-multiplier for model development, but the collection of diverse real-world data remains the most important step to improve medical AI algorithms.",https://arxiv.org/abs/2308.12453
Pranav Rajpurkar,Randomized Controlled Trials Evaluating AI in Clinical Practice: A Scoping Evaluation,2023,medRxiv,16,"Ryan Han, Julian N Acosta, Zahra Shakeri, John Ioannidis, Eric Topol, Pranav Rajpurkar",Ryan Han,Pranav Rajpurkar,6,"Artificial intelligence (AI) has emerged as a promising tool in healthcare, with numerous studies indicating its potential to perform as well or better than clinicians. However, a considerable portion of these AI models have only been tested retrospectively, raising concerns about their true effectiveness and potential risks in real-world clinical settings.We conducted a systematic search for randomized controlled trials (RCTs) involving AI algorithms used in various clinical practice fields and locations, published between January 1, 2018, and August 18, 2023. Our study included 84 trials and focused specifically on evaluating intervention characteristics, study endpoints, and trial outcomes, including the potential of AI to improve care management, patient behavior and symptoms, and clinical decision-making.Our analysis revealed that 82·1% (69/84) of trials reported positive results for their primary endpoint, highlighting AI’s potential to enhance various aspects of healthcare. Trials predominantly evaluated deep learning systems for medical imaging and were conducted in single-center settings. The US and China had the most trials, with gastroenterology being the most common field of study. However, we also identified areas requiring further research, such as multi-center trials and diverse outcome measures, to better understand AI’s true impact and limitations in healthcare.The existing landscape of RCTs on AI in clinical practice demonstrates an expanding interest in applying AI across a range of fields and locations. While most trials report positive outcomes, more comprehensive research, including multi …",https://www.medrxiv.org/content/10.1101/2023.09.12.23295381.abstract
Pranav Rajpurkar,A Generalist Learner for Multifaceted Medical Image Interpretation,2024,arXiv preprint arXiv:2405.07988,15,"Hong-Yu Zhou, Subathra Adithan, Julián Nicolás Acosta, Eric J Topol, Pranav Rajpurkar",Hong-Yu Zhou,Pranav Rajpurkar,5,"Current medical artificial intelligence systems are often limited to narrow applications, hindering their widespread adoption in clinical practice. To address this limitation, we propose MedVersa, a generalist learner that enables flexible learning and tasking for medical image interpretation. By leveraging a large language model as a learnable orchestrator, MedVersa can learn from both visual and linguistic supervision, support multimodal inputs, and perform real-time task specification. This versatility allows MedVersa to adapt to various clinical scenarios and perform multifaceted medical image analysis. We introduce MedInterp, the largest multimodal dataset to date for medical image interpretation, consisting of over 13 million annotated instances spanning 11 tasks across 3 modalities, to support the development of MedVersa. Our experiments demonstrate that MedVersa achieves state-of-the-art performance in 9 tasks, sometimes outperforming specialist counterparts by over 10%. MedVersa is the first to showcase the viability of multimodal generative medical AI in implementing multimodal outputs, inputs, and dynamic task specification, highlighting its potential as a multifunctional system for comprehensive medical image analysis. This generalist approach to medical image interpretation paves the way for more adaptable and efficient AI-assisted clinical decision-making.",https://arxiv.org/abs/2405.07988
Pranav Rajpurkar,Development of an artificial intelligence-derived histologic signature associated with adjuvant gemcitabine treatment outcomes in pancreatic cancer,2023,Cell Reports Medicine,15,"Vivek Nimgaonkar, Viswesh Krishna, Vrishab Krishna, Ekin Tiu, Anirudh Joshi, Damir Vrabac, Hriday Bhambhvani, Katelyn Smith, Julia S Johansen, Shalini Makawita, Benjamin Musher, Arnav Mehta, Andrew Hendifar, Zev Wainberg, Davendra Sohal, Christos Fountzilas, Aatur Singhi, Pranav Rajpurkar, Eric A Collisson",Vivek Nimgaonkar,Eric A Collisson,19,"Pancreatic ductal adenocarcinoma (PDAC) has been left behind in the evolution of personalized medicine. Predictive markers of response to therapy are lacking in PDAC despite various histological and transcriptional classification schemes. We report an artificial intelligence (AI) approach to histologic feature examination that extracts a signature predictive of disease-specific survival (DSS) in patients with PDAC receiving adjuvant gemcitabine. We demonstrate that this AI-generated histologic signature is associated with outcomes following adjuvant gemcitabine, while three previously developed transcriptomic classification systems are not (n = 47). We externally validate this signature in an independent cohort of patients treated with adjuvant gemcitabine (n = 46). Finally, we demonstrate that the signature does not stratify survival outcomes in a third cohort of untreated patients (n = 161), suggesting that the …",https://www.cell.com/cell-reports-medicine/fulltext/S2666-3791(23)00123-4
Pranav Rajpurkar,Improving Hospital Readmission Prediction using Individualized Utility Analysis,2021,Journal of Biomedical Informatics,15,"Michael Ko, Emma Chen, Ashwin Agrawal, Pranav Rajpurkar, Anand Avati, Andrew Ng, Sanjay Basu, Nigam H Shah",Michael Ko,Nigam H Shah,8,"Objective Machine learning (ML) models for allocating readmission-mitigating interventions are typically selected according to their discriminative ability, which may not necessarily translate into utility in allocation of resources. Our objective was to determine whether ML models for allocating readmission-mitigating interventions have different usefulness based on their overall utility and discriminative ability. Materials and methods We conducted a retrospective utility analysis of ML models using claims data acquired from the Optum Clinformatics Data Mart, including 513,495 commercially-insured inpatients (mean [SD] age 69 [19] years; 294,895 [57%] Female) over the period January 2016 through January 2017 from all 50 states with mean 90 day cost of $11,552. Utility analysis estimates the cost, in dollars, of allocating interventions for lowering readmission risk based on the reduction in the 90-day cost. Results …",https://www.sciencedirect.com/science/article/pii/S1532046421001544
Pranav Rajpurkar,CheXED: Comparison of a Deep Learning Model to a Clinical Decision Support System for Pneumonia in the Emergency Department,2022,Journal of thoracic imaging,14,"Jeremy A Irvin, Anuj Pareek, Jin Long, Pranav Rajpurkar, David Ken-Ming Eng, Nishith Khandwala, Peter J Haug, Al Jephson, Karen E Conner, Benjamin H Gordon, Fernando Rodriguez, Andrew Y Ng, Matthew P Lungren, Nathan C Dean",Jeremy A Irvin,Nathan C Dean,14,"Purpose:Patients with pneumonia often present to the emergency department (ED) and require prompt diagnosis and treatment. Clinical decision support systems for the diagnosis and management of pneumonia are commonly utilized in EDs to improve patient care. The purpose of this study is to investigate whether a deep learning model for detecting radiographic pneumonia and pleural effusions can improve functionality of a clinical decision support system (CDSS) for pneumonia management (ePNa) operating in 20 EDs.Materials and Methods:In this retrospective cohort study, a dataset of 7434 prior chest radiographic studies from 6551 ED patients was used to develop and validate a deep learning model to identify radiographic pneumonia, pleural effusions, and evidence of multilobar pneumonia. Model performance was evaluated against 3 radiologists’ adjudicated interpretation and compared with …",https://journals.lww.com/thoracicimaging/fulltext/2022/05000/chexed__comparison_of_a_deep_learning_model_to_a.5.aspx
Pranav Rajpurkar,Chexseg: Combining expert annotations with dnn-generated saliency maps for x-ray segmentation,2021,Medical Imaging with Deep Learning,14,"Soham Uday Gadgil, Mark Endo, Emily Wen, Andrew Y Ng, Pranav Rajpurkar",Soham Uday Gadgil,Pranav Rajpurkar,5,"Medical image segmentation models are typically supervised by expert annotations at the pixel-level, which can be expensive to acquire. In this work, we propose a method that combines the high quality of pixel-level expert annotations with the scale of coarse DNN-generated saliency maps for training multi-label semantic segmentation models. We demonstrate the application of our semi-supervised method, which we call CheXseg, on multi-label chest X-ray interpretation. We find that CheXseg improves upon the performance (mIoU) of fully-supervised methods that use only pixel-level expert annotations by 9.7% and weakly-supervised methods that use only DNN-generated saliency maps by 73.1%. Our best method is able to match radiologist agreement on three out of ten pathologies and reduces the overall performance gap by 57.2% as compared to weakly-supervised methods.",https://proceedings.mlr.press/v143/gadgil21a.html
Pranav Rajpurkar,MedSelect: Selective Labeling for Medical Image Classification Using Meta-Learning,2022,International Conference on Medical Imaging with Deep Learning,13,"Damir Vrabac, Akshay Smit, Yujie He, Andrew Y Ng, Andrew L Beam, Pranav Rajpurkar",Damir Vrabac,Pranav Rajpurkar,6,"We propose a selective labeling method using meta-learning for medical image interpretation in the setting of limited labeling resources. Our method, MedSelect, consists of a trainable deep learning model that uses image embeddings to select images to label, and a non-parametric classifier that uses cosine similarity to classify unseen images. We demonstrate that MedSelect learns an effective selection strategy outperforming baseline selection strategies across seen and unseen medical conditions for chest X-ray interpretation. We also perform an analysis of the selections performed by MedSelect comparing the distribution of latent embeddings and clinical features, and find significant differences compared to the strongest performing baseline. Our method is broadly applicable across medical imaging tasks where labels are expensive to acquire.",https://proceedings.mlr.press/v172/vrabac22a.html
Pranav Rajpurkar,The MAIDA initiative: establishing a framework for global medical-imaging data sharing,2024,The Lancet Digital Health,12,"Agustina Saenz, Emma Chen, Henrik Marklund, Pranav Rajpurkar",Agustina Saenz,Pranav Rajpurkar,4,"A central question in developing artificial intelligence (AI) for the interpretation of medical images is whether these algorithms will work safely and effectively across diverse patient populations and clinical settings. 1 Public datasets are the basis for training and validating AI models, making them essential for the rigorous assessment of performance and reliability that is required by regulatory bodies such as the US Food and Drug Administration. 2, 3 However, current public datasets seldom have the diversity required to adequately evaluate algorithmic generalisability. 4 More comprehensive and varied datasets would improve the assessment of AI models and their ability to generalise across patient demographics, clinical environments, imaging equipment, and geographical regions. The scarcity of diverse public data also impedes optimal AI deployment strategies for specific medical settings. For example, there is …",https://www.thelancet.com/journals/landig/article/PIIS2589-7500(23)00222-4/fulltext
Pranav Rajpurkar,Radiology SWARM: novel crowdsourcing tool for CheXNet algorithm validation,2018,SiiM Conference on Machine Intelligence in Medical Imaging,12,"Safwan Halabi, Matthew Lungren, Louis Rosenberg, David Baltaxe, Bhavik Patel, Jayne Seekins, Francis Blakenberg, David Mong, Timothy Amrhein, Pranav Raipurkar, David Larson, Jeremy Irvin, Robyn Ball, Curtis P Langlotz, Gregg Willcox",Safwan Halabi,Gregg Willcox,15,"Researchers at Stanford University School of Medicine and Unanimous AI conducted a study in which a “swarm” of radiologists (ie a group connected by Swarm AI algorithms) reviewed a set of 50 chest x-rays and for each predicted the likelihood that the patient has pneumonia. The predictive accuracy of the Swarm AI system was then compared to that of the machine learning program CheXNet, which has been shown in prior studies to significantly outperform individual human radiologists in pneumonia screening tasks. Thus, while previous research shows that a software-only solution like CheXNet can outperform individual radiologists, the current study explores if small groups of radiologists, when networked together as a real-time collaborative system moderated by AI algorithms, can amplify their collective accuracy to levels that rival or exceed the current state-of-the-art in purely algorithmic diagnosis.",https://scholar.google.com/scholar?cluster=15208820954666105100&hl=en&oi=scholarr
Pranav Rajpurkar,RadGraph2: Modeling Disease Progression in Radiology Reports via Hierarchical Information Extraction,2023,Machine Learning for Healthcare Conference,10,"Sameer Khanna, Adam Dejl, Kibo Yoon, Steven QH Truong, Hanh Duong, Agustina Saenz, Pranav Rajpurkar",Sameer Khanna,Pranav Rajpurkar,7,"We present RadGraph2, a novel dataset for extracting information from radiology reports that focuses on capturing changes in disease state and device placement over time. We introduce a hierarchical schema that organizes entities based on their relationships and show that using this hierarchy during training improves the performance of an information extraction model. Specifically, we propose a modification to the DyGIE++ framework, resulting in our model HGIE, which outperforms previous models in entity and relation extraction tasks. We demonstrate that RadGraph2 enables models to capture a wider variety of findings and perform better at relation extraction compared to those trained on the original RadGraph dataset. Our work provides the foundation for developing automated systems that can track disease progression over time and develop information extraction models that leverage the natural hierarchy of labels in the medical domain.",https://proceedings.mlr.press/v219/khanna23a.html
Pranav Rajpurkar,Transfer learning enables prediction of myocardial injury from continuous single-lead electrocardiography,2022,Journal of the American Medical Informatics Association,10,"Boyang Tom Jin, Raj Palleti, Siyu Shi, Andrew Y Ng, James V Quinn, Pranav Rajpurkar, David Kim",Boyang Tom Jin,David Kim,7,"Chest pain is common, and current risk-stratification methods, requiring 12-lead electrocardiograms (ECGs) and serial biomarker assays, are static and restricted to highly resourced settings. Our objective was to predict myocardial injury using continuous single-lead ECG waveforms similar to those obtained from wearable devices and to evaluate the potential of transfer learning from labeled 12-lead ECGs to improve these predictions.We studied 10 874 Emergency Department (ED) patients who received continuous ECG monitoring and troponin testing from 2020 to 2021. We defined myocardial injury as newly elevated troponin in patients with chest pain or shortness of breath. We developed deep learning models of myocardial injury using continuous lead II ECG from bedside monitors as well as conventional 12-lead ECGs from triage. We pretrained …",https://academic.oup.com/jamia/article-abstract/29/11/1908/6673193
Pranav Rajpurkar,Effect of Radiology Report Labeler Quality on Deep Learning Models for Chest X-Ray Interpretation,2021,NeurIPS Data-Centric AI Workshop,10,"Saahil Jain, Akshay Smit, Andrew Y Ng, Pranav Rajpurkar",Saahil Jain,Pranav Rajpurkar,4,"Although deep learning models for chest X-ray interpretation are commonly trained on labels generated by automatic radiology report labelers, the impact of improvements in report labeling on the performance of chest X-ray classification models has not been systematically investigated. We first compare the CheXpert, CheXbert, and VisualCheXbert labelers on the task of extracting accurate chest X-ray image labels from radiology reports, reporting that the VisualCheXbert labeler outperforms the CheXpert and CheXbert labelers. Next, after training image classification models using labels generated from the different radiology report labelers on one of the largest datasets of chest X-rays, we show that an image classification model trained on labels from the VisualCheXbert labeler outperforms image classification models trained on labels from the CheXpert and CheXbert labelers. Our work suggests that recent improvements in radiology report labeling can translate to the development of higher performing chest X-ray classification models.",https://arxiv.org/abs/2104.00793
Pranav Rajpurkar,A Supervised Approach To Musical Chord Recognition,2014,Stanford Undergraduate Research Journal '14,9,"Pranav Rajpurkar, Brad Girardeau, Takatoki Migimatsu",Pranav Rajpurkar,Takatoki Migimatsu,3,"I. INTRODUCTION There is significant value in an automated tool to determine chords from audio. Knowing the progressions of chords underlying the melodies is an essential part of understanding, playing, and building on the music. To a curious learner of music, such a tool creates the opportunity to play a new pop song without meticulously hand-labelled chord tags. Equally useful to a learner is being able to receive feedback concerning the accuracy with which a chord was played, making such a system a good automated feedback tool, capable of being plugged into an online music course. To a song writer, the system is useful for exploring chords supporting the melodic content of a song.Furthermore, the use of such a system extends into other machine learning tasks. The tasks of identifying a song from its waveform data, and of classifying its genre can be linked to finding the chord progressions underlying its harmonic content. Hand-labelling chord names and marking chord changes in a song takes significant manual time and effort. An automated tool for this process saves time and allows for the development of new musical tools and research. There has been progress in chord recognition research, including some real-time systems with promising results [1, 2]. However, these have not leveraged the web to make a chordrecognition system accessible online. We build a real-time online chord recognition system that makes use of modern HTML5 capabilities such as the WebAudio API and WebSockets and detail the offline training strategies and online challenges posed by the novel adaptation.",https://ojs.stanford.edu/ojs/index.php/surj/issue/download/surj-2015/41#page=36
Pranav Rajpurkar,Deep-Learning Artificial Intelligence Model for Automated Detection of Cervical Spine Fracture on Computed Tomography (CT) Imaging,2019,JOURNAL OF NEUROSURGERY,8,"Stewart B Dunsker, Michael Zhang, Lily Kim, Robin Cheong, Ben Cohen-Wang, Katie Shpanskaya, Jessica Wetstone, Nidhi Manoj, Pranav Rajpurkar, Kristen Yeom",Stewart B Dunsker,Kristen Yeom,10,,https://scholar.google.com/scholar?cluster=17135344327891502569&hl=en&oi=scholarr
Pranav Rajpurkar,Multimodal Clinical Benchmark for Emergency Care (MC-BEC): A Comprehensive Benchmark for Evaluating Foundation Models in Emergency Medicine,2023,Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track,7,"Emma Chen, Aman Kansal, Julie Chen, Boyang Tom Jin, Julia Rachel Reisler, David A Kim, Pranav Rajpurkar",Emma Chen,Pranav Rajpurkar,7,"We propose the Multimodal Clinical Benchmark for Emergency Care (MC-BEC), a comprehensive benchmark for evaluating foundation models in Emergency Medicine using a dataset of 100K+ continuously monitored Emergency Department visits from 2020-2022. MC-BEC focuses on clinically relevant prediction tasks at timescales from minutes to days, including predicting patient decompensation, disposition, and emergency department (ED) revisit, and includes a standardized evaluation framework with train-test splits and evaluation metrics. The multimodal dataset includes a wide range of detailed clinical data, including triage information, prior diagnoses and medications, continuously measured vital signs, electrocardiogram and photoplethysmograph waveforms, orders placed and medications administered throughout the visit, free-text reports of imaging studies, and information on ED diagnosis, disposition, and subsequent revisits. We provide performance baselines for each prediction task to enable the evaluation of multimodal, multitask models. We believe that MC-BEC will encourage researchers to develop more effective, generalizable, and accessible foundation models for multimodal clinical data.",https://proceedings.neurips.cc/paper_files/paper/2023/hash/8f61049e8fe5b9ed714860b951066f1e-Abstract-Datasets_and_Benchmarks.html
Pranav Rajpurkar,Improving Zero-Shot Detection of Low Prevalence Chest Pathologies using Domain Pre-trained Language Models,2023,"Medical Imaging with Deep Learning, short paper track",7,"Aakash Mishra, Rajat Mittal, Christy Jestin, Kostas Tingos, Pranav Rajpurkar",Aakash Mishra,Pranav Rajpurkar,5,"Recent advances in zero-shot learning have enabled the use of paired image-text data to replace structured labels, replacing the need for expert annotated datasets. Models such as CLIP-based CheXzero utilize these advancements in the domain of chest X-ray interpretation. We hypothesize that domain pre-trained models such as CXR-BERT, BlueBERT, and ClinicalBERT offer the potential to improve the performance of CLIP-like models with specific domain knowledge by replacing BERT weights at the cost of breaking the original model's alignment. We evaluate the performance of zero-shot classification models with domain-specific pre-training for detecting low-prevalence pathologies. Even though replacing the weights of the original CLIP-BERT degrades model performance on commonly found pathologies, we show that pre-trained text towers perform exceptionally better on low-prevalence diseases. This motivates future ensemble models with a combination of differently trained language models for maximal performance.",https://arxiv.org/abs/2306.08000
Pranav Rajpurkar,Testing the Limits of Language Models: A Conversational Framework for Medical AI Assessment,2023,medRxiv,7,"Shreya Johri, Jaehwan Jeong, Benjamin A Tran, Daniel I Schlessinger, Shannon Wongvibulsin, Zhuo Ran Cai, Roxana Daneshjou, Pranav Rajpurkar",Shreya Johri,Pranav Rajpurkar,8,"Large Language Models (LLMs) show promise for medical diagnosis, but traditional evaluations using static exam questions overlook the complexity of real-world clinical dialogues. We introduce a multi-agent conversational framework where doctor-AI and patient-AI agents interact to diagnose medical conditions, evaluated by a grader-AI agent and medical experts. We assessed the diagnostic accuracy of GPT-4 and GPT-3.5, in conversational versus static settings using 140 cases focusing on skin diseases. Our study revealed a decline in diagnostic accuracy, unmasking key limitations in LLMs’ ability to integrate details from conversational interactions to improve diagnostic performance. We introduced Conversational Summarization, a technique that enhanced performance, and expert review identified deficiencies compared to human dermatologists in comprehensive history gathering, appropriate use of terminology, and reliability. Our findings advocate for nuanced, rigorous evaluation of LLMs before clinical integration, and our framework represents a significant advancement toward responsible testing methodologies in medicine.",https://www.medrxiv.org/content/10.1101/2023.09.12.23295399v1.full?utm_source=pocket_reader
Pranav Rajpurkar,A proof of concept for a deep learning system that can aid embryologists in predicting blastocyst survival after thaw,2022,Scientific Reports,7,"Philip Marsh, Dahlia Radif, Pranav Rajpurkar, Zihan Wang, Eduardo Hariton, Salustiano Ribeiro, Rhodel Simbulan, Amy Kaing, Wingka Lin, Anthony Rajah, Fleurdeliza Rabara, Matthew Lungren, Utkan Demirci, Andrew Ng, Mitchell Rosen",Philip Marsh,Mitchell Rosen,15,"The ability to understand whether embryos survive the thaw process is crucial to transferring competent embryos that can lead to pregnancy. The objective of this study was to develop a proof of concept deep learning model capable of assisting embryologist assessment of survival of thawed blastocysts prior to embryo transfer. A deep learning model was developed using 652 labeled time-lapse videos of freeze–thaw blastocysts. The model was evaluated against and along embryologists on a test set of 99 freeze–thaw blastocysts, using images obtained at 0.5 h increments from 0 to 3 h post-thaw. The model achieved AUCs of 0.869 (95% CI 0.789, 0.934) and 0.807 (95% CI 0.717, 0.886) and the embryologists achieved average AUCs of 0.829 (95% CI 0.747, 0.896) and 0.850 (95% CI 0.773, 0.908) at 2 h and 3 h, respectively. Combining embryologist predictions with model predictions resulted in a significant …",https://www.nature.com/articles/s41598-022-25062-z
Pranav Rajpurkar,Deep Learning-Based Sparse Whole-Slide Image Analysis for the Diagnosis of Gastric Intestinal Metaplasia,2022,arXiv preprint arXiv:2201.01449,7,"Jon Braatz, Pranav Rajpurkar, Stephanie Zhang, Andrew Y Ng, Jeanne Shen",Jon Braatz,Jeanne Shen,5,"In recent years, deep learning has successfully been applied to automate a wide variety of tasks in diagnostic histopathology. However, fast and reliable localization of small-scale regions-of-interest (ROI) has remained a key challenge, as discriminative morphologic features often occupy only a small fraction of a gigapixel-scale whole-slide image (WSI). In this paper, we propose a sparse WSI analysis method for the rapid identification of high-power ROI for WSI-level classification. We develop an evaluation framework inspired by the early classification literature, in order to quantify the tradeoff between diagnostic performance and inference time for sparse analytic approaches. We test our method on a common but time-consuming task in pathology - that of diagnosing gastric intestinal metaplasia (GIM) on hematoxylin and eosin (H&E)-stained slides from endoscopic biopsy specimens. GIM is a well-known precursor lesion along the pathway to development of gastric cancer. We performed a thorough evaluation of the performance and inference time of our approach on a test set of GIM-positive and GIM-negative WSI, finding that our method successfully detects GIM in all positive WSI, with a WSI-level classification area under the receiver operating characteristic curve (AUC) of 0.98 and an average precision (AP) of 0.95. Furthermore, we show that our method can attain these metrics in under one minute on a standard CPU. Our results are applicable toward the goal of developing neural networks that can easily be deployed in clinical settings to support pathologists in quickly localizing and diagnosing small-scale morphologic features in WSI.",https://arxiv.org/abs/2201.01449
Pranav Rajpurkar,Video pretraining advances 3D deep learning on chest CT tasks,2024,Medical Imaging with Deep Learning,6,"Alexander Ke, Shih-Cheng Huang, Chloe P O’Connell, Michal Klimont, Serena Yeung, Pranav Rajpurkar",Alexander Ke,Pranav Rajpurkar,6,"Pretraining on large natural image classification datasets such as ImageNet has aided model development on data-scarce 2D medical tasks. 3D medical tasks often have much less data than 2D medical tasks, prompting practitioners to rely on pretrained 2D models to featurize slices. However, these 2D models have been surpassed by 3D models on 3D computer vision benchmarks since they do not natively leverage cross-sectional or temporal information. In this study, we explore whether natural video pretraining for 3D models can enable higher performance on smaller datasets for 3D medical tasks. We demonstrate video pretraining improves the average performance of seven 3D models on two chest CT datasets, regardless of finetuning dataset size, and that video pretraining allows 3D models to outperform 2D baselines. Lastly, we observe that pretraining on the large-scale out-of-domain Kinetics dataset improves performance more than pretraining on a typically-sized in-domain CT dataset. Our results show consistent benefits of video pretraining across a wide array of architectures, tasks, and training dataset sizes, supporting a shift from small-scale in-domain pretraining to large-scale out-of-domain pretraining for 3D medical tasks.",https://proceedings.mlr.press/v227/ke24a.html
Pranav Rajpurkar,AI-clinician collaboration via disagreement prediction: A decision pipeline and retrospective analysis of real-world radiologist-AI interactions,2023,Cell Reports Medicine,6,"Morgan Sanchez, Kyle Alford, Viswesh Krishna, Thanh M Huynh, Chanh DT Nguyen, Matthew P Lungren, Steven QH Truong, Pranav Rajpurkar",Morgan Sanchez,Pranav Rajpurkar,8,"Clinical decision support tools can improve diagnostic performance or reduce variability, but they are also subject to post-deployment underperformance. Although using AI in an assistive setting offsets many concerns with autonomous AI in medicine, systems that present all predictions equivalently fail to protect against key AI safety concerns. We design a decision pipeline that supports the diagnostic model with an ecosystem of models, integrating disagreement prediction, clinical significance categorization, and prediction quality modeling to guide prediction presentation. We characterize disagreement using data from a deployed chest X-ray interpretation aid and compare clinician burden in this proposed pipeline to the diagnostic model in isolation. The average disagreement rate is 6.5%, and the expected burden reduction is 4.8%, even if 5% of disagreements on urgent findings receive a second read. We …",https://www.cell.com/cell-reports-medicine/fulltext/S2666-3791(23)00374-9
Pranav Rajpurkar,Driverseat: Crowdstrapping Learning Tasks for Autonomous Driving,2015,ICML'15 Workshop on Crowdsourcing,6,"Pranav Rajpurkar, Toki Migimatsu, Jeff Kiske, Sameep Cheng-Yue, Royce, Tandon, Tao Wang, Andrew Ng",Pranav Rajpurkar,Andrew Ng,8,"While emerging deep-learning systems have outclassed knowledge-based approaches in many tasks, their application to detection tasks for autonomous technologies remains an open field for scientific exploration. Broadly, there are two major developmental bottlenecks: the unavailability of comprehensively labeled datasets and of expressive evaluation strategies. Approaches for labeling datasets have relied on intensive hand-engineering, and strategies for evaluating learning systems have been unable to identify failure-case scenarios. Human intelligence offers an untapped approach for breaking through these bottlenecks. This paper introduces Driverseat, a technology for embedding crowds around learning systems for autonomous driving. Driverseat utilizes crowd contributions for (a) collecting complex 3D labels and (b) tagging diverse scenarios for ready evaluation of learning systems. We demonstrate how Driverseat can crowdstrap a convolutional neural network on the lane-detection task. More generally, crowdstrapping introduces a valuable paradigm for any technology that can benefit from leveraging the powerful combination of human and computer intelligence.",https://arxiv.org/abs/1512.01872
Pranav Rajpurkar,Self-Supervised Pretraining Enables High-Performance Chest X-Ray Interpretation Across Clinical Distributions,2022,medRxiv,5,"Niveditha S Iyer, Aditya Gulati, Oishi Banerjee, Cécile Logé, Maha Farhat, Agustina Saenz, Pranav Rajpurkar",Niveditha S Iyer,Pranav Rajpurkar,7,"Chest X-rays (CXRs) are a rich source of information for physicians – essential for disease diagnosis and treatment selection. Recent deep learning models aim to alleviate strain on medical resources and improve patient care by automating the detection of diseases from CXRs. However, shortages of labeled CXRs can pose a serious challenge when training models. Currently, models are generally pretrained on ImageNet, but they often need to then be finetuned on hundreds of thousands of labeled CXRs to achieve high performance. Therefore, the current approach to model development is not viable on tasks with only a small amount of labeled data. An emerging method for reducing reliance on large amounts of labeled data is self-supervised learning (SSL), which uses unlabeled CXR datasets to automatically learn features that can be leveraged for downstream interpretation tasks. In this work, we investigated whether self-supervised pretraining methods could outperform traditional ImageNet pretraining for chest X-ray interpretation. We found that SSL-pretrained models outperformed ImageNet-pretrained models on thirteen different datasets representing high diversity in geographies, clinical settings, and prediction tasks. We thus show that SSL on unlabeled CXR data is a promising pretraining approach for a wide variety of CXR interpretation tasks, enabling a shift away from costly labeled datasets.",https://www.medrxiv.org/content/10.1101/2022.11.19.22282519.abstract
Pranav Rajpurkar,Chexbreak: Misclassification identification for deep learning models interpreting chest x-rays,2021,Machine Learning for Healthcare Conference,5,"Emma Chen, Andy Kim, Rayan Krishnan, Jin Long, Andrew Y Ng, Pranav Rajpurkar",Emma Chen,Pranav Rajpurkar,6,"A major obstacle to the integration of deep learning models for chest x-ray interpretation into clinical settings is the lack of understanding of their failure modes. In this work, we first investigate whether there are patient subgroups that chest x-ray models are likely to misclassify. We find that patient age and the radiographic finding of lung lesion, pneumothorax or support devices are statistically relevant features for predicting misclassification for some chest x-ray models. Second, we develop misclassification predictors on chest x-ray models using their outputs and clinical features. We find that our best performing misclassification identifier achieves an AUROC close to 0.9 for most diseases. Third, employing our misclassification identifiers, we develop a corrective algorithm to selectively flip model predictions that have high likelihood of misclassification at inference time. We observe F1 improvement on the prediction of Consolidation (0.008 [95% CI 0.005, 0.010]) and Edema (0.003,[95% CI 0.001, 0.006]). By carrying out our investigation on ten distinct and high-performing chest x-ray models, we are able to derive insights across model architectures and offer a generalizable framework applicable to other medical imaging tasks.",https://proceedings.mlr.press/v149/chen21a
Pranav Rajpurkar,Generating Synthetic Data for Medical Imaging,2024,,4,"Lennart R Koetzier, Jie Wu, Domenico Mastrodicasa, Aline Lutz, Matthew Chung, W Adam Koszek, Jayanth Pratap, Akshay S Chaudhari, Pranav Rajpurkar, Matthew P Lungren, Martin J Willemink",Lennart R Koetzier,Martin J Willemink,11,"Artificial intelligence (AI) models for medical imaging tasks, such as classification or segmentation, require large and diverse datasets of images. However, due to privacy and ethical issues, as well as data sharing infrastructure barriers, these datasets are scarce and difficult to assemble. Synthetic medical imaging data generated by AI from existing data could address this challenge by augmenting and anonymizing real imaging data. In addition, synthetic data enable new applications, including modality translation, contrast synthesis, and professional training for radiologists. However, the use of synthetic data also poses technical and ethical challenges. These challenges include ensuring the realism and diversity of the synthesized images while keeping data unidentifiable, evaluating the performance and generalizability of models trained on synthetic data, and high computational costs. Since existing regulations …",https://pubs.rsna.org/doi/abs/10.1148/radiol.232471
Pranav Rajpurkar,FineRadScore: A Radiology Report Line-by-Line Evaluation Technique Generating Corrections with Severity Scores,2024,arXiv preprint arXiv:2405.20613,4,"Alyssa Huang, Oishi Banerjee, Kay Wu, Eduardo Pontes Reis, Pranav Rajpurkar",Alyssa Huang,Pranav Rajpurkar,5,"The current gold standard for evaluating generated chest x-ray (CXR) reports is through radiologist annotations. However, this process can be extremely time-consuming and costly, especially when evaluating large numbers of reports. In this work, we present FineRadScore, a Large Language Model (LLM)-based automated evaluation metric for generated CXR reports. Given a candidate report and a ground-truth report, FineRadScore gives the minimum number of line-by-line corrections required to go from the candidate to the ground-truth report. Additionally, FineRadScore provides an error severity rating with each correction and generates comments explaining why the correction was needed. We demonstrate that FineRadScore's corrections and error severity scores align with radiologist opinions. We also show that, when used to judge the quality of the report as a whole, FineRadScore aligns with radiologists as well as current state-of-the-art automated CXR evaluation metrics. Finally, we analyze FineRadScore's shortcomings to provide suggestions for future improvements.",https://arxiv.org/abs/2405.20613
Pranav Rajpurkar,Adapting Segment Anything Models to Medical Imaging via Fine-Tuning without Domain Pretraining,2024,AAAI 2024 Spring Symposium on Clinical Foundation Models,4,"Kevin Li, Pranav Rajpurkar",Kevin Li,Pranav Rajpurkar,2,"Medical image segmentation is an important task in the context of medical care, with applications in diagnostic and treatment processes. Segment Anything (SAM), a generalist foundation model trained on a corpus of 11 million natural images, demonstrates limited adaptability to the medical domain in a zero-shot prompting context, but shows promise under parameter-efficient fine-tuning. MedSAM is a foundation model which adapts SAM to the medical domain via training on a diverse medical corpus consisting of different modalities (one million images of modality CT, MRI, CXR, etc). In this work, we evaluate the advantage of MedSAM over SAM for medical task-specific adaptation achieved via parameter-efficient fine-tuning. Our results demonstrate that MedSAM does not yield a consistent advantage over SAM in this setting. We also introduce a novel parameter-efficient approach, LoRaMedNet, which combines elements of previous fine-tuning methods to achieve greater flexibility of adaptation for SAM, and find that LoRaMedNet-adapted SAM attains the best performance. The implication of this finding is that generalist models like SAM can achieve superior adaptation to specific medical tasks even when compared to models with medical pre-training.",https://openreview.net/forum?id=Fxi7pRmnYJ
Pranav Rajpurkar,LymphoML: An interpretable artificial intelligence-based method identifies morphologic features that correlate with lymphoma subtype,2023,Machine Learning for Health (ML4H),4,"Vivek Shankar, Xiaoli Yang, Vrishab Krishna, Brent Tan, Oscar Silva, Rebecca Rojansky, Andrew Ng, Fabiola Valvert, Edward Briercheck, David Weinstock, Yasodha Natkunam, Sebastian Fernandez-Pol, Pranav Rajpurkar",Vivek Shankar,Pranav Rajpurkar,13,"The accurate classification of lymphoma subtypes using hematoxylin and eosin (H {\} & E)-stained tissue is complicated by the wide range of morphological features these cancers can exhibit. We present LymphoML-an interpretable machine learning method that identifies morphologic features that correlate with lymphoma subtypes. Our method applies steps to process H {\} & E-stained tissue microarray cores, segment nuclei and cells, compute features encompassing morphology, texture, and architecture, and train gradient-boosted models to make diagnostic predictions. LymphoML {’} s interpretable models, developed on a limited volume of H {\} & E-stained tissue, achieve non-inferior diagnostic accuracy to pathologists using whole-slide images and outperform black box deep-learning on a dataset of 670 cases from Guatemala spanning 8 lymphoma subtypes. Using SHapley Additive exPlanation (SHAP) analysis, we assess the impact of each feature on model prediction and find that nuclear shape features are most discriminative for DLBCL (F1-score: 78.7 {\}%) and classical Hodgkin lymphoma (F1-score: 74.5 {\}%). Finally, we provide the first demonstration that a model combining features from H {\} & E-stained tissue with features from a standardized panel of 6 immunostains results in a similar diagnostic accuracy (85.3 {\}%) to a 46-stain panel (86.1 {\}%).",https://proceedings.mlr.press/v225/shankar23a.html
Pranav Rajpurkar,Radiology Report Expert Evaluation (ReXVal) Dataset,2023,,4,"Feiyang Yu, Mark Endo, Rayan Krishnan, Ian Pan, Andy Tsai, Eduardo Pontes Reis, EKU Fonseca, Henrique Lee, Zahra Shakeri, Andrew Ng, Curtis Langlotz, Vasantha Kumar Venugopal, Pranav Rajpurkar",Feiyang Yu,Pranav Rajpurkar,13,"The Radiology Report Expert Evaluation (ReXVal) Dataset is a publicly available dataset of radiologist evaluations of errors in automatically generated radiology reports. The dataset contains annotations from 6 board certified radiologists on clinically significant and clinically insignificant errors under 6 error categories for candidate radiology reports with respect to ground-truth reports from the MIMIC-CXR dataset. There are 4 candidate reports generated for 50 studies, translating to 200 pairs of candidate and ground-truth reports on which radiologists provided annotations. The dataset has been used to evaluate the alignment between scoring of automated metrics and that of radiologists, investigate the failure modes of automated metrics, and build a composite automated metric, in a study on how to meaningfully measure progress in radiology report generation. It is also created to support additional medical AI research in radiology and other expert tasks.",https://physionet.org/content/rexval-dataset/1.0.0/
Pranav Rajpurkar,Unseen Disease Detection for Deep Learning Interpretation of Chest X-rays,2021,Medical Imaging with Deep Learning,4,"Siyu Shi, Ishaan Malhi, Kevin Tran, Andrew Y Ng, Pranav Rajpurkar",Siyu Shi,Pranav Rajpurkar,5,"We systematically evaluate the performance of deep learning models in the presence of diseases not labeled for or present during training. First, we evaluate whether deep learning models trained on a subset of diseases (seen diseases) can detect the presence of any one of a larger set of diseases. We find that models tend to falsely classify diseases outside of the subset (unseen diseases) as ‘no disease”. Second, we evaluate whether models trained on seen diseases can detect seen diseases when co-occurring with diseases outside the subset (unseen diseases). We find that models are still able to detect seen diseases even when co-occurring with unseen diseases. Third, we evaluate whether feature representations learned by models may be used to detect the presence of unseen diseases given a small labeled set of unseen diseases. We find that the penultimate layer provides useful features for unseen disease detection. Our results can inform the safe clinical deployment of deep learning models trained on a non-exhaustive set of disease classes.",https://proceedings.mlr.press/v143/shi21a.html
Pranav Rajpurkar,GloFlow: Whole Slide Image Stitching from Video Using Optical Flow and Global Image Alignment,2021,"Medical Image Computing and Computer Assisted Intervention–MICCAI 2021: 24th International Conference, Strasbourg, France, September 27–October 1, 2021, Proceedings, Part VIII 24",4,"Viswesh Krishna, Anirudh Joshi, Damir Vrabac, Philip Bulterys, Eric Yang, Sebastian Fernandez-Pol, Andrew Y Ng, Pranav Rajpurkar",Viswesh Krishna,Pranav Rajpurkar,8,"The application of deep learning to pathology assumes the existence of digital whole slide images of pathology slides. However, slide digitization is bottlenecked by the high cost of precise motor stages in slide scanners that are needed for position information used for slide stitching. We propose GloFlow, a two-stage method for creating a whole slide image using optical flow-based image registration with global alignment using a computationally tractable graph-pruning approach. In the first stage, we train an optical flow predictor to predict pairwise translations between successive video frames to approximate a stitch. In the second stage, this approximate stitch is used to create a neighborhood graph to produce a corrected stitch. On datasets of simulated video scans of pathology slides, we find that our method outperforms known approaches to slide-stitching, and stitches images resembling those …",https://link.springer.com/chapter/10.1007/978-3-030-87237-3_50
Pranav Rajpurkar,Direct Preference Optimization for Suppressing Hallucinated Prior Exams in Radiology Report Generation,2024,arXiv preprint arXiv:2406.06496,3,"Oishi Banerjee, Hong-Yu Zhou, Subathra Adithan, Stephen Kwak, Kay Wu, Pranav Rajpurkar",Oishi Banerjee,Pranav Rajpurkar,6,"Recent advances in generative vision-language models (VLMs) have exciting potential implications for AI in radiology, yet VLMs are also known to produce hallucinations, nonsensical text, and other unwanted behaviors that can waste clinicians' time and cause patient harm. Drawing on recent work on direct preference optimization (DPO), we propose a simple method for modifying the behavior of pretrained VLMs performing radiology report generation by suppressing unwanted types of generations. We apply our method to the prevention of hallucinations of prior exams, addressing a long-established problem behavior in models performing chest X-ray report generation. Across our experiments, we find that DPO fine-tuning achieves a 3.2-4.8x reduction in lines hallucinating prior exams while maintaining model performance on clinical accuracy metrics. Our work is, to the best of our knowledge, the first work to apply DPO to medical VLMs, providing a data- and compute- efficient way to suppress problem behaviors while maintaining overall clinical accuracy.",https://arxiv.org/abs/2406.06496
Pranav Rajpurkar,Comparative Advantage of Humans versus AI in the Long Tail,2024,AEA Papers and Proceedings,3,"Nikhil Agarwal, Ray Huang, Alex Moehring, Pranav Rajpurkar, Tobias Salz, Feiyang Yu",Nikhil Agarwal,Feiyang Yu,6,"Machine learning algorithms now exceed human performance on several predictive tasks, generating concerns about widespread job displacement. However, supervised learning approaches rely on large amounts of high-quality labeled data and are designed for specific predictive tasks. Thus, humans may be required for a large number of tasks, each of which is not commonly encountered—the long tail—because humans can make predictions for a broader range of outcomes and with exposure to much less data. We show that a self-supervised algorithm for chest X-rays, which does not require specifically annotated disease labels, closes this gap even in the long tail of diseases.",https://pubs.aeaweb.org/doi/abs/10.1257/pandp.20241071
Pranav Rajpurkar,Evaluating General Vision-Language Models for Clinical Medicine,2024,medRxiv,3,"Yixing Jiang, Jesutofunmi A Omiye, Cyril Zakka, Michael Moor, Haiwen Gui, Shayan Alipour, Seyed Shahabeddin Mousavi, Jonathan H Chen, Pranav Rajpurkar, Roxana Daneshjou",Yixing Jiang,Roxana Daneshjou,10,"Recently emerging large multimodal models (LMMs) utilize various types of data modalities, including text and visual inputs to generate outputs. The incorporation of LMMs into clinical medicine presents unique challenges, including accuracy, reliability, and clinical relevance. Here, we explore clinical applications of GPT-4V, an LMM that has been proposed for use in medicine, in gastroenterology, radiology, dermatology, and United States Medical Licensing Examination (USMLE) test questions. We used standardized robust datasets with thousands of endoscopy images, chest x-ray, and skin lesions to benchmark GPT-4V’s ability to predict diagnoses. To assess bias, we also explored GPT-4V’s ability to determine Fitzpatrick skin tones with dermatology images. We found that GPT-4V is limited in performance across all four domains, resulting in decreased performance compared to previously published baseline models. The macro-average precision, recall, and F1-score for gastroenterology were 11.2%, 9.1% and 6.8% respectively. For radiology, the best performing task of identifying cardiomegaly had precision, recall, and F1-score of 28%, 94%, and 43% respectively. In dermatology, GPT-4V had an overall top-1 and top-3 diagnostic accuracy of 6.2% and 21% respectively. There was a significant accuracy drop when predicting images of darker skin tones (p<0.001). GPT-4V accurately identified Fitzpatrick skin tones for 56.5% of images. For the multiple-choice-styled USMLE image-based test questions, GPT-4V had an accuracy of 59%. Our findings demonstrate that the current version of GPT-4V is limited in its diagnostic abilities across …",https://www.medrxiv.org/content/10.1101/2024.04.12.24305744.abstract
Pranav Rajpurkar,Deep Learning for Medical Image Interpretation,2021,,3,Pranav Rajpurkar,Pranav Rajpurkar,Pranav Rajpurkar,1,"There have been rapid advances at the intersection of deep learning and medicine over the last few years, especially for the interpretation of medical images. In this thesis, I describe three key directions that present challenges and opportunities for the development of deep learning technologies for medical image interpretation. First, I discuss the development of algorithms for expert-level medical image interpretation, with a focus on transfer learning and self-supervised learning algorithms designed to work in low labeled medical data settings. Second, I discuss the design and curation of high-quality datasets and their roles in advancing algorithmic developments, with a focus on high-quality labeling with limited manual annotations. Third, I discuss the real-world evaluation of medical image algorithms with studies systematically analyzing performance under clinically relevant distribution shifts. Altogether this thesis …",https://search.proquest.com/openview/3c309659307740212d2cf75964634757/1?pq-origsite=gscholar&cbl=18750&diss=y
Pranav Rajpurkar,Malaria Likelihood Prediction By Effectively Surveying Households Using Deep Reinforcement Learning,2017,NIPS'15 Workshop on Machine Learning For Health,3,"Pranav Rajpurkar, Vinaya Polamreddi, Anusha Balakrishnan",Pranav Rajpurkar,Anusha Balakrishnan,3,"We build a deep reinforcement learning (RL) agent that can predict the likelihood of an individual testing positive for malaria by asking questions about their household. The RL agent learns to determine which survey question to ask next and when to stop to make a prediction about their likelihood of malaria based on their responses hitherto. The agent incurs a small penalty for each question asked, and a large reward/penalty for making the correct/wrong prediction; it thus has to learn to balance the length of the survey with the accuracy of its final predictions. Our RL agent is a Deep Q-network that learns a policy directly from the responses to the questions, with an action defined for each possible survey question and for each possible prediction class. We focus on Kenya, where malaria is a massive health burden, and train the RL agent on a dataset of 6481 households from the Kenya Malaria Indicator Survey 2015. To investigate the importance of having survey questions be adaptive to responses, we compare our RL agent to a supervised learning (SL) baseline that fixes its set of survey questions a priori. We evaluate on prediction accuracy and on the number of survey questions asked on a holdout set and find that the RL agent is able to predict with 80% accuracy, using only 2.5 questions on average. In addition, the RL agent learns to survey adaptively to responses and is able to match the SL baseline in prediction accuracy while significantly reducing survey length.",https://arxiv.org/abs/1711.09223
Pranav Rajpurkar,Text Mining Emergent Human Behaviors for Interactive Systems,2015,Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems,3,"Ethan Fast, Pranav Rajpurkar, Michael S Bernstein",Ethan Fast,Michael S Bernstein,3,"People engage with thousands of situations, activities, and objects on a daily basis. Hand-coding this knowledge into interactive systems is prohibitively labor-intensive, but fiction captures a vast number of human lives in moment to moment detail. In this paper, we bootstrap a knowledge graph of human activities by text mining a large dataset of modern fiction on the web. Our knowledge graph, Augur, describes human actions over time as conditioned by nearby locations, people, and objects. Applications can use this graph to react to human behavior in a data-driven way. We demonstrate an Augur-enhanced video game world in which non-player characters follow realistic patterns of behavior, interact with their environment and each other, and respond to the user's behavior.",https://dl.acm.org/doi/abs/10.1145/2702613.2732805
Pranav Rajpurkar,A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges,2024,arXiv preprint arXiv:2411.00024,2,"Zifeng Wang, Hanyin Wang, Benjamin Danek, Ying Li, Christina Mack, Hoifung Poon, Yajun Wang, Pranav Rajpurkar, Jimeng Sun",Zifeng Wang,Jimeng Sun,9,"The integration of Large Language Models (LLMs) into medical applications has sparked widespread interest across the healthcare industry, from drug discovery and development to clinical decision support, assisting telemedicine, medical devices, and healthcare insurance applications. This perspective paper aims to discuss the inner workings of building LLM-powered medical AI applications and introduces a comprehensive framework for their development. We review existing literature and outline the unique challenges of applying LLMs in specialized medical contexts. Additionally, we introduce a three-step framework to organize medical LLM research activities: 1) Modeling: breaking down complex medical workflows into manageable steps for developing medical-specific models; 2) Optimization: optimizing the model performance with crafted prompts and integrating external knowledge and tools, and 3) System engineering: decomposing complex tasks into subtasks and leveraging human expertise for building medical AI applications. Furthermore, we offer a detailed use case playbook that describes various LLM-powered medical AI applications, such as optimizing clinical trial design, enhancing clinical decision support, and advancing medical imaging analysis. Finally, we discuss various challenges and considerations for building medical AI applications with LLMs, such as handling hallucination issues, data ownership and compliance, privacy, intellectual property considerations, compute cost, sustainability issues, and responsible AI requirements.",https://arxiv.org/abs/2411.00024
Pranav Rajpurkar,Targeted plasma metabolomics combined with machine learning for the diagnosis of severe acute respiratory syndrome virus type 2,2023,Frontiers in Microbiology,2,"Anthony T Le, Manhong Wu, Afraz Khan, Nicholas Phillips, Pranav Rajpurkar, Megan Garland, Kayla Magid, Mamdouh Sibai, ChunHong Huang, Malaya K Sahoo, Raffick Bowen, Tina M Cowan, Benjamin A Pinsky, Catherine A Hogan",Anthony T Le,Catherine A Hogan,14,"The routine clinical diagnosis of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) is largely restricted to real-time reverse transcription quantitative PCR (RT-qPCR), and tests that detect SARS-CoV-2 nucleocapsid antigen. Given the diagnostic delay and suboptimal sensitivity associated with these respective methods, alternative diagnostic strategies are needed for acute infection.We studied the use of a clinically validated liquid chromatography triple quadrupole method (LC/MS–MS) for detection of amino acids from plasma specimens. We applied machine learning models to distinguish between SARS-CoV-2-positive and negative samples and analyzed amino acid feature importance.A total of 200 samples were tested, including 70 from individuals with COVID-19, and 130 from negative controls. The top performing model overall allowed discrimination between SARS-CoV-2-positive and negative control samples with an area under the receiver operating characteristic curve (AUC) of 0.96 (95%CI 0.91, 1.00), overall sensitivity of 0.99 (95%CI 0.92, 1.00), and specificity of 0.92 (95%CI 0.85, 0.95).This approach holds potential as an alternative to existing methods for the rapid and accurate diagnosis of acute SARS-CoV-2 infection.",https://www.frontiersin.org/articles/10.3389/fmicb.2022.1059289/full
Pranav Rajpurkar,ReFiSco: Report Fix and Score Dataset for Radiology Report Generation,2023,,2,"Katherine Tian, Sina J Hartung, Andrew A Li, Jaehwan Jeong, Fardad Behzadi, Juan Calle-Toro, Subathra Adithan, Michael Pohlen, David Osayande, Pranav Rajpurkar",Katherine Tian,Pranav Rajpurkar,10,"Automated generation of clinically accurate radiology reports can improve patient care. In order to improve automatic report generation, it is helpful to understand what types of errors are common in generated reports. Thus, we introduce the Report Fix and Score Dataset for Radiology Reports (ReFiSco-v0), which was collected through an institutional review board-approved study. In our study, we recruit radiologists to provide expert evaluations on a subset of 60 studies from MIMIC-CXR. For each radiology image, we compile three reports: one generated from the model X-REM, one from the model CXR-RePaiR trained on the same MIMIC-CXR training set, and one taken from a human benchmark (MIMIC-CXR). To each radiologist, we present one image and one report for each of the 60 studies. Each report is randomly and independently chosen from one of the three sources. The radiologist is blinded to the source. We ask each radiologist to assess the error severity of their assigned reports.",https://physionet.org/content/refisco/
Pranav Rajpurkar,Gemcitabine response prediction in the adjuvant treatment of resected pancreatic ductal adenocarcinoma using an AI histopathology platform.,2022,,2,"Viswesh Krishna, Vivek Nimgaonkar, Ekin Tiu, Vrishab Krishna, Hriday Bhambhvani, Stephen Cook, Daniel Miller, Damir Vrabac, Anirudh Joshi, Aatur D Singhi, Andrew Eugene Hendifar, Pranav Rajpurkar, Eric Andrew Collisson",Viswesh Krishna,Eric Andrew Collisson,13,"e16295Background: Adjuvant chemotherapy improves survival following resection of pancreatic ductal adenocarcinoma (PDAC). A modified fluorouracil/irinotecan/oxaliplatin regimen (mFOLFIRINOX) has demonstrated improved disease free survival and overall survival, though gemcitabine-based monotherapy and gemcitabine plus capecitabine are alternatives in less fit patients. Though there are several proposed biomarkers to guide treatment decisions (GATA6, hENT1, and GemPred), no biomarker is used to guide treatment selection in clinical practice. Consequently, we sought to develop an artificial intelligence-derived signature of features from digital images of routine histopathology specimens that could identify patients susceptible to routine chemotherapeutic agents. Methods: 139 whole-slide digitized histological slides corresponding to 102 resected PDAC tumors from TCGA-PAAD were used in this …",https://ascopubs.org/doi/abs/10.1200/JCO.2022.40.16_suppl.e16295
Pranav Rajpurkar,CheXphotogenic: Generalization of Deep Learning Models for Chest X-ray Interpretation to Photos of Chest X-rays,2020,Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended Abstract,2,"Pranav Rajpurkar, Anirudh Joshi, Anuj Pareek, Jeremy Irvin, Andrew Y Ng, Matthew Lungren",Pranav Rajpurkar,Matthew Lungren,6,"The use of smartphones to take photographs of chest x-rays represents an appealing solution for scaled deployment of deep learning models for chest x-ray interpretation. However, the performance of chest x-ray algorithms on photos of chest x-rays has not been thoroughly investigated. In this study, we measured the diagnostic performance for 8 different chest x-ray models when applied to photos of chest x-rays. All models were developed by different groups and submitted to the CheXpert challenge, and re-applied to smartphone photos of x-rays in the CheXphoto dataset without further tuning. We found that several models had a drop in performance when applied to photos of chest x-rays, but even with this drop, some models still performed comparably to radiologists. Further investigation could be directed towards understanding how different model training procedures may affect model generalization to photos of chest x-rays.",https://researchain.net/archives/pdf/Chexphotogenic-Generalization-Of-Deep-Learning-Models-For-Chest-X-Ray-Interpretation-To-Photos-Of-Chest-X-Rays-2315047
Pranav Rajpurkar,ReXplain: Translating Radiology into Patient-Friendly Video Reports,2024,arXiv preprint arXiv:2410.00441,1,"Luyang Luo, Jenanan Vairavamurthy, Xiaoman Zhang, Abhinav Kumar, Ramon R Ter-Oganesyan, Stuart T Schroff, Dan Shilo, Rydhwana Hossain, Mike Moritz, Pranav Rajpurkar",Luyang Luo,Pranav Rajpurkar,10,"Radiology reports often remain incomprehensible to patients, undermining patient-centered care. We present ReXplain (Radiology eXplanation), an innovative AI-driven system that generates patient-friendly video reports for radiology findings. ReXplain uniquely integrates a large language model for text simplification, an image segmentation model for anatomical region identification, and an avatar generation tool, producing comprehensive explanations with plain language, highlighted imagery, and 3D organ renderings. Our proof-of-concept study with five board-certified radiologists indicates that ReXplain could accurately deliver radiological information and effectively simulate one-on-one consultations. This work demonstrates a new paradigm in AI-assisted medical communication, potentially improving patient engagement and satisfaction in radiology care, and opens new avenues for research in multimodal medical communication.",https://arxiv.org/abs/2410.00441
Pranav Rajpurkar,Uncovering Knowledge Gaps in Radiology Report Generation Models through Knowledge Graphs,2024,arXiv preprint arXiv:2408.14397,1,"Xiaoman Zhang, Julián N Acosta, Hong-Yu Zhou, Pranav Rajpurkar",Xiaoman Zhang,Pranav Rajpurkar,4,"Recent advancements in artificial intelligence have significantly improved the automatic generation of radiology reports. However, existing evaluation methods fail to reveal the models' understanding of radiological images and their capacity to achieve human-level granularity in descriptions. To bridge this gap, we introduce a system, named ReXKG, which extracts structured information from processed reports to construct a comprehensive radiology knowledge graph. We then propose three metrics to evaluate the similarity of nodes (ReXKG-NSC), distribution of edges (ReXKG-AMS), and coverage of subgraphs (ReXKG-SCS) across various knowledge graphs. We conduct an in-depth comparative analysis of AI-generated and human-written radiology reports, assessing the performance of both specialist and generalist models. Our study provides a deeper understanding of the capabilities and limitations of current AI models in radiology report generation, offering valuable insights for improving model performance and clinical applicability.",https://arxiv.org/abs/2408.14397
Pranav Rajpurkar,ReXamine-Global: A Framework for Uncovering Inconsistencies in Radiology Report Generation Metrics,2024,,1,"Oishi Banerjee, Agustina Saenz, Kay Wu, Warren Clements, Adil Zia, Dominic Buensalido, Helen Kavnoudias, Alain S Abi-Ghanem, Nour El Ghawi, Cibele Luna, Patricia Castillo, Khaled Al-Surimi, Rayyan A Daghistani, Yuh-Min Chen, Heng-sheng Chao, Lars Heiliger, Moon Kim, Johannes Haubold, Frederic Jonske, Pranav Rajpurkar",Oishi Banerjee,Pranav Rajpurkar,20,"Given the rapidly expanding capabilities of generative AI models for radiology, there is a need for robust metrics that can accurately measure the quality of AI-generated radiology reports across diverse hospitals. We develop ReXamine-Global, a LLM-powered, multi-site framework that tests metrics across different writing styles and patient populations, exposing gaps in their generalization. First, our method tests whether a metric is undesirably sensitive to reporting style, providing different scores depending on whether AI-generated reports are stylistically similar to ground-truth reports or not. Second, our method measures whether a metric reliably agrees with experts, or whether metric and expert scores of AI-generated report quality diverge for some sites. Using 240 reports from 6 hospitals around the world, we apply ReXamine-Global to 7 established report evaluation metrics and uncover serious gaps in their …",https://www.worldscientific.com/doi/abs/10.1142/9789819807024_0014
Pranav Rajpurkar,Learning Generalized Medical Image Representations Through Image-Graph Contrastive Pretraining,2023,Machine Learning for Health (ML4H),1,"Sameer Khanna, Daniel Michael, Marinka Zitnik, Pranav Rajpurkar",Sameer Khanna,Pranav Rajpurkar,4,"Medical image interpretation using deep learning has shown promise but often requires extensive expert-annotated datasets. To reduce this annotation burden, we develop an Image-Graph Contrastive Learning framework that pairs chest X-rays with structured report knowledge graphs automatically extracted from radiology notes. Our approach uniquely encodes the disconnected graph components via a relational graph convolution network and transformer attention. In experiments on the CheXpert dataset, this novel graph encoding strategy enabled the framework to outperform existing methods that use image-text contrastive learning in 1 {\}% linear evaluation and few-shot settings, while achieving comparable performance to radiologists. By exploiting unlabeled paired images and text, our framework demonstrates the potential of structured clinical insights to enhance contrastive learning for medical images. This work points toward reducing demands on medical experts for annotations, improving diagnostic precision, and advancing patient care through robust medical image understanding.",https://proceedings.mlr.press/v225/khanna23a.html
Pranav Rajpurkar,Guidelines For Rigorous Evaluation of Clinical LLMs For Conversational Reasoning,2023,medRxiv,1,"Shreya Johri, Jaehwan Jeong, Benjamin A Tran, Daniel I Schlessinger, Shannon Wongvibulsin, Zhuo Ran Cai, Roxana Daneshjou, Pranav Rajpurkar",Shreya Johri,Pranav Rajpurkar,8,"The integration of Large Language Models (LLMs) like GPT-4 and GPT-3.5 into clinical diagnostics has the potential to transform patient-doctor interactions. However, the readiness of these models for real-world clinical application remains inadequately tested. This paper introduces the Conversational Reasoning Assessment Framework for Testing in Medicine (CRAFT-MD), a novel approach for evaluating clinical LLMs. Unlike traditional methods that rely on structured medical exams, CRAFT-MD focuses on natural dialogues, using simulated AI agents to interact with LLMs in a controlled, ethical environment. We applied CRAFT-MD to assess the diagnostic capabilities of GPT-4 and GPT-3.5 in the context of skin diseases. Our experiments revealed critical insights into the limitations of current LLMs in terms of clinical conversational reasoning, history taking, and diagnostic accuracy. Based on these findings, we propose a comprehensive set of guidelines for future evaluations of clinical LLMs. These guidelines emphasize realistic doctor-patient conversations, comprehensive history taking, open-ended questioning, and a combination of automated and expert evaluations. The introduction of CRAFT-MD marks a significant advancement in LLM testing, aiming to ensure that these models augment medical practice effectively and ethically.",https://www.medrxiv.org/content/10.1101/2023.09.12.23295399.abstract
Pranav Rajpurkar,GloFlow: Global Image Alignment for Creation of Whole Slide Images for Pathology from Video,2020,Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended Abstract,1,"Viswesh Krishna, Anirudh Joshi, Philip L Bulterys, Eric Yang, Andrew Y Ng, Pranav Rajpurkar",Viswesh Krishna,Pranav Rajpurkar,6,"The application of deep learning to pathology assumes the existence of digital whole slide images of pathology slides. However, slide digitization is bottlenecked by the high cost of precise motor stages in slide scanners that are needed for position information used for slide stitching. We propose GloFlow, a two-stage method for creating a whole slide image using optical flow-based image registration with global alignment using a computationally tractable graph-pruning approach. In the first stage, we train an optical flow predictor to predict pairwise translations between successive video frames to approximate a stitch. In the second stage, this approximate stitch is used to create a neighborhood graph to produce a corrected stitch. On a simulated dataset of video scans of WSIs, we find that our method outperforms known approaches to slide-stitching, and stitches WSIs resembling those produced by slide scanners.",https://arxiv.org/abs/2010.15269
Pranav Rajpurkar,AI-Augmented Diagnosis of Brain Aneurysms from CTA: A Retrospective Study,2019,JOURNAL OF NEUROSURGERY,1,"Rashad Jabarkheel, Allison Park, Chris Chute, Pranav Rajpurkar, Joe Lou, Katie Shpanskaya, Lily Kim, Emily McKenna, David Hong, Thomas Wilson, Kristen Yeom",Rashad Jabarkheel,Kristen Yeom,11,,https://scholar.google.com/scholar?cluster=9821472319950191437&hl=en&oi=scholarr
Pranav Rajpurkar,AUTOMATED DETECTION OF PROSTATE CANCER ON MULTIPARAMETRIC MRI USING DEEP NEURAL NETWORKS TRAINED ON SPATIAL COORDINATES AND PATHOLOGY OF BIOPSY CORES,2019,The Journal of Urology,1,"Leo Chen, Nicholas Bien, Richard Fan, Robin Cheong, Pranav Rajpurkar, Alan Thong, Nancy Wang, Sarir Ahmadi, Mirabela Rusu, James Brooks, Andrew Ng, Geoffrey Sonn",Leo Chen,Geoffrey Sonn,12,"METHODS:MR-ultrasound fusion biopsies were performed at a single institution using a robotic fusion biopsy device (Artemis, Eigen) for patients that had multiparametric prostate MRIs. Patients underwent both targeted and standard template biopsies. Core level pathology was prospectively collected into a database. The spatial coordinates of both targeted and standard template cores were calculated and plotted onto the MR images. A weakly supervised convolutional neural network model was trained to predict cancer on MR images, using the spatial geometry and pathology of the biopsy core tracts as ground truth. Implementation was done using the Python programming language.RESULTS:Over 10,000 MRI-US fusion biopsy cores were collected from over 600 patients in 2015-2018, yielding over 40,000 data points. A preliminary binary classification model based on T2 sequences alone correctly predicted …",https://journals.lww.com/auajuro/abstract/2019/04001/pd60_05_automated_detection_of_prostate_cancer_on.2549.aspx
Pranav Rajpurkar,CRAFT-MD: A Conversational Evaluation Framework for Comprehensive Assessment of Clinical LLMs,,AAAI 2024 Spring Symposium on Clinical Foundation Models,1,"Shreya Johri, Jaehwan Jeong, Benjamin A Tran, Daniel I Schlessinger, Shannon Wongvibulsin, Zhuo Ran Cai, Roxana Daneshjou, Pranav Rajpurkar",Shreya Johri,Pranav Rajpurkar,8,"The integration of Large Language Models (LLMs) into clinical diagnostics has the potential to transform patient-doctor interactions. However, the readiness of these models for real-world clinical application remains inadequately tested. This paper introduces the Conversational Reasoning Assessment Framework for Testing in Medicine (CRAFT-MD), a novel approach for evaluating clinical LLMs. Unlike traditional methods that rely on structured medical exams, CRAFT-MD focuses on natural dialogues, using simulated AI agents to interact with LLMs in a controlled, ethical environment. We applied CRAFT-MD to assess the diagnostic capabilities of GPT-4 and GPT-3.5 in the context of skin diseases. Our experiments revealed critical insights into the limitations of current LLMs in terms of clinical conversational reasoning, history taking, and diagnostic accuracy, emphasising the need to evaluate clinical LLMs beyond static exam-questions. The introduction of CRAFT-MD marks a significant advancement in LLM testing, aiming to ensure that these models augment medical practice effectively and ethically.",https://openreview.net/forum?id=Bk2nbTDtm8
Pranav Rajpurkar,A clinical certification pathway for generalist medical AI systems,2025,The Lancet,0,"Pranav Rajpurkar, Eric J Topol",Pranav Rajpurkar,Eric J Topol,2,"There have been extensive evaluations of artificial intelligence (AI) systems for narrow medical tasks, but more work is needed to systematically evaluate and deploy AI systems that can perform a broad range of medical tasks. The medical training process itself might offer a template for addressing this challenge. Clinicians undergo rigorous education and training, progressing through stages of increasing responsibility and autonomy. Similarly, generalist medical AI systems could be subjected to a phased certification model before they are granted greater autonomy in patient care. At the initial stage, AI systems need to show an understanding of foundational medical knowledge, akin to medical students completing their basic sciences education. Although existing AI models have already shown good performance on standardised assessments, such as the US Medical Licensing Examination Step 1, new forms of …",https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(24)02797-1/abstract
Pranav Rajpurkar,An evaluation framework for clinical use of large language models in patient interaction tasks,2025,Nature Medicine,0,"Shreya Johri, Jaehwan Jeong, Benjamin A Tran, Daniel I Schlessinger, Shannon Wongvibulsin, Leandra A Barnes, Hong-Yu Zhou, Zhuo Ran Cai, Eliezer M Van Allen, David Kim, Roxana Daneshjou, Pranav Rajpurkar",Shreya Johri,Pranav Rajpurkar,12,"The integration of large language models (LLMs) into clinical diagnostics has the potential to transform doctor–patient interactions. However, the readiness of these models for real-world clinical application remains inadequately tested. This paper introduces the Conversational Reasoning Assessment Framework for Testing in Medicine (CRAFT-MD) approach for evaluating clinical LLMs. Unlike traditional methods that rely on structured medical examinations, CRAFT-MD focuses on natural dialogues, using simulated artificial intelligence agents to interact with LLMs in a controlled environment. We applied CRAFT-MD to assess the diagnostic capabilities of GPT-4, GPT-3.5, Mistral and LLaMA-2-7b across 12 medical specialties. Our experiments revealed critical insights into the limitations of current LLMs in terms of clinical conversational reasoning, history-taking and diagnostic accuracy. These limitations also …",https://www.nature.com/articles/s41591-024-03328-5
Pranav Rajpurkar,ReXTrust: A Model for Fine-Grained Hallucination Detection in AI-Generated Radiology Reports,2024,arXiv preprint arXiv:2412.15264,0,"Romain Hardy, Sung Eun Kim, Pranav Rajpurkar",Romain Hardy,Pranav Rajpurkar,3,"The increasing adoption of AI-generated radiology reports necessitates robust methods for detecting hallucinations--false or unfounded statements that could impact patient care. We present ReXTrust, a novel framework for fine-grained hallucination detection in AI-generated radiology reports. Our approach leverages sequences of hidden states from large vision-language models to produce finding-level hallucination risk scores. We evaluate ReXTrust on a subset of the MIMIC-CXR dataset and demonstrate superior performance compared to existing approaches, achieving an AUROC of 0.8751 across all findings and 0.8963 on clinically significant findings. Our results show that white-box approaches leveraging model hidden states can provide reliable hallucination detection for medical AI systems, potentially improving the safety and reliability of automated radiology reporting.",https://arxiv.org/abs/2412.15264
Pranav Rajpurkar,a2z-1 for Multi-Disease Detection in Abdomen-Pelvis CT: External Validation and Performance Analysis Across 21 Conditions,2024,arXiv preprint arXiv:2412.12629,0,"Pranav Rajpurkar, Julian N Acosta, Siddhant Dogra, Jaehwan Jeong, Deepanshu Jindal, Michael Moritz, Samir Rajpurkar",Pranav Rajpurkar,Samir Rajpurkar,7,"We present a comprehensive evaluation of a2z-1, an artificial intelligence (AI) model designed to analyze abdomen-pelvis CT scans for 21 time-sensitive and actionable findings. Our study focuses on rigorous assessment of the model's performance and generalizability. Large-scale retrospective analysis demonstrates an average AUC of 0.931 across 21 conditions. External validation across two distinct health systems confirms consistent performance (AUC 0.923), establishing generalizability to different evaluation scenarios, with notable performance in critical findings such as small bowel obstruction (AUC 0.958) and acute pancreatitis (AUC 0.961). Subgroup analysis shows consistent accuracy across patient sex, age groups, and varied imaging protocols, including different slice thicknesses and contrast administration types. Comparison of high-confidence model outputs to radiologist reports reveals instances where a2z-1 identified overlooked findings, suggesting potential for quality assurance applications.",https://arxiv.org/abs/2412.12629
Pranav Rajpurkar,The Impact of AI Assistance on Radiology Reporting: A Pilot Study Using Simulated AI Draft Reports,2024,arXiv preprint arXiv:2412.12042,0,"Julián N Acosta, Siddhant Dogra, Subathra Adithan, Kay Wu, Michael Moritz, Stephen Kwak, Pranav Rajpurkar",Julián N Acosta,Pranav Rajpurkar,7,"Radiologists face increasing workload pressures amid growing imaging volumes, creating risks of burnout and delayed reporting times. While artificial intelligence (AI) based automated radiology report generation shows promise for reporting workflow optimization, evidence of its real-world impact on clinical accuracy and efficiency remains limited. This study evaluated the effect of draft reports on radiology reporting workflows by conducting a three reader multi-case study comparing standard versus AI-assisted reporting workflows. In both workflows, radiologists reviewed the cases and modified either a standard template (standard workflow) or an AI-generated draft report (AI-assisted workflow) to create the final report. For controlled evaluation, we used GPT-4 to generate simulated AI drafts and deliberately introduced 1-3 errors in half the cases to mimic real AI system performance. The AI-assisted workflow significantly reduced average reporting time from 573 to 435 seconds (p=0.003), without a statistically significant difference in clinically significant errors between workflows. These findings suggest that AI-generated drafts can meaningfully accelerate radiology reporting while maintaining diagnostic accuracy, offering a practical solution to address mounting workload challenges in clinical practice.",https://arxiv.org/abs/2412.12042
Pranav Rajpurkar,MedAutoCorrect: Image-Conditioned Autocorrection in Medical Reporting,2024,arXiv preprint arXiv:2412.02971,0,"Arnold Caleb Asiimwe, Dídac Surís, Pranav Rajpurkar, Carl Vondrick",Arnold Caleb Asiimwe,Carl Vondrick,4,"In medical reporting, the accuracy of radiological reports, whether generated by humans or machine learning algorithms, is critical. We tackle a new task in this paper: image-conditioned autocorrection of inaccuracies within these reports. Using the MIMIC-CXR dataset, we first intentionally introduce a diverse range of errors into reports. Subsequently, we propose a two-stage framework capable of pinpointing these errors and then making corrections, simulating an \textit{autocorrection} process. This method aims to address the shortcomings of existing automated medical reporting systems, like factual errors and incorrect conclusions, enhancing report reliability in vital healthcare applications. Importantly, our approach could serve as a guardrail, ensuring the accuracy and trustworthiness of automated report generation. Experiments on established datasets and state of the art report generation models validate this method's potential in correcting medical reporting errors.",https://arxiv.org/abs/2412.02971
Pranav Rajpurkar,Reimbursement in the age of generalist radiology artificial intelligence,2024,,0,"Siddhant Dogra, Ezequiel Silva, Pranav Rajpurkar",Siddhant Dogra,Pranav Rajpurkar,3,"We argue that generalist radiology artificial intelligence (GRAI) challenges current healthcare reimbursement frameworks. Unlike narrow AI tools, GRAI’s multi-task capabilities render existing pathways inadequate. This perspective examines key questions surrounding GRAI reimbursement, including issues of coding, valuation, and coverage policies. We aim to catalyze dialogue among stakeholders about how reimbursement might evolve to accommodate GRAI, potentially influencing AI reimbursement strategies in radiology and beyond.",https://www.nature.com/articles/s41746-024-01352-w
Pranav Rajpurkar,FactCheXcker: Mitigating Measurement Hallucinations in Chest X-ray Report Generation Models,2024,arXiv preprint arXiv:2411.18672,0,"Alice Heiman, Xiaoman Zhang, Emma Chen, Sung Eun Kim, Pranav Rajpurkar",Alice Heiman,Pranav Rajpurkar,5,"Medical vision-language model models often struggle with generating accurate quantitative measurements in radiology reports, leading to hallucinations that undermine clinical reliability. We introduce FactCheXcker, a modular framework that de-hallucinates radiology report measurements by leveraging an improved query-code-update paradigm. Specifically, FactCheXcker employs specialized modules and the code generation capabilities of large language models to solve measurement queries generated based on the original report. After extracting measurable findings, the results are incorporated into an updated report. We evaluate FactCheXcker on endotracheal tube placement, which accounts for an average of 78% of report measurements, using the MIMIC-CXR dataset and 11 medical report-generation models. Our results show that FactCheXcker significantly reduces hallucinations, improves measurement precision, and maintains the quality of the original reports. Specifically, FactCheXcker improves the performance of all 11 models and achieves an average improvement of 94.0% in reducing measurement hallucinations measured by mean absolute error.",https://arxiv.org/abs/2411.18672
Pranav Rajpurkar,ReXrank: A Public Leaderboard for AI-Powered Radiology Report Generation,2024,arXiv preprint arXiv:2411.15122,0,"Xiaoman Zhang, Hong-Yu Zhou, Xiaoli Yang, Oishi Banerjee, Julián N Acosta, Josh Miller, Ouwen Huang, Pranav Rajpurkar",Xiaoman Zhang,Pranav Rajpurkar,8,"AI-driven models have demonstrated significant potential in automating radiology report generation for chest X-rays. However, there is no standardized benchmark for objectively evaluating their performance. To address this, we present ReXrank, https://rexrank.ai, a public leaderboard and challenge for assessing AI-powered radiology report generation. Our framework incorporates ReXGradient, the largest test dataset consisting of 10,000 studies, and three public datasets (MIMIC-CXR, IU-Xray, CheXpert Plus) for report generation assessment. ReXrank employs 8 evaluation metrics and separately assesses models capable of generating only findings sections and those providing both findings and impressions sections. By providing this standardized evaluation framework, ReXrank enables meaningful comparisons of model performance and offers crucial insights into their robustness across diverse clinical settings. Beyond its current focus on chest X-rays, ReXrank's framework sets the stage for comprehensive evaluation of automated reporting across the full spectrum of medical imaging.",https://arxiv.org/abs/2411.15122
Pranav Rajpurkar,RadFlag: A Black-Box Hallucination Detection Method for Medical Vision Language Models,2024,arXiv preprint arXiv:2411.00299,0,"Sraavya Sambara, Serena Zhang, Oishi Banerjee, Julian Acosta, John Fahrner, Pranav Rajpurkar",Sraavya Sambara,Pranav Rajpurkar,6,"Generating accurate radiology reports from medical images is a clinically important but challenging task. While current Vision Language Models (VLMs) show promise, they are prone to generating hallucinations, potentially compromising patient care. We introduce RadFlag, a black-box method to enhance the accuracy of radiology report generation. Our method uses a sampling-based flagging technique to find hallucinatory generations that should be removed. We first sample multiple reports at varying temperatures and then use a Large Language Model (LLM) to identify claims that are not consistently supported across samples, indicating that the model has low confidence in those claims. Using a calibrated threshold, we flag a fraction of these claims as likely hallucinations, which should undergo extra review or be automatically rejected. Our method achieves high precision when identifying both individual hallucinatory sentences and reports that contain hallucinations. As an easy-to-use, black-box system that only requires access to a model's temperature parameter, RadFlag is compatible with a wide range of radiology report generation models and has the potential to broadly improve the quality of automated radiology reporting.",https://arxiv.org/abs/2411.00299
Pranav Rajpurkar,Pixels and Pitfalls: Building Robust Artificial Intelligence for Medical Imaging,2024,,0,"Pranav Rajpurkar, Andrew L Beam, Arjun K Manrai",Pranav Rajpurkar,Arjun K Manrai,3,"Artificial intelligence (AI) applications in medical imaging continue to evolve rapidly, with models now capable of interpreting medical images without being trained on explicit labels. This Perspective, based on a conversation with Dr. Pranav Rajpurkar on NEJM AI Grand Rounds, discusses the progression of AI imaging models, starting from early successes in radiology, such as CheXNet, to more sophisticated recent models such as CheXzero. Dr. Rajpurkar emphasizes the importance of understanding the “data generation process,” including the artifacts and biases baked into data, which is illustrated by a specific example where an AI model exploited metadata rather than clinically relevant features. Dr. Rajpurkar addresses the urgent need for more open and accessible medical data with his initiative on Medical AI Data for All (MAIDA). We also examine the changing role of clinicians in an AI-augmented health …",https://ai.nejm.org/doi/abs/10.1056/AIp2400803
Pranav Rajpurkar,HeadCT-ONE: Enabling Granular and Controllable Automated Evaluation of Head CT Radiology Report Generation,2024,arXiv preprint arXiv:2409.13038,0,"Julián N Acosta, Xiaoman Zhang, Siddhant Dogra, Hong-Yu Zhou, Seyedmehdi Payabvash, Guido J Falcone, Eric K Oermann, Pranav Rajpurkar",Julián N Acosta,Pranav Rajpurkar,8,"We present Head CT Ontology Normalized Evaluation (HeadCT-ONE), a metric for evaluating head CT report generation through ontology-normalized entity and relation extraction. HeadCT-ONE enhances current information extraction derived metrics (such as RadGraph F1) by implementing entity normalization through domain-specific ontologies, addressing radiological language variability. HeadCT-ONE compares normalized entities and relations, allowing for controllable weighting of different entity types or specific entities. Through experiments on head CT reports from three health systems, we show that HeadCT-ONE's normalization and weighting approach improves the capture of semantically equivalent reports, better distinguishes between normal and abnormal reports, and aligns with radiologists' assessment of clinically significant errors, while offering flexibility to prioritize specific aspects of report content. Our results demonstrate how HeadCT-ONE enables more flexible, controllable, and granular automated evaluation of head CT reports.",https://arxiv.org/abs/2409.13038
Pranav Rajpurkar,Towards Non-invasive and Personalized Management of Breast Cancer Patients from Multiparametric MRI via A Large Mixture-of-Modality-Experts Model,2024,arXiv preprint arXiv:2408.12606,0,"Luyang Luo, Mingxiang Wu, Mei Li, Yi Xin, Qiong Wang, Varut Vardhanabhuti, Winnie CW Chu, Zhenhui Li, Juan Zhou, Pranav Rajpurkar, Hao Chen",Luyang Luo,Hao Chen,11,"Breast magnetic resonance imaging (MRI) is the imaging technique with the highest sensitivity for detecting breast cancer and is routinely used for women at high risk. Despite the comprehensive multiparametric protocol of breast MRI, existing artificial intelligence-based studies predominantly rely on single sequences and have limited validation. Here we report a large mixture-of-modality-experts model (MOME) that integrates multiparametric MRI information within a unified structure, offering a noninvasive method for personalized breast cancer management. We have curated the largest multiparametric breast MRI dataset, involving 5,205 patients from three hospitals in the north, southeast, and southwest of China, for the development and extensive evaluation of our model. MOME demonstrated accurate and robust identification of breast cancer. It achieved comparable performance for malignancy recognition to that of four senior radiologists and significantly outperformed a junior radiologist, with 0.913 AUROC, 0.948 AUPRC, 0.905 F1 score, and 0.723 MCC. Our findings suggest that MOME could reduce the need for biopsies in BI-RADS 4 patients with a ratio of 7.3%, classify triple-negative breast cancer with an AUROC of 0.709, and predict pathological complete response to neoadjuvant chemotherapy with an AUROC of 0.694. The model further supports scalable and interpretable inference, adapting to missing modalities and providing decision explanations by highlighting lesions and measuring modality contributions. MOME exemplifies a discriminative, robust, scalable, and interpretable multimodal model, paving the way for noninvasive …",https://arxiv.org/abs/2408.12606
Pranav Rajpurkar,ReXErr: Synthesizing Clinically Meaningful Errors in Diagnostic Radiology Reports,2024,,0,"Vishwanatha M Rao, Serena Zhang, Julian N Acosta, Subathra Adithan, Pranav Rajpurkar",Vishwanatha M Rao,Pranav Rajpurkar,5,"Accurately interpreting medical images and writing radiology reports is a critical but challenging task in healthcare. Both human-written and AI-generated reports can contain errors, ranging from clinical inaccuracies to linguistic mistakes. To address this, we introduce ReXErr, a methodology that leverages Large Language Models to generate representative errors within chest X-ray reports. Working with board-certified radiologists, we developed error categories that capture common mistakes in both human and AI-generated reports. Our approach uses a novel sampling scheme to inject diverse errors while maintaining clinical plausibility. ReXErr demonstrates consistency across error categories and produces errors that closely mimic those found in real-world scenarios. This method has the potential to aid in the development and evaluation of report correction algorithms, potentially enhancing the quality and …",https://www.worldscientific.com/doi/abs/10.1142/9789819807024_0006
Pranav Rajpurkar,Cell morphological representations of genes enhance prediction of drug targets,2024,bioRxiv,0,"Niveditha S Iyer, Daniel J Michael, SY Gordon Chi, John Arevalo, Srinivas Niranj Chandrasekaran, Anne E Carpenter, Pranav Rajpurkar, Shantanu Singh",Niveditha S Iyer,Shantanu Singh,8,"Identifying how a given chemical of interest exerts its impact on biological systems is a critical step in developing new medicines and chemical products. The mechanism of a query compound of interest can sometimes be identified when its image-based morphological profile matches a compound in a library of well-annotated compound profiles. In this study, we demonstrate a significant improvement in classification performance by incorporating side information: gene representations. We generate these representations using the morphological profiles of cells where the level of a single gene's expression has been artificially increased or decreased. The genes are selected as those encoding known protein targets of annotated compounds in the library. A transformer model is trained to classify gene-compound pairs, where each pair represents a potential interaction between a gene and a compound, as true or false. Subsequently, the model generates a ranked list of likely target genes for a previously unseen query compound. Although the strategy exhibits high performance only for compounds that target previously encountered genes - likely due to the limited size of our training dataset - the performance increase demonstrates a notable improvement over simply matching compound profiles directly to compound profiles or to gene profiles. Larger datasets may improve the prediction capabilities of this approach, enabling the prediction of gene targets for novel compounds, which can then be experimentally validated.",https://www.biorxiv.org/content/10.1101/2024.06.08.598076.abstract
Pranav Rajpurkar,Calibration and Uncertainty Estimation Challenges in Self-Supervised Chest X-ray Pathology Classification Models,2024,Medical Imaging with Deep Learning,0,"Jenny Xu, Pranav Rajpurkar",Jenny Xu,Pranav Rajpurkar,2,"Uncertainty quantification is crucial for the safe deployment of AI systems in clinical radiology. We analyze the calibration of CheXzero (Tiu et al., 2022), a high-performance self-supervised model for chest X-ray pathology detection, on two external datasets and evaluate the effectiveness of two common uncertainty estimation methods: Maximum Softmax Probabilities (MSP) and Monte Carlo Dropout. Our analysis reveals poor calibration on both external datasets, with Expected Calibration Error (ECE) scores ranging from 0.12 to 0.41. Furthermore, we find that the model’s prediction accuracy does not correlate with the uncertainty scores derived from MSP and Monte Carlo Dropout. These findings highlight the need for more robust uncertainty quantification methods to ensure the trustworthiness of AI-assisted clinical decision-making.",https://openreview.net/forum?id=PfCY5BLNHc
Pranav Rajpurkar,Systems and methods for radiology image classification from noisy images,2023,,0,"Sharon Zhou, Andrew Y Ng, Pranav Rajpurkar, Mark Sabini, Chris Wang, Nguyet Minh Phu, Amirhossein Kiani, Jeremy Irvin, Matthew Lungren",Sharon Zhou,Matthew Lungren,9,"Systems and methods for radiology image classification from noisy images in accordance with embodiments of the invention are illustrated. One embodiment includes noisy image classification device, including a processor, camera circuitry, and a memory containing a noisy image classification application, where the noisy image classification application directs the processor to obtain image data describing a first image taken of a second image using the camera circuitry, where the second image was produced by a medical imaging device, and where the first image is a noisy version of the second image, classify the image data using a neural network trained to be robust to noise, generate an investigation recommendation based on the classification, and provide the investigation recommendation via a display.",https://patents.google.com/patent/US11798159B2/en
Pranav Rajpurkar,"AI-based pathologic biomarker for pathologic downstaging in patients with muscle-invasive bladder cancer undergoing cystectomy after neoadjuvant nivolumab, gemcitabine, and cisplatin: BLAAST-1 Trial.",2023,,0,"Viswesh Krishna, Guru P Sonpavde, Sumati Gupta, Benjamin L Maughan, Neeraj Agarwal, Markus Eckstein, Matthew Mossanen, Christopher J Weight, Joaquim Bellmunt, Peter C Black, Vladimir Makarov, C Marcela Diaz-Montero, Vrishab Krishna, Waleed Abuzeid, Ekin Tiu, Damir Vrabac, Anirudh Joshi, Pranav Rajpurkar, Badrinath R Konety, Shilpa Gupta",Viswesh Krishna,Shilpa Gupta,20,"e16566Background: The BLASST-1 study is a multi-center phase II trial evaluating the combination of neoadjuvant nivolumab with gemcitabine-cisplatin (N+GC) for muscle-invasive bladder cancer (MIBC) patients undergoing radical cystectomy (RC). The primary endpoint was pathologic down staging (PaR; ≤pT1N0). We previously reported a PaR rate of 65.8% (Gupta S et al. ASCO GU 2020). Given the lack of validated and optimal biomarkers to predict PaR, we studied the association of an AI-based pathologic biomarker measuring pre-treatment morphological features with PaR. Methods: Forty-one patients with MIBC (cT2-T4a, N≤1, M0) and candidates for RC were enrolled between Feb 2018 and June 2019 (cT2N0 90%, cT3N0 7%, cT4N1 3%). Thirty-six patients had transurethral resection of bladder cancer (TURBT) with pre-treatment diagnostic specimens available for analysis. Patients received four cycles …",https://ascopubs.org/doi/abs/10.1200/JCO.2023.41.16_suppl.e16566
Pranav Rajpurkar,Development of artificial intelligence–derived histological biomarkers for first-line treatment selection in metastatic pancreatic ductal adenocarcinoma (mPDAC).,2023,,0,"Viswesh Krishna, Ekin Tiu, Vrishab Krishna, Damir Vrabac, Kunal Shah, Waleed Abuzeid, Katelyn Smith, John Davelaar, Christopher Nuesca, Brent K Larson, Christos Fountzilas, Pranav Rajpurkar, Andrew Eugene Hendifar, Eric Andrew Collisson, Anirudh Joshi, Aatur D Singhi",Viswesh Krishna,Aatur D Singhi,16,"743Background: The prognosis of metastatic pancreatic ductal adenocarcinoma (mPDAC) remains poor with a median survival time of 10-12 months. First-line treatment is largely influenced by performance status with fit patients more often receiving FOLFIRINOX (FFX) than Gemcitabine+Nab-Paclitaxel (GNP). Although the two regimens have improved outcomes over gemcitabine monotherapy, no biomarkers routinely used in clinical practice can predict which regimen is optimal to facilitate a precision medicine approach. We developed two signatures (V-FFX and V-GNP) associated with treatment outcomes for the respective first-line regimens using a retrospective cohort of mPDAC cases. Methods: We conducted a retrospective study of mPDAC patients treated at two institutions (UPMC and Cedars Sinai) from 2014 to 2021. Digitized histological H&E sections corresponding to 145 metastatic PDAC patients …",https://ascopubs.org/doi/abs/10.1200/JCO.2023.41.4_suppl.743
Pranav Rajpurkar,Machine learning analysis for metabolomics classification and biomarker discovery,2022,,0,"Catherine Hogan, Pranav Rajpurkar, Benjamin Alan Pinsky, Anthony T Le",Catherine Hogan,Anthony T Le,4,"The present invention relates to systems, methods and devices for metabolomic-based classification of biological samples, and interpretation methods for biomarker discov ery.",https://patents.google.com/patent/US20220084636A1/en
Pranav Rajpurkar,Targeted plasma metabolomics combined with machine learning for the diagnosis of severe acute respiratory syndrome virus type 2,2022,Frontiers in Microbiology,0,"Anthony T Le, Manhong Wu, Afraz Khan, Nicholas Phillips, Pranav Rajpurkar, Megan Garland, Kayla Magid, Mamdouh Sibai, ChunHong Huang, Malaya K Sahoo, Raffick Bowen, Tina M Cowan, Benjamin A Pinsky, Catherine A Hogan",Anthony T Le,Catherine A Hogan,14,,
Pranav Rajpurkar,CXR-PRO: MIMIC-CXR with Prior References Omitted,2022,,0,"Vignav Ramesh, Nathan Chi, Pranav Rajpurkar",Vignav Ramesh,Pranav Rajpurkar,3,"CXR-PRO is an adaptation of the MIMIC-CXR dataset that omits references to prior radiology reports. Consisting of 374,139 free-text radiology reports and associated chest radiographs, CXR-PRO addresses the issue of hallucinated references to priors produced by radiology report generation models. By removing nearly all prior references in MIMIC-CXR, CXR-PRO, when used as training data for report generation models, is capable of broadly improving the factual consistency and accuracy of generated reports. More generally, this dataset aims to support a wide body of research in medical image analysis and natural language processing. MIMIC-CXR is a de-identified dataset, so no protected health information (PHI) is included.",https://physionet.org/content/cxr-pro/
Pranav Rajpurkar,DEVELOPMENT AND VALIDATION OF AN ARTIFICIAL INTELLIGENCE SYSTEM TO OPTIMIZE CLINICIAN REVIEW OF PATIENT RECORDS,2021,Gastroenterology,0,"Ethan A Chi, Gordon Chi, Cheuk To Tsui, Yan Jiang, Karolin Jarr, Chiraag Kulkarni, Michael Zhang, Jin Long, Andrew Ng, Pranav Rajpurkar, Sidhartha R Sinha",Ethan A Chi,Sidhartha R Sinha,11,,
Pranav Rajpurkar,ReXPref-Prior: A MIMIC-CXR Preference Dataset for Reducing Hallucinated Prior Exams in Radiology Report Generation,,,0,"Oishi Banerjee, Hong-Yu Zhou, Subathra Adithan, Stephen Kwak, Kay Wu, Pranav Rajpurkar",Oishi Banerjee,Pranav Rajpurkar,6,"Generative vision-language models have exciting potential implications for radiology report generation, but unfortunately such models are also known to produce hallucinations and other nonsensical statements. For example, radiology report generation models regularly hallucinate prior exams, making statements such as “The lungs are hyperinflated with emphysematous changes as seen on prior CT” despite not having access to any prior exam. To address this shortcoming, we propose ReXPref-Prior, an adapted version of MIMIC-CXR where GPT-4 has removed references to prior exams from both findings and impression sections of chest X-ray reports. We expect ReXPref-Prior will be useful for training models that hallucinate prior exams less frequently, through techniques such as direct preference optimization. Additionally, ReXPref-Prior’s validation and test sets can be used as a new benchmark for evaluating report generation models.",https://physionet.org/content/rexpref-prior/1.0.0/
Pranav Rajpurkar,RadGraph2: Tracking Findings Over Time in Radiology Reports,,,0,"Adam Dejl, Sameer Khanna, Patricia Therese Pile, Kibo Yoon, Steven QH Truong, Hanh Duong, Agustina Saenz, Pranav Rajpurkar",Adam Dejl,Pranav Rajpurkar,8,"RadGraph2 is a dataset of 800 chest radiology reports annotated using a fine-grained entity-relationship schema, which is an expanded version of the previously introduced RadGraph dataset. In contrast with the previous approaches and the original RadGraph, the new version of the used information extraction schema is designed to capture not only the key findings and their context but also the mentions of changes that occurred between the prior radiology examinations and the more recent study. These changes may include the appearance of new conditions affecting the patient, their progression, or the differences in the setup of the observed supporting devices. The information extracted from each report is represented in the form of a knowledge graph composed of clinically relevant entities and relations, which makes it easily amenable to automated processing. In addition to the dataset of manually labeled reports, we release more than 220,000 reports automatically annotated by our benchmark model. This model achieved an F1 micro performance of 0.88 and 0.74 on two differently sourced withheld test sets (from MIMIC-CXR-JPG and CheXpert, respectively). We believe that RadGraph2 could facilitate the development of clinically useful systems for the automated processing of radiology reports, particularly those reasoning about the evolution of a patient’s state over time.",https://physionet.org/content/radgraph2-radiology-reports/
Michael F. Bonner,Converging evidence for the neuroanatomic basis of combinatorial semantics in the angular gyrus,2015,Journal of Neuroscience,309,"Amy R Price, Michael F Bonner, Jonathan E Peelle, Murray Grossman",Amy R Price,Murray Grossman,4,"Human thought and language rely on the brain's ability to combine conceptual information. This fundamental process supports the construction of complex concepts from basic constituents. For example, both “jacket” and “plaid” can be represented as individual concepts, but they can also be integrated to form the more complex representation “plaid jacket.” Although this process is central to the expression and comprehension of language, little is known about its neural basis. Here we present evidence for a neuroanatomic model of conceptual combination from three experiments. We predicted that the highly integrative region of heteromodal association cortex in the angular gyrus would be critical for conceptual combination, given its anatomic connectivity and its strong association with semantic memory in functional neuroimaging studies. Consistent with this hypothesis, we found that the process of combining …",https://www.jneurosci.org/content/35/7/3276.short
Michael F. Bonner,Where is the anterior temporal lobe and what does it do?,2013,Journal of Neuroscience,222,"Michael F Bonner, Amy R Price",Michael F Bonner,Amy R Price,2,"The anterior temporal lobe (ATL) is thought to be critical for semantic memory–our knowledge of objects, people, words, and facts. However, there is substantial disagreement over the precise role of the ATL in semantic memory, and there is considerable variability in the anatomic findings that link the ATL with semantic processing. The inconsistent findings across studies may be related to the diverse anatomic structures within the ATL and their differential contribution to distinct modalities of semantic information (eg, visual, auditory, affective).Much of the evidence implicating the ATL in semantic memory has come from neuropsychology. In particular, patients with semantic dementia, a neurodegenerative disease affecting the ATL, exhibit a profound deficit in semantic knowledge with a relative sparing of most other cognitive domains (Warrington, 1975; Patterson et al., 2007). These patients have little trouble …",https://www.jneurosci.org/content/33/10/4213.short
Michael F. Bonner,Heteromodal conceptual processing in the angular gyrus,2013,Neuroimage,220,"Michael F Bonner, Jonathan E Peelle, Philip A Cook, Murray Grossman",Michael F Bonner,Murray Grossman,4,"Concepts bind together the features commonly associated with objects and events to form networks in long-term semantic memory. These conceptual networks are the basis of human knowledge and underlie perception, imagination, and the ability to communicate about experiences and the contents of the environment. Although it is often assumed that this distributed semantic information is integrated in higher-level heteromodal association cortices, open questions remain about the role and anatomic basis of heteromodal representations in semantic memory. Here we used combined neuroimaging evidence from functional magnetic resonance imaging (fMRI) and diffusion tensor imaging (DTI) to characterize the cortical networks underlying concept representation. Using a lexical decision task, we examined the processing of concepts in four semantic categories that varied on their sensory–motor feature …",https://www.sciencedirect.com/science/article/pii/S1053811913000372
Michael F. Bonner,"The new classification of primary progressive aphasia into semantic, logopenic, or nonfluent/agrammatic variants",2010,,200,"Michael F Bonner, Sharon Ash, Murray Grossman",Michael F Bonner,Murray Grossman,3,"Primary progressive aphasia (PPA), typically resulting from a neurodegenerative disease such as frontotemporal lobar degeneration or Alzheimer’s disease, is characterized by a progressive loss of specific language functions with relative sparing of other cognitive domains. Three variants of PPA are now recognized: semantic variant, logopenic variant, and nonfluent/agrammatic variant. We discuss recent work characterizing the neurolinguistic, neuropsychological, imaging and pathologic profiles associated with these variants. Improved reliability of diagnoses will be increasingly important as trials for etiology-specific treatments become available. We also discuss the implications of these syndromes for theories of language function.",https://link.springer.com/article/10.1007/s11910-010-0140-4
Michael F. Bonner,Coding of navigational affordances in the human visual system,2017,Proceedings of the National Academy of Sciences,185,"Michael F Bonner, Russell A Epstein",Michael F Bonner,Russell A Epstein,2,"A central component of spatial navigation is determining where one can and cannot go in the immediate environment. We used fMRI to test the hypothesis that the human visual system solves this problem by automatically identifying the navigational affordances of the local scene. Multivoxel pattern analyses showed that a scene-selective region of dorsal occipitoparietal cortex, known as the occipital place area, represents pathways for movement in scenes in a manner that is tolerant to variability in other visual features. These effects were found in two experiments: One using tightly controlled artificial environments as stimuli, the other using a diverse set of complex, natural scenes. A reconstruction analysis demonstrated that the population codes of the occipital place area could be used to predict the affordances of novel scenes. Taken together, these results reveal a previously unknown mechanism for perceiving …",https://www.pnas.org/doi/abs/10.1073/pnas.1618228114
Michael F. Bonner,Causal evidence for a mechanism of semantic integration in the angular gyrus as revealed by high-definition transcranial direct current stimulation,2016,Journal of Neuroscience,158,"Amy Rose Price, Jonathan E Peelle, Michael F Bonner, Murray Grossman, Roy H Hamilton",Amy Rose Price,Roy H Hamilton,5,"A defining aspect of human cognition is the ability to integrate conceptual information into complex semantic combinations. For example, we can comprehend “plaid” and “jacket” as individual concepts, but we can also effortlessly combine these concepts to form the semantic representation of “plaid jacket.” Many neuroanatomic models of semantic memory propose that heteromodal cortical hubs integrate distributed semantic features into coherent representations. However, little work has specifically examined these proposed integrative mechanisms and the causal role of these regions in semantic integration. Here, we test the hypothesis that the angular gyrus (AG) is critical for integrating semantic information by applying high-definition transcranial direct current stimulation (tDCS) to an fMRI-guided region-of-interest in the left AG. We found that anodal stimulation to the left AG modulated semantic integration but …",https://www.jneurosci.org/content/36/13/3829.short
Michael F. Bonner,Reversal of the concreteness effect in semantic dementia,2009,Cognitive Neuropsychology,156,"Michael F Bonner, Luisa Vesely, Catherine Price, Chivon Anderson, Lauren Richmond, Christine Farag, Brian Avants, Murray Grossman",Michael F Bonner,Murray Grossman,8,"Patients with semantic dementia (SD) have a striking impairment in semantic memory, but the basis for this deficit is unclear. We examined semantic memory for concrete and abstract verbs with a two-alternative, forced-choice measure of lexical semantic associative knowledge. Patients with SD had significantly greater difficulty with concrete verbs (z = –3.33) than with abstract verbs (z = –2.05), a “reversal of the concreteness effect” that was present in a majority of individual patients. The subgroup of SD patients with imaging had significant cortical thinning in the anterior and inferolateral portions of the temporal lobes. These areas of visual association cortex may be important for storing and processing visual features for word meaning. Moreover, poor performance with concrete relative to abstract verbs correlated with cortical thinning of the right anterior temporal lobe in SD, suggesting that this region may …",https://www.tandfonline.com/doi/abs/10.1080/02643290903512305
Michael F. Bonner,Computational mechanisms underlying cortical responses to the affordance properties of visual scenes,2018,PLoS computational biology,90,"Michael F Bonner, Russell A Epstein",Michael F Bonner,Russell A Epstein,2,"Biologically inspired deep convolutional neural networks (CNNs), trained for computer vision tasks, have been found to predict cortical responses with remarkable accuracy. However, the internal operations of these models remain poorly understood, and the factors that account for their success are unknown. Here we develop a set of techniques for using CNNs to gain insights into the computational mechanisms underlying cortical responses. We focused on responses in the occipital place area (OPA), a scene-selective region of dorsal occipitoparietal cortex. In a previous study, we showed that fMRI activation patterns in the OPA contain information about the navigational affordances of scenes; that is, information about where one can and cannot move within the immediate environment. We hypothesized that this affordance information could be extracted using a set of purely feedforward computations. To test this idea, we examined a deep CNN with a feedforward architecture that had been previously trained for scene classification. We found that responses in the CNN to scene images were highly predictive of fMRI responses in the OPA. Moreover the CNN accounted for the portion of OPA variance relating to the navigational affordances of scenes. The CNN could thus serve as an image-computable candidate model of affordance-related responses in the OPA. We then ran a series of in silico experiments on this model to gain insights into its internal operations. These analyses showed that the computation of affordance-related features relied heavily on visual information at high-spatial frequencies and cardinal orientations, both of which have …",https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006111
Michael F. Bonner,The roles of low literacy and social support in predicting the preventability of hospital admission,2006,Journal of general internal medicine,89,"Ahsan M Arozullah, Shoou‐Yih D Lee, Taha Khan, Sindhu Kurup, Jeffrey Ryan, Michael Bonner, Robert Soltysik, Paul R Yarnold",Ahsan M Arozullah,Paul R Yarnold,8,"BACKGROUND:  Prior studies found higher hospitalization rates among patients with low literacy, but did not determine the preventability of these admissions or consider other determinants of hospitalization, such as social support. This study evaluated whether low literacy was a predictor for preventability of hospitalization when considered in the context of social support, sociodemographics, health status, and risk behaviors.METHODS:  A convenience sample of 400 patients, admitted to general medicine wards in a university‐affiliated Veterans Affairs hospital between August 1, 2001 and April 1, 2003, completed a face‐to‐face interview to assess literacy, sociodemographics, social support, health status, and risk behaviors. Two Board‐certified Internists independently assessed preventability of hospitalization and determined the primary preventable cause through blinded medical chart reviews.RESULTS …",https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1525-1497.2005.00300.x
Michael F. Bonner,Object representations in the human brain reflect the co-occurrence statistics of vision and language,2021,Nature communications,88,"Michael F Bonner, Russell A Epstein",Michael F Bonner,Russell A Epstein,2,"A central regularity of visual perception is the co-occurrence of objects in the natural environment. Here we use machine learning and fMRI to test the hypothesis that object co-occurrence statistics are encoded in the human visual system and elicited by the perception of individual objects. We identified low-dimensional representations that capture the latent statistical structure of object co-occurrence in real-world scenes, and we mapped these statistical representations onto voxel-wise fMRI responses during object viewing. We found that cortical responses to single objects were predicted by the statistical ensembles in which they typically occur, and that this link between objects and their visual contexts was made most strongly in parahippocampal cortex, overlapping with the anterior portion of scene-selective parahippocampal place area. In contrast, a language-based statistical model of the co-occurrence of …",https://www.nature.com/articles/s41467-021-24368-2
Michael F. Bonner,Gray matter density of auditory association cortex relates to knowledge of sound concepts in primary progressive aphasia,2012,Journal of Neuroscience,88,"Michael F Bonner, Murray Grossman",Michael F Bonner,Murray Grossman,2,"Long-term memory integrates the multimodal information acquired through perception into unified concepts, supporting object recognition, thought, and language. While some theories of human cognition have considered concepts to be abstract symbols, recent functional neuroimaging evidence has supported an alternative theory: that concepts are multimodal representations associated with the sensory and motor systems through which they are acquired. However, few studies have examined the effects of cortical lesions on the sensory and motor associations of concepts. We tested the hypothesis that individuals with disease in auditory association cortex would have difficulty processing concepts with strong sound associations (e.g., thunder). Human participants with the logopenic variant of primary progressive aphasia (lvPPA) performed a recognition task on words with strong associations in three modalities …",https://www.jneurosci.org/content/32/23/7986.short
Michael F. Bonner,HP1 proteins are essential for a dynamic nuclear response that rescues the function of perturbed heterochromatin in primary human cells,2007,Molecular and Cellular Biology,84,"Rugang Zhang, Song-tao Liu, Wei Chen, Michael Bonner, John Pehrson, Timothy J Yen, Peter D Adams",Rugang Zhang,Peter D Adams,7,"Cellular information is encoded genetically in the DNA nucleotide sequence and epigenetically by the “histone code,” DNA methylation, and higher-order packaging of DNA into chromatin. Cells possess intricate mechanisms to sense and repair damage to DNA and the genetic code. However, nothing is known of the mechanisms, if any, that repair and/or compensate for damage to epigenetically encoded information, predicted to result from perturbation of DNA and histone modifications or other changes in chromatin structure. Here we show that primary human cells respond to a variety of small molecules that perturb DNA and histone modifications by recruiting HP1 proteins to sites of altered pericentromeric heterochromatin. This response is essential to maintain the HP1-binding kinetochore protein hMis12 at kinetochores and to suppress catastrophic mitotic defects. Recruitment of HP1 proteins to …",https://www.tandfonline.com/doi/abs/10.1128/mcb.01639-06
Michael F. Bonner,Category-specific semantic memory: converging evidence from bold fMRI and Alzheimer's disease,2013,Neuroimage,63,"Murray Grossman, Jonathan E Peelle, Edward E Smith, Corey T McMillan, Philip Cook, John Powers, Michael Dreyfuss, Michael F Bonner, Lauren Richmond, Ashley Boller, Emily Camp, Lisa Burkholder",Murray Grossman,Lisa Burkholder,12,"Patients with Alzheimer's disease have category-specific semantic memory difficulty for natural relative to manufactured objects. We assessed the basis for this deficit by asking healthy adults and patients to judge whether pairs of words share a feature (e.g. “banana:lemon—COLOR”). In an fMRI study, healthy adults showed gray matter (GM) activation of temporal–occipital cortex (TOC) where visual–perceptual features may be represented, and prefrontal cortex (PFC) which may contribute to feature selection. Tractography revealed dorsal and ventral stream white matter (WM) projections between PFC and TOC. Patients had greater difficulty with natural than manufactured objects. This was associated with greater overlap between diseased GM areas correlated with natural kinds in patients and fMRI activation in healthy adults for natural kinds. The dorsal WM projection between PFC and TOC in patients correlated …",https://www.sciencedirect.com/science/article/pii/S105381191201169X
Michael F. Bonner,Preserved musical semantic memory in semantic dementia,2011,Archives of Neurology,61,"Jessica Weinstein, Phyllis Koenig, Delani Gunawardena, Corey McMillan, Michael Bonner, Murray Grossman",Jessica Weinstein,Murray Grossman,6,"To understand the scope of semantic impairment in semantic dementia.Case study.Academic medical center.A man with semantic dementia, as demonstrated by clinical, neuropsychological, and imaging studies.Music performance and magnetic resonance imaging results.Despite profoundly impaired semantic memory for words and objects due to left temporal lobe atrophy, this semiprofessional musician was creative and expressive in demonstrating preserved musical knowledge.Long-term representations of words and objects in semantic memory may be dissociated from meaningful knowledge in other domains, such as music.",https://jamanetwork.com/journals/jamaneurology/article-abstract/802250
Michael F. Bonner,Hierarchical organization of scripts: converging evidence from FMRI and frontotemporal degeneration,2010,Cerebral Cortex,58,"Christine Farag, Vanessa Troiani, Michael Bonner, Chivon Powers, Brian Avants, James Gee, Murray Grossman",Christine Farag,Murray Grossman,7,"The present study examined the organization of complex familiar activities, known as “scripts” (e.g., “going fishing”). We assessed whether events in a script are processed in a linear-sequential manner or clustered-hierarchical manner, and we evaluated the neural basis for this processing capacity. Converging evidence was obtained from functional neuroimaging in healthy young adults and from behavioral and structural magnetic resonance imaging (MRI) data in patients with focal neurodegenerative disease. In both studies, participants judged the order of consecutive event pairs taken from a script. Event pairs either were clustered together within a script or were from different clusters within the script. Controls judged events more accurately and quickly if taken from the same cluster within a script compared with different clusters, even though all event pairs were consecutive, consistent with the hierarchical …",https://academic.oup.com/cercor/article-abstract/20/10/2453/317746
Michael F. Bonner,Unveiling functions of the visual cortex using task-specific deep neural networks,2021,PLoS computational biology,43,"Kshitij Dwivedi, Michael F Bonner, Radoslaw Martin Cichy, Gemma Roig",Kshitij Dwivedi,Gemma Roig,4,"The human visual cortex enables visual perception through a cascade of hierarchical computations in cortical regions with distinct functionalities. Here, we introduce an AI-driven approach to discover the functional mapping of the visual cortex. We related human brain responses to scene images measured with functional MRI (fMRI) systematically to a diverse set of deep neural networks (DNNs) optimized to perform different scene perception tasks. We found a structured mapping between DNN tasks and brain regions along the ventral and dorsal visual streams. Low-level visual tasks mapped onto early brain regions, 3-dimensional scene perception tasks mapped onto the dorsal stream, and semantic tasks mapped onto the ventral stream. This mapping was of high fidelity, with more than 60% of the explainable variance in nine key regions being explained. Together, our results provide a novel functional mapping of the human visual cortex and demonstrate the power of the computational approach.",https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009267
Michael F. Bonner,Semantics of the visual environment encoded in parahippocampal cortex,2016,Journal of cognitive neuroscience,41,"Michael F Bonner, Amy Rose Price, Jonathan E Peelle, Murray Grossman",Michael F Bonner,Murray Grossman,4,"Semantic representations capture the statistics of experience and store this information in memory. A fundamental component of this memory system is knowledge of the visual environment, including knowledge of objects and their associations. Visual semantic information underlies a range of behaviors, from perceptual categorization to cognitive processes such as language and reasoning. Here we examine the neuroanatomic system that encodes visual semantics. Across three experiments, we found converging evidence indicating that knowledge of verbally mediated visual concepts relies on information encoded in a region of the ventral-medial temporal lobe centered on parahippocampal cortex. In an fMRI study, this region was strongly engaged by the processing of concepts relying on visual knowledge but not by concepts relying on other sensory modalities. In a study of patients with the semantic …",https://direct.mit.edu/jocn/article-abstract/28/3/361/28501
Michael F. Bonner,High-performing neural network models of visual cortex benefit from high latent dimensionality,2024,PLOS Computational Biology,39,"Eric Elmoznino, Michael F Bonner",Eric Elmoznino,Michael F Bonner,2,"Geometric descriptions of deep neural networks (DNNs) have the potential to uncover core representational principles of computational models in neuroscience. Here we examined the geometry of DNN models of visual cortex by quantifying the latent dimensionality of their natural image representations. A popular view holds that optimal DNNs compress their representations onto low-dimensional subspaces to achieve invariance and robustness, which suggests that better models of visual cortex should have lower dimensional geometries. Surprisingly, we found a strong trend in the opposite direction—neural networks with high-dimensional image subspaces tended to have better generalization performance when predicting cortical responses to held-out stimuli in both monkey electrophysiology and human fMRI data. Moreover, we found that high dimensionality was associated with better performance when learning new categories of stimuli, suggesting that higher dimensional representations are better suited to generalize beyond their training domains. These findings suggest a general principle whereby high-dimensional geometry confers computational benefits to DNN models of visual cortex.",https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011792
Michael F. Bonner,Similarly oriented objects appear more numerous,2020,Journal of Vision,37,"Nicholas K DeWind, Michael F Bonner, Elizabeth M Brannon",Nicholas K DeWind,Elizabeth M Brannon,3,"Several non-numerical factors influence the numerical estimation of visual arrays, including the spacing of items and whether they are arranged randomly or symmetrically. Here we report a novel numerosity illusion we term the coherence illusion. When items in an array have a coherent orientation (all pointing in the same direction) they seem to be more numerous than when items are oriented randomly. Participants show parametric effects of orientation coherence in three distinct numerical judgment tasks. These findings are not predicted by any current model of numerical estimation. We discuss array entropy as a possible framework for explaining both the coherence illusion and the previously reported regular-random illusion.",https://jov.arvojournals.org/article.aspx?articleid=2764422
Michael F. Bonner,Hierarchical organization of social action features along the lateral visual pathway,2023,Current Biology,36,"Emalie McMahon, Michael F Bonner, Leyla Isik",Emalie McMahon,Leyla Isik,3,"Recent theoretical work has argued that in addition to the classical ventral (what) and dorsal (where/how) visual streams, there is a third visual stream on the lateral surface of the brain specialized for processing social information. Like visual representations in the ventral and dorsal streams, representations in the lateral stream are thought to be hierarchically organized. However, no prior studies have comprehensively investigated the organization of naturalistic, social visual content in the lateral stream. To address this question, we curated a naturalistic stimulus set of 250 3-s videos of two people engaged in everyday actions. Each clip was richly annotated for its low-level visual features, mid-level scene and object properties, visual social primitives (including the distance between people and the extent to which they were facing), and high-level information about social interactions and affective content. Using a …",https://www.cell.com/current-biology/fulltext/S0960-9822(23)01373-8
Michael F. Bonner,Neural coding of fine-grained object knowledge in perirhinal cortex,2017,BioRxiv,31,"Amy Rose Price, Michael F Bonner, Jonathan E Peelle, Murray Grossman",Amy Rose Price,Murray Grossman,4,"Over 40 years of research has examined the role of the ventral visual stream in transforming retinal inputs into high-level representations of object identity [–]. However, there remains an ongoing debate over the role of the ventral stream in coding abstract semantic content, which relies on stored knowledge, versus perceptual content that relies only on retinal inputs [–]. A major difficulty in adjudicating between these mechanisms is that the semantic similarity of objects is often highly confounded with their perceptual similarity (e.g., animate things are more perceptually similar to other animate things than to inanimate things). To address this problem, we developed a paradigm that exploits the statistical regularities of object colors while perfectly controlling for perceptual shape information, allowing us to dissociate lower-level perceptual features (i.e., color perception) from higher-level semantic knowledge (i.e., color meaning). Using multivoxel-pattern analyses of fMRI data, we observed a striking double dissociation between the processing of color information at a perceptual and at a semantic level along the posterior to anterior axis of the ventral visual pathway. Specifically, we found that the visual association region V4 assigned similar representations to objects with similar colors, regardless of object category. In contrast, perirhinal cortex, at the apex of the ventral visual stream, assigned similar representations to semantically similar objects, even when this was in opposition to their perceptual similarity. These findings suggest that perirhinal cortex untangles the representational space of lower-level perceptual features and organizes visual …",https://www.biorxiv.org/content/10.1101/194829.abstract
Michael F. Bonner,Semantic memory: cognitive and neuroanatomical perspectives,2015,"Brain mapping an encyclopedic reference. Academic Press: Elsevier, Amsterdam",24,"AR Price, MF Bonner, M Grossman",AR Price,M Grossman,3,"Nothing, at first view, may seem more unbounded than the thought of man, which not only escapes all human power and authority, but is not even restrained within the limits of nature and reality. To form monsters, and join incongruous shapes and appearances, costs the imagination no more trouble than to conceive the most natural and familiar objects. But though our thought seems to possess this unbounded liberty, we shall find, upon a nearer examination, that it is really confined within very narrow limits, and that all this creative power of the mind amounts to no more than the faculty of compounding, transposing, augmenting, or diminishing the materials afforded us by the senses and experience. David Hume, 1777",https://scholar.google.com/scholar?cluster=2591807190845372012&hl=en&oi=scholarr
Michael F. Bonner,Perceived distance alters memory for scene boundaries,2022,Psychological Science,18,"Alon Hafri, Shreya Wadhwa, Michael F Bonner",Alon Hafri,Michael F Bonner,3,"Memory often fills in what is not there. A striking example of this is boundary extension, whereby observers mistakenly recall a view that extends beyond what was seen. However, not all visual memories extend in this way, which suggests that this process depends on specific scene properties. What factors determine when visual memories will include details that go beyond perceptual experience? Here, seven experiments (N = 1,100 adults) explored whether spatial scale—specifically, perceived viewing distance—drives boundary extension. We created fake miniatures by exploiting tilt shift, a photographic effect that selectively reduces perceived distance while preserving other scene properties (e.g., making a distant railway appear like a model train). Fake miniaturization increased boundary extension for otherwise identical scenes: Participants who performed a scene-memory task misremembered fake …",https://journals.sagepub.com/doi/abs/10.1177/09567976221093575
Michael F. Bonner,Early electrophysiological markers of navigational affordances in scenes,2022,,16,"Assaf Harel, Jeffery D Nador, Michael F Bonner, Russell A Epstein",Assaf Harel,Russell A Epstein,4,"Scene perception and spatial navigation are interdependent cognitive functions,                     and there is increasing evidence that cortical areas that process perceptual                     scene properties also carry information about the potential for navigation in                     the environment (navigational affordances). However, the temporal stages by                     which visual information is transformed into navigationally relevant information                     are not yet known. We hypothesized that navigational affordances are encoded                     during perceptual processing and therefore should modulate early visually evoked                     ERPs, especially the scene-selective P2 component. To test this idea, we                     recorded ERPs from participants while they passively viewed computer-generated                     room scenes matched in visual complexity. By simply changing the number of doors                     (0 doors, 1 …",https://direct.mit.edu/jocn/article-abstract/34/3/397/109068
Michael F. Bonner,Scene memories are biased toward high-probability views.,2022,Journal of Experimental Psychology: Human Perception and Performance,10,"Feikai Lin, Alon Hafri, Michael F Bonner",Feikai Lin,Michael F Bonner,3,"Visual scenes are often remembered as if they were observed from a different viewpoint. Some scenes are remembered as farther than they appeared, and others as closer. These memory distortions—also known as boundary extension and contraction—are strikingly consistent for a given scene, but their cause remains unknown. We tested whether these distortions can be explained by an inferential process that adjusts scene memories toward high-probability views, using viewing depth as a test case. We first carried out a large-scale analysis of depth maps of natural indoor scenes to quantify the statistical probability of views in depth. We then assessed human observers’ memory for these scenes at various depths and found that viewpoint judgments were consistently biased toward the modal depth, even when just a few seconds elapsed between viewing and reporting. Thus, scenes closer than the modal depth …",https://psycnet.apa.org/record/2022-92424-001
Michael F. Bonner,Curvature as an organizing principle of mid-level visual representation: a semantic-preference mapping approach,2020,NeurIPS 2020 Workshop SVRHM,10,"Shi Pui Donald Li, Michael Bonner",Shi Pui Donald Li,Michael Bonner,2,"A central challenge in visual neuroscience is understanding the mid-level representations of the ventral stream. We used a novel, data-driven approach (semantic-preference mapping) combined with an image-statistics approach (curvature index) to characterize the mid-level features of category-selective visual regions. First, we fit voxelwise encoding models using a deep convolutional neural network (DCNN) to predict scene-evoked fMRI responses in object-selective and scene-selective regions. We then performed semantic-preference mapping to examine how the responses of these encoding models changed when specific object classes were removed from natural images. This analysis motivated the hypothesis that object-selective cortex model is best predicted by mid-level features with curved contours, while scene-selective cortex model is best predicted by mid-level features with rectilinear contours. We further developed an image-computable model that outputs a summary statistic for the prevalence of curved contours in local image patches, and we used this model to demonstrate the importance of curvature-preferences for linking DCNN representations with the representations of category-selective cortex models. Overall, our findings suggest that curvature is a key property of the mid-level representations that are shared between DCNNs and category-selective cortex models of the ventral visual stream.",https://openreview.net/forum?id=CUi1G2UWsAm
Michael F. Bonner,Free association in semantic dementia: The importance of being abstract,2007,Brain and Language,10,"Luisa Vesely, Michael F Bonner, Jamie Reilly, Murray Grossman",Luisa Vesely,Murray Grossman,4,"Free association in semantic dementia: The importance of being abstract × Close The 
Infona portal uses cookies, ie strings of text saved by a browser on the user's device. The 
portal can access those files and use them to remember the user's data, such as their 
chosen settings (screen view, interface language, etc.), or their login data. By using the 
Infona portal the user accepts automatic saving and using this information for portal 
operation purposes. More information on the subject can be found in the Privacy Policy and 
Terms of Service. By closing this window the user confirms that they have read the 
information on cookie usage, and they accept the privacy policy and the way cookies are 
used by the portal. You can change the cookie settings in your browser. I accept Polski 
English Login or register account remember me Password recovery INFONA - science 
communication portal INFONA Search advanced search …",https://www.infona.pl/resource/bwmeta1.element.elsevier-1edf76ed-44ef-3890-8c1a-31c332d18501
Michael F. Bonner,"Emergent selectivity for scenes, object properties, and contour statistics in feedforward models of scene-preferring cortex",2021,,7,"Donald Shi Pui Li, Michael F Bonner",Donald Shi Pui Li,Michael F Bonner,2,"The scene-preferring portion of the human ventral visual stream, known as the parahippocampal place area (PPA), responds to scenes and landmark objects, which tend to be large in real-world size, fixed in location, and inanimate. However, the PPA also exhibits preferences for low-level contour statistics, including rectilinearity and cardinal orientations, that are not directly predicted by theories of scene-and landmark-selectivity. It is unknown whether these divergent findings of both low-and high-level selectivity in the PPA can be explained by a unified computational theory. To address this issue, we fit feedforward computational models of visual feature coding to the image-evoked fMRI responses of the PPA, and we performed a series of high-throughput experiments on these models. Our findings show that feedforward models of the PPA exhibit emergent selectivity across multiple levels of complexity, giving rise to seemingly high-level preferences for scenes and for objects that are large, spatially fixed, and inanimate/manmade while simultaneously yielding low-level preferences for rectilinear shapes and cardinal orientations. These results reconcile disparate theories of PPA function in a unified model of feedforward feature coding, and they demonstrate how multifaceted selectivity profiles naturally emerge from the feedforward computations of visual cortex and the natural statistics of images.",https://europepmc.org/article/ppr/ppr400214
Michael F. Bonner,The neural basis of semantic memory,2013,,7,"Michael F Bonner, Murray Grossman",Michael F Bonner,Murray Grossman,2,"The theory of reserve against brain insult arose to explain individuals who continue to function clinically despite brain pathology. In an early example, the brains  of 10 cognitively normal elderly women were found to have Alzheimer’s plaques  at autopsy (Katzman et al., 1988). These women’s brains were heavier and contained more neurons, which were thought to provide ‘reserve’ which helped the  women to function despite their pathology. Indeed, later studies have found that  25% to 67% of subjects characterized as cognitively normal throughout longitudinal assessments meet pathological criteria for dementia at autopsy (Crystal et al.,  1988; Ince, 2001; Morris et al., 1996; Mortimer, Snowdon, & Markesbery, 2003;  Price & Morris, 1999).",https://api.taylorfrancis.com/content/chapters/edit/download?identifierName=doi&identifierValue=10.4324/9781315851730-16&type=chapterpdf
Michael F. Bonner,A phone in a basket looks like a knife in a cup: The perception of abstract relations,2021,PsyArXiv,6,"Alon Hafri, Michael F Bonner, Barbara Landau, Chaz Firestone",Alon Hafri,Chaz Firestone,4,"The world contains not only objects and features, but also relations between them. When a piece of fruit is in a bowl, and the bowl is on a table, we appreciate not only the individual objects and their features, but also the relations containment and support, which abstract away from the particular objects involved. How does the mind represent relations themselves, separately from the objects participating in them? Though abstraction of this sort is frequently studied within the domains of language and higher-level reasoning, here we show that abstract relations may also arise in automatic visual processing, by exploring a surprising perceptual “error” that such relations can produce. In four experiments, participants saw a stream of images containing different objects arranged in forcedynamic relations—eg, a phone contained inside a basket, a marker resting on a garbage can, or a knife sitting inside a cup. Participants’ task was to respond to a single target image (eg, phone-inbasket) within the stream of distractors. Surprisingly, even though participants completed this task quickly and accurately, they false-alarmed more often to images that matched the target’s relational category than to those that did not—even when such images involved completely different objects. In other words, when participants were searching for a phone in a basket, they were more likely to mistakenly respond to a knife in a cup than to a marker on a garbage can. Follow-up experiments using this “image confusion” paradigm ruled out strategic responding, and also controlled for various image features that may have been confounded with these relations. We suggest that …",https://files.osf.io/v1/resources/jx4yg/providers/osfstorage/5eb1c79369d3e10195de9e6d?action=download&direct&version=5
Michael F. Bonner,A phone in a basket looks like a knife in a cup: Role-filler independence in visual processing,2024,Open Mind,3,"Alon Hafri, Michael F Bonner, Barbara Landau, Chaz Firestone",Alon Hafri,Chaz Firestone,4,"When a piece of fruit is in a bowl, and the bowl is on a table, we appreciate not only the individual objects and their features, but also the relations containment and support, which abstract away from the particular objects involved. Independent representation of roles (e.g., containers vs. supporters) and “fillers” of those roles (e.g., bowls vs. cups, tables vs. chairs) is a core principle of language and higher-level reasoning. But does such role-filler independence also arise in automatic visual processing? Here, we show that it does, by exploring a surprising error that such independence can produce. In four experiments, participants saw a stream of images containing different objects arranged in force-dynamic relations—e.g., a phone contained in a basket, a marker resting on a garbage can, or a knife sitting in a cup. Participants had to respond to a single target image (e.g., a phone in a basket) within a stream of …",https://direct.mit.edu/opmi/article/doi/10.1162/opmi_a_00146/123216
Michael F. Bonner,Universal dimensions of visual representation,2024,arXiv preprint arXiv:2408.12804,2,"Zirui Chen, Michael F Bonner",Zirui Chen,Michael F Bonner,2,"Do neural network models of vision learn brain-aligned representations because they share architectural constraints and task objectives with biological vision or because they learn universal features of natural image processing? We characterized the universality of hundreds of thousands of representational dimensions from visual neural networks with varied construction. We found that networks with varied architectures and task objectives learn to represent natural images using a shared set of latent dimensions, despite appearing highly distinct at a surface level. Next, by comparing these networks with human brain representations measured with fMRI, we found that the most brain-aligned representations in neural networks are those that are universal and independent of a network's specific characteristics. Remarkably, each network can be reduced to fewer than ten of its most universal dimensions with little impact on its representational similarity to the human brain. These results suggest that the underlying similarities between artificial and biological vision are primarily governed by a core set of universal image representations that are convergently learned by diverse systems.",https://arxiv.org/abs/2408.12804
Michael F. Bonner,Modeling dynamic social vision highlights gaps between deep learning and humans,2024,,2,"Kathy Garcia, Emalie McMahon, Colin Conwell, Michael F Bonner, Leyla Isik",Kathy Garcia,Leyla Isik,5,"Deep learning models trained on computer vision tasks are widely considered the most successful models of human vision to date. The majority of work that supports this idea evaluates how accurately these models predict brain and behavioral responses to static images of objects and natural scenes. Real-world vision, however, is highly dynamic, and far less work has focused on evaluating the accuracy of deep learning models in predicting responses to stimuli that move, and that involve more complicated, higher-order phenomena like social interactions. Here, we present a dataset of natural videos and captions involving complex multi-agent interactions, and we benchmark 350+ image, video, and language models on behavioral and neural responses to the videos. As with prior work, we find that many vision models reach the noise ceiling in predicting visual scene features and responses along the ventral visual stream (often considered the primary neural substrate of object and scene recognition). In contrast, image models poorly predict human action and social interaction ratings and neural responses in the lateral stream (a neural pathway increasingly theorized as specializing in dynamic, social vision). Language models (given human sentence captions of the videos) predict action and social ratings better than either image or video models, but they still perform poorly at predicting neural responses in the lateral stream. Together these results identify a major gap in AI’s ability to match human social vision and highlight the importance of studying vision in dynamic, natural contexts.",https://osf.io/4mpd9/download
Michael F. Bonner,A sparse null code emerges in deep neural networks,2024,Proceedings of UniReps: the First Workshop on Unifying Representations in Neural Models,2,"Brian S Robinson, Nathan Drenkow, Colin Conwell, Michael Bonner",Brian S Robinson,Michael Bonner,4,"The internal representations of deep vision models are often assumed to encode specific image features, such as contours, textures, and object parts. However, it is possible for deep networks to learn highly abstract representations that may not be linked to any specific image feature. Here we present evidence for one such abstract representation in transformers and modern convolutional architectures that appears to serve as a null code, indicating image regions that are non-diagnostic for the object class. These null codes are both statistically and qualitatively distinct from the more commonly reported feature-related codes of vision models. Specifically, these null codes have several distinct characteristics: they are highly sparse, they have a single unique activation pattern for each network, they emerge abruptly at intermediate network depths, and they are activated in a feature-independent manner by weakly informative image regions, such as backgrounds. Together, these findings reveal a new class of highly abstract representations in deep vision models: sparse null codes that seem to indicate the absence of relevant features.",https://proceedings.mlr.press/v243/robinson24a.html
Michael F. Bonner,An interpretable alternative to convolutional neural networks: the scattering transform,2022,Journal of Vision,2,"Shi Pui Li, Michael Bonner",Shi Pui Li,Michael Bonner,2,"Neural networks trained on large image datasets have been shown to successfully model the ventral visual stream. However, there is a lack of understanding of the features captured by these models. Here, we investigate an interpretable alternative to deep learning models called the scattering transform. Similar to convolutional neural networks, scattering transforms have a hierarchical structure with multiple layers implementing convolutions, non-linear activations, and pooling. However, instead of using learned convolutional kernels, these models use pre-defined Morlet wavelets at different orientations and spatial scales. In a forward propagation, an image is passed through a convolutional layer, followed by a modulus activation function, and this process is repeated across multiple layers in a hierarchical manner. During read-out, scattering coefficients are obtained by average pooling of the activations for each …",https://jov.arvojournals.org/article.aspx?articleid=2784695
Michael F. Bonner,Context predicts commonsense notions of object similarity,2022,,2,"Caterina Magri, Eric Elmoznino, Michael F Bonner",Caterina Magri,Michael F Bonner,3,"What makes objects alike in the human mind? Computational approaches for characterizing object similarity have largely focused on the visual forms of objects or their linguistic associations. However, intuitive notions of object similarity may depend heavily on contextual reasoning—that is, objects may be grouped together in the mind if they occur in the context of similar scenes or events. Using large-scale analyses of natural scene statistics and human behavior, we found that a computational model of the associations between objects and their scene contexts is strongly predictive of how humans spontaneously group objects by similarity. Specifically, we learned contextual prototypes for a diverse set of object categories by taking the average response of a convolutional neural network (CNN) to the scene contexts in which the objects typically occurred. In behavioral experiments, we found that contextual prototypes were strongly predictive of human similarity judgments for a large set of objects and rivaled the performance of models based on CNN representations of the objects themselves or word embeddings for their names. Together, our findings reveal the remarkable degree to which context alone predicts commonsense notions of object similarity in the human mind.",https://osf.io/preprints/psyarxiv/wh36c/
Michael F. Bonner,Universal scale-free representations in human visual cortex,2024,arXiv preprint arXiv:2409.06843,1,"Raj Magesh Gauthaman, Brice Ménard, Michael F Bonner",Raj Magesh Gauthaman,Michael F Bonner,3,"How does the human visual cortex encode sensory information? To address this question, we explore the covariance structure of neural representations. We perform a cross-decomposition analysis of fMRI responses to natural images in multiple individuals from the Natural Scenes Dataset and find that neural representations systematically exhibit a power-law covariance spectrum over four orders of magnitude in ranks. This scale-free structure is found in multiple regions along the visual hierarchy, pointing to the existence of a generic encoding strategy in visual cortex. We also show that, up to a rotation, a large ensemble of principal axes of these population codes are shared across subjects, showing the existence of a universal high-dimensional representation. This suggests a high level of convergence in how the human brain learns to represent natural scenes despite individual differences in neuroanatomy and experience. We further demonstrate that a spectral approach is critical for characterizing population codes in their full extent, and in doing so, we reveal a vast space of uncharted dimensions that have been out of reach for conventional variance-weighted methods. A global view of neural representations thus requires embracing their high-dimensional nature and understanding them statistically rather than through visual or semantic interpretation of individual dimensions.",https://arxiv.org/abs/2409.06843
Michael F. Bonner,Convolutional architectures are cortex-aligned de novo,2024,bioRxiv,1,"Atlas Kazemian, Eric Elmoznino, Michael F Bonner",Atlas Kazemian,Michael F Bonner,3,"What underlies the emergence of cortex-aligned representations in deep neural network models of vision? The success of widely varied architectures has motivated the prevailing hypothesis that large-scale pre-training is the primary factor underlying the similarities between brains and neural networks. Here, we challenge this view by revealing the role of architectural inductive biases in models with minimal training. We examined networks with varied architectures but no pre-training and quantified their ability to predict image representations in the visual cortices of both monkeys and humans. We found that cortex-aligned representations emerge in convolutional architectures that combine two key manipulations of dimensionality: compression in the spatial domain and expansion in the feature domain. We further show that the inductive biases of convolutional architectures are critical for obtaining performance gains from feature expansion—dimensionality manipulations were relatively ineffective in other architectures and in convolutional models with targeted lesions. Our findings suggest that the architectural constraints of convolutional networks are sufficiently close to the constraints of biological vision to allow many aspects of cortical visual representation to emerge even before synaptic connections have been tuned through experience.",https://www.biorxiv.org/content/10.1101/2024.05.10.593623.abstract
Michael F. Bonner,Hierarchical organization of social action features along the lateral visual pathway,2024,Current biology: CB,1,"Emalie McMahon, Michael F Bonner, Leyla Isik",Emalie McMahon,Leyla Isik,3,"After publication, we noted an error in the color bar label in Figures 2B and S2D–S2G stating that the brain maps reported the squared split-half reliability when the plotted data were not squared. We have corrected the color bar label in these plots. No other results were affected by the error, and the error does not affect the conclusions of the manuscript. We apologize for our mistake.",https://www.ncbi.nlm.nih.gov/pmc/articles/PMC11000801/
Michael F. Bonner,Canonical Dimensions of Neural Visual Representation,2023,Journal of Vision,1,"Zirui Chen, Michael Bonner",Zirui Chen,Michael Bonner,2,"What key factors of deep neural networks (DNNs) account for their representational similarity to visual cortex? Many properties that neuroscientists proposed to be critical, such as architecture or training task, have turned out to have surprisingly little explanatory power. Instead, there appears to be a high degree of “degeneracy,” as many DNNs with distinct designs yield equally good models of visual cortex. Here, we suggest that a more global perspective is needed to understand the relationship between DNNs and the brain. We reasoned that the most essential visual representations are general-purpose and thus naturally emerge from systems with diverse architectures or neuroanatomies. This leads to a specific hypothesis: it should be possible to identify a set of canonical dimensions, extensively learned by many DNNs, that best explain cortical visual representations. To test this hypothesis, we developed a …",https://jov.arvojournals.org/article.aspx?articleid=2791573
Michael F. Bonner,Contextual coherence increases perceived numerosity independent of semantic content,2023,,1,"Chuyan Qu, Michael F Bonner, Nicholas K DeWind, Elizabeth M Brannon",Chuyan Qu,Elizabeth M Brannon,4,"Understanding if and how visual features systematically bias numerosity perception is central to understanding the processes that give rise to our visual number sense. Recent work demonstrated that reducing coherence of low-level visual attributes such as color and orientation systematically reduces perceived number. Here we ask when in the visual processing hierarchy coherence affects numerosity perception and specifically whether the coherence effect is exclusive to low-level visual features or instead whether it can be driven by contextual or semantic relationships. We tested adults in an ordinal numerical comparison task with contextual coherence mathematically manipulated using a statistical model of visual object co-occurrence. Across several experiments, we found that arrays with high contextual coherence were perceived as numerically larger than arrays with low contextual coherence. This contextual coherence effect was not attenuated even when we reduced objects to texforms (unrecognizable images that preserve mid-level visual features) or removed semantic content from the images through box scrambling and diffeomorphic warping. Together, these results suggest that visual coherence derived from natural statistics of object co-occurrence systematically alters perceived numerosity at low-level visual processing, even before later stages at which items can be explicitly categorized and identified.",https://osf.io/preprints/psyarxiv/tcn8q/
Michael F. Bonner,Latent dimensionality scales with the performance of deep learning models of visual cortex,2022,Journal of Vision,1,"Eric Elmoznino, Michael Bonner",Eric Elmoznino,Michael Bonner,2,"The ventral visual stream is a complex, nonlinear system whose internal representations are currently best approximated through deep learning in convolutional neural networks (CNNs). Neuroscientists have been in search of the core principles that explain why some CNNs are better than others at predicting the responses in visual cortex. Previous efforts have focused on factors related to architecture, training task, visual diet, and interpretable properties of the learned features. Here, we take a different approach and seek to understand the performance of CNN models of the ventral stream in terms of their latent geometric properties. Specifically, we focus on latent dimensionality, which is the number of dimensions spanned by the activity space of a CNN’s responses to natural images. While low dimensionality can promote invariance to incidental image properties, high dimensionality increases expressivity and …",https://jov.arvojournals.org/article.aspx?articleid=2784749
Michael F. Bonner,Boundary extension and contraction are predicted by the natural statistics of images,2021,Journal of Vision,1,"Feikai Lin, Yiyuan Zhang, Michael Bonner",Feikai Lin,Michael Bonner,3,"Visual memory is subject to systematic errors. By understanding how these errors come about, we can uncover fundamental processes that shape the visual representations of human memory. One of the most robust and perplexing types of memory error is boundary transformation, in which observers reliably misremember a scene as either farther (boundary extension) or closer (boundary contraction) than it actually was. What drives these boundary-transformation errors? The normalization theory proposes that scene memories are biased toward canonical views. For example, if our view of a scene is unusually close, our memory will be biased toward a farther and more typical view, showing boundary extension. This theory raises a central question that has yet to be addressed: Can boundary-transformation effects be predicted from the natural statistics of observed viewpoints in real-world scenes? Here we …",https://jov.arvojournals.org/article.aspx?articleid=2777847
Michael F. Bonner,High-performing computational models of visual cortex are marked by high intrinsic dimensionality,2021,Journal of Vision,1,"Eric Elmoznino, Michael Bonner",Eric Elmoznino,Michael Bonner,2,"A central goal of cognitive neuroscience is to understand the computational properties of neural representations in visual cortex. Above and beyond the information content or visual features encoded in neural populations, we wish to understand the encoding format itself and the computations it subserves. These questions are at the heart of research into computational properties such as sparsity, dimensionality, manifold geometry, invariance, and dynamics in both biological and artificial neural networks. Here we investigate the computational properties of representations across human visual cortex using fMRI encoding models. We first fit voxelwise encoding models to predict fMRI responses to images of natural objects and scenes using both hand-engineered feature detectors (eg edge detectors) and pre-trained and untrained convolutional neural networks (CNNs). We then performed statistical analyses of the …",https://jov.arvojournals.org/article.aspx?articleid=2777793
Michael F. Bonner,Deep neural network models of visual cortex reveal curvature and real-world size as organizing principles of mid-level representation,2021,Journal of Vision,1,"Shi Pui Li, Michael Bonner",Shi Pui Li,Michael Bonner,2,"Mid-level visual features directly support an array of behaviors; thus, they may be critical for understanding the functional organization of visual cortex. However, attempts at characterizing mid-level features have been hampered by the difficulty of describing these features in words—they exist in an “ineffable valley” between the describable patterns of low-level vision (eg, edges) and the commonsense concepts of visual cognition (eg, objects). Here we developed a novel approach to identify interpretable emergent properties of mid-level representations in deep neural network (DNN) models of visual cortex. Using this approach, we examined DNN models that were fit to scene-evoked fMRI responses in category-selective regions of visual cortex—specifically, scene-selective cortex (sceneDNN) and object-selective cortex (objectDNN). Our method uses a semantically-guided image-occlusion procedure to …",https://jov.arvojournals.org/article.aspx?articleid=2777713
Michael F. Bonner,When a phone in a basket looks like a knife in a cup: Perception and abstraction of visual-spatial relations between objects,2019,Journal of Vision,1,"Alon Hafri, Barbara Landau, Michael F Bonner, Chaz Firestone",Alon Hafri,Chaz Firestone,4,"Our minds effortlessly recognize the objects and environments that make up the scenes around us. Yet scene understanding relies on much richer information, including the relationships between objects—such as which objects may be in, on, above, below, behind, or in front of one another. Such spatial relations are the basis for especially sophisticated inferences about the current and future physical state of a scene (“What will fall if I bump this table?”“What will come with if I grab this cup?”). Are such distinctions made by the visual system itself? Here, we ask whether spatial relations are extracted at a sufficiently abstract level such that particular instances of these relations might be confused for one another. Inspired by the observation that certain spatial distinctions show wide agreement across the world’s languages, we focus on two cross-linguistically “core” categories—Containment (“in”) and Support (“on …",https://jov.arvojournals.org/article.aspx?articleid=2750558
Michael F. Bonner,Early electrophysiological markers of navigational affordances in scenes,2018,Journal of Vision,1,"Assaf Harel, Jeffrey Nador, Michael Bonner, Russell Epstein",Assaf Harel,Russell Epstein,4,"Recent work has demonstrated that information about the structure and function of visual scenes is encoded in the brain by 220ms post-stimulus onset. For example, Harel et al.(2016) reported that diagnostic scene properties, such as spatial expanse (open vs. closed) and naturalness (manmade vs. naturalness), modulate the amplitude of early visual Event-Related Potentials (ERPs), particularly the P2. Given that open and closed scenes can be thought as two ends on a navigability continuum, we reasoned that these ERP markers might contain information about the number of pathways that afford movement in the local environment. To test this idea, we recorded ERPs from participants while they passively viewed computer-generated room scenes matched in visual complexity used in a previous fMRI study of navigability (Bonner & Epstein, 2017). By simply changing the number of doors (no-doors, one door, two …",https://jov.arvojournals.org/article.aspx?articleid=2699723
Michael F. Bonner,Modulating language comprehension using HD-tDCS,2017,"Brain Stimulation: Basic, Translational, and Clinical Research in Neuromodulation",1,"Amy Price, Michael Bonner, Roy Hamilton, Jonathan Peelle, Murray Grossman",Amy Price,Murray Grossman,5,"Language comprehension relies on the ability to integrate the meaning of individual words into coherent combinations (eg, integrating “plaid” and “jacket” into a coherent understanding of “plaid jacket”). In a previous fMRI and patient study we found that the angular gyrus was important for the process of successfully integrating conceptual information. Here we demonstrate that highdefinition transcranial direct current stimulation (HD-tDCS) to the left angular gyrus modulates the process of integrating word meaning with no effect on control tasks. In this study, participants viewed an adjective-noun word pair on a screen and indicated by button press whether or not the word pair was a coherent combination (eg, coherent combinations were word pairs like “tiny radish” and low coherent combinations were word pairs like “fast blueberry”). We hypothesized that anodal stimulation to the left angular gyrus would enhance …",https://www.brainstimjrnl.com/article/S1935-861X(16)30357-6/abstract
Michael F. Bonner,Neural coding of navigational affordances in the local visual environment,2015,Journal of Vision,1,"Michael Bonner, Jack Ryan, Russell Epstein",Michael Bonner,Russell Epstein,3,"An essential component of visually guided navigation is the ability to perceive features of the environment that afford or constrain movement. For example, in indoor environments, walls limit one’s potential routes, while passageways facilitate movement. Here we attempt to identify the cortical mechanisms that encode such navigational features. Specifically, we test the hypothesis that scene-selective regions of the human brain represent navigational affordances in visual scenes. In an fMRI experiment, subjects viewed images of artificially rendered rooms that had identical geometry as defined by their walls, but varied on the number (one to three) and position (left, right, center) of spatial passageways (ie, open doorways) connected to them. Thus, the layout of these passageways defined the navigable space in each scene. Several versions of each layout were shown, each with the same set of passageways but …",https://jov.arvojournals.org/article.aspx?articleid=2433617
Michael F. Bonner,Large-scale Deep Neural Network Benchmarking in Dynamic Social Vision,2024,Journal of Vision,0,"Kathy Garcia, Colin Conwell, Emalie McMahon, Michael F Bonner, Leyla Isik",Kathy Garcia,Leyla Isik,5,"Many Deep Neural Networks (DNNs) with diverse architectures and learning objectives have yielded high brain similarity and hierarchical correspondence to ventral stream responses to static images. However, they have not been evaluated on dynamic social scenes, which are thought to be processed primarily in the recently proposed lateral visual stream. Here, we ask whether DNNs are similarly good models of processing in the lateral stream and the superior temporal sulcus as they are in the ventral stream. To investigate this, we employ large-scale deep neural network benchmarking against fMRI responses to a curated dataset of 200 naturalistic social videos. We examine over 300 DNNs with diverse architectures, objectives, and training sets. Notably, we find a hierarchical correspondence between DNNs and lateral stream responses: earlier DNN layers correlate better with earlier visual areas (including …",https://jov.arvojournals.org/article.aspx?articleid=2801014
Michael F. Bonner,High-dimensional latent manifolds as predictors of individual differences in naturalistic movie viewing,2024,Journal of Vision,0,"Chihye Han, Michael Bonner",Chihye Han,Michael Bonner,2,"The human visual system is adept at processing complex, high-dimensional sensory data. A prominent theory proposes that the visual system accomplishes this by transforming high-dimensional sensory inputs into simpler, low-dimensional representations. However, recent theoretical and empirical work suggests that the dimensionality of visual cortical representations may be more extensive than previously thought. We hypothesize that even low-variance dimensions in cortical population activity are critical to human vision and that individual differences in visual experience are captured by these high-dimensional codes. To investigate this possibility, we used a recent method, known as cross-decomposition, to identify the shared high-dimensional signal between pairs of individuals. We applied this method to publicly available fMRI data collected from forty participants while they viewed four short movies. We first …",https://jov.arvojournals.org/article.aspx?articleid=2800945
Michael F. Bonner,How to estimate noise ceilings for computational models of visual cortex,2024,Journal of Vision,0,"Zirui Chen, Michael Bonner",Zirui Chen,Michael Bonner,2,"A pivotal goal in neuroscience is to develop computational models that can account for the explainable variance in cortical responses to sensory stimuli. It is widely recognized that when evaluating the similarity between brain and model representations, it is necessary to estimate the noise ceiling in measurements of cortical activity. Traditional approaches have focused on factors such as reliability across trials or subjects, with the goal of establishing a benchmark for the maximum predictive accuracy that any model could theoretically achieve. However, one important source of noise that has been largely overlooked in the literature is the reliability of the computational models themselves. In the case of deep learning models, a natural measure of reliability is the consistency of learned representations across different random initializations. Using such a metric of model reliability, we demonstrate how an aggregate …",https://jov.arvojournals.org/article.aspx?articleid=2802015
Michael F. Bonner,Geometric properties of object manifolds in neural network models of visual cortex,2024,Journal of Vision,0,"Michael Bonner, Eric Elmoznino, Colin Conwell",Michael Bonner,Colin Conwell,3,"A classic signature of high-performing neural network models of visual cortex is their strong accuracy on object classification tasks. However, recent work suggests that classification accuracy alone is an impoverished metric that fails to capture the complexity of biologically relevant visual representations. Here we sought to gain a richer understanding of the representational structure in a diverse set of deep neural networks (DNNs, N= 492) by examining multiple geometric properties of their object manifolds (eg, dimensionality, radius, between-category separation). We also examined the encoding performance of these networks for predicting scene-evoked fMRI responses in human visual cortex using the Natural Scenes Dataset. Our findings show that geometric properties of object manifolds are in some cases robust predictors of encoding performance, and they reveal the specific ways in which the …",https://jov.arvojournals.org/article.aspx?articleid=2801659
Michael F. Bonner,Spatial filters in neural network models of visual cortex do not need to be learned,2024,Journal of Vision,0,"Ananya Passi, Atlas Kazemian, Michael Bonner",Ananya Passi,Michael Bonner,3,"The performance of convolutional neural networks as models of visual cortex relies on pre-training millions of parameters, optimizing them for a specific classification task. This process not only requires massive computational resources, but also results in learned features whose effectiveness is limited by the dataset richness. Furthermore, the time and resource intensive nature of this training process discourages iterative parameter studies, further reducing the interpretability of high-performing models of visual cortex. Here we propose a theoretically grounded convolutional architecture in which the training process is limited to learning linear combinations of pre-defined wavelet filters. This simplified model is based on an iterative process of expanding and subsequently reducing dimensionality in a deep hierarchy of modules, where each module consists of a filtering operation, followed by a non-linearly and …",https://jov.arvojournals.org/article.aspx?articleid=2800855
Michael F. Bonner,"Unveiling core, interpretable image properties underlying model-brain similarity with generative models",2024,Journal of Vision,0,"Yingqi Rong, Colin Conwell, Dianna Hidalgo, Michael Bonner",Yingqi Rong,Michael Bonner,4,"Deep Neural Networks (DNNs) are now capable of predicting the hierarchy of natural images representations in human visual cortex with substantial accuracy. However, a key challenge in the use of these networks to predict representations in the brain is discerning the specific properties of these networks that underlie their predictive accuracy. In this work, we developed an approach for leveraging high-throughput generative vision models to run targeted, hypothesis-driven experiments on the key image properties that drive DNN predictions of brain representation. Specifically, we used diffusion models to create diverse image variations while preserving targeted image information. This targeted information included specific visual features (eg edges, background) as well as semantics from captions and categories. Using our synthesized image variations, we quantified the impact of each interpretable manipulation …",https://jov.arvojournals.org/article.aspx?articleid=2801846
Michael F. Bonner,The high-dimensional structure of natural image representations varies systematically across visual cortex,2024,Journal of Vision,0,"Raj Magesh Gauthaman, Brice Ménard, Michael Bonner",Raj Magesh Gauthaman,Michael Bonner,3,"The computational goal of the visual cortex is often described as systematic dimensionality reduction, where high-dimensional sensory input is gradually reduced to a low-dimensional manifold over multiple stages of processing. Recently, thanks to the unprecedented size of the Natural Scenes Dataset, we showed that the structure of human visual cortex representation is high-dimensional. We were able to reliably detect visual information encoded over many hundreds of latent dimensions. In an effort to reconcile these divergent theoretical predictions and empirical results, we set out to investigate how natural image representations are transformed along the visual hierarchy from a spectral perspective. Using a robust cross-decomposition approach, we estimated cross-validated covariance spectra of fMRI responses in several regions of interest in the visual cortex. In all of them, we observed power-law covariance …",https://jov.arvojournals.org/article.aspx?articleid=2800940
Michael F. Bonner,Sparse null codes emerge and dominate representations in deep neural network vision models,2024,Journal of Vision,0,"Brian S Robinson, Nathan Drenkow, Colin Conwell, Michael F Bonner",Brian S Robinson,Michael F Bonner,4,"Representations in vision-based deep neural networks and biological vision are often analyzed from the perspective of the image features they encode, such as contours, textures, and object parts. In this work, we present evidence for an alternative, more abstract type of representation in deep neural networks, which we refer to as a “null code”. Through a series of analyses inspecting the embeddings of a range of neural networks, including different transformer architectures and a recent performant convolutional neural network, we observe null codes that are both statistically and qualitatively distinct from the more commonly reported feature-related codes of vision models. These null codes are highly sparse, have a single unique activation pattern for each network, emerge abruptly at intermediate network depths, and are activated in a feature-independent manner by weakly informative image regions, such as …",https://jov.arvojournals.org/article.aspx?articleid=2801955
Michael F. Bonner,Language model prediction of visual cortex responses to dynamic social scenes,2024,Journal of Vision,0,"Emalie McMahon, Colin Conwell, Kathy Garcia, Michael F Bonner, Leyla Isik",Emalie McMahon,Leyla Isik,5,"Recent work has shown that language models based on sentence captions of images are good models of high-level ventral visual cortex, on par with vision models. Text manipulation experiments reveal that this match to the ventral stream is strongly dependent on the nouns in the image captions, suggesting that language models perform well because they represent the things (ie, agents and objects) in an image. However, the visual world is much richer than static things. We see people dynamically interacting with objects and other people. These dynamic scenes have been shown to more strongly activate visual cortex, and high-level lateral regions, in particular, uniquely respond to dynamic social content. Can vision and language models predict responses to dynamic social scenes in ventral and lateral visual cortices? To investigate this question, we used a large-scale dataset of three-second clips of social …",https://jov.arvojournals.org/article.aspx?articleid=2801580
Michael F. Bonner,Universal scale-free representations in human visual cortex,2024,arXiv e-prints,0,"Raj Magesh Gauthaman, Brice Ménard, Michael F Bonner",Raj Magesh Gauthaman,Michael F Bonner,3,"How does the human visual cortex encode sensory information? To address this question, we explore the covariance structure of neural representations. We perform a cross-decomposition analysis of fMRI responses to natural images in multiple individuals from the Natural Scenes Dataset and find that neural representations systematically exhibit a power-law covariance spectrum over four orders of magnitude in ranks. This scale-free structure is found in multiple regions along the visual hierarchy, pointing to the existence of a generic encoding strategy in visual cortex. We also show that, up to a rotation, a large ensemble of principal axes of these population codes are shared across subjects, showing the existence of a universal high-dimensional representation. This suggests a high level of convergence in how the human brain learns to represent natural scenes despite individual differences in neuroanatomy and …",https://ui.adsabs.harvard.edu/abs/2024arXiv240906843M/abstract
Michael F. Bonner,Scene context is predictive of unconstrained object similarity judgments,2023,Cognition,0,"Caterina Magri, Eric Elmoznino, Michael F Bonner",Caterina Magri,Michael F Bonner,3,"What makes objects alike in the human mind? Computational approaches for characterizing object similarity have largely focused on the visual forms of objects or their linguistic associations. However, intuitive notions of object similarity may depend heavily on contextual reasoning—that is, objects may be grouped together in the mind if they occur in the context of similar scenes or events. Using large-scale analyses of natural scene statistics and human behavior, we found that a computational model of the associations between objects and their scene contexts is strongly predictive of how humans spontaneously group objects by similarity. Specifically, we learned contextual prototypes for a diverse set of object categories by taking the average response of a convolutional neural network (CNN) to the scene contexts in which the objects typically occurred. In behavioral experiments, we found that contextual …",https://www.sciencedirect.com/science/article/pii/S0010027723001695
Michael F. Bonner,Understanding the high-dimensional nature of visual cortex representations,2023,Journal of Vision,0,"Raj Magesh Gauthaman, Brice Ménard, Michael Bonner",Raj Magesh Gauthaman,Michael Bonner,3,"Most of the variance in cortical image representations is concentrated on a small set of latent dimensions that typically correspond to interpretable image properties like animacy, aspect ratio, and curvature. This has led to speculation that the cortex uses a low-dimensional code to represent natural images. However, this perspective neglects the long tail of low-variance dimensions that may be critical to human vision. We set out to determine if these dimensions contain meaningful visual information and whether deep neural networks (DNNs) can explain them. Using inter-participant comparisons, we quantified the reliable signal present in each dimension of the large-scale Natural Scenes fMRI dataset. Specifically, we used cross-validated ridge regression to predict the principal components (PCs) of one participant's neural responses using another participant's responses. We reasoned that if a dimension in one …",https://jov.arvojournals.org/article.aspx?articleid=2791969
Michael F. Bonner,The spatiotemporal dynamics of social scene perception in the human brain,2023,Journal of Vision,0,"Emalie McMahon, Taylor Abel, Jorge Gonzalez-Martinez, Michael F Bonner, Avniel Ghuman, Leyla Isik",Emalie McMahon,Leyla Isik,6,"Social perception is an important part of everyday life that develops early and is shared with non-human primates. To understand the spatiotemporal dynamics of naturalistic social perception in the human brain, we first curated a dataset of 250 500-ms video clips of two people performing everyday actions. We densely labeled these videos with features of visual social scene, including scene and object features, visual social primitives, and higher-level social/affective features. To investigate when and where these features are represented in the brain, patients with implanted stereoelectroencephalography electrodes viewed the videos. We used time-resolved encoding models in individual channels to investigate the time course of representations across the human brain. We find that an encoding model based on all of our social scene features predicts responses in a subset of channels around 400 ms after video …",https://jov.arvojournals.org/article.aspx?articleid=2791837
Michael F. Bonner,Toward a computational neuroscience of visual cortex without deep learning,2023,Journal of Vision,0,"Atlas Kazemian, Eric Elmoznino, Michael Bonner",Atlas Kazemian,Michael Bonner,3,"The performance of convolutional neural networks (CNNs) as representational models of visual cortex is thought to be associated with their optimization on ethologically relevant tasks. Here, we show that this view is incorrect and that there are other architectural and statistical factors that primarily account for their performance. We show this by developing a novel statistically inspired neural network that yields accurate predictions of cortical image representation without the need for optimization on supervised or self-supervised tasks. Our architecture is characterized by a core module of convolutions and max pooling, which can be stacked in a deep hierarchy. An important characteristic of our model is the use of thousands of random filters to sample the high-dimensional space of natural image statistics. These filters can be mapped to cortical responses through a simple linear-regression procedure, which we …",https://jov.arvojournals.org/article.aspx?articleid=2791949
Michael F. Bonner,Naturalistic two-person social perception in the brain,2022,Journal of Vision,0,"Emalie McMahon, Michael Bonner, Leyla Isik",Emalie McMahon,Leyla Isik,3,"In a bustling social event, like the VSS Tiki Bar, we quickly and effortlessly perceive who is interacting with whom and details of their interactions such as whether our colleagues are engaged in a friendly or adversarial debate. Extracting these social details is crucial for deciding how we want to act. While we do this with ease, little is understood about how this is solved in the mind and brain. Although recent research has shown that a region in the posterior superior temporal sulcus (pSTS) is visually selective for social interactions, which features of a social interaction this and other regions of the brain represent is unknown. To answer this question, we showed participants 250 3-second video clips of naturalistic two-person interactions in the fMRI experiment. The stimulus set was curated to limit low-level confounds such that early features from an ImageNet-trained AlexNet were minimally correlated with social …",https://jov.arvojournals.org/article.aspx?articleid=2785031
Michael F. Bonner,"A large-scale, naturalistic dataset of two-person social actions",2021,Journal of Vision,0,"Emalie McMahon, Michael Bonner, Leyla Isik",Emalie McMahon,Leyla Isik,3,"During everyday tasks like navigating a crowded store or deciding where to sit on a bus, we perceive rich details about the social interactions of others. The ability to perceive others’ social interactions is a core component of human cognition, but its neural computations are only beginning to be understood. While recent work has made progress in understanding the neural mechanisms of social interaction perception with tightly controlled stimuli, continued progress requires a dataset of social and nonsocial actions that is representative of everyday life and captures variance along a range of social dimensions, eg valence, cooperativity, and interpersonal relationships. However, using naturalistic stimuli to investigate social interaction perception presents significant challenges. First, the number of people in a given video is highly predictive of the presence of a social interaction–a video of one person likely shows a …",https://jov.arvojournals.org/article.aspx?articleid=2776992
Michael F. Bonner,"The stuff of natural scenes: probing human property judgments of textures, materials, and other amorphous scene components with convolutional neural networks",2021,Journal of Vision,0,"Neha Nandiwada, Caterina Magri, Michael Bonner",Neha Nandiwada,Michael Bonner,3,"Scenes are composed not only of discrete objects with defined shapes but also complex visual “stuff” in the form of amorphous textures and patterns (eg, grass, bricks, smoke). Many behaviorally relevant properties of scenes can be quickly recognized based solely on the stuff they contain—eg, hotness of fire, hardness of concrete, fragility of glass. Though much work has explored how the human visual system represents individual objects, less is known about how we process the amorphous stuff that makes up most of the visual environment. Furthermore, an open question is to determine what classes of computational models can account for the human ability to rapidly detect a rich set of high-level properties from a brief glance at a patch of visual stuff. To address these questions, we developed a dataset of 500 high-quality images from 50 categories of textures encountered in real-world environments, and we …",https://jov.arvojournals.org/article.aspx?articleid=2777224
Michael F. Bonner,The unreasonable effectiveness of context: Object representations are well predicted by computational models of their natural scene contexts,2021,Journal of Vision,0,"Caterina Magri, Michael Bonner",Caterina Magri,Michael Bonner,2,"In natural vision, objects are always encountered in a surrounding context, and these contexts can be highly consistent (eg, most boats appear in aquatic scenes). Previous observations suggest that the human visual system leverages the statistical associations between objects and contexts to facilitate object representation. What are these statistical associations, and how much object information can be inferred from contextual associations alone? Here, we developed a computational approach to model the statistical associations between objects and their image contexts, and we used this approach to determine if contextual information alone can explain key aspects of human object representation. Using large-scale scene datasets, we systematically occluded instances of target objects—leaving only the context intact—and passed the occluded images through an Imagenet-pretrained convolutional neural …",https://jov.arvojournals.org/article.aspx?articleid=2777291
Michael F. Bonner,Quantifying the latent semantic content of visual representations,2021,Journal of Vision,0,"Chihye Han, Caterina Magri, Michael Bonner",Chihye Han,Michael Bonner,3,"How does visual cortex extract semantic meaning from images? We hypothesize that visual cortex leverages the natural covariance between perceptual features and semantic properties and that it does so by representing perceptual features that support the efficient decoding of large numbers of semantic properties. Using convolutional neural networks (CNNs) and word embeddings (eg, word2vec), we developed a statistical measure called semantic dimensionality that quantifies the number of language-derived semantic properties that can be decoded from a set of image-computable perceptual features. We combined this method with fMRI encoding models to estimate the semantic dimensionality of perceptual-feature tuning in the ventral visual stream. We first fit image-computable encoding models to object-evoked fMRI responses using mid-level features from pre-trained CNNs. Encoding-model performance …",https://jov.arvojournals.org/article.aspx?articleid=2777135
Michael F. Bonner,"“Honey, I shrunk the scene”: Changing perceived distance alters memory for scene boundaries",2021,Journal of Vision,0,"Shreya Wadhwa, Alon Hafri, Michael Bonner",Shreya Wadhwa,Michael Bonner,3,"Memory for visual scenes is a constructive process that is prone to systematic distortions. These distortions can reveal the mechanisms by which the visual environment is encoded in the mind. One striking distortion is “boundary extension”, whereby observers mistakenly recall viewing a scene from farther away than actually observed—and recent work has revealed the existence of a surprising, complementary effect of “boundary contraction”. What memory processes drive these distortions? We hypothesized that these distortions are driven by normalization toward canonical viewing distances, pushing memory outward for close-up scenes and inward for distant scenes. We directly tested this hypothesis by exploiting image manipulations that selectively alter perceived distance while preserving other perceptual and semantic content. First, we created “fake miniatures” of distant scenes using a digital “tilt-shift” effect …",https://jov.arvojournals.org/article.aspx?articleid=2777739
Michael F. Bonner,Visual predictions from physical relations,2020,Journal of Vision,0,"Alon Hafri, Michael Bonner, Chaz Firestone",Alon Hafri,Chaz Firestone,3,"Understanding the world around us involves understanding not only which objects are where, but also how they relate—as when we see that one object is on, above, behind, or inside another. Some of these relations are physical, and play a special role in predicting the future state of a scene: If something is inside a cup—rather than occluded by it—we can assume that it will move if the cup moves. But beyond our ability to reason about what different physical relations entail, might they influence visual attention itself? Here, we ask whether the perception of physical relations automatically guides active maintenance of object identities—a core visual process by which the mind computes correspondence between current and previously seen objects. We turned the classic “object reviewing” paradigm into a “cups-and-balls” game in which participants rapidly responded to a target letter. On each trial, two balls with …",https://jov.arvojournals.org/article.aspx?articleid=2771300
Michael F. Bonner,Parahippocampal cortex represents the natural statistics of object context,2019,Journal of Vision,0,"Michael F Bonner, Russell A Epstein",Michael F Bonner,Russell A Epstein,2,"Many objects have a natural place in the world—a context where they and other objects are typically found. For example, tea kettles and stoves are often found together in kitchens, while fire hydrants and traffic lights are found on city sidewalks. This type of contextual knowledge about object co-occurrence can help people identify where they are in the world and what other objects they might encounter. Investigations of object perception have long sought to understand how contextual knowledge is represented in the brain (Bar, 2004), but conclusive evidence for such representations has remained elusive. Here we used fMRI and machine learning to test the hypothesis that object co-occurrence statistics are encoded in the human visual system and automatically elicited by the perception of individual objects. Using a statistical-learning technique from computational linguistics and a database of~ 22,000 densely …",https://jov.arvojournals.org/article.aspx?articleid=2750362
Michael F. Bonner,Explaining Scene-selective Visual Area Using Task-specific and Category-specific DNN Units,2019,Journal of Vision,0,"Kshitij Dwivedi, Michael F Bonner, Gemma Roig",Kshitij Dwivedi,Gemma Roig,3,"Deep neural networks (DNN) trained for classification are often used to explain responses of the visual cortex. Recently it was demonstrated that a DNN trained on a task related to the function of a brain region explains its responses better than a DNN trained on a task which is not explicitly related. Taking motivation from the previous results, in this work we investigate if we can infer the functionality of different areas in the scene-selective visual cortex by comparing the correlation of brain areas with DNNs trained on different tasks. We select 20 DNNs trained on diverse computer vision tasks including multiple 2D, 3D, and semantic tasks from the Taskonomy dataset. We select 2 areas in the scene-selective visual cortex, namely occipital place area (OPA) and parahippocampal place area (PPA). We perform representation similarity analysis (RSA) of OPA and PPA with 20 DNNs to investigate if the relative correlation …",https://jov.arvojournals.org/article.aspx?articleid=2750681
Michael F. Bonner,What lies beyond: Representations of the connectivity structure of the local environment,2019,Journal of Vision,0,"Rachel C Metzgar, Michael F Bonner, Russell A Epstein",Rachel C Metzgar,Russell A Epstein,3,"To navigate in a familiar environment, it is useful to have a representation of the relationship between the local perceptual scene and the broader spatial surroundings. It has been suggested that retrosplenial complex (RSC), a scene-selective region of the brain, plays an important role in this function. Here we use multivoxel pattern analysis (MVPA) of fMRI data to test the idea that RSC and other scene-selective regions represent memories of the connections between the local environment and adjacent parts of space. Before scanning, participants (N= 18) learned the locations of 32 target objects within 4 environments by navigating through them in immersive virtual reality. Each environment consisted of a rectangular room with two visually identical doors, one of which led to a small closet, the other to an exterior space. We then scanned participants while they viewed snapshots of the corresponding rooms with all …",https://jov.arvojournals.org/article.aspx?articleid=2750563
Michael F. Bonner,Computational mechanisms for identifying the navigational affordances of scenes in a deep convolutional neural network,2017,Journal of Vision,0,"Michael Bonner, Russell Epstein",Michael Bonner,Russell Epstein,2,"A central component of spatial navigation is determining where one can and cannot go in the immediate environment. For example, in indoor environments, walls limit one's potential routes, while passageways facilitate movement. In a recent set of fMRI experiments, we found evidence suggesting that the human visual system solves this problem by automatically identifying the navigational affordances of the local scene. Specifically, we found that the occipital place area (OPA), a scene-selective region near the transverse occipital sulcus, appears to automatically encode the navigational layout of visual scenes, even when subjects are not engaged in a navigational task. Given the apparent automaticity of this process, we predicted that affordance identification could be rapidly achieved through a series of purely feedforward computations performed on retinal inputs. To test this prediction and to explore other …",https://jov.arvojournals.org/article.aspx?articleid=2651183
Michael F. Bonner,Neural coding of navigational affordances in visual scenes,2016,Journal of Vision,0,"Michael Bonner, Jack Ryan, Russell Epstein",Michael Bonner,Russell Epstein,3,"An essential component of visually guided navigation is the ability to perceive features of the environment that afford or constrain movement. For example, in indoor environments, walls limit one's potential routes, while passageways facilitate movement. Here we examine the cortical mechanisms that encode such navigational features. In two fMRI experiments we test the hypothesis that scene-selective cortices represent the navigational affordances of local space. In the first study, subjects viewed images of artificially rendered rooms that had identical geometry as defined by their walls, but varied on the number and position of open passageways leading out of them. The layout of these passageways defined the principal navigational affordances in each scene. We used multivoxel pattern analysis to identify representations of navigational layout that were invariant to other visual features, including surface textures …",https://jov.arvojournals.org/article.aspx?articleid=2550550
Michael F. Bonner,Intersubject similarity of mulitvoxel codes in perirhinal cortex reflects the typicality of visual objects,2016,Journal of Vision,0,"Amy Price, Michael Bonner, Jonathan Peelle, Murray Grossman",Amy Price,Murray Grossman,4,"The ventral visual pathway transforms perceptual inputs of objects into increasingly complex representations, and its highest stages are thought to contain abstract semantic codes. A key function of these semantic codes is to provide a common understanding of visual objects across individuals. For example, my stored knowledge of the familiar object"" red apple"" should be similar to yours if we are to communicate and coordinate our behaviors. This predicts a specific functional architecture: neural codes of visual-semantic regions are structured to provide a common ground between observers of the visual world. Here we tested for a key signature of this proposed architecture by: 1) identifying regions encoding high-level object meaning and 2) testing whether inter-subject similarity in these regions tracks object meaning. During fMRI, subjects viewed objects created from combinations of shapes (apples, leaves …",https://jov.arvojournals.org/article.aspx?articleid=2551402
Michael F. Bonner,Neural coding of object knowledge reflects the co-occurrence statistics of the environment,2015,Journal of Vision,0,"Amy Price, Michael Bonner, Jonathan Peelle, Murray Grossman",Amy Price,Murray Grossman,4,"Our knowledge of objects reflects the statistics of the visual environment. From our experiences in the world, we store information about categories of objects and the features that define them. One important statistical property of objects is the co-occurrence of their constituent features. For example, the round shape of an apple co-occurs frequently with the color red, but not the color blue. Here we examine the neural mechanisms that encode such feature co-occurrence statistics at the interface of perception and memory. In an fMRI experiment, subjects viewed images of colored objects while performing an unrelated scrambled-object detection task. The stimuli included exemplars from three different categories: apples, leaves, and roses. To create stimuli that sampled a range of co-occurrence statistics, each exemplar image had its color systematically manipulated to be red, pink, yellow, green, or blue (Fig. 1A). We …",https://jov.arvojournals.org/article.aspx?articleid=2434229
Michael F. Bonner,Deficits in Semantic Memory Associated With Focal Neurodegenerative Diseases,2013,The Boston Process Approach to Neuropsychological Assessment: A Practitioner's Guide,0,"Michael Bonner, Murray Grossman",Michael Bonner,Murray Grossman,2,"It was a heady time in Boston. It felt like an earth-shattering discovery in the social sciences occurred daily. Noam Chomsky introduced the systematic analysis of syntax in the late 1950s. His theory of generative grammar brought the mid-century structural revolution in social sciences to a critical human activity that had previously been considered only in a vaguely descriptive manner. Chomsky’s fundamental insights seemed to provide a viable account of the infinitely creative variety of sentence structures that we produce. Structural approaches to lexical semantics and phonology quickly followed. These analyses attempted to decompose the meanings and sounds of words into collections of primitive features. Paralleling Chomsky’s theory, these primitives could be recombined in an infinite number of ways to represent every imaginable concept with a unique sequence of speech sounds, ultimately resulting in a meaningful word. If robust, this approach should support generalization to other domains of language. One test of this structural approach involved developmental psycholinguistics. This approach was validated by Roger Brown’s tender descriptions of three children systematically exploring language through single-word and then two-word utterances. Elegant, internally consistent theories such as generative grammar and generative semantics are hypothesis-generating, but independent validation of these theories was lacking.This validation was achieved at the Aphasia Research Center located at the Boston Veterans Administration (VA) Hospital, where studies of the neuroanatomic basis for language were being pursued. Norman …",https://books.google.com/books?hl=en&lr=&id=dFV-6zt9BS4C&oi=fnd&pg=PA200&dq=info:J0ieYk7gETEJ:scholar.google.com&ots=8MzadP6PuN&sig=ftUsuzbzv656dbZ_rAo_akVbJrU
Michael F. Bonner,At the interface of visual perception and long-term memory: Object knowledge and the medial temporal lobe,2013,Journal of Vision,0,"Michael F Bonner, Amy R Price, Jonathan E Peelle, Murray Grossman",Michael F Bonner,Murray Grossman,4,"Along the ventral visual pathway, neurons are increasingly selective for complex features and invariant to low-level details. This hierarchy culminates in the medial temporal lobe (MTL), where neurons exhibit highly selective and invariant responses to objects, responding even to the spoken and written names of objects. One interpretation of these findings is that MTL neurons encode a stable representation of visual concepts, providing a link between ongoing visual perception and long-term object knowledge. We tested this MTL hypothesis in three experiments that investigate the neural basis of visual concepts. In an fMRI experiment, healthy adults (N= 16) performed a semantic matching task on word triads that varied on their visual feature associations. fMRI analysis showed that visual features parametrically modulated activity in the MTL and fusiform gyrus (p<. 05, whole-brain corrected), such that highly visual …",https://jov.arvojournals.org/article.aspx?articleid=2143033
Michael F. Bonner,Neural representations at the interface of perception and memory,2012,,0,Michael F Bonner,Michael F Bonner,Michael F Bonner,1,"The human brain stores a vast network of knowledge about the contents of our environment. This memory system underlies our ability to identify objects in perception, to refer to things in language, and to engage in complex cognitive processes like imagination and reasoning. How such conceptual memories are encoded in the brain remains unclear. Using functional and structural neuroimaging techniques, I investigated the neural basis of conceptual memory networks in healthy adults and in patients with memory impairments resulting from neurodegenerative disease. I found that conceptual memories are represented in networks of modality-specific and heteromodal association regions of the brain. These findings show that when healthy adults encounter a word, a distributed network of information is activated that includes an integrative heteromodal region in the inferior parietal and lateral temporal cortices and …",https://search.proquest.com/openview/d853c67068cc47140ae54d892f347609/1?pq-origsite=gscholar&cbl=18750
Michael F. Bonner,Music and Semantic Dementia—Reply,2011,Archives of Neurology,0,"Murray Grossman, Michael F Bonner, Jessica Weinstein",Murray Grossman,Jessica Weinstein,3,"The recent study by Weinstein and colleagues1 pro-vides further evidence that semantic memory for music may be relatively spared in semantic dementia (SemD). This issue is both clinically and neurobiologically relevant. Music may be a potential island of meaning in the increasingly meaningless world inhabited by patients with SemD. More fundamentally, the apparent sparing of music knowledge despite a “panmodal” breakdown of sensory and conceptual knowledge is likely to hold a clue to the nature of the core deficit underpinning SemD.We have presented evidence2 that knowledge of melodies and musical notation may be spared in SemD, whereas knowledge of musical instruments and emotions is affected comparably with other knowledge categories. These findings support the interpretation offered by Weinstein and colleagues1 that it appears to be the more abstract aspects of music that are relatively …",https://jamanetwork.com/journals/jamaneurology/article-abstract/1107829
Michael F. Bonner,Error Patterns in the Semantic Judgment Test Differentiate Semantic Dementia from Alzheimer's Disease,2011,NEUROLOGY,0,"Katya Rascovsky, David Libon, Michael Dreyfuss, Corey McMillan, Michael Bonner, Murray Grossman",Katya Rascovsky,Murray Grossman,6,,https://scholar.google.com/scholar?cluster=7910337583700171374&hl=en&oi=scholarr
Michael F. Bonner,Degradation of Lexical Semantic Knowledge in Alzheimer's Disease,2011,NEUROLOGY,0,"Michael Dreyfuss, Peachie Moore, Corey McMillan, Michael Bonner, Lauren Richmond, Edward E Smith, Murray Grossman",Michael Dreyfuss,Murray Grossman,7,,https://scholar.google.com/scholar?cluster=3405763783393269685&hl=en&oi=scholarr
Michael F. Bonner,Insensitive to Hierarchy: ALS and FTD Display Overlapping Executive Impairment,2009,NEUROLOGY,0,"Christine Farag, Leo McCluskey, Lauren Elman, Rachel Goldmann Gross, Michael Bonner, Murray Grossman",Christine Farag,Murray Grossman,6,,https://scholar.google.com/scholar?cluster=9961784139388569384&hl=en&oi=scholarr
Michael F. Bonner,"Regular Articles Pewpan M. Intapan, Wanchai Maleewong. Opisthorchis viverrini: Influence of maternal infection in hamsters on offspring infected with homologous parasite and their IgG antibody response.................... 67 Wulamu Mamuti, Yasuhito Sako, Ning Xiao, Kazuhiro Nakaya, Minoru Nakao, Hiroshi Yamasaki, Marshall",2006,Experimental Parasitology,0,"W Lightowlers, Philip S Craig, Akira Ito, Bin Lu, Shaoting Wu, Yun Shi, Renli Zhang, Lijun Zou, Shitong Gao, Min Lin, Yikai Zhou, BH Welter, RR Powell, RC Laughlin, GC McGugan, M Bonner, A King, LA Temesvari, Joao Luis Garcia, Italmar Teodorico Navarro, Odilon Vidotto, Solange Maria Gennari, Rosângela Zacarias, Hai Long, Xuan Wang, Jian Hua Xu",W Lightowlers,Jian Hua Xu,26,,https://scholar.google.com/scholar?cluster=392228736315896211&hl=en&oi=scholarr
Michael F. Bonner,Representational subspaces with different levels of abstraction in transformers,,,0,"Brian S Robinson, Colin Conwell, Michael F Bonner",Brian S Robinson,Michael F Bonner,3,"A widespread assumption in analyzing the representations of artificial neural networks (ANNs) and the brain is that neurons in the same ANN layer or cortical region have a shared level of abstraction. In this work, by analyzing the learned LayerNorm weights across a range of transformer networks, we find evidence for distinct subspaces in the network dimensions. In an in-depth analysis for a single vision transformer, we find three representational subspaces within each layer that can be identified by LayerNorm weights. In comparisons to human fMRI representations, we find distinct properties of these subspaces with two of the subspaces demonstrating higher representational similarity to early and late regions of the cortical visual hierarchy. These findings show that analyses of hierarchical feature processing in ANNs need to consider the role of subspaces with distinct representational properties.",https://2024.ccneuro.org/pdf/273_Paper_authored_CCN_2024_Hierarchical_Dimensions-Submission-Authors.pdf
Michael F. Bonner,An EEG-fMRI Investigation of the Spatiotemporal Hierarchy of Social Actions,,,0,"Emalie McMahon, Elizabeth Jiwon Im, Michael F Bonner, Leyla Isik",Emalie McMahon,Leyla Isik,4,"Recent work has argued that in addition to the dorsal and ventral visual streams, there is a third visual stream projecting laterally from primary visual cortex to the superior temporal sulcus that is specialized for dynamic social content. A key characteristic of the dorsal and ventral streams is hierarchical computations. To investigate whether the lateral visual stream also has hierarchical computations, we combine the spatial precision of fMRI with the temporal precision of EEG to investigate the direction of information flow through lateral regions of the brain. We find evidence of a temporal and spatial dissociation between features computed early and late in both ventral and lateral regions of the brain providing evidence of hierarchical computations in the lateral visual stream and insight into visual processing of dynamic, social scenes.",https://2024.ccneuro.org/pdf/403_Paper_authored_CCN2024_deanonymized.pdf
Michael F. Bonner,High-dimensional spectrum of reliable individual differences in visual cortex,,,0,"Chihye Han, Michael F Bonner",Chihye Han,Michael F Bonner,2,"Human visual cortex represents sensory stimuli in population codes spanning thousands of latent dimensions. Although the variance along these dimensions is largely shared across individuals, a portion appears to reflect individual differences. We sought to determine if these individual differences are reliable and, if so, across how many dimensions. We examined a large-scale fMRI dataset of movie-viewing and characterized individual differences across the full spectrum of latent dimensions in visual cortex. We detected reliable individual differences spanning the almost entire spectrum of latent dimensions. Comparisons with voxelwise inter-subject correlations showed that our procedure reveals many dimensions of individual differences that are undetectable with conventional voxelwise analyses. Together, these findings reveal the surprisingly high-dimensional nature of individual differences in visual cortex, and they demonstrate an approach for exploring dimensions of individual variability that are unreachable with conventional methods.",https://2024.ccneuro.org/pdf/303_Paper_authored_CCN_2024_Han_authored_final.pdf
Michael F. Bonner,Universality in mouse and human visual cortex: relating covariance to the spatial structure of latent dimensions,,,0,"Raj Magesh Gauthaman, Brice Ménard, Michael F Bonner",Raj Magesh Gauthaman,Michael F Bonner,3,"Recent work has revealed the high-dimensional structure of visual cortex responses to natural images in both mice and humans, where stimulus-related variance is distributed as a power law over thousands of latent dimensions. Here, we characterize the covariance spectra of two datasets containing V1 responses to thousands of visual stimuli measured at two very different scales: mouse calcium imaging and human fMRI. We find that the powerlaw exponent α characterizing the spectral decay varies substantially across experiments, contradicting previous claims of universality and optimality in the power law exponents of visual cortex. However, we also discover a striking pattern where variance along a latent dimension is directly related to its spatial scale–a measure of how strongly neighboring neurons co-activate. When viewed through this lens, the spectra of the mouse and human neural activations show striking similarities, suggesting that both visual systems represent natural images in similar ways. Our results demonstrate that analyzing the spatial scale of latent modes of variation might be a more fundamental way to quantify the covariance structure of neural representations.",https://2024.ccneuro.org/pdf/454_Paper_authored_ccn_authored.pdf
Michael F. Bonner,"Dynamic, social vision highlights gaps between deep learning and human behavior and neural responses",,,0,"Kathy Garcia, Emalie McMahon, Colin Conwell, Michael F Bonner, Leyla Isik",Kathy Garcia,Leyla Isik,5,"To date, deep learning models trained for computer vision tasks are the best models of human vision. This work has largely focused on behavioral and neural responses to static images, but the visual world is highly dynamic, and recent work has suggested that in addition to the ventral visual stream specializing in static object recognition, there is a lateral visual stream that processes dynamic, social content. Here, we investigated the ability of 350+ modern image, video, and language models to predict human ratings of visual-social content of short video clips and neural responses to the same videos. We find that unlike prior benchmarks, even the best imagetrained models do a poor job of explaining human behavioral judgements and neural responses. Language models outperform vision models in predicting behavior but are less effective at modeling neural responses. In early and mid-level lateral visual regions, video-trained models predicted neural responses far better than image-trained models. However, prediction by all models was overall lower in lateral than ventral visual regions of the brain, particularly in the superior temporal sulcus. Together, these results reveal a key gap in modern deep learning models’ ability to match human responses to dynamic visual scenes.",https://2024.ccneuro.org/pdf/417_Paper_authored_Garcia_CCN2024.pdf
Michael F. Bonner,Exploring untrained neural network architectures for modeling higher visual cortex representations,,,0,"Yash Mehta, Atlas Kazemian, Colin Conwell, Michael F Bonner",Yash Mehta,Michael F Bonner,4,"Convolutional neural networks (CNNs) have been widely employed to model the visual cortex, with the prevailing view being that supervised training of these CNNs is crucial for achieving high representational similarity with the visual cortex. We investigate the extent to which untrained neural networks can align with visual features extracted by the brain solely based on the optimization of architectural parameters. Notably, we find that untrained neural networks employing pre-specified wavelets can achieve 95% of the performance of trained AlexNet in the occipital temporal cortex region on human fMRI data. Our results suggest that while supervised training is beneficial, it is not strictly necessary for achieving high brain scores in CNNs. This research opens up new avenues for exploring the relationship between artificial neural networks and the visual cortex, aiming to uncover the shared architectural principles of …",https://scholar.google.com/scholar?cluster=16414100221096213130&hl=en&oi=scholarr
Michael F. Bonner,Accounting for the reliability of deep neural networks in representational modeling,,,0,"Zirui Chen, Michael F Bonner",Zirui Chen,Michael F Bonner,2,"In neuroscience, a critical goal is to develop computational models for explaining cortical responses to sensory stimuli. It has been widely recognized that, when evaluating the similarity between brain and model representations, it is necessary to estimate the noise ceiling of cortical activity measurements. However, one important source of noise that has been neglected is the reliability of the models themselves. For deep neural networks, a natural criterion is the consistency of representations learned across different random initializations. Here we demonstrate how to account for the reliability of both brains and models when assessing their similarity, using a metric called integrated reliability integrated reliability. We used simulated data to validate integrated reliability as a more accurate measure for evaluating the limitations in representational modeling compared with conventional noise ceiling estimates based on brain reliability alone. Furthermore, through analyses on actual neural networks and brain representations, we show that model reliability is a key constraint on representational modeling results in neuroscience. Our findings underscore the need to identify and mitigate model variability for improving computational models of cortical representation.",https://2024.ccneuro.org/pdf/435_Paper_authored_ccn_2024_zchen.pdf
Michael F. Bonner,High-dimensional alignment of neural networks and visual cortex,,,0,"Tailai Shen, Colin Conwell, Michael F Bonner",Tailai Shen,Michael F Bonner,3,"Research into the representational similarity between deep neural networks (DNNs) and the human visual cortex aims to deepen our understanding of both systems. Here we explored the alignment between DNNs and the ventral visual stream by extending conventional representational similarity statistics to a spectrum of similarities across thousands of latent dimensions. The spectrum is generated by computing the correlations between aligned latent dimensions in model and brain representations. Using this approach, we found that DNN layers and regions of visual cortex have shared high-dimensional representations, spanning thousands of dimensions. The dimensionality of these shared representations exhibits an overall decrease from early to late visual regions. However, by separately reducing the channel and spatial dimensions of DNNs, we found that there is a complex relationship between dimensionality and the visual hierarchy. Specifically, in early visual regions, the alignment with DNNs relies heavily on high spatial dimensionality, whereas in late visual regions, it relies heavily on high channel dimensionality. Together, these results demonstrate the potential insights that can be gained by characterizing the full spectrum of high-dimensional alignment between computational models and visual cortex.",https://2024.ccneuro.org/pdf/301_Paper_authored_ccn2024_authored.pdf
Michael F. Bonner,Do We Need Deep Learning? Towards High-Performance Encoding Models of Visual Cortex Using Modules of Canonical Computations,,,0,"Atlas Kazemian, Eric Elmoznino, Michael F Bonner",Atlas Kazemian,Michael F Bonner,3,"The field of computational neuroscience has witnessed a surge of interest in convolutional neural networks (CNNs) trained through deep learning, following the finding that they can recapitulate representations of visual information along the ventral stream. This has led to the routine use of CNNs as standard encoding models of visual cortex, despite limitations such as a large dependency on training data and low interpretability. Here, we propose an alternative approach that addresses such limitations without sacrificing performance. We introduce a family of hand-engineered models based on a module of convolution operations combined with a set of canonical neural computations, resulting in a highperformance model that requires little to no training. We present one such architecture and compare its encoding performance to a standard CNN by linearly mapping each model’s features to fMRI responses. We show that, with no learning involved, the performance of the hand-engineered model competes with the trained CNN for predicting object-evoked and scene-evoked fMRI responses in visual cortex. Our approach opens the possibility of designing high-performance encoding models without relying on deep learning, and it has promise for revealing critical inductive biases and computational efficiencies of visual cortex.",https://2022.ccneuro.org/proceedings/0000362.pdf
Michael F. Bonner,Visual representations derived from multiplicative interactions,,NeurIPS 2020 Workshop SVRHM,0,"Eric Elmoznino, Michael Bonner",Eric Elmoznino,Michael Bonner,2,"Biological sensory systems appear to rely on canonical nonlinear computations that can be readily adapted to a broad range of representational objectives. Here we test the hypothesis that one such computation—multiplicative interaction—is a pervasive nonlinearity that underlies the representational transformations in human vision. We computed local multiplicative interactions of features in several classes of convolutional models and used the resulting representations to predict object-evoked responses in voxelwise models of human fMRI data. We found that multiplicative interactions predicted widespread representations throughout the ventral stream and were competitive with state-of-the-art supervised deep nets. Surprisingly, the performance of multiplicative interactions did not require supervision and could be achieved even with random or hand-engineered convolutional filters. These findings suggest that multiplicative interaction may be a canonical computation for feature transformations in human vision.",https://openreview.net/forum?id=mkdc7hWBas-
Michael F. Bonner,Explaining Scene-selective Visual Areas Using Task-specific Deep Neural Network Representations,,,0,"Kshitij Dwivedi, Michael F Bonner, Gemma Roig",Kshitij Dwivedi,Gemma Roig,3,"Deep neural networks (DNNs) are currently the models that account for higher variance of the responses from the human visual cortex. In this work, we aim to explore the power of DNNs as a tool to gain insights into functions of visual brain areas. Particulary, we focus on scene selective visual areas. We use a set of DNNs trained to perform different visual tasks, comprising 2D, 3D and semantic aspects of scene perception, to explain fMRI responses in early visual cortex (EVC) and scene selective visual areas (OPA, PPA). We find that EVC representation is more similar to early layers of all DNNs and deeper layers of 2D-task DNNs. OPA representation is more similar to deeper layers of 3D DNNs, whereas PPA representation to deeper layers of semantic DNNs. We extend our study to performing searchlight analysis using such task specific DNN representations to generate task-specificity maps of visual cortex, and visualize their overlap with existing ROI parcels. Our findings suggest that DNNs trained on a diverse set of visual task can be used to gain insights into functions of visual cortex. Our approach has the potential to be applied beyond visual areas.",https://pdfs.semanticscholar.org/fe9f/91679a12e4923aabeebd592623652c45ac9d.pdf
Michael F. Bonner,Computational mechanisms underlying fMRI responses to affordance properties in visual scenes,,,0,Submitter Michael Bonner,Submitter Michael Bonner,Submitter Michael Bonner,1,"A central component of spatial navigation is determining where one can move in the immediate environment. In a recent set of fMRI experiments, we found that a region of the human visual system known as the occipital place area (OPA) solves this problem by automatically identifying the navigational affordances of the local scene (Bonner & Epstein, 2017). Based on these results, we hypothesized that affordance identification could be achieved through a series of purely feedforward computations performed on retinal inputs. To test this idea, we examined responses within a biologically inspired convolutional neural network (CNN) with a feedforward architecture that was previously trained for scene categorization (Zhou et al., 2014). We found that the CNN contained information relating to both fMRI responses of the OPA and the navigational affordances of scenes. These representations relied heavily on features from the lower visual field, high-spatial frequencies, and cardinal orientations—consistent with visual biases in the OPA. In summary, we used functional mapping of visual cortex to identify a previously unknown mechanism for encoding the navigational affordances of scenes, and we identified a biologically plausible implementation of this process in a single forward pass through a hierarchical computational model.",https://www2.securecms.com/CCNeuro/docs-0/5914c9a668ed3fdc07e2b86d.pdf
